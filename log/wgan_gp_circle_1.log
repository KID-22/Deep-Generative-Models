nohup: 忽略输入
dataset:circle_1
Epoch[10/50000]
**Train**: G Loss: -23.9965, D Loss: -92.4574
Epoch[10/50000]
**Valid**: G Loss: -24.7129, D Loss: -87.8979
Epoch[20/50000]
**Train**: G Loss: -14.6072, D Loss: -30.3339
Epoch[20/50000]
**Valid**: G Loss: 1.5627, D Loss: -26.2746
Epoch[30/50000]
**Train**: G Loss: -48.3252, D Loss: -1.3939
Epoch[30/50000]
**Valid**: G Loss: -12.7140, D Loss: 2.7116
Epoch[40/50000]
**Train**: G Loss: -17.8611, D Loss: -1.3086
Epoch[40/50000]
**Valid**: G Loss: -15.8091, D Loss: 0.5552
Epoch[50/50000]
**Train**: G Loss: -4.5004, D Loss: -1.1822
Epoch[50/50000]
**Valid**: G Loss: -10.8992, D Loss: 1.2281
Epoch[60/50000]
**Train**: G Loss: -5.0802, D Loss: -1.3195
Epoch[60/50000]
**Valid**: G Loss: 3.7202, D Loss: -1.3281
Epoch[70/50000]
**Train**: G Loss: 6.7878, D Loss: -1.6895
Epoch[70/50000]
**Valid**: G Loss: -2.8330, D Loss: -4.4433
Epoch[80/50000]
**Train**: G Loss: 0.3185, D Loss: -1.7247
Epoch[80/50000]
**Valid**: G Loss: -1.2108, D Loss: -2.2206
Epoch[90/50000]
**Train**: G Loss: 3.0900, D Loss: -1.5465
Epoch[90/50000]
**Valid**: G Loss: 3.5188, D Loss: 1.4426
Epoch[100/50000]
**Train**: G Loss: -12.5049, D Loss: -1.7305
Epoch[100/50000]
**Valid**: G Loss: -17.4402, D Loss: -0.5593
Epoch[110/50000]
**Train**: G Loss: -7.2657, D Loss: -2.2565
Epoch[110/50000]
**Valid**: G Loss: -6.4897, D Loss: 1.6752
Epoch[120/50000]
**Train**: G Loss: 7.1323, D Loss: -0.1892
Epoch[120/50000]
**Valid**: G Loss: -4.5742, D Loss: 1.0201
Epoch[130/50000]
**Train**: G Loss: 4.9965, D Loss: -2.2791
Epoch[130/50000]
**Valid**: G Loss: -21.9501, D Loss: 0.3829
Epoch[140/50000]
**Train**: G Loss: 3.7344, D Loss: -2.7218
Epoch[140/50000]
**Valid**: G Loss: 0.2632, D Loss: -0.5362
Epoch[150/50000]
**Train**: G Loss: 9.5722, D Loss: -1.2579
Epoch[150/50000]
**Valid**: G Loss: 12.1380, D Loss: 1.2508
Epoch[160/50000]
**Train**: G Loss: 63.5586, D Loss: -3.5535
Epoch[160/50000]
**Valid**: G Loss: 47.5248, D Loss: -2.3839
Epoch[170/50000]
**Train**: G Loss: 1.1721, D Loss: -4.6006
Epoch[170/50000]
**Valid**: G Loss: 9.6870, D Loss: -3.6339
Epoch[180/50000]
**Train**: G Loss: 11.2190, D Loss: -4.7885
Epoch[180/50000]
**Valid**: G Loss: -2.2237, D Loss: -3.6793
Epoch[190/50000]
**Train**: G Loss: 7.3281, D Loss: -4.6130
Epoch[190/50000]
**Valid**: G Loss: 14.0191, D Loss: -4.7244
Epoch[200/50000]
**Train**: G Loss: 7.7644, D Loss: -4.4621
Epoch[200/50000]
**Valid**: G Loss: 5.3435, D Loss: -3.7579
Epoch[210/50000]
**Train**: G Loss: 4.1412, D Loss: -4.0858
Epoch[210/50000]
**Valid**: G Loss: -18.2673, D Loss: -3.4169
Epoch[220/50000]
**Train**: G Loss: 11.1996, D Loss: -3.4858
Epoch[220/50000]
**Valid**: G Loss: -21.4642, D Loss: -3.5902
Epoch[230/50000]
**Train**: G Loss: -2.9826, D Loss: -3.7507
Epoch[230/50000]
**Valid**: G Loss: -1.4101, D Loss: -3.5754
Epoch[240/50000]
**Train**: G Loss: 16.8642, D Loss: -4.7875
Epoch[240/50000]
**Valid**: G Loss: 39.2004, D Loss: -4.8036
Epoch[250/50000]
**Train**: G Loss: 14.2357, D Loss: -5.4359
Epoch[250/50000]
**Valid**: G Loss: -1.2679, D Loss: -5.8994
Epoch[260/50000]
**Train**: G Loss: 22.5678, D Loss: -6.4595
Epoch[260/50000]
**Valid**: G Loss: 3.1332, D Loss: -4.1917
Epoch[270/50000]
**Train**: G Loss: 29.1441, D Loss: -6.4119
Epoch[270/50000]
**Valid**: G Loss: 5.0615, D Loss: -7.8379
Epoch[280/50000]
**Train**: G Loss: 43.8735, D Loss: -7.8623
Epoch[280/50000]
**Valid**: G Loss: 37.2394, D Loss: -9.3823
Epoch[290/50000]
**Train**: G Loss: 66.3971, D Loss: -9.1200
Epoch[290/50000]
**Valid**: G Loss: 65.6813, D Loss: -9.9936
Epoch[300/50000]
**Train**: G Loss: 81.9893, D Loss: -13.8504
Epoch[300/50000]
**Valid**: G Loss: 89.3662, D Loss: -14.4532
Epoch[310/50000]
**Train**: G Loss: 120.1561, D Loss: -19.4474
Epoch[310/50000]
**Valid**: G Loss: 146.1774, D Loss: -13.6833
Epoch[320/50000]
**Train**: G Loss: 129.2001, D Loss: -21.2451
Epoch[320/50000]
**Valid**: G Loss: 105.5896, D Loss: -23.0636
Epoch[330/50000]
**Train**: G Loss: 128.7698, D Loss: -22.0767
Epoch[330/50000]
**Valid**: G Loss: 141.0069, D Loss: -24.6879
Epoch[340/50000]
**Train**: G Loss: 119.9096, D Loss: -25.6262
Epoch[340/50000]
**Valid**: G Loss: 128.5990, D Loss: -28.8966
Epoch[350/50000]
**Train**: G Loss: 108.7183, D Loss: -26.3195
Epoch[350/50000]
**Valid**: G Loss: 101.3026, D Loss: -25.6447
Epoch[360/50000]
**Train**: G Loss: 121.9287, D Loss: -25.0956
Epoch[360/50000]
**Valid**: G Loss: 135.5156, D Loss: -18.3764
Epoch[370/50000]
**Train**: G Loss: 111.1609, D Loss: -27.5437
Epoch[370/50000]
**Valid**: G Loss: 103.0213, D Loss: -30.7603
Epoch[380/50000]
**Train**: G Loss: 117.4623, D Loss: -25.9388
Epoch[380/50000]
**Valid**: G Loss: 125.4212, D Loss: -22.5082
Epoch[390/50000]
**Train**: G Loss: 112.1489, D Loss: -26.3282
Epoch[390/50000]
**Valid**: G Loss: 105.8916, D Loss: -22.3414
Epoch[400/50000]
**Train**: G Loss: 112.7221, D Loss: -21.1438
Epoch[400/50000]
**Valid**: G Loss: 102.1173, D Loss: -20.7000
Epoch[410/50000]
**Train**: G Loss: 96.9693, D Loss: -16.5766
Epoch[410/50000]
**Valid**: G Loss: 91.3870, D Loss: -13.4483
Epoch[420/50000]
**Train**: G Loss: 88.7366, D Loss: -10.0026
Epoch[420/50000]
**Valid**: G Loss: 82.5552, D Loss: -9.5567
Epoch[430/50000]
**Train**: G Loss: 110.4010, D Loss: -1.9635
Epoch[430/50000]
**Valid**: G Loss: 157.4974, D Loss: -1.7645
Epoch[440/50000]
**Train**: G Loss: 96.1475, D Loss: -5.7565
Epoch[440/50000]
**Valid**: G Loss: 99.8947, D Loss: -4.5510
Epoch[450/50000]
**Train**: G Loss: 91.5373, D Loss: -4.0610
Epoch[450/50000]
**Valid**: G Loss: 90.1069, D Loss: -3.3669
Epoch[460/50000]
**Train**: G Loss: 87.7793, D Loss: -4.0584
Epoch[460/50000]
**Valid**: G Loss: 83.7475, D Loss: -3.8754
Epoch[470/50000]
**Train**: G Loss: 83.5321, D Loss: -3.7040
Epoch[470/50000]
**Valid**: G Loss: 87.5809, D Loss: -2.9197
Epoch[480/50000]
**Train**: G Loss: 68.3827, D Loss: -3.8032
Epoch[480/50000]
**Valid**: G Loss: 67.1585, D Loss: -3.5997
Epoch[490/50000]
**Train**: G Loss: 70.9535, D Loss: -3.4368
Epoch[490/50000]
**Valid**: G Loss: 63.1164, D Loss: -3.0779
Epoch[500/50000]
**Train**: G Loss: 57.9391, D Loss: -3.7190
Epoch[500/50000]
**Valid**: G Loss: 54.9192, D Loss: -2.4501
Epoch[510/50000]
**Train**: G Loss: 49.8774, D Loss: -3.6030
Epoch[510/50000]
**Valid**: G Loss: 50.7493, D Loss: -2.3005
Epoch[520/50000]
**Train**: G Loss: 41.5015, D Loss: -3.2932
Epoch[520/50000]
**Valid**: G Loss: 55.6546, D Loss: -2.8573
Epoch[530/50000]
**Train**: G Loss: 33.3906, D Loss: -3.6752
Epoch[530/50000]
**Valid**: G Loss: 28.8810, D Loss: -3.6202
Epoch[540/50000]
**Train**: G Loss: 20.8143, D Loss: -3.6252
Epoch[540/50000]
**Valid**: G Loss: 21.1153, D Loss: -2.6374
Epoch[550/50000]
**Train**: G Loss: 13.1780, D Loss: -3.6988
Epoch[550/50000]
**Valid**: G Loss: 14.3824, D Loss: -3.1135
Epoch[560/50000]
**Train**: G Loss: 6.2464, D Loss: -3.5990
Epoch[560/50000]
**Valid**: G Loss: 4.6800, D Loss: -2.6103
Epoch[570/50000]
**Train**: G Loss: 1.1497, D Loss: -3.5709
Epoch[570/50000]
**Valid**: G Loss: -0.5141, D Loss: -2.8897
Epoch[580/50000]
**Train**: G Loss: -7.4157, D Loss: -3.5313
Epoch[580/50000]
**Valid**: G Loss: -11.6530, D Loss: -3.3492
Epoch[590/50000]
**Train**: G Loss: -14.5064, D Loss: -3.5777
Epoch[590/50000]
**Valid**: G Loss: -19.9243, D Loss: -3.5651
Epoch[600/50000]
**Train**: G Loss: -24.9556, D Loss: -3.5098
Epoch[600/50000]
**Valid**: G Loss: -27.3134, D Loss: -3.2944
Epoch[610/50000]
**Train**: G Loss: -26.2393, D Loss: -3.4888
Epoch[610/50000]
**Valid**: G Loss: -27.4964, D Loss: -3.0971
Epoch[620/50000]
**Train**: G Loss: -23.4995, D Loss: -3.4490
Epoch[620/50000]
**Valid**: G Loss: -20.2399, D Loss: -2.4290
Epoch[630/50000]
**Train**: G Loss: -21.8408, D Loss: -3.5393
Epoch[630/50000]
**Valid**: G Loss: -17.6222, D Loss: -2.3550
Epoch[640/50000]
**Train**: G Loss: -26.0921, D Loss: -3.3226
Epoch[640/50000]
**Valid**: G Loss: -32.3272, D Loss: -3.0167
Epoch[650/50000]
**Train**: G Loss: -20.5530, D Loss: -3.4135
Epoch[650/50000]
**Valid**: G Loss: -11.6963, D Loss: -2.6261
Epoch[660/50000]
**Train**: G Loss: -18.7319, D Loss: -3.3269
Epoch[660/50000]
**Valid**: G Loss: -21.9179, D Loss: -3.1240
Epoch[670/50000]
**Train**: G Loss: -18.9539, D Loss: -3.4650
Epoch[670/50000]
**Valid**: G Loss: -21.5031, D Loss: -2.5265
Epoch[680/50000]
**Train**: G Loss: -18.9151, D Loss: -3.2501
Epoch[680/50000]
**Valid**: G Loss: -20.8961, D Loss: -2.9636
Epoch[690/50000]
**Train**: G Loss: -20.5314, D Loss: -3.3313
Epoch[690/50000]
**Valid**: G Loss: -24.4183, D Loss: -3.2556
Epoch[700/50000]
**Train**: G Loss: -20.0704, D Loss: -3.3529
Epoch[700/50000]
**Valid**: G Loss: -12.8432, D Loss: -2.5915
Epoch[710/50000]
**Train**: G Loss: -17.0604, D Loss: -3.4096
Epoch[710/50000]
**Valid**: G Loss: -22.2179, D Loss: -2.4602
Epoch[720/50000]
**Train**: G Loss: -15.8067, D Loss: -3.1866
Epoch[720/50000]
**Valid**: G Loss: -12.1735, D Loss: -3.0176
Epoch[730/50000]
**Train**: G Loss: -12.1174, D Loss: -3.2362
Epoch[730/50000]
**Valid**: G Loss: -12.7340, D Loss: -3.1505
Epoch[740/50000]
**Train**: G Loss: -9.6023, D Loss: -3.2427
Epoch[740/50000]
**Valid**: G Loss: 1.7907, D Loss: -2.8977
Epoch[750/50000]
**Train**: G Loss: -11.3026, D Loss: -3.2385
Epoch[750/50000]
**Valid**: G Loss: -1.1096, D Loss: -2.8674
Epoch[760/50000]
**Train**: G Loss: -12.6315, D Loss: -3.1937
Epoch[760/50000]
**Valid**: G Loss: -18.3591, D Loss: -3.0001
Epoch[770/50000]
**Train**: G Loss: -7.5237, D Loss: -3.1352
Epoch[770/50000]
**Valid**: G Loss: -29.0980, D Loss: -2.7154
Epoch[780/50000]
**Train**: G Loss: -7.5133, D Loss: -3.2812
Epoch[780/50000]
**Valid**: G Loss: -3.2796, D Loss: -2.6050
Epoch[790/50000]
**Train**: G Loss: -4.8620, D Loss: -3.3182
Epoch[790/50000]
**Valid**: G Loss: 30.4286, D Loss: -2.5063
Epoch[800/50000]
**Train**: G Loss: -8.1345, D Loss: -3.5132
Epoch[800/50000]
**Valid**: G Loss: -40.4873, D Loss: -0.4865
Epoch[810/50000]
**Train**: G Loss: -5.9443, D Loss: -3.5960
Epoch[810/50000]
**Valid**: G Loss: -33.0797, D Loss: 0.0772
Epoch[820/50000]
**Train**: G Loss: -11.2875, D Loss: -3.6253
Epoch[820/50000]
**Valid**: G Loss: 49.7160, D Loss: -5.5390
Epoch[830/50000]
**Train**: G Loss: -10.0554, D Loss: -3.6749
Epoch[830/50000]
**Valid**: G Loss: 52.9463, D Loss: -4.7142
Epoch[840/50000]
**Train**: G Loss: -12.2868, D Loss: -3.4403
Epoch[840/50000]
**Valid**: G Loss: -27.6151, D Loss: -0.7568
Epoch[850/50000]
**Train**: G Loss: 40.4684, D Loss: -2.7145
Epoch[850/50000]
**Valid**: G Loss: 0.1871, D Loss: -3.1533
Epoch[860/50000]
**Train**: G Loss: -22.1913, D Loss: -3.3501
Epoch[860/50000]
**Valid**: G Loss: -8.7214, D Loss: -1.5379
Epoch[870/50000]
**Train**: G Loss: 32.6284, D Loss: -3.3657
Epoch[870/50000]
**Valid**: G Loss: 47.1057, D Loss: 0.4009
Epoch[880/50000]
**Train**: G Loss: -7.4738, D Loss: -3.2585
Epoch[880/50000]
**Valid**: G Loss: -22.1657, D Loss: -1.2718
Epoch[890/50000]
**Train**: G Loss: 2.5133, D Loss: -3.4011
Epoch[890/50000]
**Valid**: G Loss: 50.1166, D Loss: -4.3283
Epoch[900/50000]
**Train**: G Loss: 11.2958, D Loss: -3.3897
Epoch[900/50000]
**Valid**: G Loss: -29.0840, D Loss: -3.2840
Epoch[910/50000]
**Train**: G Loss: 23.0969, D Loss: -3.0234
Epoch[910/50000]
**Valid**: G Loss: 55.2310, D Loss: -1.0169
Epoch[920/50000]
**Train**: G Loss: -5.6363, D Loss: -3.4966
Epoch[920/50000]
**Valid**: G Loss: 20.4243, D Loss: -2.6672
Epoch[930/50000]
**Train**: G Loss: 21.3304, D Loss: -3.3521
Epoch[930/50000]
**Valid**: G Loss: -19.1058, D Loss: -2.4535
Epoch[940/50000]
**Train**: G Loss: 18.5059, D Loss: -3.2382
Epoch[940/50000]
**Valid**: G Loss: -12.6771, D Loss: -3.6622
Epoch[950/50000]
**Train**: G Loss: 19.2814, D Loss: -3.1113
Epoch[950/50000]
**Valid**: G Loss: 4.4837, D Loss: -2.9163
Epoch[960/50000]
**Train**: G Loss: 12.0653, D Loss: -3.0301
Epoch[960/50000]
**Valid**: G Loss: 15.3015, D Loss: -2.8051
Epoch[970/50000]
**Train**: G Loss: 6.9826, D Loss: -3.0977
Epoch[970/50000]
**Valid**: G Loss: 10.0652, D Loss: -2.8825
Epoch[980/50000]
**Train**: G Loss: 3.3526, D Loss: -3.3702
Epoch[980/50000]
**Valid**: G Loss: 1.3879, D Loss: -3.2084
Epoch[990/50000]
**Train**: G Loss: -5.7696, D Loss: -3.1167
Epoch[990/50000]
**Valid**: G Loss: -7.2882, D Loss: -2.9222
Epoch[1000/50000]
**Train**: G Loss: -4.3058, D Loss: -3.1552
Epoch[1000/50000]
**Valid**: G Loss: -9.6259, D Loss: -1.3472
Epoch[1010/50000]
**Train**: G Loss: -7.8720, D Loss: -3.1367
Epoch[1010/50000]
**Valid**: G Loss: -10.5597, D Loss: -2.7487
Epoch[1020/50000]
**Train**: G Loss: -6.1647, D Loss: -3.0595
Epoch[1020/50000]
**Valid**: G Loss: -4.1744, D Loss: -2.7118
Epoch[1030/50000]
**Train**: G Loss: -8.3534, D Loss: -3.1275
Epoch[1030/50000]
**Valid**: G Loss: -8.7935, D Loss: -2.1385
Epoch[1040/50000]
**Train**: G Loss: -7.2842, D Loss: -3.0162
Epoch[1040/50000]
**Valid**: G Loss: -10.3355, D Loss: -2.7913
Epoch[1050/50000]
**Train**: G Loss: -8.9850, D Loss: -3.0190
Epoch[1050/50000]
**Valid**: G Loss: -3.2059, D Loss: -2.9332
Epoch[1060/50000]
**Train**: G Loss: -4.7615, D Loss: -2.9836
Epoch[1060/50000]
**Valid**: G Loss: -6.3552, D Loss: -2.5062
Epoch[1070/50000]
**Train**: G Loss: -6.6645, D Loss: -2.8717
Epoch[1070/50000]
**Valid**: G Loss: -16.9639, D Loss: -2.7792
Epoch[1080/50000]
**Train**: G Loss: 2.5297, D Loss: -2.9719
Epoch[1080/50000]
**Valid**: G Loss: 7.3454, D Loss: -2.3903
Epoch[1090/50000]
**Train**: G Loss: -3.9519, D Loss: -2.9317
Epoch[1090/50000]
**Valid**: G Loss: -15.9399, D Loss: -2.4748
Epoch[1100/50000]
**Train**: G Loss: -14.0276, D Loss: -2.9313
Epoch[1100/50000]
**Valid**: G Loss: -11.2442, D Loss: -0.6459
Epoch[1110/50000]
**Train**: G Loss: 6.8061, D Loss: -3.4953
Epoch[1110/50000]
**Valid**: G Loss: 40.4127, D Loss: -1.5786
Epoch[1120/50000]
**Train**: G Loss: 29.9325, D Loss: -2.9067
Epoch[1120/50000]
**Valid**: G Loss: 0.4043, D Loss: -2.1565
Epoch[1130/50000]
**Train**: G Loss: -9.5510, D Loss: -3.6664
Epoch[1130/50000]
**Valid**: G Loss: 37.5176, D Loss: -2.9723
Epoch[1140/50000]
**Train**: G Loss: 51.3052, D Loss: -2.8172
Epoch[1140/50000]
**Valid**: G Loss: -12.0273, D Loss: -5.2154
Epoch[1150/50000]
**Train**: G Loss: -0.3243, D Loss: -3.1315
Epoch[1150/50000]
**Valid**: G Loss: -24.8069, D Loss: -1.1958
Epoch[1160/50000]
**Train**: G Loss: 27.7001, D Loss: -2.9860
Epoch[1160/50000]
**Valid**: G Loss: 43.8132, D Loss: -0.3622
Epoch[1170/50000]
**Train**: G Loss: 17.2624, D Loss: -3.1070
Epoch[1170/50000]
**Valid**: G Loss: -27.1603, D Loss: -4.0186
Epoch[1180/50000]
**Train**: G Loss: 0.8547, D Loss: -3.3517
Epoch[1180/50000]
**Valid**: G Loss: 49.8980, D Loss: -1.2898
Epoch[1190/50000]
**Train**: G Loss: 3.8180, D Loss: -3.0922
Epoch[1190/50000]
**Valid**: G Loss: -25.0718, D Loss: -1.2057
Epoch[1200/50000]
**Train**: G Loss: 5.2348, D Loss: -3.2645
Epoch[1200/50000]
**Valid**: G Loss: 44.2483, D Loss: -2.6036
Epoch[1210/50000]
**Train**: G Loss: 51.5851, D Loss: -2.7811
Epoch[1210/50000]
**Valid**: G Loss: -10.8681, D Loss: -4.5993
Epoch[1220/50000]
**Train**: G Loss: -0.1950, D Loss: -2.9291
Epoch[1220/50000]
**Valid**: G Loss: 6.1088, D Loss: -2.2165
Epoch[1230/50000]
**Train**: G Loss: 30.7695, D Loss: -2.7303
Epoch[1230/50000]
**Valid**: G Loss: 12.0552, D Loss: -2.4990
Epoch[1240/50000]
**Train**: G Loss: -3.3064, D Loss: -3.2002
Epoch[1240/50000]
**Valid**: G Loss: 14.0971, D Loss: -2.0319
Epoch[1250/50000]
**Train**: G Loss: 52.1619, D Loss: -2.2187
Epoch[1250/50000]
**Valid**: G Loss: 13.1924, D Loss: -3.4628
Epoch[1260/50000]
**Train**: G Loss: 1.4489, D Loss: -3.0273
Epoch[1260/50000]
**Valid**: G Loss: 25.9953, D Loss: -3.0819
Epoch[1270/50000]
**Train**: G Loss: 8.1939, D Loss: -2.9145
Epoch[1270/50000]
**Valid**: G Loss: -7.1886, D Loss: -1.5950
Epoch[1280/50000]
**Train**: G Loss: 22.5815, D Loss: -2.8355
Epoch[1280/50000]
**Valid**: G Loss: 0.4873, D Loss: -3.3910
Epoch[1290/50000]
**Train**: G Loss: 45.7791, D Loss: -2.8663
Epoch[1290/50000]
**Valid**: G Loss: -15.8429, D Loss: -3.2844
Epoch[1300/50000]
**Train**: G Loss: 33.6029, D Loss: -2.9285
Epoch[1300/50000]
**Valid**: G Loss: 57.1392, D Loss: 0.3030
Epoch[1310/50000]
**Train**: G Loss: 22.6490, D Loss: -2.6737
Epoch[1310/50000]
**Valid**: G Loss: 28.7987, D Loss: -1.6946
Epoch[1320/50000]
**Train**: G Loss: 37.0844, D Loss: -2.5377
Epoch[1320/50000]
**Valid**: G Loss: 43.5793, D Loss: -1.2016
Epoch[1330/50000]
**Train**: G Loss: 31.7135, D Loss: -2.5691
Epoch[1330/50000]
**Valid**: G Loss: 25.1042, D Loss: -2.0531
Epoch[1340/50000]
**Train**: G Loss: 15.5977, D Loss: -2.6716
Epoch[1340/50000]
**Valid**: G Loss: 14.3540, D Loss: -2.4257
Epoch[1350/50000]
**Train**: G Loss: 10.5721, D Loss: -2.7485
Epoch[1350/50000]
**Valid**: G Loss: 8.9696, D Loss: -2.5027
Epoch[1360/50000]
**Train**: G Loss: 9.2642, D Loss: -2.6648
Epoch[1360/50000]
**Valid**: G Loss: 7.5991, D Loss: -2.1459
Epoch[1370/50000]
**Train**: G Loss: 7.5059, D Loss: -2.6706
Epoch[1370/50000]
**Valid**: G Loss: 10.0797, D Loss: -2.1534
Epoch[1380/50000]
**Train**: G Loss: 3.0044, D Loss: -2.6052
Epoch[1380/50000]
**Valid**: G Loss: 1.0282, D Loss: -2.5910
Epoch[1390/50000]
**Train**: G Loss: 1.5142, D Loss: -2.6479
Epoch[1390/50000]
**Valid**: G Loss: 1.1380, D Loss: -2.3005
Epoch[1400/50000]
**Train**: G Loss: 1.2157, D Loss: -2.5084
Epoch[1400/50000]
**Valid**: G Loss: -0.6127, D Loss: -2.6324
Epoch[1410/50000]
**Train**: G Loss: 0.7202, D Loss: -2.5216
Epoch[1410/50000]
**Valid**: G Loss: 9.7187, D Loss: -2.4671
Epoch[1420/50000]
**Train**: G Loss: 0.2734, D Loss: -2.5675
Epoch[1420/50000]
**Valid**: G Loss: -2.5159, D Loss: -2.3985
Epoch[1430/50000]
**Train**: G Loss: 2.2621, D Loss: -2.4798
Epoch[1430/50000]
**Valid**: G Loss: 4.2950, D Loss: -2.1842
Epoch[1440/50000]
**Train**: G Loss: 6.4067, D Loss: -2.5511
Epoch[1440/50000]
**Valid**: G Loss: 12.1977, D Loss: -1.7985
Epoch[1450/50000]
**Train**: G Loss: 3.8005, D Loss: -2.4820
Epoch[1450/50000]
**Valid**: G Loss: -2.0507, D Loss: -2.2021
Epoch[1460/50000]
**Train**: G Loss: 0.6631, D Loss: -2.4065
Epoch[1460/50000]
**Valid**: G Loss: 1.8911, D Loss: -2.2006
Epoch[1470/50000]
**Train**: G Loss: 11.9854, D Loss: -2.4368
Epoch[1470/50000]
**Valid**: G Loss: -2.6472, D Loss: -1.8316
Epoch[1480/50000]
**Train**: G Loss: 8.3219, D Loss: -3.1517
Epoch[1480/50000]
**Valid**: G Loss: -39.5729, D Loss: -0.0483
Epoch[1490/50000]
**Train**: G Loss: -9.9412, D Loss: -2.3905
Epoch[1490/50000]
**Valid**: G Loss: -16.6845, D Loss: -0.1629
Epoch[1500/50000]
**Train**: G Loss: 11.3511, D Loss: -3.0491
Epoch[1500/50000]
**Valid**: G Loss: -30.4312, D Loss: -1.7702
Epoch[1510/50000]
**Train**: G Loss: 62.5112, D Loss: -1.9904
Epoch[1510/50000]
**Valid**: G Loss: 42.2576, D Loss: -0.6319
Epoch[1520/50000]
**Train**: G Loss: -10.8820, D Loss: -2.7375
Epoch[1520/50000]
**Valid**: G Loss: -0.7258, D Loss: -0.0348
Epoch[1530/50000]
**Train**: G Loss: 37.5812, D Loss: -2.5002
Epoch[1530/50000]
**Valid**: G Loss: 78.2527, D Loss: -0.6202
Epoch[1540/50000]
**Train**: G Loss: 46.9829, D Loss: -2.4792
Epoch[1540/50000]
**Valid**: G Loss: -3.4253, D Loss: -3.9062
Epoch[1550/50000]
**Train**: G Loss: 34.3375, D Loss: -2.8305
Epoch[1550/50000]
**Valid**: G Loss: -32.1315, D Loss: -3.9336
Epoch[1560/50000]
**Train**: G Loss: 37.1172, D Loss: -2.6474
Epoch[1560/50000]
**Valid**: G Loss: -25.9510, D Loss: -4.2469
Epoch[1570/50000]
**Train**: G Loss: 8.1419, D Loss: -2.6591
Epoch[1570/50000]
**Valid**: G Loss: -33.9858, D Loss: -1.5222
Epoch[1580/50000]
**Train**: G Loss: 49.3721, D Loss: -2.3455
Epoch[1580/50000]
**Valid**: G Loss: -7.0079, D Loss: -4.2281
Epoch[1590/50000]
**Train**: G Loss: 51.6705, D Loss: -2.4444
Epoch[1590/50000]
**Valid**: G Loss: 44.4569, D Loss: 0.2152
Epoch[1600/50000]
**Train**: G Loss: 34.9359, D Loss: -2.2937
Epoch[1600/50000]
**Valid**: G Loss: 89.5787, D Loss: -2.1467
Epoch[1610/50000]
**Train**: G Loss: 20.2398, D Loss: -2.3275
Epoch[1610/50000]
**Valid**: G Loss: 80.5820, D Loss: -3.1453
Epoch[1620/50000]
**Train**: G Loss: -1.6406, D Loss: -2.7129
Epoch[1620/50000]
**Valid**: G Loss: 2.2412, D Loss: -0.6006
Epoch[1630/50000]
**Train**: G Loss: 34.8561, D Loss: -2.4873
Epoch[1630/50000]
**Valid**: G Loss: -15.4027, D Loss: -3.7542
Epoch[1640/50000]
**Train**: G Loss: 50.3965, D Loss: -2.3889
Epoch[1640/50000]
**Valid**: G Loss: -8.1219, D Loss: -3.7207
Epoch[1650/50000]
**Train**: G Loss: 39.1004, D Loss: -2.1860
Epoch[1650/50000]
**Valid**: G Loss: 17.9907, D Loss: -1.8475
Epoch[1660/50000]
**Train**: G Loss: 63.6334, D Loss: -2.0694
Epoch[1660/50000]
**Valid**: G Loss: 54.1703, D Loss: 0.7689
Epoch[1670/50000]
**Train**: G Loss: 61.1191, D Loss: -1.9264
Epoch[1670/50000]
**Valid**: G Loss: 53.8588, D Loss: -0.3842
Epoch[1680/50000]
**Train**: G Loss: 29.4948, D Loss: -2.0560
Epoch[1680/50000]
**Valid**: G Loss: 12.3048, D Loss: -1.9551
Epoch[1690/50000]
**Train**: G Loss: 31.5727, D Loss: -2.2793
Epoch[1690/50000]
**Valid**: G Loss: -11.2671, D Loss: -3.8857
Epoch[1700/50000]
**Train**: G Loss: 11.8251, D Loss: -2.4294
Epoch[1700/50000]
**Valid**: G Loss: -19.9930, D Loss: -1.9275
Epoch[1710/50000]
**Train**: G Loss: -6.2126, D Loss: -2.4089
Epoch[1710/50000]
**Valid**: G Loss: 9.3516, D Loss: -0.8913
Epoch[1720/50000]
**Train**: G Loss: 0.6687, D Loss: -2.2757
Epoch[1720/50000]
**Valid**: G Loss: -4.3320, D Loss: -0.6763
Epoch[1730/50000]
**Train**: G Loss: -1.5963, D Loss: -2.3155
Epoch[1730/50000]
**Valid**: G Loss: 10.8481, D Loss: -1.3386
Epoch[1740/50000]
**Train**: G Loss: 0.1876, D Loss: -2.3796
Epoch[1740/50000]
**Valid**: G Loss: 34.7958, D Loss: -1.7346
Epoch[1750/50000]
**Train**: G Loss: 17.3605, D Loss: -2.2661
Epoch[1750/50000]
**Valid**: G Loss: 51.5592, D Loss: -1.0493
Epoch[1760/50000]
**Train**: G Loss: 49.5293, D Loss: -1.9864
Epoch[1760/50000]
**Valid**: G Loss: 57.7207, D Loss: 0.3010
Epoch[1770/50000]
**Train**: G Loss: 68.0998, D Loss: -1.6924
Epoch[1770/50000]
**Valid**: G Loss: 40.7695, D Loss: -0.6565
Epoch[1780/50000]
**Train**: G Loss: 25.9386, D Loss: -2.1137
Epoch[1780/50000]
**Valid**: G Loss: -15.5920, D Loss: -2.9724
Epoch[1790/50000]
**Train**: G Loss: 25.4859, D Loss: -2.1438
Epoch[1790/50000]
**Valid**: G Loss: -9.4838, D Loss: -2.7958
Epoch[1800/50000]
**Train**: G Loss: 53.9506, D Loss: -2.2081
Epoch[1800/50000]
**Valid**: G Loss: -11.1943, D Loss: -3.5354
Epoch[1810/50000]
**Train**: G Loss: 40.3629, D Loss: -1.8584
Epoch[1810/50000]
**Valid**: G Loss: 37.1474, D Loss: -0.4014
Epoch[1820/50000]
**Train**: G Loss: 20.5945, D Loss: -2.0173
Epoch[1820/50000]
**Valid**: G Loss: 3.6557, D Loss: -2.0603
Epoch[1830/50000]
**Train**: G Loss: 25.5167, D Loss: -2.0075
Epoch[1830/50000]
**Valid**: G Loss: 85.8761, D Loss: -3.0629
Epoch[1840/50000]
**Train**: G Loss: 50.3605, D Loss: -1.5258
Epoch[1840/50000]
**Valid**: G Loss: 39.3826, D Loss: -0.7061
Epoch[1850/50000]
**Train**: G Loss: 22.0189, D Loss: -1.8908
Epoch[1850/50000]
**Valid**: G Loss: 24.4478, D Loss: -1.1608
Epoch[1860/50000]
**Train**: G Loss: 17.3265, D Loss: -1.8621
Epoch[1860/50000]
**Valid**: G Loss: 18.7666, D Loss: -1.6078
Epoch[1870/50000]
**Train**: G Loss: 18.8997, D Loss: -1.8812
Epoch[1870/50000]
**Valid**: G Loss: 17.4009, D Loss: -1.6425
Epoch[1880/50000]
**Train**: G Loss: 22.8466, D Loss: -1.7238
Epoch[1880/50000]
**Valid**: G Loss: 37.9910, D Loss: -1.9513
Epoch[1890/50000]
**Train**: G Loss: 14.0143, D Loss: -1.8023
Epoch[1890/50000]
**Valid**: G Loss: 13.7637, D Loss: -1.7026
Epoch[1900/50000]
**Train**: G Loss: 10.0501, D Loss: -1.8577
Epoch[1900/50000]
**Valid**: G Loss: 9.0317, D Loss: -1.4816
Epoch[1910/50000]
**Train**: G Loss: 10.7189, D Loss: -1.8395
Epoch[1910/50000]
**Valid**: G Loss: 4.8887, D Loss: -1.4755
Epoch[1920/50000]
**Train**: G Loss: 9.5533, D Loss: -1.7716
Epoch[1920/50000]
**Valid**: G Loss: 9.3543, D Loss: -1.5882
Epoch[1930/50000]
**Train**: G Loss: 8.4660, D Loss: -1.7590
Epoch[1930/50000]
**Valid**: G Loss: 5.5643, D Loss: -1.6572
Epoch[1940/50000]
**Train**: G Loss: 10.3210, D Loss: -1.6255
Epoch[1940/50000]
**Valid**: G Loss: 9.5007, D Loss: -1.5976
Epoch[1950/50000]
**Train**: G Loss: 12.4759, D Loss: -1.6897
Epoch[1950/50000]
**Valid**: G Loss: 12.9799, D Loss: -1.4221
Epoch[1960/50000]
**Train**: G Loss: 9.3666, D Loss: -1.7355
Epoch[1960/50000]
**Valid**: G Loss: 9.5344, D Loss: -1.3216
Epoch[1970/50000]
**Train**: G Loss: 10.5252, D Loss: -1.7057
Epoch[1970/50000]
**Valid**: G Loss: 8.1952, D Loss: -1.6496
Epoch[1980/50000]
**Train**: G Loss: 8.5705, D Loss: -1.6551
Epoch[1980/50000]
**Valid**: G Loss: 11.1079, D Loss: -1.5790
Epoch[1990/50000]
**Train**: G Loss: 12.0009, D Loss: -1.7795
Epoch[1990/50000]
**Valid**: G Loss: 22.3541, D Loss: -0.1497
Epoch[2000/50000]
**Train**: G Loss: 13.5566, D Loss: -1.7219
Epoch[2000/50000]
**Valid**: G Loss: 3.8441, D Loss: -1.4229
Epoch[2010/50000]
**Train**: G Loss: 36.1099, D Loss: -2.0865
Epoch[2010/50000]
**Valid**: G Loss: 130.7253, D Loss: -0.2370
Epoch[2020/50000]
**Train**: G Loss: 16.5062, D Loss: -2.0814
Epoch[2020/50000]
**Valid**: G Loss: 100.6549, D Loss: -1.6104
Epoch[2030/50000]
**Train**: G Loss: 22.8691, D Loss: -2.1701
Epoch[2030/50000]
**Valid**: G Loss: -47.3046, D Loss: -2.8033
Epoch[2040/50000]
**Train**: G Loss: -11.9664, D Loss: -1.6231
Epoch[2040/50000]
**Valid**: G Loss: 22.5529, D Loss: -1.1866
Epoch[2050/50000]
**Train**: G Loss: 12.8894, D Loss: -1.7712
Epoch[2050/50000]
**Valid**: G Loss: 70.7510, D Loss: -2.9249
Epoch[2060/50000]
**Train**: G Loss: 56.4579, D Loss: -1.3663
Epoch[2060/50000]
**Valid**: G Loss: 22.6070, D Loss: -0.8394
Epoch[2070/50000]
**Train**: G Loss: 52.2715, D Loss: -2.2163
Epoch[2070/50000]
**Valid**: G Loss: -35.9424, D Loss: -3.6510
Epoch[2080/50000]
**Train**: G Loss: 21.6964, D Loss: -1.9759
Epoch[2080/50000]
**Valid**: G Loss: -25.6234, D Loss: -2.2585
Epoch[2090/50000]
**Train**: G Loss: 3.3268, D Loss: -1.9807
Epoch[2090/50000]
**Valid**: G Loss: 1.3503, D Loss: 0.4157
Epoch[2100/50000]
**Train**: G Loss: -7.8191, D Loss: -1.9256
Epoch[2100/50000]
**Valid**: G Loss: 2.9261, D Loss: -0.0320
Epoch[2110/50000]
**Train**: G Loss: -8.9580, D Loss: -1.9427
Epoch[2110/50000]
**Valid**: G Loss: -2.1106, D Loss: 0.0867
Epoch[2120/50000]
**Train**: G Loss: 13.4554, D Loss: -1.7614
Epoch[2120/50000]
**Valid**: G Loss: 49.9552, D Loss: -2.7374
Epoch[2130/50000]
**Train**: G Loss: 50.1741, D Loss: -1.2342
Epoch[2130/50000]
**Valid**: G Loss: 85.4716, D Loss: 0.2643
Epoch[2140/50000]
**Train**: G Loss: 41.3376, D Loss: -1.1679
Epoch[2140/50000]
**Valid**: G Loss: 21.2069, D Loss: -2.2636
Epoch[2150/50000]
**Train**: G Loss: 26.8584, D Loss: -1.7460
Epoch[2150/50000]
**Valid**: G Loss: -11.5512, D Loss: -1.3204
Epoch[2160/50000]
**Train**: G Loss: 6.0973, D Loss: -1.7941
Epoch[2160/50000]
**Valid**: G Loss: 3.7959, D Loss: 0.1478
Epoch[2170/50000]
**Train**: G Loss: 19.7473, D Loss: -1.3427
Epoch[2170/50000]
**Valid**: G Loss: 13.4725, D Loss: -1.6512
Epoch[2180/50000]
**Train**: G Loss: 18.6600, D Loss: -1.4815
Epoch[2180/50000]
**Valid**: G Loss: 19.7946, D Loss: -1.2652
Epoch[2190/50000]
**Train**: G Loss: 18.1034, D Loss: -1.3210
Epoch[2190/50000]
**Valid**: G Loss: 18.9965, D Loss: -1.1356
Epoch[2200/50000]
**Train**: G Loss: 14.2230, D Loss: -1.4258
Epoch[2200/50000]
**Valid**: G Loss: 17.9008, D Loss: -1.0106
Epoch[2210/50000]
**Train**: G Loss: 8.7019, D Loss: -1.2976
Epoch[2210/50000]
**Valid**: G Loss: 6.6927, D Loss: -1.5024
Epoch[2220/50000]
**Train**: G Loss: 7.5622, D Loss: -1.1800
Epoch[2220/50000]
**Valid**: G Loss: 23.2995, D Loss: -0.6563
Epoch[2230/50000]
**Train**: G Loss: 59.5499, D Loss: -1.3220
Epoch[2230/50000]
**Valid**: G Loss: 52.6626, D Loss: 2.1300
Epoch[2240/50000]
**Train**: G Loss: 49.2810, D Loss: -1.5742
Epoch[2240/50000]
**Valid**: G Loss: -15.2642, D Loss: -4.1657
Epoch[2250/50000]
**Train**: G Loss: 2.0008, D Loss: -1.5079
Epoch[2250/50000]
**Valid**: G Loss: -21.7855, D Loss: -0.5698
Epoch[2260/50000]
**Train**: G Loss: 42.2255, D Loss: -1.6380
Epoch[2260/50000]
**Valid**: G Loss: 7.6620, D Loss: -2.0094
Epoch[2270/50000]
**Train**: G Loss: 65.9262, D Loss: -1.1549
Epoch[2270/50000]
**Valid**: G Loss: 7.3967, D Loss: -2.7854
Epoch[2280/50000]
**Train**: G Loss: 41.3291, D Loss: -1.1517
Epoch[2280/50000]
**Valid**: G Loss: 52.3596, D Loss: 1.1295
Epoch[2290/50000]
**Train**: G Loss: 21.3298, D Loss: -1.3389
Epoch[2290/50000]
**Valid**: G Loss: 32.9471, D Loss: 0.5582
Epoch[2300/50000]
**Train**: G Loss: 7.6414, D Loss: -1.3079
Epoch[2300/50000]
**Valid**: G Loss: 1.1517, D Loss: -0.7373
Epoch[2310/50000]
**Train**: G Loss: 19.0834, D Loss: -1.2690
Epoch[2310/50000]
**Valid**: G Loss: 24.0157, D Loss: -0.7148
Epoch[2320/50000]
**Train**: G Loss: 17.9960, D Loss: -1.3235
Epoch[2320/50000]
**Valid**: G Loss: 11.2565, D Loss: -0.3897
Epoch[2330/50000]
**Train**: G Loss: 10.2251, D Loss: -1.4492
Epoch[2330/50000]
**Valid**: G Loss: 1.4587, D Loss: -0.0169
Epoch[2340/50000]
**Train**: G Loss: 23.2546, D Loss: -1.5670
Epoch[2340/50000]
**Valid**: G Loss: -0.1795, D Loss: -1.0479
Epoch[2350/50000]
**Train**: G Loss: 39.0286, D Loss: -1.1393
Epoch[2350/50000]
**Valid**: G Loss: -30.5439, D Loss: -4.0013
Epoch[2360/50000]
**Train**: G Loss: 73.7941, D Loss: -1.3264
Epoch[2360/50000]
**Valid**: G Loss: 11.4531, D Loss: -2.7642
Epoch[2370/50000]
**Train**: G Loss: 79.1237, D Loss: -1.2461
Epoch[2370/50000]
**Valid**: G Loss: 7.3812, D Loss: -3.0214
Epoch[2380/50000]
**Train**: G Loss: 13.9989, D Loss: -1.5396
Epoch[2380/50000]
**Valid**: G Loss: 3.0854, D Loss: 0.6269
Epoch[2390/50000]
**Train**: G Loss: 59.3484, D Loss: -1.3284
Epoch[2390/50000]
**Valid**: G Loss: -21.0995, D Loss: -3.8396
Epoch[2400/50000]
**Train**: G Loss: 31.9443, D Loss: -1.1836
Epoch[2400/50000]
**Valid**: G Loss: 9.5600, D Loss: -0.9827
Epoch[2410/50000]
**Train**: G Loss: 7.6237, D Loss: -1.1874
Epoch[2410/50000]
**Valid**: G Loss: 54.4908, D Loss: -2.7584
Epoch[2420/50000]
**Train**: G Loss: 15.9049, D Loss: -1.2905
Epoch[2420/50000]
**Valid**: G Loss: -12.8595, D Loss: -1.2910
Epoch[2430/50000]
**Train**: G Loss: 51.0739, D Loss: -1.0782
Epoch[2430/50000]
**Valid**: G Loss: 50.8919, D Loss: 1.6917
Epoch[2440/50000]
**Train**: G Loss: 7.9252, D Loss: -1.3984
Epoch[2440/50000]
**Valid**: G Loss: 32.8055, D Loss: -0.2185
Epoch[2450/50000]
**Train**: G Loss: 23.7037, D Loss: -1.4483
Epoch[2450/50000]
**Valid**: G Loss: -8.5600, D Loss: -2.2599
Epoch[2460/50000]
**Train**: G Loss: 23.6387, D Loss: -0.8629
Epoch[2460/50000]
**Valid**: G Loss: 70.5699, D Loss: -2.1295
Epoch[2470/50000]
**Train**: G Loss: -0.1495, D Loss: -1.6648
Epoch[2470/50000]
**Valid**: G Loss: -0.2959, D Loss: 0.0752
Epoch[2480/50000]
**Train**: G Loss: -4.2133, D Loss: -1.9274
Epoch[2480/50000]
**Valid**: G Loss: 2.5562, D Loss: -0.2545
Epoch[2490/50000]
**Train**: G Loss: 17.5157, D Loss: -1.3098
Epoch[2490/50000]
**Valid**: G Loss: -7.4586, D Loss: -0.4220
Epoch[2500/50000]
**Train**: G Loss: 28.7577, D Loss: -1.3106
Epoch[2500/50000]
**Valid**: G Loss: -20.8727, D Loss: -2.2657
Epoch[2510/50000]
**Train**: G Loss: 58.5611, D Loss: -1.0357
Epoch[2510/50000]
**Valid**: G Loss: 39.0399, D Loss: 0.8081
Epoch[2520/50000]
**Train**: G Loss: 2.7978, D Loss: -1.7431
Epoch[2520/50000]
**Valid**: G Loss: -15.6022, D Loss: -0.0417
Epoch[2530/50000]
**Train**: G Loss: 41.4404, D Loss: -0.9758
Epoch[2530/50000]
**Valid**: G Loss: 13.9184, D Loss: -2.1275
Epoch[2540/50000]
**Train**: G Loss: 9.1548, D Loss: -1.1093
Epoch[2540/50000]
**Valid**: G Loss: 41.1628, D Loss: -1.5343
Epoch[2550/50000]
**Train**: G Loss: -0.1029, D Loss: -1.6935
Epoch[2550/50000]
**Valid**: G Loss: 14.1710, D Loss: 0.9389
Epoch[2560/50000]
**Train**: G Loss: 20.6680, D Loss: -1.1729
Epoch[2560/50000]
**Valid**: G Loss: -10.4408, D Loss: -2.5012
Epoch[2570/50000]
**Train**: G Loss: 19.3422, D Loss: -0.9462
Epoch[2570/50000]
**Valid**: G Loss: 78.8408, D Loss: -2.3321
Epoch[2580/50000]
**Train**: G Loss: 79.6593, D Loss: -1.2054
Epoch[2580/50000]
**Valid**: G Loss: 62.4392, D Loss: 1.8845
Epoch[2590/50000]
**Train**: G Loss: -7.5958, D Loss: -1.6208
Epoch[2590/50000]
**Valid**: G Loss: 2.0968, D Loss: 0.9802
Epoch[2600/50000]
**Train**: G Loss: 68.5096, D Loss: -1.1321
Epoch[2600/50000]
**Valid**: G Loss: 97.0765, D Loss: 0.3082
Epoch[2610/50000]
**Train**: G Loss: 39.8777, D Loss: -0.8939
Epoch[2610/50000]
**Valid**: G Loss: -11.1416, D Loss: -3.0669
Epoch[2620/50000]
**Train**: G Loss: -4.7610, D Loss: -1.8295
Epoch[2620/50000]
**Valid**: G Loss: -5.8251, D Loss: 0.5651
Epoch[2630/50000]
**Train**: G Loss: 18.7195, D Loss: -1.3060
Epoch[2630/50000]
**Valid**: G Loss: 6.9193, D Loss: -0.5046
Epoch[2640/50000]
**Train**: G Loss: 14.3875, D Loss: -1.2850
Epoch[2640/50000]
**Valid**: G Loss: -7.8965, D Loss: -0.6497
Epoch[2650/50000]
**Train**: G Loss: 32.4179, D Loss: -1.0725
Epoch[2650/50000]
**Valid**: G Loss: 4.5232, D Loss: -2.3673
Epoch[2660/50000]
**Train**: G Loss: 46.8979, D Loss: -1.0484
Epoch[2660/50000]
**Valid**: G Loss: 24.1221, D Loss: -1.5274
Epoch[2670/50000]
**Train**: G Loss: 12.0208, D Loss: -1.8570
Epoch[2670/50000]
**Valid**: G Loss: 31.7982, D Loss: 0.5347
Epoch[2680/50000]
**Train**: G Loss: 72.4744, D Loss: -1.0202
Epoch[2680/50000]
**Valid**: G Loss: 32.6944, D Loss: -0.1377
Epoch[2690/50000]
**Train**: G Loss: 0.0576, D Loss: -1.7787
Epoch[2690/50000]
**Valid**: G Loss: -12.9864, D Loss: 0.5310
Epoch[2700/50000]
**Train**: G Loss: 38.3734, D Loss: -0.8382
Epoch[2700/50000]
**Valid**: G Loss: 46.9588, D Loss: 1.5654
Epoch[2710/50000]
**Train**: G Loss: 7.0933, D Loss: -1.6620
Epoch[2710/50000]
**Valid**: G Loss: -7.6712, D Loss: 0.1156
Epoch[2720/50000]
**Train**: G Loss: 82.2127, D Loss: -1.0064
Epoch[2720/50000]
**Valid**: G Loss: 82.0663, D Loss: 1.2963
Epoch[2730/50000]
**Train**: G Loss: 8.3105, D Loss: -1.5130
Epoch[2730/50000]
**Valid**: G Loss: 5.8507, D Loss: 0.8398
Epoch[2740/50000]
**Train**: G Loss: 86.2478, D Loss: -0.9623
Epoch[2740/50000]
**Valid**: G Loss: 83.4685, D Loss: 1.6551
Epoch[2750/50000]
**Train**: G Loss: 12.2559, D Loss: -1.4670
Epoch[2750/50000]
**Valid**: G Loss: -4.8636, D Loss: 0.0091
Epoch[2760/50000]
**Train**: G Loss: 39.0784, D Loss: -1.0450
Epoch[2760/50000]
**Valid**: G Loss: 38.0194, D Loss: 1.6722
Epoch[2770/50000]
**Train**: G Loss: 1.8427, D Loss: -1.4079
Epoch[2770/50000]
**Valid**: G Loss: -7.4185, D Loss: 0.1405
Epoch[2780/50000]
**Train**: G Loss: 58.3450, D Loss: -0.6929
Epoch[2780/50000]
**Valid**: G Loss: 25.9894, D Loss: -2.0082
Epoch[2790/50000]
**Train**: G Loss: 43.5892, D Loss: -0.8246
Epoch[2790/50000]
**Valid**: G Loss: 29.2405, D Loss: -2.4671
Epoch[2800/50000]
**Train**: G Loss: 32.4900, D Loss: -1.0092
Epoch[2800/50000]
**Valid**: G Loss: 35.3253, D Loss: 0.0881
Epoch[2810/50000]
**Train**: G Loss: 35.3944, D Loss: -1.0562
Epoch[2810/50000]
**Valid**: G Loss: 17.6433, D Loss: -1.6180
Epoch[2820/50000]
**Train**: G Loss: 38.1575, D Loss: -0.7260
Epoch[2820/50000]
**Valid**: G Loss: 35.2729, D Loss: 0.9669
Epoch[2830/50000]
**Train**: G Loss: 75.8502, D Loss: -0.7876
Epoch[2830/50000]
**Valid**: G Loss: 1.9537, D Loss: -2.7034
Epoch[2840/50000]
**Train**: G Loss: -16.8365, D Loss: -1.7663
Epoch[2840/50000]
**Valid**: G Loss: 0.6354, D Loss: 1.2955
Epoch[2850/50000]
**Train**: G Loss: 58.3789, D Loss: -0.5594
Epoch[2850/50000]
**Valid**: G Loss: 3.7228, D Loss: -2.1997
Epoch[2860/50000]
**Train**: G Loss: -16.9636, D Loss: -1.6113
Epoch[2860/50000]
**Valid**: G Loss: 0.3858, D Loss: 1.7773
Epoch[2870/50000]
**Train**: G Loss: 28.2078, D Loss: -0.4191
Epoch[2870/50000]
**Valid**: G Loss: 101.2037, D Loss: -3.2755
Epoch[2880/50000]
**Train**: G Loss: 95.0877, D Loss: -0.6412
Epoch[2880/50000]
**Valid**: G Loss: 46.7966, D Loss: 0.1509
Epoch[2890/50000]
**Train**: G Loss: 4.7835, D Loss: -1.3636
Epoch[2890/50000]
**Valid**: G Loss: -11.7170, D Loss: -0.3173
Epoch[2900/50000]
**Train**: G Loss: -6.9164, D Loss: -1.8529
Epoch[2900/50000]
**Valid**: G Loss: 3.1108, D Loss: 1.4780
Epoch[2910/50000]
**Train**: G Loss: -1.7370, D Loss: -2.0617
Epoch[2910/50000]
**Valid**: G Loss: 13.3368, D Loss: 1.4883
Epoch[2920/50000]
**Train**: G Loss: 4.5583, D Loss: -1.5647
Epoch[2920/50000]
**Valid**: G Loss: 25.2474, D Loss: 1.7412
Epoch[2930/50000]
**Train**: G Loss: -16.5670, D Loss: -1.7193
Epoch[2930/50000]
**Valid**: G Loss: 0.1039, D Loss: 1.2318
Epoch[2940/50000]
**Train**: G Loss: -3.9269, D Loss: -1.2187
Epoch[2940/50000]
**Valid**: G Loss: 9.3569, D Loss: 0.1228
Epoch[2950/50000]
**Train**: G Loss: 14.5927, D Loss: -0.3301
Epoch[2950/50000]
**Valid**: G Loss: 58.7010, D Loss: -0.4605
Epoch[2960/50000]
**Train**: G Loss: 40.1207, D Loss: -0.3921
Epoch[2960/50000]
**Valid**: G Loss: 119.3021, D Loss: -2.9053
Epoch[2970/50000]
**Train**: G Loss: 65.0920, D Loss: -1.2777
Epoch[2970/50000]
**Valid**: G Loss: 62.9619, D Loss: 2.2695
Epoch[2980/50000]
**Train**: G Loss: 55.6451, D Loss: -0.9705
Epoch[2980/50000]
**Valid**: G Loss: 74.0670, D Loss: 1.0546
Epoch[2990/50000]
**Train**: G Loss: 78.7156, D Loss: -1.1059
Epoch[2990/50000]
**Valid**: G Loss: 88.4059, D Loss: 1.2752
Epoch[3000/50000]
**Train**: G Loss: 36.7991, D Loss: -0.3787
Epoch[3000/50000]
**Valid**: G Loss: 3.8441, D Loss: -1.6155
Epoch[3010/50000]
**Train**: G Loss: 87.4137, D Loss: -0.5209
Epoch[3010/50000]
**Valid**: G Loss: 49.2105, D Loss: 1.3464
Epoch[3020/50000]
**Train**: G Loss: 104.3953, D Loss: -0.9690
Epoch[3020/50000]
**Valid**: G Loss: 86.5849, D Loss: 1.8323
Epoch[3030/50000]
**Train**: G Loss: 51.3480, D Loss: -0.7128
Epoch[3030/50000]
**Valid**: G Loss: 36.4197, D Loss: 2.0238
Epoch[3040/50000]
**Train**: G Loss: 73.6286, D Loss: -0.3994
Epoch[3040/50000]
**Valid**: G Loss: 22.1821, D Loss: -2.8344
Epoch[3050/50000]
**Train**: G Loss: 52.8372, D Loss: 0.3623
Epoch[3050/50000]
**Valid**: G Loss: 17.7515, D Loss: -0.9279
Epoch[3060/50000]
**Train**: G Loss: 86.9720, D Loss: -1.0879
Epoch[3060/50000]
**Valid**: G Loss: 58.8172, D Loss: 2.3798
Epoch[3070/50000]
**Train**: G Loss: 94.3320, D Loss: -0.5576
Epoch[3070/50000]
**Valid**: G Loss: 51.6872, D Loss: 1.0572
Epoch[3080/50000]
**Train**: G Loss: 95.0457, D Loss: -1.2524
Epoch[3080/50000]
**Valid**: G Loss: 68.4247, D Loss: 2.3181
Epoch[3090/50000]
**Train**: G Loss: 50.6782, D Loss: -0.9067
Epoch[3090/50000]
**Valid**: G Loss: 49.9347, D Loss: 1.7926
Epoch[3100/50000]
**Train**: G Loss: 28.9484, D Loss: -0.8926
Epoch[3100/50000]
**Valid**: G Loss: 57.3967, D Loss: 0.1547
Epoch[3110/50000]
**Train**: G Loss: 22.4666, D Loss: -0.4168
Epoch[3110/50000]
**Valid**: G Loss: 82.3643, D Loss: -2.7293
Epoch[3120/50000]
**Train**: G Loss: -20.1626, D Loss: -1.2484
Epoch[3120/50000]
**Valid**: G Loss: -3.7567, D Loss: 1.8626
Epoch[3130/50000]
**Train**: G Loss: 10.2422, D Loss: -0.8964
Epoch[3130/50000]
**Valid**: G Loss: 25.8356, D Loss: 0.7292
Epoch[3140/50000]
**Train**: G Loss: -7.2717, D Loss: -1.5903
Epoch[3140/50000]
**Valid**: G Loss: 2.5157, D Loss: 0.9083
Epoch[3150/50000]
**Train**: G Loss: -12.6481, D Loss: -1.7889
Epoch[3150/50000]
**Valid**: G Loss: -11.0183, D Loss: 1.3004
Epoch[3160/50000]
**Train**: G Loss: 66.2438, D Loss: -1.2914
Epoch[3160/50000]
**Valid**: G Loss: 46.6684, D Loss: 1.3412
Epoch[3170/50000]
**Train**: G Loss: 108.7383, D Loss: -0.7789
Epoch[3170/50000]
**Valid**: G Loss: 74.3270, D Loss: 1.9688
Epoch[3180/50000]
**Train**: G Loss: 80.2644, D Loss: -1.0394
Epoch[3180/50000]
**Valid**: G Loss: 100.0609, D Loss: 0.7491
Epoch[3190/50000]
**Train**: G Loss: 12.9308, D Loss: -0.4300
Epoch[3190/50000]
**Valid**: G Loss: 41.8703, D Loss: -0.7548
Epoch[3200/50000]
**Train**: G Loss: 53.7826, D Loss: -0.3069
Epoch[3200/50000]
**Valid**: G Loss: 124.7392, D Loss: -1.7974
Epoch[3210/50000]
**Train**: G Loss: 17.1890, D Loss: -0.5048
Epoch[3210/50000]
**Valid**: G Loss: 42.3031, D Loss: 0.8020
Epoch[3220/50000]
**Train**: G Loss: 33.6862, D Loss: -0.3774
Epoch[3220/50000]
**Valid**: G Loss: -8.6169, D Loss: -3.1659
Epoch[3230/50000]
**Train**: G Loss: 54.4377, D Loss: -0.7636
Epoch[3230/50000]
**Valid**: G Loss: 41.3776, D Loss: 1.9205
Epoch[3240/50000]
**Train**: G Loss: 45.2829, D Loss: -0.5292
Epoch[3240/50000]
**Valid**: G Loss: 91.8257, D Loss: -0.5833
Epoch[3250/50000]
**Train**: G Loss: 12.4795, D Loss: -1.6740
Epoch[3250/50000]
**Valid**: G Loss: 30.5112, D Loss: 2.2815
Epoch[3260/50000]
**Train**: G Loss: 17.0130, D Loss: -0.3953
Epoch[3260/50000]
**Valid**: G Loss: -24.2023, D Loss: -2.5093
Epoch[3270/50000]
**Train**: G Loss: 47.4627, D Loss: -0.9869
Epoch[3270/50000]
**Valid**: G Loss: 50.2080, D Loss: 2.0911
Epoch[3280/50000]
**Train**: G Loss: 77.7431, D Loss: -0.8713
Epoch[3280/50000]
**Valid**: G Loss: 108.4079, D Loss: -0.1310
Epoch[3290/50000]
**Train**: G Loss: 20.8586, D Loss: -0.2807
Epoch[3290/50000]
**Valid**: G Loss: 55.2518, D Loss: 0.1744
Epoch[3300/50000]
**Train**: G Loss: 25.5758, D Loss: -0.7820
Epoch[3300/50000]
**Valid**: G Loss: 6.9043, D Loss: -1.6936
Epoch[3310/50000]
**Train**: G Loss: 100.5770, D Loss: -0.7178
Epoch[3310/50000]
**Valid**: G Loss: 69.2002, D Loss: 1.8904
Epoch[3320/50000]
**Train**: G Loss: 42.4225, D Loss: -0.1259
Epoch[3320/50000]
**Valid**: G Loss: 118.2617, D Loss: -2.7030
Epoch[3330/50000]
**Train**: G Loss: -17.8341, D Loss: -1.7105
Epoch[3330/50000]
**Valid**: G Loss: -17.3757, D Loss: 1.1747
Epoch[3340/50000]
**Train**: G Loss: 84.2404, D Loss: -0.6054
Epoch[3340/50000]
**Valid**: G Loss: 52.3549, D Loss: 1.9166
Epoch[3350/50000]
**Train**: G Loss: 31.7934, D Loss: -0.4360
Epoch[3350/50000]
**Valid**: G Loss: 73.5180, D Loss: -1.0430
Epoch[3360/50000]
**Train**: G Loss: -17.2987, D Loss: -1.7467
Epoch[3360/50000]
**Valid**: G Loss: -24.4089, D Loss: 0.5562
Epoch[3370/50000]
**Train**: G Loss: 46.2248, D Loss: -0.6295
Epoch[3370/50000]
**Valid**: G Loss: 91.0374, D Loss: -1.0870
Epoch[3380/50000]
**Train**: G Loss: -20.7252, D Loss: -1.9900
Epoch[3380/50000]
**Valid**: G Loss: -15.1878, D Loss: 1.4380
Epoch[3390/50000]
**Train**: G Loss: 78.7789, D Loss: -0.1151
Epoch[3390/50000]
**Valid**: G Loss: 40.5258, D Loss: 0.7786
Epoch[3400/50000]
**Train**: G Loss: -21.1816, D Loss: -1.7644
Epoch[3400/50000]
**Valid**: G Loss: -9.2818, D Loss: 1.9072
Epoch[3410/50000]
**Train**: G Loss: 12.5504, D Loss: -1.2561
Epoch[3410/50000]
**Valid**: G Loss: -2.5393, D Loss: -0.2643
Epoch[3420/50000]
**Train**: G Loss: 99.2460, D Loss: -0.3312
Epoch[3420/50000]
**Valid**: G Loss: 67.2029, D Loss: 1.4981
Epoch[3430/50000]
**Train**: G Loss: 2.4018, D Loss: -1.0693
Epoch[3430/50000]
**Valid**: G Loss: 12.2431, D Loss: 0.8998
Epoch[3440/50000]
**Train**: G Loss: 5.7541, D Loss: -1.2078
Epoch[3440/50000]
**Valid**: G Loss: -7.8350, D Loss: 0.1294
Epoch[3450/50000]
**Train**: G Loss: 111.2872, D Loss: -0.6603
Epoch[3450/50000]
**Valid**: G Loss: 93.7830, D Loss: 1.9908
Epoch[3460/50000]
**Train**: G Loss: -0.3743, D Loss: -1.7292
Epoch[3460/50000]
**Valid**: G Loss: 5.7537, D Loss: 0.8506
Epoch[3470/50000]
**Train**: G Loss: 13.8143, D Loss: -1.3927
Epoch[3470/50000]
**Valid**: G Loss: 23.8413, D Loss: 1.1038
Epoch[3480/50000]
**Train**: G Loss: 52.6614, D Loss: 0.0820
Epoch[3480/50000]
**Valid**: G Loss: 23.7661, D Loss: -0.6693
Epoch[3490/50000]
**Train**: G Loss: 46.6329, D Loss: 0.0549
Epoch[3490/50000]
**Valid**: G Loss: 4.2341, D Loss: -1.8691
Epoch[3500/50000]
**Train**: G Loss: 56.1515, D Loss: 0.2891
Epoch[3500/50000]
**Valid**: G Loss: 35.2518, D Loss: -0.0864
Epoch[3510/50000]
**Train**: G Loss: 54.4007, D Loss: -0.5358
Epoch[3510/50000]
**Valid**: G Loss: 48.4740, D Loss: 1.8528
Epoch[3520/50000]
**Train**: G Loss: 87.2292, D Loss: -0.5383
Epoch[3520/50000]
**Valid**: G Loss: 121.6696, D Loss: 0.5694
Epoch[3530/50000]
**Train**: G Loss: 15.2125, D Loss: -0.9657
Epoch[3530/50000]
**Valid**: G Loss: 31.8702, D Loss: 0.9734
Epoch[3540/50000]
**Train**: G Loss: 21.1978, D Loss: -0.6874
Epoch[3540/50000]
**Valid**: G Loss: -23.7568, D Loss: -2.0943
Epoch[3550/50000]
**Train**: G Loss: 30.2156, D Loss: -0.5049
Epoch[3550/50000]
**Valid**: G Loss: 65.2635, D Loss: -0.4088
Epoch[3560/50000]
**Train**: G Loss: 56.0321, D Loss: -0.6496
Epoch[3560/50000]
**Valid**: G Loss: 73.5391, D Loss: 0.6453
Epoch[3570/50000]
**Train**: G Loss: 29.0651, D Loss: 0.3934
Epoch[3570/50000]
**Valid**: G Loss: 80.6990, D Loss: -1.5565
Epoch[3580/50000]
**Train**: G Loss: -3.8092, D Loss: -1.4651
Epoch[3580/50000]
**Valid**: G Loss: -0.9466, D Loss: 1.1880
Epoch[3590/50000]
**Train**: G Loss: 62.7714, D Loss: -0.4399
Epoch[3590/50000]
**Valid**: G Loss: 50.2188, D Loss: 1.5264
Epoch[3600/50000]
**Train**: G Loss: 23.1802, D Loss: 0.2272
Epoch[3600/50000]
**Valid**: G Loss: 72.4952, D Loss: -1.2250
Epoch[3610/50000]
**Train**: G Loss: 9.6868, D Loss: -1.0925
Epoch[3610/50000]
**Valid**: G Loss: 5.3727, D Loss: 0.5967
Epoch[3620/50000]
**Train**: G Loss: 58.4622, D Loss: -0.1041
Epoch[3620/50000]
**Valid**: G Loss: -6.6293, D Loss: -2.7920
Epoch[3630/50000]
**Train**: G Loss: 90.3474, D Loss: -0.9775
Epoch[3630/50000]
**Valid**: G Loss: 90.5432, D Loss: 1.4567
Epoch[3640/50000]
**Train**: G Loss: 15.8290, D Loss: 0.2294
Epoch[3640/50000]
**Valid**: G Loss: 54.2745, D Loss: 0.0046
Epoch[3650/50000]
**Train**: G Loss: 37.1573, D Loss: -0.3854
Epoch[3650/50000]
**Valid**: G Loss: 17.2274, D Loss: -2.5374
Epoch[3660/50000]
**Train**: G Loss: 23.9617, D Loss: 1.9237
Epoch[3660/50000]
**Valid**: G Loss: 87.9293, D Loss: -0.3529
Epoch[3670/50000]
**Train**: G Loss: 63.2851, D Loss: -0.2814
Epoch[3670/50000]
**Valid**: G Loss: 35.7142, D Loss: -0.3187
Epoch[3680/50000]
**Train**: G Loss: 21.3314, D Loss: 0.7235
Epoch[3680/50000]
**Valid**: G Loss: 83.5023, D Loss: -2.5286
Epoch[3690/50000]
**Train**: G Loss: 97.5360, D Loss: -1.6250
Epoch[3690/50000]
**Valid**: G Loss: 104.9448, D Loss: 0.9391
Epoch[3700/50000]
**Train**: G Loss: 30.5069, D Loss: -0.2423
Epoch[3700/50000]
**Valid**: G Loss: 2.9186, D Loss: -2.2165
Epoch[3710/50000]
**Train**: G Loss: 63.3812, D Loss: -0.2364
Epoch[3710/50000]
**Valid**: G Loss: 128.0631, D Loss: -1.6286
Epoch[3720/50000]
**Train**: G Loss: 34.6671, D Loss: -0.5141
Epoch[3720/50000]
**Valid**: G Loss: 16.0459, D Loss: -1.1946
Epoch[3730/50000]
**Train**: G Loss: 100.1792, D Loss: -0.7771
Epoch[3730/50000]
**Valid**: G Loss: 77.9690, D Loss: 2.5260
Epoch[3740/50000]
**Train**: G Loss: -19.7530, D Loss: -1.5739
Epoch[3740/50000]
**Valid**: G Loss: -6.4154, D Loss: 1.2957
Epoch[3750/50000]
**Train**: G Loss: 52.2070, D Loss: -0.6530
Epoch[3750/50000]
**Valid**: G Loss: 55.2151, D Loss: 1.5396
Epoch[3760/50000]
**Train**: G Loss: 33.5237, D Loss: -0.2458
Epoch[3760/50000]
**Valid**: G Loss: 80.1996, D Loss: -1.6728
Epoch[3770/50000]
**Train**: G Loss: 15.0565, D Loss: -1.3366
Epoch[3770/50000]
**Valid**: G Loss: -6.6061, D Loss: -0.3295
Epoch[3780/50000]
**Train**: G Loss: 112.0215, D Loss: -0.9799
Epoch[3780/50000]
**Valid**: G Loss: 114.9564, D Loss: 1.1760
Epoch[3790/50000]
**Train**: G Loss: 22.2389, D Loss: -1.2833
Epoch[3790/50000]
**Valid**: G Loss: 27.9834, D Loss: 1.2640
Epoch[3800/50000]
**Train**: G Loss: 101.5110, D Loss: -0.3722
Epoch[3800/50000]
**Valid**: G Loss: 75.9332, D Loss: 1.4545
Epoch[3810/50000]
**Train**: G Loss: 77.9172, D Loss: -0.2902
Epoch[3810/50000]
**Valid**: G Loss: 147.9573, D Loss: -0.4503
Epoch[3820/50000]
**Train**: G Loss: 21.1189, D Loss: 0.1783
Epoch[3820/50000]
**Valid**: G Loss: 51.5214, D Loss: 0.2629
Epoch[3830/50000]
**Train**: G Loss: 18.2008, D Loss: -1.2305
Epoch[3830/50000]
**Valid**: G Loss: 1.7731, D Loss: -0.0762
Epoch[3840/50000]
**Train**: G Loss: 56.8635, D Loss: -0.0367
Epoch[3840/50000]
**Valid**: G Loss: 134.0386, D Loss: -1.8345
Epoch[3850/50000]
**Train**: G Loss: -9.6163, D Loss: -1.4436
Epoch[3850/50000]
**Valid**: G Loss: -10.9126, D Loss: 1.3639
Epoch[3860/50000]
**Train**: G Loss: 72.6133, D Loss: -0.7245
Epoch[3860/50000]
**Valid**: G Loss: 111.3393, D Loss: -0.2870
Epoch[3870/50000]
**Train**: G Loss: 1.9961, D Loss: -0.5684
Epoch[3870/50000]
**Valid**: G Loss: 16.3824, D Loss: 1.4515
Epoch[3880/50000]
**Train**: G Loss: 73.5830, D Loss: 0.1221
Epoch[3880/50000]
**Valid**: G Loss: 16.0953, D Loss: -2.6795
Epoch[3890/50000]
**Train**: G Loss: 53.7388, D Loss: -0.2268
Epoch[3890/50000]
**Valid**: G Loss: 92.1563, D Loss: -0.0634
Epoch[3900/50000]
**Train**: G Loss: 19.8470, D Loss: -0.6610
Epoch[3900/50000]
**Valid**: G Loss: 30.5810, D Loss: 0.7297
Epoch[3910/50000]
**Train**: G Loss: 38.3686, D Loss: -1.0264
Epoch[3910/50000]
**Valid**: G Loss: 25.6612, D Loss: 0.4495
Epoch[3920/50000]
**Train**: G Loss: 60.0731, D Loss: 0.1848
Epoch[3920/50000]
**Valid**: G Loss: 26.8967, D Loss: -2.1459
Epoch[3930/50000]
**Train**: G Loss: 79.2107, D Loss: 0.0995
Epoch[3930/50000]
**Valid**: G Loss: 15.4882, D Loss: -2.6306
Epoch[3940/50000]
**Train**: G Loss: 108.5990, D Loss: -0.3437
Epoch[3940/50000]
**Valid**: G Loss: 74.7912, D Loss: 1.9999
Epoch[3950/50000]
**Train**: G Loss: 6.5550, D Loss: -1.5660
Epoch[3950/50000]
**Valid**: G Loss: -15.9938, D Loss: -0.3731
Epoch[3960/50000]
**Train**: G Loss: 48.0526, D Loss: 0.1467
Epoch[3960/50000]
**Valid**: G Loss: 121.6796, D Loss: -1.5731
Epoch[3970/50000]
**Train**: G Loss: 0.8770, D Loss: -1.3519
Epoch[3970/50000]
**Valid**: G Loss: 5.1370, D Loss: 1.1463
Epoch[3980/50000]
**Train**: G Loss: 14.2085, D Loss: -1.0006
Epoch[3980/50000]
**Valid**: G Loss: -19.2926, D Loss: -0.4790
Epoch[3990/50000]
**Train**: G Loss: 23.7682, D Loss: -0.0607
Epoch[3990/50000]
**Valid**: G Loss: 56.9092, D Loss: -1.8120
Epoch[4000/50000]
**Train**: G Loss: 80.4035, D Loss: -0.2434
Epoch[4000/50000]
**Valid**: G Loss: 130.0218, D Loss: 0.6110
Epoch[4010/50000]
**Train**: G Loss: 92.3202, D Loss: -0.2389
Epoch[4010/50000]
**Valid**: G Loss: 139.3332, D Loss: 1.3979
Epoch[4020/50000]
**Train**: G Loss: 25.4633, D Loss: 0.6645
Epoch[4020/50000]
**Valid**: G Loss: 65.3293, D Loss: -0.8606
Epoch[4030/50000]
**Train**: G Loss: 31.6100, D Loss: -0.8362
Epoch[4030/50000]
**Valid**: G Loss: 3.9462, D Loss: -0.8753
Epoch[4040/50000]
**Train**: G Loss: 58.0721, D Loss: -0.2967
Epoch[4040/50000]
**Valid**: G Loss: 20.3067, D Loss: -0.9310
Epoch[4050/50000]
**Train**: G Loss: 29.6178, D Loss: -0.7025
Epoch[4050/50000]
**Valid**: G Loss: 3.2453, D Loss: -0.1324
Epoch[4060/50000]
**Train**: G Loss: 30.3499, D Loss: -0.7289
Epoch[4060/50000]
**Valid**: G Loss: 8.1420, D Loss: 0.1125
Epoch[4070/50000]
**Train**: G Loss: 26.0063, D Loss: -0.8555
Epoch[4070/50000]
**Valid**: G Loss: 27.4484, D Loss: 0.7416
Epoch[4080/50000]
**Train**: G Loss: -12.4581, D Loss: -1.6427
Epoch[4080/50000]
**Valid**: G Loss: -15.8313, D Loss: 1.1527
Epoch[4090/50000]
**Train**: G Loss: 116.6705, D Loss: -0.7187
Epoch[4090/50000]
**Valid**: G Loss: 105.1414, D Loss: 1.5587
Epoch[4100/50000]
**Train**: G Loss: 35.6890, D Loss: 0.4413
Epoch[4100/50000]
**Valid**: G Loss: -44.3627, D Loss: -3.5754
Epoch[4110/50000]
**Train**: G Loss: -31.5824, D Loss: -1.9982
Epoch[4110/50000]
**Valid**: G Loss: -27.4401, D Loss: 0.8317
Epoch[4120/50000]
**Train**: G Loss: 81.1994, D Loss: -0.5042
Epoch[4120/50000]
**Valid**: G Loss: 96.6921, D Loss: 1.6991
Epoch[4130/50000]
**Train**: G Loss: 64.1594, D Loss: 0.2835
Epoch[4130/50000]
**Valid**: G Loss: 128.5030, D Loss: -1.2018
Epoch[4140/50000]
**Train**: G Loss: 11.1196, D Loss: -1.3655
Epoch[4140/50000]
**Valid**: G Loss: 7.8101, D Loss: 1.0413
Epoch[4150/50000]
**Train**: G Loss: 94.3072, D Loss: -0.3901
Epoch[4150/50000]
**Valid**: G Loss: 89.6267, D Loss: 2.5039
Epoch[4160/50000]
**Train**: G Loss: 48.8123, D Loss: 0.0965
Epoch[4160/50000]
**Valid**: G Loss: 94.6422, D Loss: 0.2137
Epoch[4170/50000]
**Train**: G Loss: 28.0408, D Loss: -0.2456
Epoch[4170/50000]
**Valid**: G Loss: 40.5381, D Loss: 0.5847
Epoch[4180/50000]
**Train**: G Loss: 39.7323, D Loss: 0.0903
Epoch[4180/50000]
**Valid**: G Loss: 75.4792, D Loss: 0.3442
Epoch[4190/50000]
**Train**: G Loss: 33.9809, D Loss: -0.8103
Epoch[4190/50000]
**Valid**: G Loss: 24.1209, D Loss: 0.4283
Epoch[4200/50000]
**Train**: G Loss: 12.9322, D Loss: -0.9977
Epoch[4200/50000]
**Valid**: G Loss: -12.6225, D Loss: -0.1261
Epoch[4210/50000]
**Train**: G Loss: 65.4087, D Loss: -0.2915
Epoch[4210/50000]
**Valid**: G Loss: 102.3827, D Loss: 0.9913
Epoch[4220/50000]
**Train**: G Loss: 125.0773, D Loss: -0.2760
Epoch[4220/50000]
**Valid**: G Loss: 136.5768, D Loss: 1.6943
Epoch[4230/50000]
**Train**: G Loss: 8.2768, D Loss: -1.5000
Epoch[4230/50000]
**Valid**: G Loss: 12.6902, D Loss: 1.2819
Epoch[4240/50000]
**Train**: G Loss: 126.5564, D Loss: -0.9452
Epoch[4240/50000]
**Valid**: G Loss: 97.6084, D Loss: 2.1201
Epoch[4250/50000]
**Train**: G Loss: 36.3408, D Loss: 0.0147
Epoch[4250/50000]
**Valid**: G Loss: -21.5469, D Loss: -2.7950
Epoch[4260/50000]
**Train**: G Loss: 39.1148, D Loss: 0.5311
Epoch[4260/50000]
**Valid**: G Loss: 77.4029, D Loss: -0.6264
Epoch[4270/50000]
**Train**: G Loss: 36.6424, D Loss: -0.6346
Epoch[4270/50000]
**Valid**: G Loss: 40.2739, D Loss: 0.9606
Epoch[4280/50000]
**Train**: G Loss: 68.1465, D Loss: 0.5997
Epoch[4280/50000]
**Valid**: G Loss: 4.6924, D Loss: -2.9294
Epoch[4290/50000]
**Train**: G Loss: -16.6283, D Loss: -1.8581
Epoch[4290/50000]
**Valid**: G Loss: -8.3898, D Loss: 1.2860
Epoch[4300/50000]
**Train**: G Loss: 77.0591, D Loss: 0.0941
Epoch[4300/50000]
**Valid**: G Loss: 148.5972, D Loss: -1.6047
Epoch[4310/50000]
**Train**: G Loss: 76.6591, D Loss: -0.7653
Epoch[4310/50000]
**Valid**: G Loss: 79.0494, D Loss: 1.4281
Epoch[4320/50000]
**Train**: G Loss: 53.4182, D Loss: 0.7513
Epoch[4320/50000]
**Valid**: G Loss: -22.0187, D Loss: -3.5368
Epoch[4330/50000]
**Train**: G Loss: 18.2149, D Loss: -0.1452
Epoch[4330/50000]
**Valid**: G Loss: 42.2509, D Loss: 0.1380
Epoch[4340/50000]
**Train**: G Loss: 35.8281, D Loss: -0.8948
Epoch[4340/50000]
**Valid**: G Loss: 30.9310, D Loss: 0.6558
Epoch[4350/50000]
**Train**: G Loss: 68.9409, D Loss: -0.2147
Epoch[4350/50000]
**Valid**: G Loss: 131.6634, D Loss: -1.0711
Epoch[4360/50000]
**Train**: G Loss: 119.6416, D Loss: -1.1200
Epoch[4360/50000]
**Valid**: G Loss: 91.7262, D Loss: 2.2310
Epoch[4370/50000]
**Train**: G Loss: 54.1325, D Loss: -0.2853
Epoch[4370/50000]
**Valid**: G Loss: 20.6762, D Loss: -1.4184
Epoch[4380/50000]
**Train**: G Loss: 49.2616, D Loss: -0.4788
Epoch[4380/50000]
**Valid**: G Loss: 62.9526, D Loss: -0.0282
Epoch[4390/50000]
**Train**: G Loss: 130.9034, D Loss: -0.2014
Epoch[4390/50000]
**Valid**: G Loss: 89.5432, D Loss: 2.2745
Epoch[4400/50000]
**Train**: G Loss: 3.7207, D Loss: -1.3148
Epoch[4400/50000]
**Valid**: G Loss: 11.3487, D Loss: 1.6657
Epoch[4410/50000]
**Train**: G Loss: 85.2090, D Loss: -0.9309
Epoch[4410/50000]
**Valid**: G Loss: 98.2902, D Loss: 0.6694
Epoch[4420/50000]
**Train**: G Loss: 62.8139, D Loss: 0.3287
Epoch[4420/50000]
**Valid**: G Loss: 22.9791, D Loss: -0.6730
Epoch[4430/50000]
**Train**: G Loss: 6.8439, D Loss: -1.0486
Epoch[4430/50000]
**Valid**: G Loss: -21.2660, D Loss: -0.8705
Epoch[4440/50000]
**Train**: G Loss: 97.1703, D Loss: -0.0620
Epoch[4440/50000]
**Valid**: G Loss: 110.5151, D Loss: 1.2204
Epoch[4450/50000]
**Train**: G Loss: 64.3519, D Loss: -0.1041
Epoch[4450/50000]
**Valid**: G Loss: 59.4186, D Loss: 0.9826
Epoch[4460/50000]
**Train**: G Loss: 85.2934, D Loss: 0.9386
Epoch[4460/50000]
**Valid**: G Loss: 7.5820, D Loss: -2.8385
Epoch[4470/50000]
**Train**: G Loss: 40.2655, D Loss: 0.2716
Epoch[4470/50000]
**Valid**: G Loss: -26.0959, D Loss: -3.4586
Epoch[4480/50000]
**Train**: G Loss: 4.7337, D Loss: 0.8407
Epoch[4480/50000]
**Valid**: G Loss: 42.7564, D Loss: 1.4302
Epoch[4490/50000]
**Train**: G Loss: -13.5087, D Loss: -1.0291
Epoch[4490/50000]
**Valid**: G Loss: 1.7738, D Loss: 2.2393
Epoch[4500/50000]
**Train**: G Loss: 15.2132, D Loss: 0.0591
Epoch[4500/50000]
**Valid**: G Loss: 36.5358, D Loss: 1.6334
Epoch[4510/50000]
**Train**: G Loss: 46.8844, D Loss: 0.6933
Epoch[4510/50000]
**Valid**: G Loss: 93.2831, D Loss: 0.5923
Epoch[4520/50000]
**Train**: G Loss: 15.3984, D Loss: -1.1210
Epoch[4520/50000]
**Valid**: G Loss: 14.7558, D Loss: 0.9384
Epoch[4530/50000]
**Train**: G Loss: 103.8174, D Loss: -0.3873
Epoch[4530/50000]
**Valid**: G Loss: 137.8981, D Loss: 0.8077
Epoch[4540/50000]
**Train**: G Loss: 92.9611, D Loss: 0.1585
Epoch[4540/50000]
**Valid**: G Loss: 43.7225, D Loss: 0.0870
Epoch[4550/50000]
**Train**: G Loss: 64.0924, D Loss: -0.1261
Epoch[4550/50000]
**Valid**: G Loss: 88.6859, D Loss: 1.4799
Epoch[4560/50000]
**Train**: G Loss: 67.7774, D Loss: 0.2798
Epoch[4560/50000]
**Valid**: G Loss: 20.9939, D Loss: -2.4131
Epoch[4570/50000]
**Train**: G Loss: 68.9952, D Loss: 0.5304
Epoch[4570/50000]
**Valid**: G Loss: 15.9631, D Loss: -2.6036
Epoch[4580/50000]
**Train**: G Loss: 35.3274, D Loss: 0.4882
Epoch[4580/50000]
**Valid**: G Loss: 75.1995, D Loss: -0.0909
Epoch[4590/50000]
**Train**: G Loss: 81.6127, D Loss: -0.0220
Epoch[4590/50000]
**Valid**: G Loss: 37.4142, D Loss: -1.6490
Epoch[4600/50000]
**Train**: G Loss: 88.3338, D Loss: -0.1829
Epoch[4600/50000]
**Valid**: G Loss: 106.8134, D Loss: 1.5023
Epoch[4610/50000]
**Train**: G Loss: 64.9030, D Loss: -0.5111
Epoch[4610/50000]
**Valid**: G Loss: 53.1765, D Loss: -0.2237
Epoch[4620/50000]
**Train**: G Loss: 74.4830, D Loss: 0.0985
Epoch[4620/50000]
**Valid**: G Loss: 76.6965, D Loss: 0.2046
Epoch[4630/50000]
**Train**: G Loss: 109.1184, D Loss: 0.0239
Epoch[4630/50000]
**Valid**: G Loss: 176.5212, D Loss: -0.2654
Epoch[4640/50000]
**Train**: G Loss: 52.6440, D Loss: 0.7295
Epoch[4640/50000]
**Valid**: G Loss: -29.0075, D Loss: -3.8765
Epoch[4650/50000]
**Train**: G Loss: 10.1248, D Loss: -1.0247
Epoch[4650/50000]
**Valid**: G Loss: -32.0037, D Loss: -1.6414
Epoch[4660/50000]
**Train**: G Loss: 18.9389, D Loss: -0.8560
Epoch[4660/50000]
**Valid**: G Loss: 20.8536, D Loss: 1.5451
Epoch[4670/50000]
**Train**: G Loss: 50.2494, D Loss: -0.1866
Epoch[4670/50000]
**Valid**: G Loss: 31.1209, D Loss: -0.3733
Epoch[4680/50000]
**Train**: G Loss: -5.1983, D Loss: 0.8869
Epoch[4680/50000]
**Valid**: G Loss: 28.4193, D Loss: 1.3355
Epoch[4690/50000]
**Train**: G Loss: 65.2218, D Loss: 0.3125
Epoch[4690/50000]
**Valid**: G Loss: 51.2092, D Loss: -0.4228
Epoch[4700/50000]
**Train**: G Loss: 3.9334, D Loss: -1.1361
Epoch[4700/50000]
**Valid**: G Loss: -23.4903, D Loss: 0.1136
Epoch[4710/50000]
**Train**: G Loss: 129.7657, D Loss: -1.2493
Epoch[4710/50000]
**Valid**: G Loss: 108.8374, D Loss: 1.9055
Epoch[4720/50000]
**Train**: G Loss: 82.3565, D Loss: -1.0023
Epoch[4720/50000]
**Valid**: G Loss: 64.5132, D Loss: 1.9631
Epoch[4730/50000]
**Train**: G Loss: 39.7817, D Loss: -0.2250
Epoch[4730/50000]
**Valid**: G Loss: 18.5739, D Loss: -0.7722
Epoch[4740/50000]
**Train**: G Loss: 3.1912, D Loss: -1.1998
Epoch[4740/50000]
**Valid**: G Loss: -20.3447, D Loss: -0.1660
Epoch[4750/50000]
**Train**: G Loss: 11.1600, D Loss: -0.9157
Epoch[4750/50000]
**Valid**: G Loss: 18.2275, D Loss: 1.0706
Epoch[4760/50000]
**Train**: G Loss: 91.6499, D Loss: 0.0252
Epoch[4760/50000]
**Valid**: G Loss: 61.4448, D Loss: 0.0453
Epoch[4770/50000]
**Train**: G Loss: 18.5358, D Loss: -1.2666
Epoch[4770/50000]
**Valid**: G Loss: -2.3480, D Loss: -0.0939
Epoch[4780/50000]
**Train**: G Loss: 119.9874, D Loss: 0.0275
Epoch[4780/50000]
**Valid**: G Loss: 91.5837, D Loss: 1.9599
Epoch[4790/50000]
**Train**: G Loss: 26.8110, D Loss: -0.7406
Epoch[4790/50000]
**Valid**: G Loss: 9.4532, D Loss: -0.2393
Epoch[4800/50000]
**Train**: G Loss: -29.9850, D Loss: -1.2201
Epoch[4800/50000]
**Valid**: G Loss: -42.5985, D Loss: 0.3935
Epoch[4810/50000]
**Train**: G Loss: 23.5340, D Loss: -0.1099
Epoch[4810/50000]
**Valid**: G Loss: -37.4712, D Loss: -2.6029
Epoch[4820/50000]
**Train**: G Loss: 46.2749, D Loss: 0.1004
Epoch[4820/50000]
**Valid**: G Loss: -13.9395, D Loss: -2.4407
Epoch[4830/50000]
**Train**: G Loss: 79.5128, D Loss: 0.0399
Epoch[4830/50000]
**Valid**: G Loss: 92.3487, D Loss: 0.7748
Epoch[4840/50000]
**Train**: G Loss: 81.6972, D Loss: -0.1720
Epoch[4840/50000]
**Valid**: G Loss: 92.3689, D Loss: 1.9477
Epoch[4850/50000]
**Train**: G Loss: 115.2296, D Loss: -0.4029
Epoch[4850/50000]
**Valid**: G Loss: 89.5499, D Loss: 2.4636
Epoch[4860/50000]
**Train**: G Loss: 128.0970, D Loss: -1.1483
Epoch[4860/50000]
**Valid**: G Loss: 92.4263, D Loss: 2.2167
Epoch[4870/50000]
**Train**: G Loss: 101.7393, D Loss: -0.6449
Epoch[4870/50000]
**Valid**: G Loss: 82.9289, D Loss: 2.2249
Epoch[4880/50000]
**Train**: G Loss: 64.3040, D Loss: -0.5218
Epoch[4880/50000]
**Valid**: G Loss: 35.8185, D Loss: 2.9166
Epoch[4890/50000]
**Train**: G Loss: 33.5714, D Loss: 0.0339
Epoch[4890/50000]
**Valid**: G Loss: -13.7286, D Loss: -2.1160
Epoch[4900/50000]
**Train**: G Loss: 92.0735, D Loss: -0.0932
Epoch[4900/50000]
**Valid**: G Loss: 70.6229, D Loss: 1.0857
Epoch[4910/50000]
**Train**: G Loss: -0.2075, D Loss: -0.8054
Epoch[4910/50000]
**Valid**: G Loss: -45.0301, D Loss: -1.3172
Epoch[4920/50000]
**Train**: G Loss: 67.3015, D Loss: 1.7086
Epoch[4920/50000]
**Valid**: G Loss: 32.4195, D Loss: 0.3023
Epoch[4930/50000]
**Train**: G Loss: -30.0830, D Loss: -1.4333
Epoch[4930/50000]
**Valid**: G Loss: -34.4696, D Loss: 0.5743
Epoch[4940/50000]
**Train**: G Loss: 16.0697, D Loss: -0.4057
Epoch[4940/50000]
**Valid**: G Loss: -30.4661, D Loss: -1.7882
Epoch[4950/50000]
**Train**: G Loss: 0.9416, D Loss: -1.2016
Epoch[4950/50000]
**Valid**: G Loss: -25.5615, D Loss: -0.3154
Epoch[4960/50000]
**Train**: G Loss: -21.6034, D Loss: -1.2965
Epoch[4960/50000]
**Valid**: G Loss: -8.8473, D Loss: 1.1973
Epoch[4970/50000]
**Train**: G Loss: 50.6015, D Loss: 0.0497
Epoch[4970/50000]
**Valid**: G Loss: 56.5094, D Loss: 2.0169
Epoch[4980/50000]
**Train**: G Loss: 44.6923, D Loss: -0.7376
Epoch[4980/50000]
**Valid**: G Loss: 27.7609, D Loss: 0.4652
Epoch[4990/50000]
**Train**: G Loss: 54.8739, D Loss: 0.7721
Epoch[4990/50000]
**Valid**: G Loss: 135.3306, D Loss: -2.6374
Epoch[5000/50000]
**Train**: G Loss: 40.0907, D Loss: 0.7677
Epoch[5000/50000]
**Valid**: G Loss: 98.7640, D Loss: -1.3694
Epoch[5010/50000]
**Train**: G Loss: 136.2464, D Loss: -0.8336
Epoch[5010/50000]
**Valid**: G Loss: 105.0452, D Loss: 2.2842
Epoch[5020/50000]
**Train**: G Loss: 127.7030, D Loss: -0.5791
Epoch[5020/50000]
**Valid**: G Loss: 93.4667, D Loss: 2.2851
Epoch[5030/50000]
**Train**: G Loss: 19.1218, D Loss: -0.7253
Epoch[5030/50000]
**Valid**: G Loss: 2.0647, D Loss: -0.2293
Epoch[5040/50000]
**Train**: G Loss: 85.9063, D Loss: 0.2369
Epoch[5040/50000]
**Valid**: G Loss: 102.5310, D Loss: 1.5908
Epoch[5050/50000]
**Train**: G Loss: 86.7470, D Loss: -0.0667
Epoch[5050/50000]
**Valid**: G Loss: 69.7324, D Loss: -0.5384
Epoch[5060/50000]
**Train**: G Loss: 137.7858, D Loss: -0.3314
Epoch[5060/50000]
**Valid**: G Loss: 132.2343, D Loss: 1.2685
Epoch[5070/50000]
**Train**: G Loss: 19.5894, D Loss: -1.2981
Epoch[5070/50000]
**Valid**: G Loss: 17.8541, D Loss: 0.7537
Epoch[5080/50000]
**Train**: G Loss: 54.6532, D Loss: -0.2754
Epoch[5080/50000]
**Valid**: G Loss: 7.7834, D Loss: -1.2582
Epoch[5090/50000]
**Train**: G Loss: 91.0812, D Loss: 0.0002
Epoch[5090/50000]
**Valid**: G Loss: 70.2543, D Loss: -0.4674
Epoch[5100/50000]
**Train**: G Loss: 69.0709, D Loss: 0.1540
Epoch[5100/50000]
**Valid**: G Loss: 55.7667, D Loss: -0.5830
Epoch[5110/50000]
**Train**: G Loss: 31.8028, D Loss: 0.5681
Epoch[5110/50000]
**Valid**: G Loss: 61.1945, D Loss: 1.4105
Epoch[5120/50000]
**Train**: G Loss: 43.5657, D Loss: -0.1635
Epoch[5120/50000]
**Valid**: G Loss: 35.2424, D Loss: 0.1584
Epoch[5130/50000]
**Train**: G Loss: 84.6404, D Loss: 0.3131
Epoch[5130/50000]
**Valid**: G Loss: 44.2568, D Loss: -1.6427
Epoch[5140/50000]
**Train**: G Loss: 75.7392, D Loss: 0.2155
Epoch[5140/50000]
**Valid**: G Loss: 163.9761, D Loss: -1.0860
Epoch[5150/50000]
**Train**: G Loss: 33.6067, D Loss: -0.8927
Epoch[5150/50000]
**Valid**: G Loss: 39.6452, D Loss: 0.9877
Epoch[5160/50000]
**Train**: G Loss: 63.3670, D Loss: 0.2302
Epoch[5160/50000]
**Valid**: G Loss: 116.7416, D Loss: 0.0801
Epoch[5170/50000]
**Train**: G Loss: 43.5586, D Loss: 0.7695
Epoch[5170/50000]
**Valid**: G Loss: 76.1761, D Loss: 0.6375
Epoch[5180/50000]
**Train**: G Loss: 113.1110, D Loss: 0.8139
Epoch[5180/50000]
**Valid**: G Loss: 75.4438, D Loss: 1.3138
Epoch[5190/50000]
**Train**: G Loss: 93.7665, D Loss: 1.2752
Epoch[5190/50000]
**Valid**: G Loss: 65.4039, D Loss: 1.1392
Epoch[5200/50000]
**Train**: G Loss: 25.2965, D Loss: -1.3947
Epoch[5200/50000]
**Valid**: G Loss: 20.7480, D Loss: 0.5773
Epoch[5210/50000]
**Train**: G Loss: 55.4325, D Loss: 0.1683
Epoch[5210/50000]
**Valid**: G Loss: 67.5437, D Loss: -0.5699
Epoch[5220/50000]
**Train**: G Loss: 18.9946, D Loss: -0.7998
Epoch[5220/50000]
**Valid**: G Loss: -14.6819, D Loss: -0.6592
Epoch[5230/50000]
**Train**: G Loss: 48.9319, D Loss: 0.7436
Epoch[5230/50000]
**Valid**: G Loss: -27.6436, D Loss: -3.3849
Epoch[5240/50000]
**Train**: G Loss: 64.7594, D Loss: 0.5385
Epoch[5240/50000]
**Valid**: G Loss: 114.2740, D Loss: -1.0343
Epoch[5250/50000]
**Train**: G Loss: 39.1860, D Loss: 0.2922
Epoch[5250/50000]
**Valid**: G Loss: 3.7402, D Loss: -1.8473
Epoch[5260/50000]
**Train**: G Loss: 78.6899, D Loss: 0.0637
Epoch[5260/50000]
**Valid**: G Loss: 130.2135, D Loss: -0.5578
Epoch[5270/50000]
**Train**: G Loss: 28.9370, D Loss: -0.8182
Epoch[5270/50000]
**Valid**: G Loss: 12.7982, D Loss: -0.6528
Epoch[5280/50000]
**Train**: G Loss: 89.7050, D Loss: 0.5175
Epoch[5280/50000]
**Valid**: G Loss: 200.9503, D Loss: -1.5555
Epoch[5290/50000]
**Train**: G Loss: 54.5011, D Loss: 0.5586
Epoch[5290/50000]
**Valid**: G Loss: 170.5865, D Loss: -1.8973
Epoch[5300/50000]
**Train**: G Loss: -1.0416, D Loss: 1.4785
Epoch[5300/50000]
**Valid**: G Loss: 51.1052, D Loss: 1.7305
Epoch[5310/50000]
**Train**: G Loss: 12.4739, D Loss: -1.0072
Epoch[5310/50000]
**Valid**: G Loss: -23.4503, D Loss: -1.4936
Epoch[5320/50000]
**Train**: G Loss: 97.0167, D Loss: 0.8417
Epoch[5320/50000]
**Valid**: G Loss: 73.4357, D Loss: 2.3557
Epoch[5330/50000]
**Train**: G Loss: 96.6100, D Loss: -0.6418
Epoch[5330/50000]
**Valid**: G Loss: 123.5488, D Loss: -0.1215
Epoch[5340/50000]
**Train**: G Loss: 99.0489, D Loss: 0.1714
Epoch[5340/50000]
**Valid**: G Loss: 80.3262, D Loss: -0.0213
Epoch[5350/50000]
**Train**: G Loss: 75.6313, D Loss: 0.2226
Epoch[5350/50000]
**Valid**: G Loss: 55.6102, D Loss: -0.7480
Epoch[5360/50000]
**Train**: G Loss: 100.9572, D Loss: 0.4122
Epoch[5360/50000]
**Valid**: G Loss: 59.2570, D Loss: 1.0959
Epoch[5370/50000]
**Train**: G Loss: 56.8876, D Loss: -0.6080
Epoch[5370/50000]
**Valid**: G Loss: 57.7113, D Loss: 0.7493
Epoch[5380/50000]
**Train**: G Loss: 71.9120, D Loss: 0.4106
Epoch[5380/50000]
**Valid**: G Loss: 130.7627, D Loss: -1.6774
Epoch[5390/50000]
**Train**: G Loss: 127.5426, D Loss: 0.0622
Epoch[5390/50000]
**Valid**: G Loss: 99.0774, D Loss: 2.2131
Epoch[5400/50000]
**Train**: G Loss: 78.9302, D Loss: 0.6124
Epoch[5400/50000]
**Valid**: G Loss: 173.9044, D Loss: -2.9319
Epoch[5410/50000]
**Train**: G Loss: 14.8607, D Loss: -1.5511
Epoch[5410/50000]
**Valid**: G Loss: 18.1627, D Loss: 1.4952
Epoch[5420/50000]
**Train**: G Loss: 34.4500, D Loss: -1.1160
Epoch[5420/50000]
**Valid**: G Loss: 24.1439, D Loss: -0.1853
Epoch[5430/50000]
**Train**: G Loss: 56.2247, D Loss: 0.0466
Epoch[5430/50000]
**Valid**: G Loss: 82.9918, D Loss: -0.0036
Epoch[5440/50000]
**Train**: G Loss: 79.3082, D Loss: 1.2485
Epoch[5440/50000]
**Valid**: G Loss: 23.6946, D Loss: -1.4025
Epoch[5450/50000]
**Train**: G Loss: 53.1121, D Loss: 0.0624
Epoch[5450/50000]
**Valid**: G Loss: 86.2869, D Loss: 0.0747
Epoch[5460/50000]
**Train**: G Loss: 128.9559, D Loss: 0.3335
Epoch[5460/50000]
**Valid**: G Loss: 83.7483, D Loss: 0.6021
Epoch[5470/50000]
**Train**: G Loss: 100.9441, D Loss: -0.8540
Epoch[5470/50000]
**Valid**: G Loss: 99.9183, D Loss: 1.0342
Epoch[5480/50000]
**Train**: G Loss: 136.2156, D Loss: -1.2659
Epoch[5480/50000]
**Valid**: G Loss: 119.8289, D Loss: 1.1105
Epoch[5490/50000]
**Train**: G Loss: 70.6977, D Loss: 0.1722
Epoch[5490/50000]
**Valid**: G Loss: 146.7302, D Loss: -1.8775
Epoch[5500/50000]
**Train**: G Loss: -26.8286, D Loss: -2.4509
Epoch[5500/50000]
**Valid**: G Loss: -27.1317, D Loss: 0.9104
Epoch[5510/50000]
**Train**: G Loss: 133.6138, D Loss: -0.7669
Epoch[5510/50000]
**Valid**: G Loss: 103.9844, D Loss: 2.3504
Epoch[5520/50000]
**Train**: G Loss: 119.5533, D Loss: -0.0587
Epoch[5520/50000]
**Valid**: G Loss: 122.0937, D Loss: 1.6153
Epoch[5530/50000]
**Train**: G Loss: 73.7389, D Loss: -0.1356
Epoch[5530/50000]
**Valid**: G Loss: 63.9309, D Loss: 0.3684
Epoch[5540/50000]
**Train**: G Loss: 113.3900, D Loss: -1.1681
Epoch[5540/50000]
**Valid**: G Loss: 97.4787, D Loss: 1.7274
Epoch[5550/50000]
**Train**: G Loss: 67.4257, D Loss: 0.5675
Epoch[5550/50000]
**Valid**: G Loss: 163.8254, D Loss: -2.6573
Epoch[5560/50000]
**Train**: G Loss: -1.4927, D Loss: 1.1610
Epoch[5560/50000]
**Valid**: G Loss: 44.5886, D Loss: 1.1357
Epoch[5570/50000]
**Train**: G Loss: -25.9280, D Loss: -1.3152
Epoch[5570/50000]
**Valid**: G Loss: -8.5442, D Loss: 2.2735
Epoch[5580/50000]
**Train**: G Loss: 76.2879, D Loss: 1.5701
Epoch[5580/50000]
**Valid**: G Loss: 34.5510, D Loss: 0.1442
Epoch[5590/50000]
**Train**: G Loss: 148.5889, D Loss: -1.4376
Epoch[5590/50000]
**Valid**: G Loss: 120.5479, D Loss: 1.8336
Epoch[5600/50000]
**Train**: G Loss: 21.0925, D Loss: 1.4701
Epoch[5600/50000]
**Valid**: G Loss: 75.5193, D Loss: -0.8502
Epoch[5610/50000]
**Train**: G Loss: 14.3036, D Loss: 0.3659
Epoch[5610/50000]
**Valid**: G Loss: 48.3343, D Loss: 0.2172
Epoch[5620/50000]
**Train**: G Loss: 71.1446, D Loss: 0.6119
Epoch[5620/50000]
**Valid**: G Loss: 39.9789, D Loss: -1.2260
Epoch[5630/50000]
**Train**: G Loss: 48.0179, D Loss: 0.8888
Epoch[5630/50000]
**Valid**: G Loss: -46.0763, D Loss: -3.5337
Epoch[5640/50000]
**Train**: G Loss: 119.7201, D Loss: -1.3437
Epoch[5640/50000]
**Valid**: G Loss: 102.7182, D Loss: 1.8066
Epoch[5650/50000]
**Train**: G Loss: 113.3349, D Loss: -0.5045
Epoch[5650/50000]
**Valid**: G Loss: 158.7259, D Loss: -0.5542
Epoch[5660/50000]
**Train**: G Loss: -18.0000, D Loss: -0.1646
Epoch[5660/50000]
**Valid**: G Loss: 2.4642, D Loss: 2.9361
Epoch[5670/50000]
**Train**: G Loss: 85.4300, D Loss: 1.7489
Epoch[5670/50000]
**Valid**: G Loss: 50.7824, D Loss: 1.2908
Epoch[5680/50000]
**Train**: G Loss: 59.9383, D Loss: 1.0906
Epoch[5680/50000]
**Valid**: G Loss: 174.6723, D Loss: -3.3044
Epoch[5690/50000]
**Train**: G Loss: 16.2307, D Loss: -0.1737
Epoch[5690/50000]
**Valid**: G Loss: -46.8543, D Loss: -2.3995
Epoch[5700/50000]
**Train**: G Loss: 63.4666, D Loss: 0.7551
Epoch[5700/50000]
**Valid**: G Loss: 152.1893, D Loss: -3.0793
Epoch[5710/50000]
**Train**: G Loss: 5.6066, D Loss: -0.6844
Epoch[5710/50000]
**Valid**: G Loss: -40.8719, D Loss: -1.7716
Epoch[5720/50000]
**Train**: G Loss: 115.3493, D Loss: -0.8949
Epoch[5720/50000]
**Valid**: G Loss: 135.2074, D Loss: -0.3073
Epoch[5730/50000]
**Train**: G Loss: -27.9412, D Loss: -1.5491
Epoch[5730/50000]
**Valid**: G Loss: -17.8007, D Loss: 1.4113
Epoch[5740/50000]
**Train**: G Loss: 69.8162, D Loss: 1.2764
Epoch[5740/50000]
**Valid**: G Loss: -13.0004, D Loss: -1.9701
Epoch[5750/50000]
**Train**: G Loss: 124.7158, D Loss: -1.1396
Epoch[5750/50000]
**Valid**: G Loss: 137.0256, D Loss: -0.2998
Epoch[5760/50000]
**Train**: G Loss: -27.4455, D Loss: -1.5940
Epoch[5760/50000]
**Valid**: G Loss: -18.9517, D Loss: 1.6567
Epoch[5770/50000]
**Train**: G Loss: 117.3257, D Loss: -0.2463
Epoch[5770/50000]
**Valid**: G Loss: 96.3779, D Loss: 2.2277
Epoch[5780/50000]
**Train**: G Loss: -9.5681, D Loss: -0.7284
Epoch[5780/50000]
**Valid**: G Loss: 2.6576, D Loss: 1.9566
Epoch[5790/50000]
**Train**: G Loss: 119.8597, D Loss: -0.3910
Epoch[5790/50000]
**Valid**: G Loss: 95.8175, D Loss: 2.3797
Epoch[5800/50000]
**Train**: G Loss: 68.9922, D Loss: 0.3353
Epoch[5800/50000]
**Valid**: G Loss: 151.7125, D Loss: -2.0907
Epoch[5810/50000]
**Train**: G Loss: -15.0922, D Loss: -0.9944
Epoch[5810/50000]
**Valid**: G Loss: -10.6368, D Loss: 1.5144
Epoch[5820/50000]
**Train**: G Loss: 28.8421, D Loss: -0.0037
Epoch[5820/50000]
**Valid**: G Loss: -5.5728, D Loss: -0.9987
Epoch[5830/50000]
**Train**: G Loss: 47.6854, D Loss: -0.2777
Epoch[5830/50000]
**Valid**: G Loss: 19.0495, D Loss: -0.9170
Epoch[5840/50000]
**Train**: G Loss: 27.8570, D Loss: 0.3141
Epoch[5840/50000]
**Valid**: G Loss: 41.3800, D Loss: 0.9653
Epoch[5850/50000]
**Train**: G Loss: 67.2269, D Loss: -0.0109
Epoch[5850/50000]
**Valid**: G Loss: 41.1338, D Loss: -0.6035
Epoch[5860/50000]
**Train**: G Loss: 70.9229, D Loss: 0.3916
Epoch[5860/50000]
**Valid**: G Loss: 49.1526, D Loss: -1.0593
Epoch[5870/50000]
**Train**: G Loss: -23.1855, D Loss: -1.3499
Epoch[5870/50000]
**Valid**: G Loss: -11.0848, D Loss: 1.5157
Epoch[5880/50000]
**Train**: G Loss: 93.7151, D Loss: 1.5912
Epoch[5880/50000]
**Valid**: G Loss: 74.7455, D Loss: 2.1350
Epoch[5890/50000]
**Train**: G Loss: 68.5004, D Loss: 0.2440
Epoch[5890/50000]
**Valid**: G Loss: 142.7807, D Loss: -1.7274
Epoch[5900/50000]
**Train**: G Loss: -29.3076, D Loss: -1.5896
Epoch[5900/50000]
**Valid**: G Loss: -48.0286, D Loss: -0.1265
Epoch[5910/50000]
**Train**: G Loss: 119.9020, D Loss: 0.3239
Epoch[5910/50000]
**Valid**: G Loss: 96.5157, D Loss: 2.1046
Epoch[5920/50000]
**Train**: G Loss: 84.0671, D Loss: -0.0051
Epoch[5920/50000]
**Valid**: G Loss: 69.7108, D Loss: 1.6700
Epoch[5930/50000]
**Train**: G Loss: 99.8404, D Loss: -0.2410
Epoch[5930/50000]
**Valid**: G Loss: 154.9348, D Loss: -0.8884
Epoch[5940/50000]
**Train**: G Loss: 4.1303, D Loss: 0.8323
Epoch[5940/50000]
**Valid**: G Loss: 21.1419, D Loss: 1.5856
Epoch[5950/50000]
**Train**: G Loss: 25.2645, D Loss: -0.3191
Epoch[5950/50000]
**Valid**: G Loss: 25.4388, D Loss: 0.9417
Epoch[5960/50000]
**Train**: G Loss: 84.4817, D Loss: 0.2436
Epoch[5960/50000]
**Valid**: G Loss: 64.5171, D Loss: 0.1782
Epoch[5970/50000]
**Train**: G Loss: 29.9764, D Loss: -0.3619
Epoch[5970/50000]
**Valid**: G Loss: 32.7647, D Loss: 0.9521
Epoch[5980/50000]
**Train**: G Loss: 135.9471, D Loss: -0.7479
Epoch[5980/50000]
**Valid**: G Loss: 130.3451, D Loss: 1.1215
Epoch[5990/50000]
**Train**: G Loss: 86.4642, D Loss: -0.0054
Epoch[5990/50000]
**Valid**: G Loss: 138.0316, D Loss: 0.7353
Epoch[6000/50000]
**Train**: G Loss: 41.7550, D Loss: -0.7110
Epoch[6000/50000]
**Valid**: G Loss: 31.4717, D Loss: 0.6011
Epoch[6010/50000]
**Train**: G Loss: 88.5759, D Loss: 0.0847
Epoch[6010/50000]
**Valid**: G Loss: 101.9452, D Loss: 1.6975
Epoch[6020/50000]
**Train**: G Loss: 38.0181, D Loss: -0.2078
Epoch[6020/50000]
**Valid**: G Loss: 39.5121, D Loss: 1.1119
Epoch[6030/50000]
**Train**: G Loss: 51.7300, D Loss: -0.5841
Epoch[6030/50000]
**Valid**: G Loss: 43.2862, D Loss: 0.5955
Epoch[6040/50000]
**Train**: G Loss: 94.8052, D Loss: 0.3342
Epoch[6040/50000]
**Valid**: G Loss: 122.8903, D Loss: 1.7009
Epoch[6050/50000]
**Train**: G Loss: 47.2465, D Loss: 0.9527
Epoch[6050/50000]
**Valid**: G Loss: 74.6716, D Loss: 0.3576
Epoch[6060/50000]
**Train**: G Loss: 120.7463, D Loss: -0.1917
Epoch[6060/50000]
**Valid**: G Loss: 163.8814, D Loss: -0.1071
Epoch[6070/50000]
**Train**: G Loss: 73.7019, D Loss: 0.7509
Epoch[6070/50000]
**Valid**: G Loss: 193.5890, D Loss: -2.1401
Epoch[6080/50000]
**Train**: G Loss: -18.6319, D Loss: -0.4124
Epoch[6080/50000]
**Valid**: G Loss: -4.9533, D Loss: 2.2193
Epoch[6090/50000]
**Train**: G Loss: 86.1491, D Loss: 1.9542
Epoch[6090/50000]
**Valid**: G Loss: 48.9060, D Loss: 0.4506
Epoch[6100/50000]
**Train**: G Loss: 101.4692, D Loss: -0.2481
Epoch[6100/50000]
**Valid**: G Loss: 153.8464, D Loss: -1.5274
Epoch[6110/50000]
**Train**: G Loss: 7.4694, D Loss: -2.0049
Epoch[6110/50000]
**Valid**: G Loss: 6.2424, D Loss: 0.3569
Epoch[6120/50000]
**Train**: G Loss: 51.5350, D Loss: -0.6305
Epoch[6120/50000]
**Valid**: G Loss: 34.9707, D Loss: -0.0184
Epoch[6130/50000]
**Train**: G Loss: 118.5542, D Loss: 0.1678
Epoch[6130/50000]
**Valid**: G Loss: 128.5310, D Loss: 1.2514
Epoch[6140/50000]
**Train**: G Loss: 66.4800, D Loss: 0.2674
Epoch[6140/50000]
**Valid**: G Loss: 100.7528, D Loss: -0.4443
Epoch[6150/50000]
**Train**: G Loss: 52.9781, D Loss: -0.0707
Epoch[6150/50000]
**Valid**: G Loss: 61.7406, D Loss: 0.4383
Epoch[6160/50000]
**Train**: G Loss: 20.5905, D Loss: -1.3674
Epoch[6160/50000]
**Valid**: G Loss: 13.9732, D Loss: 0.6717
Epoch[6170/50000]
**Train**: G Loss: 114.3906, D Loss: -0.2141
Epoch[6170/50000]
**Valid**: G Loss: 143.0111, D Loss: -0.2127
Epoch[6180/50000]
**Train**: G Loss: 15.1456, D Loss: 1.3816
Epoch[6180/50000]
**Valid**: G Loss: 83.9022, D Loss: 0.4754
Epoch[6190/50000]
**Train**: G Loss: -8.9013, D Loss: -1.7917
Epoch[6190/50000]
**Valid**: G Loss: -3.9817, D Loss: 1.0822
Epoch[6200/50000]
**Train**: G Loss: 39.7961, D Loss: 0.0799
Epoch[6200/50000]
**Valid**: G Loss: 49.1194, D Loss: 0.7616
Epoch[6210/50000]
**Train**: G Loss: 57.9114, D Loss: -0.2164
Epoch[6210/50000]
**Valid**: G Loss: 71.0919, D Loss: 0.3789
Epoch[6220/50000]
**Train**: G Loss: 109.5909, D Loss: 0.1070
Epoch[6220/50000]
**Valid**: G Loss: 174.9162, D Loss: -1.0525
Epoch[6230/50000]
**Train**: G Loss: -11.4863, D Loss: 0.0030
Epoch[6230/50000]
**Valid**: G Loss: 13.8277, D Loss: 2.0199
Epoch[6240/50000]
**Train**: G Loss: 4.1639, D Loss: -1.2987
Epoch[6240/50000]
**Valid**: G Loss: 2.5507, D Loss: 0.5568
Epoch[6250/50000]
**Train**: G Loss: 82.9451, D Loss: 1.1569
Epoch[6250/50000]
**Valid**: G Loss: 53.6370, D Loss: 0.1290
Epoch[6260/50000]
**Train**: G Loss: 42.1696, D Loss: 0.6707
Epoch[6260/50000]
**Valid**: G Loss: -60.2293, D Loss: -2.6837
Epoch[6270/50000]
**Train**: G Loss: 153.6866, D Loss: -1.2823
Epoch[6270/50000]
**Valid**: G Loss: 135.8530, D Loss: 1.0504
Epoch[6280/50000]
**Train**: G Loss: -2.0563, D Loss: 0.4545
Epoch[6280/50000]
**Valid**: G Loss: 13.5295, D Loss: 2.3152
Epoch[6290/50000]
**Train**: G Loss: 83.8688, D Loss: 1.7573
Epoch[6290/50000]
**Valid**: G Loss: 50.5654, D Loss: 0.0248
Epoch[6300/50000]
**Train**: G Loss: 128.4116, D Loss: 0.0829
Epoch[6300/50000]
**Valid**: G Loss: 114.4538, D Loss: 1.6400
Epoch[6310/50000]
**Train**: G Loss: 71.2424, D Loss: 0.1204
Epoch[6310/50000]
**Valid**: G Loss: 74.7415, D Loss: 0.1282
Epoch[6320/50000]
**Train**: G Loss: 76.1909, D Loss: 1.4166
Epoch[6320/50000]
**Valid**: G Loss: 42.6970, D Loss: 0.4131
Epoch[6330/50000]
**Train**: G Loss: 150.2857, D Loss: -1.3540
Epoch[6330/50000]
**Valid**: G Loss: 128.8624, D Loss: 1.5162
Epoch[6340/50000]
**Train**: G Loss: 32.6817, D Loss: 1.3370
Epoch[6340/50000]
**Valid**: G Loss: 107.9311, D Loss: -0.3636
Epoch[6350/50000]
**Train**: G Loss: 9.0897, D Loss: -0.6463
Epoch[6350/50000]
**Valid**: G Loss: -37.5982, D Loss: -1.5645
Epoch[6360/50000]
**Train**: G Loss: 116.2531, D Loss: -0.6186
Epoch[6360/50000]
**Valid**: G Loss: 94.2348, D Loss: 2.4788
Epoch[6370/50000]
**Train**: G Loss: 111.1982, D Loss: 0.5228
Epoch[6370/50000]
**Valid**: G Loss: 98.5080, D Loss: 0.4294
Epoch[6380/50000]
**Train**: G Loss: 58.6937, D Loss: -0.2261
Epoch[6380/50000]
**Valid**: G Loss: 49.5540, D Loss: 0.7267
Epoch[6390/50000]
**Train**: G Loss: -9.2269, D Loss: -1.1927
Epoch[6390/50000]
**Valid**: G Loss: -32.6897, D Loss: -0.6151
Epoch[6400/50000]
**Train**: G Loss: 144.9602, D Loss: -1.6708
Epoch[6400/50000]
**Valid**: G Loss: 116.0891, D Loss: 1.5425
Epoch[6410/50000]
**Train**: G Loss: -38.3579, D Loss: -1.0971
Epoch[6410/50000]
**Valid**: G Loss: -23.1525, D Loss: 1.8910
Epoch[6420/50000]
**Train**: G Loss: 119.8853, D Loss: 0.6631
Epoch[6420/50000]
**Valid**: G Loss: 94.1231, D Loss: 2.5403
Epoch[6430/50000]
**Train**: G Loss: -13.0997, D Loss: -1.8946
Epoch[6430/50000]
**Valid**: G Loss: -4.3059, D Loss: 1.5421
Epoch[6440/50000]
**Train**: G Loss: 110.0905, D Loss: 0.7626
Epoch[6440/50000]
**Valid**: G Loss: 76.4505, D Loss: 0.4240
Epoch[6450/50000]
**Train**: G Loss: 78.5875, D Loss: 0.2100
Epoch[6450/50000]
**Valid**: G Loss: 87.5594, D Loss: -0.1116
Epoch[6460/50000]
**Train**: G Loss: 46.8621, D Loss: -0.4447
Epoch[6460/50000]
**Valid**: G Loss: 51.5900, D Loss: 1.6581
Epoch[6470/50000]
**Train**: G Loss: -15.2935, D Loss: -1.3581
Epoch[6470/50000]
**Valid**: G Loss: -6.4958, D Loss: 1.4742
Epoch[6480/50000]
**Train**: G Loss: 82.6088, D Loss: 1.4468
Epoch[6480/50000]
**Valid**: G Loss: 18.2005, D Loss: -1.2000
Epoch[6490/50000]
**Train**: G Loss: 84.7125, D Loss: 0.1745
Epoch[6490/50000]
**Valid**: G Loss: 162.3800, D Loss: -1.8872
Epoch[6500/50000]
**Train**: G Loss: 6.8657, D Loss: -0.2794
Epoch[6500/50000]
**Valid**: G Loss: -30.4704, D Loss: -1.1283
Epoch[6510/50000]
**Train**: G Loss: 128.7499, D Loss: -1.4168
Epoch[6510/50000]
**Valid**: G Loss: 111.9341, D Loss: 1.5047
Epoch[6520/50000]
**Train**: G Loss: -33.7119, D Loss: -1.7484
Epoch[6520/50000]
**Valid**: G Loss: -29.1007, D Loss: 0.5227
Epoch[6530/50000]
**Train**: G Loss: 139.0397, D Loss: -1.2071
Epoch[6530/50000]
**Valid**: G Loss: 112.6861, D Loss: 1.6043
Epoch[6540/50000]
**Train**: G Loss: -12.0041, D Loss: -1.4734
Epoch[6540/50000]
**Valid**: G Loss: -4.0512, D Loss: 1.2446
Epoch[6550/50000]
**Train**: G Loss: 123.8520, D Loss: 0.2321
Epoch[6550/50000]
**Valid**: G Loss: 98.7948, D Loss: 2.1825
Epoch[6560/50000]
**Train**: G Loss: -24.8574, D Loss: -1.3572
Epoch[6560/50000]
**Valid**: G Loss: -16.9037, D Loss: 1.7581
Epoch[6570/50000]
**Train**: G Loss: 140.3857, D Loss: -1.3280
Epoch[6570/50000]
**Valid**: G Loss: 116.8503, D Loss: 1.6347
Epoch[6580/50000]
**Train**: G Loss: -28.2272, D Loss: -1.8016
Epoch[6580/50000]
**Valid**: G Loss: -31.3223, D Loss: 0.1137
Epoch[6590/50000]
**Train**: G Loss: 134.1467, D Loss: -0.2625
Epoch[6590/50000]
**Valid**: G Loss: 109.5573, D Loss: 2.3692
Epoch[6600/50000]
**Train**: G Loss: -28.1574, D Loss: -2.1546
Epoch[6600/50000]
**Valid**: G Loss: -21.8889, D Loss: 0.4635
Epoch[6610/50000]
**Train**: G Loss: 141.6480, D Loss: -1.0930
Epoch[6610/50000]
**Valid**: G Loss: 124.5886, D Loss: 1.6038
Epoch[6620/50000]
**Train**: G Loss: 18.9113, D Loss: 0.8209
Epoch[6620/50000]
**Valid**: G Loss: 47.9919, D Loss: 0.7266
Epoch[6630/50000]
**Train**: G Loss: 30.4340, D Loss: 0.8816
Epoch[6630/50000]
**Valid**: G Loss: 60.5212, D Loss: 0.0631
Epoch[6640/50000]
**Train**: G Loss: 113.6565, D Loss: 0.5654
Epoch[6640/50000]
**Valid**: G Loss: 105.3727, D Loss: 0.1865
Epoch[6650/50000]
**Train**: G Loss: 54.1411, D Loss: 0.9038
Epoch[6650/50000]
**Valid**: G Loss: 91.8227, D Loss: 0.0423
Epoch[6660/50000]
**Train**: G Loss: 91.4289, D Loss: 0.3973
Epoch[6660/50000]
**Valid**: G Loss: 95.6540, D Loss: 1.5787
Epoch[6670/50000]
**Train**: G Loss: 41.4308, D Loss: -0.6199
Epoch[6670/50000]
**Valid**: G Loss: 36.2167, D Loss: 0.7126
Epoch[6680/50000]
**Train**: G Loss: 44.6625, D Loss: 0.5755
Epoch[6680/50000]
**Valid**: G Loss: 55.6116, D Loss: 0.9043
Epoch[6690/50000]
**Train**: G Loss: 83.3551, D Loss: 0.1290
Epoch[6690/50000]
**Valid**: G Loss: 108.4316, D Loss: 0.5078
Epoch[6700/50000]
**Train**: G Loss: 74.2907, D Loss: 0.2380
Epoch[6700/50000]
**Valid**: G Loss: 128.0777, D Loss: 0.0565
Epoch[6710/50000]
**Train**: G Loss: 88.1053, D Loss: 0.3756
Epoch[6710/50000]
**Valid**: G Loss: 48.6311, D Loss: -1.3889
Epoch[6720/50000]
**Train**: G Loss: 44.6021, D Loss: 0.1119
Epoch[6720/50000]
**Valid**: G Loss: -10.4517, D Loss: -1.8453
Epoch[6730/50000]
**Train**: G Loss: 158.6618, D Loss: -1.2641
Epoch[6730/50000]
**Valid**: G Loss: 140.0535, D Loss: 1.2640
Epoch[6740/50000]
**Train**: G Loss: -44.1341, D Loss: -1.7644
Epoch[6740/50000]
**Valid**: G Loss: -34.8916, D Loss: 1.4553
Epoch[6750/50000]
**Train**: G Loss: 143.5205, D Loss: -1.4801
Epoch[6750/50000]
**Valid**: G Loss: 116.9669, D Loss: 1.5983
Epoch[6760/50000]
**Train**: G Loss: 8.1802, D Loss: -0.0325
Epoch[6760/50000]
**Valid**: G Loss: 20.3977, D Loss: 1.9217
Epoch[6770/50000]
**Train**: G Loss: 89.7877, D Loss: 1.4063
Epoch[6770/50000]
**Valid**: G Loss: 75.8266, D Loss: 2.1628
Epoch[6780/50000]
**Train**: G Loss: -6.5303, D Loss: -0.3127
Epoch[6780/50000]
**Valid**: G Loss: 6.0307, D Loss: 1.8971
Epoch[6790/50000]
**Train**: G Loss: 94.6542, D Loss: 1.4358
Epoch[6790/50000]
**Valid**: G Loss: 68.3980, D Loss: 0.4837
Epoch[6800/50000]
**Train**: G Loss: 74.5004, D Loss: 0.7542
Epoch[6800/50000]
**Valid**: G Loss: 158.6271, D Loss: -1.2462
Epoch[6810/50000]
**Train**: G Loss: 25.2982, D Loss: 0.2047
Epoch[6810/50000]
**Valid**: G Loss: 32.7892, D Loss: 1.5153
Epoch[6820/50000]
**Train**: G Loss: 32.4220, D Loss: -1.2044
Epoch[6820/50000]
**Valid**: G Loss: 19.3153, D Loss: 0.1416
Epoch[6830/50000]
**Train**: G Loss: 55.4822, D Loss: -0.4871
Epoch[6830/50000]
**Valid**: G Loss: 28.8062, D Loss: -0.7490
Epoch[6840/50000]
**Train**: G Loss: 18.8355, D Loss: -0.9929
Epoch[6840/50000]
**Valid**: G Loss: 15.1085, D Loss: 0.4557
Epoch[6850/50000]
**Train**: G Loss: 32.3095, D Loss: -0.2920
Epoch[6850/50000]
**Valid**: G Loss: 35.6970, D Loss: 1.0851
Epoch[6860/50000]
**Train**: G Loss: 50.8838, D Loss: 0.7444
Epoch[6860/50000]
**Valid**: G Loss: 90.7222, D Loss: -0.2722
Epoch[6870/50000]
**Train**: G Loss: 90.6835, D Loss: 0.2590
Epoch[6870/50000]
**Valid**: G Loss: 90.2019, D Loss: 2.2819
Epoch[6880/50000]
**Train**: G Loss: 85.4114, D Loss: 0.2114
Epoch[6880/50000]
**Valid**: G Loss: 29.1697, D Loss: -1.1045
Epoch[6890/50000]
**Train**: G Loss: 43.2068, D Loss: -0.1565
Epoch[6890/50000]
**Valid**: G Loss: 44.0889, D Loss: 1.0609
Epoch[6900/50000]
**Train**: G Loss: 61.4155, D Loss: -0.0225
Epoch[6900/50000]
**Valid**: G Loss: 57.6202, D Loss: 1.0241
Epoch[6910/50000]
**Train**: G Loss: 154.4669, D Loss: -0.2850
Epoch[6910/50000]
**Valid**: G Loss: 117.6674, D Loss: 2.4628
Epoch[6920/50000]
**Train**: G Loss: 144.8701, D Loss: 0.4567
Epoch[6920/50000]
**Valid**: G Loss: 106.6267, D Loss: 2.0528
Epoch[6930/50000]
**Train**: G Loss: 115.5957, D Loss: 0.8770
Epoch[6930/50000]
**Valid**: G Loss: 67.5633, D Loss: -0.8239
Epoch[6940/50000]
**Train**: G Loss: 37.4504, D Loss: -0.6668
Epoch[6940/50000]
**Valid**: G Loss: 33.6869, D Loss: 0.9488
Epoch[6950/50000]
**Train**: G Loss: 113.2410, D Loss: 0.0601
Epoch[6950/50000]
**Valid**: G Loss: 122.0543, D Loss: 2.5499
Epoch[6960/50000]
**Train**: G Loss: 64.8176, D Loss: 0.3804
Epoch[6960/50000]
**Valid**: G Loss: 85.1477, D Loss: -0.3548
Epoch[6970/50000]
**Train**: G Loss: 120.7686, D Loss: -0.1370
Epoch[6970/50000]
**Valid**: G Loss: 164.0333, D Loss: 0.4417
Epoch[6980/50000]
**Train**: G Loss: 119.0180, D Loss: 0.2002
Epoch[6980/50000]
**Valid**: G Loss: 126.1237, D Loss: 1.5585
Epoch[6990/50000]
**Train**: G Loss: 53.6214, D Loss: 0.7402
Epoch[6990/50000]
**Valid**: G Loss: 73.0901, D Loss: 1.4589
Epoch[7000/50000]
**Train**: G Loss: 24.3601, D Loss: 0.3240
Epoch[7000/50000]
**Valid**: G Loss: 36.0327, D Loss: 1.0317
Epoch[7010/50000]
**Train**: G Loss: 91.0459, D Loss: 0.5924
Epoch[7010/50000]
**Valid**: G Loss: 67.0813, D Loss: -0.8406
Epoch[7020/50000]
**Train**: G Loss: 95.3872, D Loss: -0.3334
Epoch[7020/50000]
**Valid**: G Loss: 95.1329, D Loss: 1.1448
Epoch[7030/50000]
**Train**: G Loss: 90.6248, D Loss: 0.4997
Epoch[7030/50000]
**Valid**: G Loss: 201.4961, D Loss: -1.9172
Epoch[7040/50000]
**Train**: G Loss: -4.4891, D Loss: -0.7690
Epoch[7040/50000]
**Valid**: G Loss: 10.6218, D Loss: 1.7394
Epoch[7050/50000]
**Train**: G Loss: 9.7603, D Loss: -1.0050
Epoch[7050/50000]
**Valid**: G Loss: 17.0646, D Loss: 0.9528
Epoch[7060/50000]
**Train**: G Loss: 58.9078, D Loss: 0.4430
Epoch[7060/50000]
**Valid**: G Loss: 87.6705, D Loss: 0.2348
Epoch[7070/50000]
**Train**: G Loss: 53.1072, D Loss: 0.1026
Epoch[7070/50000]
**Valid**: G Loss: 19.6572, D Loss: -0.6920
Epoch[7080/50000]
**Train**: G Loss: 92.8152, D Loss: 0.7704
Epoch[7080/50000]
**Valid**: G Loss: 45.7663, D Loss: -1.7299
Epoch[7090/50000]
**Train**: G Loss: 75.4666, D Loss: 0.4693
Epoch[7090/50000]
**Valid**: G Loss: 66.7515, D Loss: -0.7593
Epoch[7100/50000]
**Train**: G Loss: 77.6183, D Loss: 0.4404
Epoch[7100/50000]
**Valid**: G Loss: 105.6153, D Loss: 0.5645
Epoch[7110/50000]
**Train**: G Loss: 93.6951, D Loss: 0.6202
Epoch[7110/50000]
**Valid**: G Loss: 79.8463, D Loss: -0.1264
Epoch[7120/50000]
**Train**: G Loss: 37.7566, D Loss: 0.8182
Epoch[7120/50000]
**Valid**: G Loss: 84.4223, D Loss: -0.4112
Epoch[7130/50000]
**Train**: G Loss: 20.3646, D Loss: 1.0185
Epoch[7130/50000]
**Valid**: G Loss: 79.0503, D Loss: -0.3350
Epoch[7140/50000]
**Train**: G Loss: 71.0040, D Loss: 0.4564
Epoch[7140/50000]
**Valid**: G Loss: 120.2354, D Loss: -0.0105
Epoch[7150/50000]
**Train**: G Loss: 102.2282, D Loss: 0.3703
Epoch[7150/50000]
**Valid**: G Loss: 80.2042, D Loss: 2.2868
Epoch[7160/50000]
**Train**: G Loss: 49.4063, D Loss: -0.4407
Epoch[7160/50000]
**Valid**: G Loss: 40.6374, D Loss: 0.3721
Epoch[7170/50000]
**Train**: G Loss: 92.6201, D Loss: -0.0200
Epoch[7170/50000]
**Valid**: G Loss: 152.6901, D Loss: -0.3508
Epoch[7180/50000]
**Train**: G Loss: 111.4004, D Loss: 0.4979
Epoch[7180/50000]
**Valid**: G Loss: 104.5770, D Loss: 1.1587
Epoch[7190/50000]
**Train**: G Loss: 39.6938, D Loss: -0.1077
Epoch[7190/50000]
**Valid**: G Loss: 41.7677, D Loss: 1.5685
Epoch[7200/50000]
**Train**: G Loss: 48.6697, D Loss: -1.2759
Epoch[7200/50000]
**Valid**: G Loss: 44.3180, D Loss: 1.3820
Epoch[7210/50000]
**Train**: G Loss: -20.6138, D Loss: -1.0543
Epoch[7210/50000]
**Valid**: G Loss: -12.4912, D Loss: 1.1827
Epoch[7220/50000]
**Train**: G Loss: 55.7602, D Loss: -0.1564
Epoch[7220/50000]
**Valid**: G Loss: 2.2776, D Loss: -0.9779
Epoch[7230/50000]
**Train**: G Loss: 38.0293, D Loss: -0.2925
Epoch[7230/50000]
**Valid**: G Loss: 43.0231, D Loss: 1.0561
Epoch[7240/50000]
**Train**: G Loss: 86.8201, D Loss: 0.3226
Epoch[7240/50000]
**Valid**: G Loss: 140.7905, D Loss: -0.8782
Epoch[7250/50000]
**Train**: G Loss: 91.4775, D Loss: 0.2293
Epoch[7250/50000]
**Valid**: G Loss: 102.4587, D Loss: 1.2861
Epoch[7260/50000]
**Train**: G Loss: 10.8133, D Loss: -0.5742
Epoch[7260/50000]
**Valid**: G Loss: 24.3090, D Loss: 1.7019
Epoch[7270/50000]
**Train**: G Loss: 58.6419, D Loss: 0.5368
Epoch[7270/50000]
**Valid**: G Loss: -33.1193, D Loss: -2.1411
Epoch[7280/50000]
**Train**: G Loss: 164.4333, D Loss: -0.9411
Epoch[7280/50000]
**Valid**: G Loss: 130.8253, D Loss: 1.8346
Epoch[7290/50000]
**Train**: G Loss: 103.5385, D Loss: 0.2605
Epoch[7290/50000]
**Valid**: G Loss: 179.2746, D Loss: -1.2385
Epoch[7300/50000]
**Train**: G Loss: -0.2204, D Loss: -1.4091
Epoch[7300/50000]
**Valid**: G Loss: -19.7955, D Loss: -0.3656
Epoch[7310/50000]
**Train**: G Loss: 105.5769, D Loss: -0.2527
Epoch[7310/50000]
**Valid**: G Loss: 131.6224, D Loss: 1.0374
Epoch[7320/50000]
**Train**: G Loss: 96.7836, D Loss: 0.3122
Epoch[7320/50000]
**Valid**: G Loss: 87.0240, D Loss: 0.8539
Epoch[7330/50000]
**Train**: G Loss: 40.4111, D Loss: -0.2003
Epoch[7330/50000]
**Valid**: G Loss: -7.0728, D Loss: -1.6547
Epoch[7340/50000]
**Train**: G Loss: 113.5839, D Loss: 0.0639
Epoch[7340/50000]
**Valid**: G Loss: 97.1722, D Loss: 1.7814
Epoch[7350/50000]
**Train**: G Loss: 81.9183, D Loss: 0.8272
Epoch[7350/50000]
**Valid**: G Loss: 38.8220, D Loss: -1.8037
Epoch[7360/50000]
**Train**: G Loss: 114.4176, D Loss: 0.5306
Epoch[7360/50000]
**Valid**: G Loss: 81.0503, D Loss: 1.4404
Epoch[7370/50000]
**Train**: G Loss: 39.9348, D Loss: -0.1256
Epoch[7370/50000]
**Valid**: G Loss: 46.5989, D Loss: 0.7663
Epoch[7380/50000]
**Train**: G Loss: 32.3266, D Loss: -0.4998
Epoch[7380/50000]
**Valid**: G Loss: -2.4192, D Loss: -0.7638
Epoch[7390/50000]
**Train**: G Loss: 18.7713, D Loss: -0.5310
Epoch[7390/50000]
**Valid**: G Loss: -9.4766, D Loss: -0.3215
Epoch[7400/50000]
**Train**: G Loss: 51.2431, D Loss: 0.7571
Epoch[7400/50000]
**Valid**: G Loss: 64.4732, D Loss: 1.6981
Epoch[7410/50000]
**Train**: G Loss: -16.8906, D Loss: -0.2807
Epoch[7410/50000]
**Valid**: G Loss: 8.5008, D Loss: 1.9649
Epoch[7420/50000]
**Train**: G Loss: -26.9290, D Loss: -1.4119
Epoch[7420/50000]
**Valid**: G Loss: -27.0863, D Loss: 0.5890
Epoch[7430/50000]
**Train**: G Loss: 91.1688, D Loss: 0.3029
Epoch[7430/50000]
**Valid**: G Loss: 94.3824, D Loss: 0.5685
Epoch[7440/50000]
**Train**: G Loss: 82.7236, D Loss: 1.3068
Epoch[7440/50000]
**Valid**: G Loss: 57.1261, D Loss: -0.1694
Epoch[7450/50000]
**Train**: G Loss: 116.2411, D Loss: -0.2941
Epoch[7450/50000]
**Valid**: G Loss: 159.6764, D Loss: -0.9888
Epoch[7460/50000]
**Train**: G Loss: -7.7081, D Loss: -1.0599
Epoch[7460/50000]
**Valid**: G Loss: -1.2761, D Loss: 1.2798
Epoch[7470/50000]
**Train**: G Loss: 98.3001, D Loss: -0.5313
Epoch[7470/50000]
**Valid**: G Loss: 88.4187, D Loss: 1.4467
Epoch[7480/50000]
**Train**: G Loss: 77.9958, D Loss: -0.0188
Epoch[7480/50000]
**Valid**: G Loss: 138.1524, D Loss: -1.0288
Epoch[7490/50000]
**Train**: G Loss: 69.8199, D Loss: 0.2566
Epoch[7490/50000]
**Valid**: G Loss: 48.4023, D Loss: -0.5426
Epoch[7500/50000]
**Train**: G Loss: 27.5783, D Loss: 0.1402
Epoch[7500/50000]
**Valid**: G Loss: -17.5370, D Loss: -1.0555
Epoch[7510/50000]
**Train**: G Loss: 14.5977, D Loss: -0.4889
Epoch[7510/50000]
**Valid**: G Loss: 23.6517, D Loss: 1.4768
Epoch[7520/50000]
**Train**: G Loss: 53.7075, D Loss: -0.1847
Epoch[7520/50000]
**Valid**: G Loss: 54.6399, D Loss: 0.7807
Epoch[7530/50000]
**Train**: G Loss: 88.0599, D Loss: 0.3850
Epoch[7530/50000]
**Valid**: G Loss: 136.1411, D Loss: -1.1492
Epoch[7540/50000]
**Train**: G Loss: 14.5754, D Loss: 0.9235
Epoch[7540/50000]
**Valid**: G Loss: 81.8809, D Loss: 0.1388
Epoch[7550/50000]
**Train**: G Loss: 77.1212, D Loss: 0.9024
Epoch[7550/50000]
**Valid**: G Loss: 55.1993, D Loss: 0.6422
Epoch[7560/50000]
**Train**: G Loss: 122.2772, D Loss: 0.8641
Epoch[7560/50000]
**Valid**: G Loss: 93.9710, D Loss: 1.9148
Epoch[7570/50000]
**Train**: G Loss: 121.7414, D Loss: -1.0782
Epoch[7570/50000]
**Valid**: G Loss: 108.9234, D Loss: 1.9939
Epoch[7580/50000]
**Train**: G Loss: 9.6426, D Loss: 1.2454
Epoch[7580/50000]
**Valid**: G Loss: 50.0541, D Loss: 1.4650
Epoch[7590/50000]
**Train**: G Loss: 115.5990, D Loss: 1.1285
Epoch[7590/50000]
**Valid**: G Loss: 82.6459, D Loss: 2.3763
Epoch[7600/50000]
**Train**: G Loss: 29.7591, D Loss: 1.4960
Epoch[7600/50000]
**Valid**: G Loss: 119.3413, D Loss: -1.3366
Epoch[7610/50000]
**Train**: G Loss: 44.9577, D Loss: 0.3577
Epoch[7610/50000]
**Valid**: G Loss: -29.9218, D Loss: -1.7774
Epoch[7620/50000]
**Train**: G Loss: 103.8531, D Loss: -0.2181
Epoch[7620/50000]
**Valid**: G Loss: 146.3151, D Loss: -0.9600
Epoch[7630/50000]
**Train**: G Loss: 9.2677, D Loss: -1.2901
Epoch[7630/50000]
**Valid**: G Loss: 9.4674, D Loss: 0.7360
Epoch[7640/50000]
**Train**: G Loss: 158.0219, D Loss: -1.2235
Epoch[7640/50000]
**Valid**: G Loss: 131.7144, D Loss: 1.7181
Epoch[7650/50000]
**Train**: G Loss: -14.4287, D Loss: -1.8660
Epoch[7650/50000]
**Valid**: G Loss: -14.4200, D Loss: 0.5640
Epoch[7660/50000]
**Train**: G Loss: 49.2572, D Loss: -0.4446
Epoch[7660/50000]
**Valid**: G Loss: 30.7993, D Loss: -0.2121
Epoch[7670/50000]
**Train**: G Loss: 59.8621, D Loss: 0.2734
Epoch[7670/50000]
**Valid**: G Loss: 62.7491, D Loss: 0.5756
Epoch[7680/50000]
**Train**: G Loss: 61.3783, D Loss: 0.5901
Epoch[7680/50000]
**Valid**: G Loss: 11.4018, D Loss: -2.5800
Epoch[7690/50000]
**Train**: G Loss: 125.9331, D Loss: -0.2380
Epoch[7690/50000]
**Valid**: G Loss: 174.4146, D Loss: -1.0994
Epoch[7700/50000]
**Train**: G Loss: 13.9362, D Loss: -0.5422
Epoch[7700/50000]
**Valid**: G Loss: -34.5337, D Loss: -1.4406
Epoch[7710/50000]
**Train**: G Loss: 91.7892, D Loss: 0.7981
Epoch[7710/50000]
**Valid**: G Loss: 207.2886, D Loss: -2.3466
Epoch[7720/50000]
**Train**: G Loss: 38.1759, D Loss: -0.4785
Epoch[7720/50000]
**Valid**: G Loss: -3.4573, D Loss: -1.4457
Epoch[7730/50000]
**Train**: G Loss: 106.1319, D Loss: -0.0386
Epoch[7730/50000]
**Valid**: G Loss: 170.1070, D Loss: -1.2422
Epoch[7740/50000]
**Train**: G Loss: 0.6519, D Loss: -1.4215
Epoch[7740/50000]
**Valid**: G Loss: -5.3847, D Loss: 0.4669
Epoch[7750/50000]
**Train**: G Loss: 77.3038, D Loss: 0.2892
Epoch[7750/50000]
**Valid**: G Loss: 132.0672, D Loss: -2.0938
Epoch[7760/50000]
**Train**: G Loss: 98.7573, D Loss: 1.6830
Epoch[7760/50000]
**Valid**: G Loss: 61.8260, D Loss: 0.7063
Epoch[7770/50000]
**Train**: G Loss: -13.9677, D Loss: -0.0459
Epoch[7770/50000]
**Valid**: G Loss: 7.4228, D Loss: 1.7753
Epoch[7780/50000]
**Train**: G Loss: 157.4982, D Loss: -1.2216
Epoch[7780/50000]
**Valid**: G Loss: 140.4095, D Loss: 1.1356
Epoch[7790/50000]
**Train**: G Loss: 13.8785, D Loss: -0.5423
Epoch[7790/50000]
**Valid**: G Loss: 17.3980, D Loss: 0.7588
Epoch[7800/50000]
**Train**: G Loss: 36.5412, D Loss: 0.0616
Epoch[7800/50000]
**Valid**: G Loss: 42.8186, D Loss: 1.1873
Epoch[7810/50000]
**Train**: G Loss: 10.5418, D Loss: -1.0014
Epoch[7810/50000]
**Valid**: G Loss: -6.4957, D Loss: -0.4567
Epoch[7820/50000]
**Train**: G Loss: 142.8398, D Loss: 0.1417
Epoch[7820/50000]
**Valid**: G Loss: 116.2778, D Loss: 2.0499
Epoch[7830/50000]
**Train**: G Loss: -25.1114, D Loss: -1.1503
Epoch[7830/50000]
**Valid**: G Loss: -16.4931, D Loss: 1.2699
Epoch[7840/50000]
**Train**: G Loss: 136.6211, D Loss: -0.4004
Epoch[7840/50000]
**Valid**: G Loss: 167.0412, D Loss: -0.2965
Epoch[7850/50000]
**Train**: G Loss: 30.6951, D Loss: -0.4446
Epoch[7850/50000]
**Valid**: G Loss: -9.1303, D Loss: -1.1064
Epoch[7860/50000]
**Train**: G Loss: 11.8555, D Loss: 1.3482
Epoch[7860/50000]
**Valid**: G Loss: 44.8503, D Loss: 1.5911
Epoch[7870/50000]
**Train**: G Loss: 124.1200, D Loss: 0.0001
Epoch[7870/50000]
**Valid**: G Loss: 101.3677, D Loss: 2.3496
Epoch[7880/50000]
**Train**: G Loss: -14.3891, D Loss: -1.2801
Epoch[7880/50000]
**Valid**: G Loss: -35.3506, D Loss: 0.0879
Epoch[7890/50000]
**Train**: G Loss: 110.2547, D Loss: -0.0407
Epoch[7890/50000]
**Valid**: G Loss: 130.6729, D Loss: 1.1528
Epoch[7900/50000]
**Train**: G Loss: 69.4014, D Loss: 0.1559
Epoch[7900/50000]
**Valid**: G Loss: 58.5163, D Loss: 0.2250
Epoch[7910/50000]
**Train**: G Loss: -0.9411, D Loss: -1.0788
Epoch[7910/50000]
**Valid**: G Loss: -22.2958, D Loss: 0.2801
Epoch[7920/50000]
**Train**: G Loss: 91.4293, D Loss: 0.6281
Epoch[7920/50000]
**Valid**: G Loss: 75.3487, D Loss: 1.8695
Epoch[7930/50000]
**Train**: G Loss: 124.4383, D Loss: 0.8488
Epoch[7930/50000]
**Valid**: G Loss: 96.4933, D Loss: 1.7297
Epoch[7940/50000]
**Train**: G Loss: 82.0160, D Loss: 0.3402
Epoch[7940/50000]
**Valid**: G Loss: 89.7543, D Loss: 1.5772
Epoch[7950/50000]
**Train**: G Loss: 44.6140, D Loss: -0.2735
Epoch[7950/50000]
**Valid**: G Loss: 38.3511, D Loss: 0.0366
Epoch[7960/50000]
**Train**: G Loss: 63.5039, D Loss: 0.5169
Epoch[7960/50000]
**Valid**: G Loss: 49.0231, D Loss: -0.8528
Epoch[7970/50000]
**Train**: G Loss: 57.1240, D Loss: 0.0316
Epoch[7970/50000]
**Valid**: G Loss: 42.9884, D Loss: 1.3787
Epoch[7980/50000]
**Train**: G Loss: 78.5443, D Loss: 0.3944
Epoch[7980/50000]
**Valid**: G Loss: 87.2221, D Loss: 1.4437
Epoch[7990/50000]
**Train**: G Loss: 69.4023, D Loss: 0.3352
Epoch[7990/50000]
**Valid**: G Loss: 129.8306, D Loss: -0.6130
Epoch[8000/50000]
**Train**: G Loss: 64.8278, D Loss: 0.3372
Epoch[8000/50000]
**Valid**: G Loss: 94.0637, D Loss: -0.6158
Epoch[8010/50000]
**Train**: G Loss: 34.6979, D Loss: 1.2785
Epoch[8010/50000]
**Valid**: G Loss: 79.3294, D Loss: 0.9518
Epoch[8020/50000]
**Train**: G Loss: 35.2787, D Loss: -0.5849
Epoch[8020/50000]
**Valid**: G Loss: 21.5947, D Loss: 0.0707
Epoch[8030/50000]
**Train**: G Loss: 112.9205, D Loss: -0.6265
Epoch[8030/50000]
**Valid**: G Loss: 119.0676, D Loss: 1.0426
Epoch[8040/50000]
**Train**: G Loss: -37.5934, D Loss: -0.3431
Epoch[8040/50000]
**Valid**: G Loss: -18.7590, D Loss: 1.6680
Epoch[8050/50000]
**Train**: G Loss: 159.3648, D Loss: -0.6882
Epoch[8050/50000]
**Valid**: G Loss: 129.8773, D Loss: 1.5421
Epoch[8060/50000]
**Train**: G Loss: 1.0474, D Loss: -1.7104
Epoch[8060/50000]
**Valid**: G Loss: -3.3772, D Loss: 0.2537
Epoch[8070/50000]
**Train**: G Loss: 89.1315, D Loss: -0.8435
Epoch[8070/50000]
**Valid**: G Loss: 87.3855, D Loss: 0.5273
Epoch[8080/50000]
**Train**: G Loss: 12.6669, D Loss: 0.1011
Epoch[8080/50000]
**Valid**: G Loss: 25.3619, D Loss: 1.6318
Epoch[8090/50000]
**Train**: G Loss: 120.8003, D Loss: 0.7942
Epoch[8090/50000]
**Valid**: G Loss: 98.9842, D Loss: 1.8841
Epoch[8100/50000]
**Train**: G Loss: 93.5636, D Loss: 0.3577
Epoch[8100/50000]
**Valid**: G Loss: 156.0460, D Loss: -0.3288
Epoch[8110/50000]
**Train**: G Loss: -32.8110, D Loss: -1.3848
Epoch[8110/50000]
**Valid**: G Loss: -31.3032, D Loss: 0.2812
Epoch[8120/50000]
**Train**: G Loss: 151.3446, D Loss: -0.1315
Epoch[8120/50000]
**Valid**: G Loss: 117.5495, D Loss: 1.9042
Epoch[8130/50000]
**Train**: G Loss: 37.4089, D Loss: 0.8447
Epoch[8130/50000]
**Valid**: G Loss: 48.0728, D Loss: 1.1917
Epoch[8140/50000]
**Train**: G Loss: 67.8935, D Loss: 0.8055
Epoch[8140/50000]
**Valid**: G Loss: 88.4833, D Loss: 0.3227
Epoch[8150/50000]
**Train**: G Loss: 41.7560, D Loss: 0.3539
Epoch[8150/50000]
**Valid**: G Loss: 49.0705, D Loss: 1.5953
Epoch[8160/50000]
**Train**: G Loss: 28.4563, D Loss: -0.7989
Epoch[8160/50000]
**Valid**: G Loss: 18.7852, D Loss: 0.5560
Epoch[8170/50000]
**Train**: G Loss: 117.3950, D Loss: 1.1525
Epoch[8170/50000]
**Valid**: G Loss: 73.3834, D Loss: 0.7383
Epoch[8180/50000]
**Train**: G Loss: 72.1786, D Loss: -0.0898
Epoch[8180/50000]
**Valid**: G Loss: 87.0656, D Loss: 0.2318
Epoch[8190/50000]
**Train**: G Loss: 34.1786, D Loss: 0.8172
Epoch[8190/50000]
**Valid**: G Loss: 78.4232, D Loss: -0.7828
Epoch[8200/50000]
**Train**: G Loss: 61.2891, D Loss: 0.8988
Epoch[8200/50000]
**Valid**: G Loss: 91.6969, D Loss: -0.2658
Epoch[8210/50000]
**Train**: G Loss: 34.9735, D Loss: 0.6277
Epoch[8210/50000]
**Valid**: G Loss: 40.9675, D Loss: 0.7922
Epoch[8220/50000]
**Train**: G Loss: 110.5335, D Loss: 0.2173
Epoch[8220/50000]
**Valid**: G Loss: 102.5845, D Loss: 1.8591
Epoch[8230/50000]
**Train**: G Loss: 113.4852, D Loss: 0.6836
Epoch[8230/50000]
**Valid**: G Loss: 96.8533, D Loss: 1.2289
Epoch[8240/50000]
**Train**: G Loss: 43.4124, D Loss: -0.1656
Epoch[8240/50000]
**Valid**: G Loss: 47.8858, D Loss: 1.1267
Epoch[8250/50000]
**Train**: G Loss: 75.6144, D Loss: 0.2842
Epoch[8250/50000]
**Valid**: G Loss: 85.9257, D Loss: 1.6859
Epoch[8260/50000]
**Train**: G Loss: 41.8067, D Loss: -0.6201
Epoch[8260/50000]
**Valid**: G Loss: 40.6678, D Loss: 0.7559
Epoch[8270/50000]
**Train**: G Loss: 117.7494, D Loss: 0.3961
Epoch[8270/50000]
**Valid**: G Loss: 106.7663, D Loss: 1.5684
Epoch[8280/50000]
**Train**: G Loss: 59.9254, D Loss: 0.0811
Epoch[8280/50000]
**Valid**: G Loss: 16.9318, D Loss: 0.0932
Epoch[8290/50000]
**Train**: G Loss: 96.2731, D Loss: 0.4135
Epoch[8290/50000]
**Valid**: G Loss: 118.0362, D Loss: 1.2623
Epoch[8300/50000]
**Train**: G Loss: 84.2914, D Loss: 0.2965
Epoch[8300/50000]
**Valid**: G Loss: 91.8486, D Loss: 0.1174
Epoch[8310/50000]
**Train**: G Loss: 139.7476, D Loss: -0.2679
Epoch[8310/50000]
**Valid**: G Loss: 108.8011, D Loss: 1.8702
Epoch[8320/50000]
**Train**: G Loss: 136.1496, D Loss: 0.3472
Epoch[8320/50000]
**Valid**: G Loss: 111.4651, D Loss: 1.0385
Epoch[8330/50000]
**Train**: G Loss: 33.4297, D Loss: -0.7198
Epoch[8330/50000]
**Valid**: G Loss: 36.6485, D Loss: 0.9629
Epoch[8340/50000]
**Train**: G Loss: 0.1536, D Loss: -0.3502
Epoch[8340/50000]
**Valid**: G Loss: -42.4773, D Loss: -0.3631
Epoch[8350/50000]
**Train**: G Loss: 117.0958, D Loss: 1.1527
Epoch[8350/50000]
**Valid**: G Loss: 76.3068, D Loss: 0.4480
Epoch[8360/50000]
**Train**: G Loss: 34.7580, D Loss: 1.0825
Epoch[8360/50000]
**Valid**: G Loss: 58.0105, D Loss: 0.4716
Epoch[8370/50000]
**Train**: G Loss: 59.4155, D Loss: -0.2857
Epoch[8370/50000]
**Valid**: G Loss: 58.4981, D Loss: 0.9127
Epoch[8380/50000]
**Train**: G Loss: 100.5908, D Loss: 0.8008
Epoch[8380/50000]
**Valid**: G Loss: 85.3210, D Loss: 1.0072
Epoch[8390/50000]
**Train**: G Loss: 62.4673, D Loss: 0.4872
Epoch[8390/50000]
**Valid**: G Loss: 67.5506, D Loss: 1.4541
Epoch[8400/50000]
**Train**: G Loss: 58.9223, D Loss: -0.5710
Epoch[8400/50000]
**Valid**: G Loss: 40.1762, D Loss: -0.8655
Epoch[8410/50000]
**Train**: G Loss: 106.1401, D Loss: 0.8034
Epoch[8410/50000]
**Valid**: G Loss: 88.1391, D Loss: -0.4892
Epoch[8420/50000]
**Train**: G Loss: 49.2550, D Loss: -0.6485
Epoch[8420/50000]
**Valid**: G Loss: 51.4507, D Loss: 0.4792
Epoch[8430/50000]
**Train**: G Loss: 35.5810, D Loss: -0.7011
Epoch[8430/50000]
**Valid**: G Loss: 21.2108, D Loss: -0.2460
Epoch[8440/50000]
**Train**: G Loss: 57.2257, D Loss: -0.6827
Epoch[8440/50000]
**Valid**: G Loss: 49.4364, D Loss: 0.1697
Epoch[8450/50000]
**Train**: G Loss: 138.5782, D Loss: 0.1075
Epoch[8450/50000]
**Valid**: G Loss: 104.3601, D Loss: 2.3670
Epoch[8460/50000]
**Train**: G Loss: 19.6571, D Loss: 1.0554
Epoch[8460/50000]
**Valid**: G Loss: 48.7770, D Loss: 1.1302
Epoch[8470/50000]
**Train**: G Loss: 54.7758, D Loss: -0.5296
Epoch[8470/50000]
**Valid**: G Loss: 54.3920, D Loss: 0.9095
Epoch[8480/50000]
**Train**: G Loss: 86.6434, D Loss: 0.2709
Epoch[8480/50000]
**Valid**: G Loss: 90.7591, D Loss: 0.4668
Epoch[8490/50000]
**Train**: G Loss: 132.7490, D Loss: 0.1995
Epoch[8490/50000]
**Valid**: G Loss: 127.7838, D Loss: 1.3000
Epoch[8500/50000]
**Train**: G Loss: 56.1566, D Loss: 0.6077
Epoch[8500/50000]
**Valid**: G Loss: 30.0129, D Loss: -0.9474
Epoch[8510/50000]
**Train**: G Loss: 146.9184, D Loss: 0.1204
Epoch[8510/50000]
**Valid**: G Loss: 112.9277, D Loss: 1.9559
Epoch[8520/50000]
**Train**: G Loss: 90.7682, D Loss: 0.1331
Epoch[8520/50000]
**Valid**: G Loss: 162.0235, D Loss: -1.1498
Epoch[8530/50000]
**Train**: G Loss: 22.1668, D Loss: -1.4436
Epoch[8530/50000]
**Valid**: G Loss: 17.3374, D Loss: 0.6074
Epoch[8540/50000]
**Train**: G Loss: 43.2128, D Loss: -0.0931
Epoch[8540/50000]
**Valid**: G Loss: 41.7715, D Loss: 1.5201
Epoch[8550/50000]
**Train**: G Loss: 24.0058, D Loss: 0.0276
Epoch[8550/50000]
**Valid**: G Loss: 34.1524, D Loss: 1.5433
Epoch[8560/50000]
**Train**: G Loss: 59.5050, D Loss: 0.5341
Epoch[8560/50000]
**Valid**: G Loss: -37.0700, D Loss: -1.7320
Epoch[8570/50000]
**Train**: G Loss: 126.1018, D Loss: -0.0418
Epoch[8570/50000]
**Valid**: G Loss: 181.2715, D Loss: -0.8545
Epoch[8580/50000]
**Train**: G Loss: 23.2872, D Loss: -0.5220
Epoch[8580/50000]
**Valid**: G Loss: -19.9579, D Loss: -1.1103
Epoch[8590/50000]
**Train**: G Loss: 150.6432, D Loss: -0.6259
Epoch[8590/50000]
**Valid**: G Loss: 161.5345, D Loss: 0.2500
Epoch[8600/50000]
**Train**: G Loss: 48.2101, D Loss: -0.6886
Epoch[8600/50000]
**Valid**: G Loss: 15.1933, D Loss: -1.1210
Epoch[8610/50000]
**Train**: G Loss: 108.2277, D Loss: 0.7956
Epoch[8610/50000]
**Valid**: G Loss: 76.2228, D Loss: -0.3463
Epoch[8620/50000]
**Train**: G Loss: 73.7288, D Loss: 0.4730
Epoch[8620/50000]
**Valid**: G Loss: 92.9818, D Loss: 0.3888
Epoch[8630/50000]
**Train**: G Loss: 65.2474, D Loss: -0.0130
Epoch[8630/50000]
**Valid**: G Loss: 65.8120, D Loss: 0.6269
Epoch[8640/50000]
**Train**: G Loss: 42.4195, D Loss: 0.7090
Epoch[8640/50000]
**Valid**: G Loss: 52.0074, D Loss: 1.1565
Epoch[8650/50000]
**Train**: G Loss: 58.1611, D Loss: 0.1072
Epoch[8650/50000]
**Valid**: G Loss: 58.5531, D Loss: 1.0325
Epoch[8660/50000]
**Train**: G Loss: 38.2564, D Loss: -0.4047
Epoch[8660/50000]
**Valid**: G Loss: 3.1102, D Loss: -0.9289
Epoch[8670/50000]
**Train**: G Loss: 126.2335, D Loss: 0.8450
Epoch[8670/50000]
**Valid**: G Loss: 83.3613, D Loss: 0.4261
Epoch[8680/50000]
**Train**: G Loss: 77.0676, D Loss: 0.1585
Epoch[8680/50000]
**Valid**: G Loss: 80.2874, D Loss: 0.2132
Epoch[8690/50000]
**Train**: G Loss: 106.4016, D Loss: 0.6966
Epoch[8690/50000]
**Valid**: G Loss: 84.0808, D Loss: 1.3319
Epoch[8700/50000]
**Train**: G Loss: 160.3646, D Loss: -0.6898
Epoch[8700/50000]
**Valid**: G Loss: 129.2857, D Loss: 1.7514
Epoch[8710/50000]
**Train**: G Loss: 18.5404, D Loss: 1.0938
Epoch[8710/50000]
**Valid**: G Loss: 82.2631, D Loss: 0.7243
Epoch[8720/50000]
**Train**: G Loss: 50.4469, D Loss: 0.2137
Epoch[8720/50000]
**Valid**: G Loss: -23.4278, D Loss: -1.7497
Epoch[8730/50000]
**Train**: G Loss: 90.4103, D Loss: 0.4178
Epoch[8730/50000]
**Valid**: G Loss: 178.8160, D Loss: -1.9677
Epoch[8740/50000]
**Train**: G Loss: 41.1634, D Loss: -0.1413
Epoch[8740/50000]
**Valid**: G Loss: -12.6025, D Loss: -1.6535
Epoch[8750/50000]
**Train**: G Loss: 94.7158, D Loss: 0.4355
Epoch[8750/50000]
**Valid**: G Loss: 188.0658, D Loss: -2.0011
Epoch[8760/50000]
**Train**: G Loss: 80.4618, D Loss: 0.9858
Epoch[8760/50000]
**Valid**: G Loss: 16.7509, D Loss: -2.0963
Epoch[8770/50000]
**Train**: G Loss: 43.7030, D Loss: 1.3727
Epoch[8770/50000]
**Valid**: G Loss: 89.6689, D Loss: 0.1693
Epoch[8780/50000]
**Train**: G Loss: 116.8859, D Loss: 1.0596
Epoch[8780/50000]
**Valid**: G Loss: 84.6803, D Loss: 1.7191
Epoch[8790/50000]
**Train**: G Loss: 40.9822, D Loss: 1.3674
Epoch[8790/50000]
**Valid**: G Loss: 94.4185, D Loss: 0.2530
Epoch[8800/50000]
**Train**: G Loss: 91.2334, D Loss: 1.5995
Epoch[8800/50000]
**Valid**: G Loss: 75.1867, D Loss: 1.5888
Epoch[8810/50000]
**Train**: G Loss: 106.4739, D Loss: -0.4530
Epoch[8810/50000]
**Valid**: G Loss: 107.2544, D Loss: 0.9934
Epoch[8820/50000]
**Train**: G Loss: 28.1165, D Loss: 1.0058
Epoch[8820/50000]
**Valid**: G Loss: 52.3928, D Loss: 1.4537
Epoch[8830/50000]
**Train**: G Loss: 109.8236, D Loss: 1.3266
Epoch[8830/50000]
**Valid**: G Loss: 81.5862, D Loss: 1.5006
Epoch[8840/50000]
**Train**: G Loss: 32.4388, D Loss: 0.5566
Epoch[8840/50000]
**Valid**: G Loss: 49.9610, D Loss: 1.4552
Epoch[8850/50000]
**Train**: G Loss: 122.0175, D Loss: -0.4944
Epoch[8850/50000]
**Valid**: G Loss: 99.0222, D Loss: 1.9759
Epoch[8860/50000]
**Train**: G Loss: -0.8951, D Loss: -0.4984
Epoch[8860/50000]
**Valid**: G Loss: 4.0964, D Loss: 1.5145
Epoch[8870/50000]
**Train**: G Loss: 163.2339, D Loss: -1.1182
Epoch[8870/50000]
**Valid**: G Loss: 139.4726, D Loss: 1.3776
Epoch[8880/50000]
**Train**: G Loss: -2.5768, D Loss: -0.8632
Epoch[8880/50000]
**Valid**: G Loss: -36.9312, D Loss: -0.5625
Epoch[8890/50000]
**Train**: G Loss: 115.9006, D Loss: -0.3826
Epoch[8890/50000]
**Valid**: G Loss: 100.4372, D Loss: 1.8498
Epoch[8900/50000]
**Train**: G Loss: 56.4872, D Loss: 1.0539
Epoch[8900/50000]
**Valid**: G Loss: 89.0401, D Loss: -1.2496
Epoch[8910/50000]
**Train**: G Loss: 93.6771, D Loss: 0.1570
Epoch[8910/50000]
**Valid**: G Loss: 86.5390, D Loss: 1.4458
Epoch[8920/50000]
**Train**: G Loss: 60.4685, D Loss: -0.2954
Epoch[8920/50000]
**Valid**: G Loss: 58.2201, D Loss: 1.0978
Epoch[8930/50000]
**Train**: G Loss: 85.3593, D Loss: 0.4063
Epoch[8930/50000]
**Valid**: G Loss: 76.1942, D Loss: -0.1285
Epoch[8940/50000]
**Train**: G Loss: 38.7356, D Loss: -0.0168
Epoch[8940/50000]
**Valid**: G Loss: 42.0911, D Loss: 1.5055
Epoch[8950/50000]
**Train**: G Loss: 11.8640, D Loss: -0.6608
Epoch[8950/50000]
**Valid**: G Loss: -20.6913, D Loss: -0.8105
Epoch[8960/50000]
**Train**: G Loss: 128.9810, D Loss: -0.4553
Epoch[8960/50000]
**Valid**: G Loss: 147.5082, D Loss: 0.2981
Epoch[8970/50000]
**Train**: G Loss: -33.3700, D Loss: -0.8216
Epoch[8970/50000]
**Valid**: G Loss: -17.3255, D Loss: 1.3669
Epoch[8980/50000]
**Train**: G Loss: 103.3078, D Loss: 1.2619
Epoch[8980/50000]
**Valid**: G Loss: 39.5159, D Loss: -0.0617
Epoch[8990/50000]
**Train**: G Loss: 52.3391, D Loss: 1.0063
Epoch[8990/50000]
**Valid**: G Loss: 142.1392, D Loss: -1.4027
Epoch[9000/50000]
**Train**: G Loss: 71.3272, D Loss: 0.8553
Epoch[9000/50000]
**Valid**: G Loss: 8.3855, D Loss: -2.2304
Epoch[9010/50000]
**Train**: G Loss: 78.7133, D Loss: 0.4944
Epoch[9010/50000]
**Valid**: G Loss: 146.5995, D Loss: -0.9332
Epoch[9020/50000]
**Train**: G Loss: 25.6430, D Loss: 0.5006
Epoch[9020/50000]
**Valid**: G Loss: 38.7834, D Loss: 1.3824
Epoch[9030/50000]
**Train**: G Loss: 121.0524, D Loss: 0.2646
Epoch[9030/50000]
**Valid**: G Loss: 97.6349, D Loss: 2.1800
Epoch[9040/50000]
**Train**: G Loss: 19.8628, D Loss: -0.4288
Epoch[9040/50000]
**Valid**: G Loss: 21.5879, D Loss: 1.0433
Epoch[9050/50000]
**Train**: G Loss: 85.0470, D Loss: 0.1426
Epoch[9050/50000]
**Valid**: G Loss: 73.6401, D Loss: 1.8510
Epoch[9060/50000]
**Train**: G Loss: 78.6652, D Loss: -0.0937
Epoch[9060/50000]
**Valid**: G Loss: 92.4669, D Loss: 0.7857
Epoch[9070/50000]
**Train**: G Loss: 64.0519, D Loss: 0.2074
Epoch[9070/50000]
**Valid**: G Loss: 75.6850, D Loss: 1.0772
Epoch[9080/50000]
**Train**: G Loss: 85.7481, D Loss: 0.4367
Epoch[9080/50000]
**Valid**: G Loss: 73.1416, D Loss: 1.7404
Epoch[9090/50000]
**Train**: G Loss: 15.6691, D Loss: 1.1523
Epoch[9090/50000]
**Valid**: G Loss: 51.0997, D Loss: 1.3001
Epoch[9100/50000]
**Train**: G Loss: 151.0108, D Loss: -0.0601
Epoch[9100/50000]
**Valid**: G Loss: 122.8412, D Loss: 2.0001
Epoch[9110/50000]
**Train**: G Loss: -38.4733, D Loss: -0.9998
Epoch[9110/50000]
**Valid**: G Loss: -23.4151, D Loss: 1.2271
Epoch[9120/50000]
**Train**: G Loss: 171.7302, D Loss: -0.6627
Epoch[9120/50000]
**Valid**: G Loss: 138.7895, D Loss: 1.6228
Epoch[9130/50000]
**Train**: G Loss: -28.2525, D Loss: -1.2488
Epoch[9130/50000]
**Valid**: G Loss: -26.5224, D Loss: 0.8435
Epoch[9140/50000]
**Train**: G Loss: 59.5010, D Loss: 0.9382
Epoch[9140/50000]
**Valid**: G Loss: 119.6710, D Loss: -1.6324
Epoch[9150/50000]
**Train**: G Loss: 89.6225, D Loss: 1.4013
Epoch[9150/50000]
**Valid**: G Loss: 49.5635, D Loss: -0.4754
Epoch[9160/50000]
**Train**: G Loss: 34.7608, D Loss: 0.9683
Epoch[9160/50000]
**Valid**: G Loss: 61.0946, D Loss: 0.7011
Epoch[9170/50000]
**Train**: G Loss: 53.9114, D Loss: -0.4100
Epoch[9170/50000]
**Valid**: G Loss: 38.8680, D Loss: 0.3932
Epoch[9180/50000]
**Train**: G Loss: 78.2359, D Loss: -0.3523
Epoch[9180/50000]
**Valid**: G Loss: 65.7651, D Loss: 0.2238
Epoch[9190/50000]
**Train**: G Loss: 92.8493, D Loss: 0.3553
Epoch[9190/50000]
**Valid**: G Loss: 113.2822, D Loss: 0.5952
Epoch[9200/50000]
**Train**: G Loss: 100.4423, D Loss: 0.4059
Epoch[9200/50000]
**Valid**: G Loss: 84.6228, D Loss: 0.0705
Epoch[9210/50000]
**Train**: G Loss: 108.5127, D Loss: 0.0973
Epoch[9210/50000]
**Valid**: G Loss: 114.4035, D Loss: 1.4552
Epoch[9220/50000]
**Train**: G Loss: 60.6664, D Loss: 0.5257
Epoch[9220/50000]
**Valid**: G Loss: 82.4337, D Loss: 0.4508
Epoch[9230/50000]
**Train**: G Loss: 127.1004, D Loss: 0.1118
Epoch[9230/50000]
**Valid**: G Loss: 98.8474, D Loss: 2.0438
Epoch[9240/50000]
**Train**: G Loss: 74.2610, D Loss: 0.2125
Epoch[9240/50000]
**Valid**: G Loss: 42.4531, D Loss: -0.6565
Epoch[9250/50000]
**Train**: G Loss: 94.7361, D Loss: 0.4263
Epoch[9250/50000]
**Valid**: G Loss: 107.9221, D Loss: 1.3752
Epoch[9260/50000]
**Train**: G Loss: 26.3826, D Loss: -0.1010
Epoch[9260/50000]
**Valid**: G Loss: 30.3654, D Loss: 1.2574
Epoch[9270/50000]
**Train**: G Loss: 45.2582, D Loss: -1.0596
Epoch[9270/50000]
**Valid**: G Loss: 33.1554, D Loss: 0.1328
Epoch[9280/50000]
**Train**: G Loss: 82.3739, D Loss: 0.6655
Epoch[9280/50000]
**Valid**: G Loss: 40.3098, D Loss: -1.9088
Epoch[9290/50000]
**Train**: G Loss: 118.7179, D Loss: -0.4979
Epoch[9290/50000]
**Valid**: G Loss: 114.9525, D Loss: 1.3884
Epoch[9300/50000]
**Train**: G Loss: 97.3058, D Loss: 0.2222
Epoch[9300/50000]
**Valid**: G Loss: 118.5580, D Loss: 1.2488
Epoch[9310/50000]
**Train**: G Loss: 71.9307, D Loss: 0.3946
Epoch[9310/50000]
**Valid**: G Loss: 71.3481, D Loss: 0.7126
Epoch[9320/50000]
**Train**: G Loss: 110.0488, D Loss: -0.1368
Epoch[9320/50000]
**Valid**: G Loss: 136.6151, D Loss: 0.0578
Epoch[9330/50000]
**Train**: G Loss: 63.0609, D Loss: 0.9990
Epoch[9330/50000]
**Valid**: G Loss: 96.4720, D Loss: -1.2929
Epoch[9340/50000]
**Train**: G Loss: 63.1087, D Loss: 0.2815
Epoch[9340/50000]
**Valid**: G Loss: 5.3666, D Loss: -1.8565
Epoch[9350/50000]
**Train**: G Loss: 127.0796, D Loss: 0.1427
Epoch[9350/50000]
**Valid**: G Loss: 212.4156, D Loss: -1.2896
Epoch[9360/50000]
**Train**: G Loss: 25.5535, D Loss: 0.1660
Epoch[9360/50000]
**Valid**: G Loss: 41.0655, D Loss: 0.8464
Epoch[9370/50000]
**Train**: G Loss: 107.0863, D Loss: 0.2641
Epoch[9370/50000]
**Valid**: G Loss: 74.2466, D Loss: 0.0089
Epoch[9380/50000]
**Train**: G Loss: 34.6219, D Loss: -0.0428
Epoch[9380/50000]
**Valid**: G Loss: -13.5188, D Loss: -1.2587
Epoch[9390/50000]
**Train**: G Loss: 158.6941, D Loss: -0.6586
Epoch[9390/50000]
**Valid**: G Loss: 158.3050, D Loss: 0.5965
Epoch[9400/50000]
**Train**: G Loss: 44.6505, D Loss: 0.6414
Epoch[9400/50000]
**Valid**: G Loss: 77.5376, D Loss: 0.2142
Epoch[9410/50000]
**Train**: G Loss: 88.4287, D Loss: 0.2242
Epoch[9410/50000]
**Valid**: G Loss: 91.2558, D Loss: 0.4067
Epoch[9420/50000]
**Train**: G Loss: 106.7093, D Loss: 0.2249
Epoch[9420/50000]
**Valid**: G Loss: 95.8945, D Loss: 1.5566
Epoch[9430/50000]
**Train**: G Loss: 96.9365, D Loss: -0.1001
Epoch[9430/50000]
**Valid**: G Loss: 128.8116, D Loss: -0.3495
Epoch[9440/50000]
**Train**: G Loss: 55.0433, D Loss: 0.6191
Epoch[9440/50000]
**Valid**: G Loss: 82.3388, D Loss: 0.0556
Epoch[9450/50000]
**Train**: G Loss: 52.4004, D Loss: 0.5732
Epoch[9450/50000]
**Valid**: G Loss: 69.7063, D Loss: 0.6817
Epoch[9460/50000]
**Train**: G Loss: 56.9085, D Loss: 0.6903
Epoch[9460/50000]
**Valid**: G Loss: 75.9768, D Loss: 0.5100
Epoch[9470/50000]
**Train**: G Loss: 107.4799, D Loss: 0.5785
Epoch[9470/50000]
**Valid**: G Loss: 74.0158, D Loss: -1.1342
Epoch[9480/50000]
**Train**: G Loss: 83.7526, D Loss: 0.7325
Epoch[9480/50000]
**Valid**: G Loss: 95.3510, D Loss: 0.5572
Epoch[9490/50000]
**Train**: G Loss: 72.1314, D Loss: 0.5900
Epoch[9490/50000]
**Valid**: G Loss: 121.0604, D Loss: -1.0283
Epoch[9500/50000]
**Train**: G Loss: 37.2147, D Loss: 0.8113
Epoch[9500/50000]
**Valid**: G Loss: 58.4066, D Loss: 0.8718
Epoch[9510/50000]
**Train**: G Loss: 61.8602, D Loss: 0.6563
Epoch[9510/50000]
**Valid**: G Loss: 86.4060, D Loss: 0.5964
Epoch[9520/50000]
**Train**: G Loss: 74.2951, D Loss: 0.3928
Epoch[9520/50000]
**Valid**: G Loss: 86.0071, D Loss: -0.0141
Epoch[9530/50000]
**Train**: G Loss: 81.5932, D Loss: 0.8589
Epoch[9530/50000]
**Valid**: G Loss: 65.0908, D Loss: -1.2936
Epoch[9540/50000]
**Train**: G Loss: 153.0489, D Loss: -0.5910
Epoch[9540/50000]
**Valid**: G Loss: 168.8727, D Loss: 0.7211
Epoch[9550/50000]
**Train**: G Loss: 19.6819, D Loss: -1.1140
Epoch[9550/50000]
**Valid**: G Loss: 26.0097, D Loss: 1.4696
Epoch[9560/50000]
**Train**: G Loss: 139.6008, D Loss: -0.5207
Epoch[9560/50000]
**Valid**: G Loss: 122.6447, D Loss: 1.7830
Epoch[9570/50000]
**Train**: G Loss: 43.8238, D Loss: 0.6786
Epoch[9570/50000]
**Valid**: G Loss: 53.3245, D Loss: 1.5138
Epoch[9580/50000]
**Train**: G Loss: 111.7896, D Loss: 1.3699
Epoch[9580/50000]
**Valid**: G Loss: 84.7883, D Loss: 0.7165
Epoch[9590/50000]
**Train**: G Loss: 67.9588, D Loss: 1.0588
Epoch[9590/50000]
**Valid**: G Loss: 108.1300, D Loss: -0.4499
Epoch[9600/50000]
**Train**: G Loss: 106.1357, D Loss: 1.1927
Epoch[9600/50000]
**Valid**: G Loss: 76.3060, D Loss: -0.1895
Epoch[9610/50000]
**Train**: G Loss: 50.2275, D Loss: 1.1628
Epoch[9610/50000]
**Valid**: G Loss: 86.1058, D Loss: 0.7155
Epoch[9620/50000]
**Train**: G Loss: 105.1542, D Loss: 1.1922
Epoch[9620/50000]
**Valid**: G Loss: 43.5629, D Loss: -0.2524
Epoch[9630/50000]
**Train**: G Loss: 138.1882, D Loss: -0.2903
Epoch[9630/50000]
**Valid**: G Loss: 171.4551, D Loss: -0.3285
Epoch[9640/50000]
**Train**: G Loss: 76.9936, D Loss: 0.3644
Epoch[9640/50000]
**Valid**: G Loss: 44.8875, D Loss: -2.0442
Epoch[9650/50000]
**Train**: G Loss: 55.7746, D Loss: 1.2997
Epoch[9650/50000]
**Valid**: G Loss: 113.3148, D Loss: -0.2707
Epoch[9660/50000]
**Train**: G Loss: 50.3570, D Loss: -0.9922
Epoch[9660/50000]
**Valid**: G Loss: 39.6288, D Loss: 0.0869
Epoch[9670/50000]
**Train**: G Loss: 164.4782, D Loss: -0.6572
Epoch[9670/50000]
**Valid**: G Loss: 141.2013, D Loss: 1.4854
Epoch[9680/50000]
**Train**: G Loss: 22.9376, D Loss: 0.1825
Epoch[9680/50000]
**Valid**: G Loss: 38.9162, D Loss: 1.3732
Epoch[9690/50000]
**Train**: G Loss: 67.4631, D Loss: -0.5884
Epoch[9690/50000]
**Valid**: G Loss: 60.5646, D Loss: 0.0144
Epoch[9700/50000]
**Train**: G Loss: 85.7567, D Loss: 0.1836
Epoch[9700/50000]
**Valid**: G Loss: 56.7414, D Loss: -0.3540
Epoch[9710/50000]
**Train**: G Loss: 61.5181, D Loss: -0.1092
Epoch[9710/50000]
**Valid**: G Loss: 28.2783, D Loss: -0.6195
Epoch[9720/50000]
**Train**: G Loss: 130.5787, D Loss: 0.8785
Epoch[9720/50000]
**Valid**: G Loss: 107.6218, D Loss: 1.6375
Epoch[9730/50000]
**Train**: G Loss: 56.6994, D Loss: 1.1106
Epoch[9730/50000]
**Valid**: G Loss: 70.0803, D Loss: 0.8845
Epoch[9740/50000]
**Train**: G Loss: 140.4737, D Loss: 1.1495
Epoch[9740/50000]
**Valid**: G Loss: 110.4859, D Loss: 2.0219
Epoch[9750/50000]
**Train**: G Loss: 43.7989, D Loss: -0.4247
Epoch[9750/50000]
**Valid**: G Loss: 48.0933, D Loss: 2.0686
Epoch[9760/50000]
**Train**: G Loss: 110.7630, D Loss: -1.0160
Epoch[9760/50000]
**Valid**: G Loss: 110.8969, D Loss: 0.9471
Epoch[9770/50000]
**Train**: G Loss: 87.0123, D Loss: 1.2643
Epoch[9770/50000]
**Valid**: G Loss: 55.7924, D Loss: -1.6451
Epoch[9780/50000]
**Train**: G Loss: 11.6417, D Loss: 0.8032
Epoch[9780/50000]
**Valid**: G Loss: 41.5893, D Loss: 1.7627
Epoch[9790/50000]
**Train**: G Loss: 131.2660, D Loss: 1.4162
Epoch[9790/50000]
**Valid**: G Loss: 93.2991, D Loss: 1.6100
Epoch[9800/50000]
**Train**: G Loss: 16.1900, D Loss: 0.3425
Epoch[9800/50000]
**Valid**: G Loss: 34.0674, D Loss: 1.9315
Epoch[9810/50000]
**Train**: G Loss: 158.6749, D Loss: -1.0718
Epoch[9810/50000]
**Valid**: G Loss: 140.8110, D Loss: 1.2522
Epoch[9820/50000]
**Train**: G Loss: 40.1601, D Loss: -0.1994
Epoch[9820/50000]
**Valid**: G Loss: -7.9203, D Loss: -1.2554
Epoch[9830/50000]
**Train**: G Loss: 48.5800, D Loss: 1.0149
Epoch[9830/50000]
**Valid**: G Loss: 101.0091, D Loss: -1.0163
Epoch[9840/50000]
**Train**: G Loss: 22.5265, D Loss: -0.9128
Epoch[9840/50000]
**Valid**: G Loss: 9.5653, D Loss: 0.2497
Epoch[9850/50000]
**Train**: G Loss: 113.9043, D Loss: -0.5291
Epoch[9850/50000]
**Valid**: G Loss: 121.3727, D Loss: 0.3892
Epoch[9860/50000]
**Train**: G Loss: 38.7849, D Loss: -0.5957
Epoch[9860/50000]
**Valid**: G Loss: 42.0375, D Loss: 1.0333
Epoch[9870/50000]
**Train**: G Loss: 86.8442, D Loss: 1.2669
Epoch[9870/50000]
**Valid**: G Loss: 69.1787, D Loss: 0.1666
Epoch[9880/50000]
**Train**: G Loss: 59.4409, D Loss: 1.1282
Epoch[9880/50000]
**Valid**: G Loss: 64.2231, D Loss: 1.3542
Epoch[9890/50000]
**Train**: G Loss: 77.2282, D Loss: 0.8382
Epoch[9890/50000]
**Valid**: G Loss: 62.0899, D Loss: -1.7280
Epoch[9900/50000]
**Train**: G Loss: 52.0048, D Loss: 1.0769
Epoch[9900/50000]
**Valid**: G Loss: 84.2854, D Loss: -0.4234
Epoch[9910/50000]
**Train**: G Loss: 96.9246, D Loss: 1.2673
Epoch[9910/50000]
**Valid**: G Loss: 46.7606, D Loss: -1.4624
Epoch[9920/50000]
**Train**: G Loss: 47.9140, D Loss: 0.9050
Epoch[9920/50000]
**Valid**: G Loss: 81.9532, D Loss: -0.6679
Epoch[9930/50000]
**Train**: G Loss: 86.0144, D Loss: 1.5788
Epoch[9930/50000]
**Valid**: G Loss: 70.5483, D Loss: 0.8321
Epoch[9940/50000]
**Train**: G Loss: 49.0122, D Loss: 1.2927
Epoch[9940/50000]
**Valid**: G Loss: 65.0996, D Loss: 1.6781
Epoch[9950/50000]
**Train**: G Loss: 128.3001, D Loss: -1.2077
Epoch[9950/50000]
**Valid**: G Loss: 120.6334, D Loss: 0.6754
Epoch[9960/50000]
**Train**: G Loss: 100.2832, D Loss: 1.5619
Epoch[9960/50000]
**Valid**: G Loss: 66.7060, D Loss: -1.1262
Epoch[9970/50000]
**Train**: G Loss: -29.2233, D Loss: -1.3045
Epoch[9970/50000]
**Valid**: G Loss: -47.4558, D Loss: -0.3663
Epoch[9980/50000]
**Train**: G Loss: 41.5210, D Loss: 1.4545
Epoch[9980/50000]
**Valid**: G Loss: 66.4400, D Loss: 1.1444
Epoch[9990/50000]
**Train**: G Loss: 165.9090, D Loss: -1.3298
Epoch[9990/50000]
**Valid**: G Loss: 151.7334, D Loss: 0.8377
Epoch[10000/50000]
**Train**: G Loss: 61.6835, D Loss: -0.5764
Epoch[10000/50000]
**Valid**: G Loss: 46.4374, D Loss: -0.4299
Epoch[10010/50000]
**Train**: G Loss: 64.7743, D Loss: 0.7801
Epoch[10010/50000]
**Valid**: G Loss: 113.7567, D Loss: -1.7852
Epoch[10020/50000]
**Train**: G Loss: 93.4033, D Loss: 0.6665
Epoch[10020/50000]
**Valid**: G Loss: 60.5897, D Loss: -1.9063
Epoch[10030/50000]
**Train**: G Loss: 59.7759, D Loss: 1.4955
Epoch[10030/50000]
**Valid**: G Loss: 92.9240, D Loss: 0.5502
Epoch[10040/50000]
**Train**: G Loss: 202.7812, D Loss: -1.1843
Epoch[10040/50000]
**Valid**: G Loss: 172.4339, D Loss: 2.1445
Epoch[10050/50000]
**Train**: G Loss: 9.2183, D Loss: -0.7797
Epoch[10050/50000]
**Valid**: G Loss: -27.3356, D Loss: -0.4251
Epoch[10060/50000]
**Train**: G Loss: 32.3736, D Loss: -0.4851
Epoch[10060/50000]
**Valid**: G Loss: 34.9660, D Loss: 1.5578
Epoch[10070/50000]
**Train**: G Loss: 86.2662, D Loss: 1.5878
Epoch[10070/50000]
**Valid**: G Loss: 112.8783, D Loss: 0.9111
Epoch[10080/50000]
**Train**: G Loss: 170.5646, D Loss: -1.0195
Epoch[10080/50000]
**Valid**: G Loss: 178.0441, D Loss: -0.0570
Epoch[10090/50000]
**Train**: G Loss: 135.2139, D Loss: 1.3579
Epoch[10090/50000]
**Valid**: G Loss: 97.8346, D Loss: 1.0270
Epoch[10100/50000]
**Train**: G Loss: 9.8219, D Loss: -0.8027
Epoch[10100/50000]
**Valid**: G Loss: -22.6230, D Loss: -0.7705
Epoch[10110/50000]
**Train**: G Loss: 16.9501, D Loss: 0.6957
Epoch[10110/50000]
**Valid**: G Loss: 36.8959, D Loss: 1.7907
Epoch[10120/50000]
**Train**: G Loss: 122.7759, D Loss: 0.1509
Epoch[10120/50000]
**Valid**: G Loss: 196.5419, D Loss: -1.2517
Epoch[10130/50000]
**Train**: G Loss: 172.6084, D Loss: -0.3429
Epoch[10130/50000]
**Valid**: G Loss: 146.2104, D Loss: 2.0966
Epoch[10140/50000]
**Train**: G Loss: 110.4994, D Loss: 1.9909
Epoch[10140/50000]
**Valid**: G Loss: 85.6647, D Loss: 1.6191
Epoch[10150/50000]
**Train**: G Loss: 62.2706, D Loss: 0.0075
Epoch[10150/50000]
**Valid**: G Loss: 11.4082, D Loss: -1.6770
Epoch[10160/50000]
**Train**: G Loss: 4.9734, D Loss: -1.0022
Epoch[10160/50000]
**Valid**: G Loss: 7.2731, D Loss: 0.9080
Epoch[10170/50000]
**Train**: G Loss: 28.6639, D Loss: 1.5628
Epoch[10170/50000]
**Valid**: G Loss: 63.3850, D Loss: 1.5111
Epoch[10180/50000]
**Train**: G Loss: 117.6164, D Loss: -0.7384
Epoch[10180/50000]
**Valid**: G Loss: 119.5155, D Loss: 0.6786
Epoch[10190/50000]
**Train**: G Loss: 114.7359, D Loss: 1.5141
Epoch[10190/50000]
**Valid**: G Loss: 84.9662, D Loss: -0.2263
Epoch[10200/50000]
**Train**: G Loss: -4.6785, D Loss: -1.2604
Epoch[10200/50000]
**Valid**: G Loss: -5.3940, D Loss: 0.5351
Epoch[10210/50000]
**Train**: G Loss: -23.0346, D Loss: 0.4449
Epoch[10210/50000]
**Valid**: G Loss: 3.4719, D Loss: 1.8794
Epoch[10220/50000]
**Train**: G Loss: 78.3472, D Loss: 1.0174
Epoch[10220/50000]
**Valid**: G Loss: 162.9585, D Loss: -2.2134
Epoch[10230/50000]
**Train**: G Loss: 112.5897, D Loss: 0.3837
Epoch[10230/50000]
**Valid**: G Loss: 206.2556, D Loss: -2.1375
Epoch[10240/50000]
**Train**: G Loss: 133.8405, D Loss: -1.2135
Epoch[10240/50000]
**Valid**: G Loss: 131.5601, D Loss: 0.1452
Epoch[10250/50000]
**Train**: G Loss: 122.6960, D Loss: -0.7192
Epoch[10250/50000]
**Valid**: G Loss: 106.9986, D Loss: 1.6019
Epoch[10260/50000]
**Train**: G Loss: 86.7289, D Loss: 0.3449
Epoch[10260/50000]
**Valid**: G Loss: 76.6445, D Loss: 2.6521
Epoch[10270/50000]
**Train**: G Loss: 90.7481, D Loss: 0.9678
Epoch[10270/50000]
**Valid**: G Loss: 62.8733, D Loss: -1.8322
Epoch[10280/50000]
**Train**: G Loss: 59.3295, D Loss: 1.2490
Epoch[10280/50000]
**Valid**: G Loss: 89.3903, D Loss: 0.4061
Epoch[10290/50000]
**Train**: G Loss: 80.2480, D Loss: -0.0399
Epoch[10290/50000]
**Valid**: G Loss: 60.3225, D Loss: -1.0430
Epoch[10300/50000]
**Train**: G Loss: 14.2427, D Loss: -0.1801
Epoch[10300/50000]
**Valid**: G Loss: 19.2199, D Loss: 1.5272
Epoch[10310/50000]
**Train**: G Loss: 116.4762, D Loss: -0.3024
Epoch[10310/50000]
**Valid**: G Loss: 127.3224, D Loss: 0.5423
Epoch[10320/50000]
**Train**: G Loss: 33.2026, D Loss: -1.0180
Epoch[10320/50000]
**Valid**: G Loss: 28.2774, D Loss: -0.3205
Epoch[10330/50000]
**Train**: G Loss: 49.0786, D Loss: 1.3667
Epoch[10330/50000]
**Valid**: G Loss: 77.4639, D Loss: 1.1425
Epoch[10340/50000]
**Train**: G Loss: 115.5113, D Loss: 1.2889
Epoch[10340/50000]
**Valid**: G Loss: 100.1078, D Loss: 1.8714
Epoch[10350/50000]
**Train**: G Loss: 23.9919, D Loss: -1.3287
Epoch[10350/50000]
**Valid**: G Loss: 17.5176, D Loss: 0.5795
Epoch[10360/50000]
**Train**: G Loss: 34.1232, D Loss: 1.3357
Epoch[10360/50000]
**Valid**: G Loss: 59.8387, D Loss: 1.2006
Epoch[10370/50000]
**Train**: G Loss: 116.3793, D Loss: -0.6252
Epoch[10370/50000]
**Valid**: G Loss: 101.6283, D Loss: 1.2843
Epoch[10380/50000]
**Train**: G Loss: 111.2247, D Loss: 1.9553
Epoch[10380/50000]
**Valid**: G Loss: 77.6599, D Loss: 1.8276
Epoch[10390/50000]
**Train**: G Loss: 68.9748, D Loss: -0.9620
Epoch[10390/50000]
**Valid**: G Loss: 56.9439, D Loss: 1.0602
Epoch[10400/50000]
**Train**: G Loss: 169.3857, D Loss: -0.8125
Epoch[10400/50000]
**Valid**: G Loss: 156.9155, D Loss: 0.9374
Epoch[10410/50000]
**Train**: G Loss: 133.2876, D Loss: 1.4075
Epoch[10410/50000]
**Valid**: G Loss: 91.3256, D Loss: 0.9485
Epoch[10420/50000]
**Train**: G Loss: 16.7232, D Loss: -1.2118
Epoch[10420/50000]
**Valid**: G Loss: 11.5799, D Loss: 0.4183
Epoch[10430/50000]
**Train**: G Loss: 54.1790, D Loss: 1.3318
Epoch[10430/50000]
**Valid**: G Loss: 78.5474, D Loss: 0.7560
Epoch[10440/50000]
**Train**: G Loss: 70.0681, D Loss: 0.6101
Epoch[10440/50000]
**Valid**: G Loss: 42.0275, D Loss: -1.0841
Epoch[10450/50000]
**Train**: G Loss: 79.0503, D Loss: 0.8196
Epoch[10450/50000]
**Valid**: G Loss: 131.5377, D Loss: -1.4084
Epoch[10460/50000]
**Train**: G Loss: 53.1454, D Loss: 0.2780
Epoch[10460/50000]
**Valid**: G Loss: 42.8863, D Loss: -1.1396
Epoch[10470/50000]
**Train**: G Loss: 40.1317, D Loss: 0.3647
Epoch[10470/50000]
**Valid**: G Loss: 46.9039, D Loss: 1.3373
Epoch[10480/50000]
**Train**: G Loss: 131.2786, D Loss: -0.1107
Epoch[10480/50000]
**Valid**: G Loss: 117.5687, D Loss: 2.1601
Epoch[10490/50000]
**Train**: G Loss: 65.7933, D Loss: 0.2272
Epoch[10490/50000]
**Valid**: G Loss: 69.7634, D Loss: 1.0691
Epoch[10500/50000]
**Train**: G Loss: 106.9157, D Loss: 0.2982
Epoch[10500/50000]
**Valid**: G Loss: 101.5386, D Loss: 0.2535
Epoch[10510/50000]
**Train**: G Loss: 161.9995, D Loss: -0.4506
Epoch[10510/50000]
**Valid**: G Loss: 139.4004, D Loss: 1.6691
Epoch[10520/50000]
**Train**: G Loss: 79.4931, D Loss: -1.1901
Epoch[10520/50000]
**Valid**: G Loss: 68.7404, D Loss: -0.2629
Epoch[10530/50000]
**Train**: G Loss: 76.3361, D Loss: 0.6955
Epoch[10530/50000]
**Valid**: G Loss: 112.4676, D Loss: -1.5332
Epoch[10540/50000]
**Train**: G Loss: 47.5190, D Loss: -0.0395
Epoch[10540/50000]
**Valid**: G Loss: 58.8319, D Loss: 1.2154
Epoch[10550/50000]
**Train**: G Loss: 95.4770, D Loss: 1.2503
Epoch[10550/50000]
**Valid**: G Loss: 67.5202, D Loss: -0.2516
Epoch[10560/50000]
**Train**: G Loss: 58.1838, D Loss: 0.9824
Epoch[10560/50000]
**Valid**: G Loss: 69.5028, D Loss: 0.9793
Epoch[10570/50000]
**Train**: G Loss: 139.9860, D Loss: 1.3156
Epoch[10570/50000]
**Valid**: G Loss: 115.1196, D Loss: 1.7507
Epoch[10580/50000]
**Train**: G Loss: 45.0863, D Loss: -1.1590
Epoch[10580/50000]
**Valid**: G Loss: 46.3072, D Loss: 1.1014
Epoch[10590/50000]
**Train**: G Loss: 81.2691, D Loss: -0.1737
Epoch[10590/50000]
**Valid**: G Loss: 93.5886, D Loss: -0.2164
Epoch[10600/50000]
**Train**: G Loss: 38.5877, D Loss: -0.4968
Epoch[10600/50000]
**Valid**: G Loss: 20.9756, D Loss: -0.3535
Epoch[10610/50000]
**Train**: G Loss: 56.6831, D Loss: 1.0760
Epoch[10610/50000]
**Valid**: G Loss: 82.7360, D Loss: 0.4061
Epoch[10620/50000]
**Train**: G Loss: 129.7023, D Loss: 1.3151
Epoch[10620/50000]
**Valid**: G Loss: 94.5634, D Loss: 0.9681
Epoch[10630/50000]
**Train**: G Loss: 39.4749, D Loss: 0.5093
Epoch[10630/50000]
**Valid**: G Loss: 48.4515, D Loss: 1.6662
Epoch[10640/50000]
**Train**: G Loss: 137.4580, D Loss: 0.5404
Epoch[10640/50000]
**Valid**: G Loss: 114.9346, D Loss: 2.1579
Epoch[10650/50000]
**Train**: G Loss: -9.1101, D Loss: -1.0695
Epoch[10650/50000]
**Valid**: G Loss: -1.4281, D Loss: 0.8523
Epoch[10660/50000]
**Train**: G Loss: 138.0506, D Loss: 0.4024
Epoch[10660/50000]
**Valid**: G Loss: 119.8959, D Loss: 1.6371
Epoch[10670/50000]
**Train**: G Loss: 116.3974, D Loss: -0.1598
Epoch[10670/50000]
**Valid**: G Loss: 129.2139, D Loss: 0.7545
Epoch[10680/50000]
**Train**: G Loss: 56.0652, D Loss: 0.5500
Epoch[10680/50000]
**Valid**: G Loss: 53.8484, D Loss: 1.1750
Epoch[10690/50000]
**Train**: G Loss: 70.9061, D Loss: -0.2611
Epoch[10690/50000]
**Valid**: G Loss: 70.9851, D Loss: 0.6362
Epoch[10700/50000]
**Train**: G Loss: 49.9014, D Loss: 0.3481
Epoch[10700/50000]
**Valid**: G Loss: 56.9753, D Loss: 0.7485
Epoch[10710/50000]
**Train**: G Loss: 40.3055, D Loss: 0.1385
Epoch[10710/50000]
**Valid**: G Loss: 54.2503, D Loss: 1.1811
Epoch[10720/50000]
**Train**: G Loss: 108.1451, D Loss: 0.3446
Epoch[10720/50000]
**Valid**: G Loss: 96.2578, D Loss: -0.7712
Epoch[10730/50000]
**Train**: G Loss: 87.5820, D Loss: 0.4634
Epoch[10730/50000]
**Valid**: G Loss: 85.5831, D Loss: -0.9300
Epoch[10740/50000]
**Train**: G Loss: 123.0592, D Loss: -0.2487
Epoch[10740/50000]
**Valid**: G Loss: 120.3531, D Loss: 1.3479
Epoch[10750/50000]
**Train**: G Loss: 54.9472, D Loss: 0.2306
Epoch[10750/50000]
**Valid**: G Loss: 62.4249, D Loss: 1.4385
Epoch[10760/50000]
**Train**: G Loss: 89.8572, D Loss: 1.1360
Epoch[10760/50000]
**Valid**: G Loss: 67.2856, D Loss: 0.8542
Epoch[10770/50000]
**Train**: G Loss: 60.7872, D Loss: 0.9183
Epoch[10770/50000]
**Valid**: G Loss: 68.3596, D Loss: -0.2017
Epoch[10780/50000]
**Train**: G Loss: 77.5996, D Loss: -0.4923
Epoch[10780/50000]
**Valid**: G Loss: 70.7508, D Loss: 1.0080
Epoch[10790/50000]
**Train**: G Loss: 66.0962, D Loss: 0.2898
Epoch[10790/50000]
**Valid**: G Loss: 52.8899, D Loss: -0.5539
Epoch[10800/50000]
**Train**: G Loss: 94.7833, D Loss: -0.0942
Epoch[10800/50000]
**Valid**: G Loss: 122.7466, D Loss: -0.7542
Epoch[10810/50000]
**Train**: G Loss: 94.7640, D Loss: 0.0709
Epoch[10810/50000]
**Valid**: G Loss: 94.1321, D Loss: 1.4308
Epoch[10820/50000]
**Train**: G Loss: 98.3988, D Loss: 1.0577
Epoch[10820/50000]
**Valid**: G Loss: 59.3302, D Loss: -1.3388
Epoch[10830/50000]
**Train**: G Loss: 113.6502, D Loss: -0.2241
Epoch[10830/50000]
**Valid**: G Loss: 123.2456, D Loss: 0.8810
Epoch[10840/50000]
**Train**: G Loss: 21.0380, D Loss: 0.6417
Epoch[10840/50000]
**Valid**: G Loss: 43.7902, D Loss: 1.3681
Epoch[10850/50000]
**Train**: G Loss: 119.8122, D Loss: -0.8752
Epoch[10850/50000]
**Valid**: G Loss: 117.8834, D Loss: 0.8350
Epoch[10860/50000]
**Train**: G Loss: 76.5696, D Loss: 0.3654
Epoch[10860/50000]
**Valid**: G Loss: 24.2478, D Loss: -1.7796
Epoch[10870/50000]
**Train**: G Loss: 39.7252, D Loss: 0.8106
Epoch[10870/50000]
**Valid**: G Loss: 50.0887, D Loss: 1.0981
Epoch[10880/50000]
**Train**: G Loss: 81.2717, D Loss: 1.0158
Epoch[10880/50000]
**Valid**: G Loss: 44.7760, D Loss: -1.1389
Epoch[10890/50000]
**Train**: G Loss: 104.2106, D Loss: 0.8809
Epoch[10890/50000]
**Valid**: G Loss: 183.7420, D Loss: -1.6097
Epoch[10900/50000]
**Train**: G Loss: 95.2004, D Loss: 0.5506
Epoch[10900/50000]
**Valid**: G Loss: 83.6941, D Loss: 1.8141
Epoch[10910/50000]
**Train**: G Loss: 24.8441, D Loss: -0.8959
Epoch[10910/50000]
**Valid**: G Loss: 27.1059, D Loss: 1.0771
Epoch[10920/50000]
**Train**: G Loss: 160.1153, D Loss: -0.5001
Epoch[10920/50000]
**Valid**: G Loss: 185.4515, D Loss: -0.0893
Epoch[10930/50000]
**Train**: G Loss: 69.1744, D Loss: 1.0307
Epoch[10930/50000]
**Valid**: G Loss: 37.7793, D Loss: -1.4472
Epoch[10940/50000]
**Train**: G Loss: 39.4921, D Loss: 0.8616
Epoch[10940/50000]
**Valid**: G Loss: 47.3262, D Loss: 1.7232
Epoch[10950/50000]
**Train**: G Loss: 124.9481, D Loss: -0.0153
Epoch[10950/50000]
**Valid**: G Loss: 113.9411, D Loss: 1.8507
Epoch[10960/50000]
**Train**: G Loss: 45.3898, D Loss: 0.6741
Epoch[10960/50000]
**Valid**: G Loss: 54.3763, D Loss: 0.8377
Epoch[10970/50000]
**Train**: G Loss: 38.8387, D Loss: -0.6653
Epoch[10970/50000]
**Valid**: G Loss: 39.4177, D Loss: 0.7170
Epoch[10980/50000]
**Train**: G Loss: 91.4042, D Loss: -0.3435
Epoch[10980/50000]
**Valid**: G Loss: 87.9879, D Loss: 0.4111
Epoch[10990/50000]
**Train**: G Loss: 191.9942, D Loss: -0.5030
Epoch[10990/50000]
**Valid**: G Loss: 169.5788, D Loss: 1.2258
Epoch[11000/50000]
**Train**: G Loss: 11.4004, D Loss: -1.0033
Epoch[11000/50000]
**Valid**: G Loss: -12.1920, D Loss: -0.0550
Epoch[11010/50000]
**Train**: G Loss: 55.6545, D Loss: 1.0264
Epoch[11010/50000]
**Valid**: G Loss: 87.2341, D Loss: -0.7955
Epoch[11020/50000]
**Train**: G Loss: 130.9111, D Loss: -0.1599
Epoch[11020/50000]
**Valid**: G Loss: 119.3311, D Loss: 1.6634
Epoch[11030/50000]
**Train**: G Loss: 6.9079, D Loss: -0.9571
Epoch[11030/50000]
**Valid**: G Loss: -9.4432, D Loss: 0.4414
Epoch[11040/50000]
**Train**: G Loss: 53.4842, D Loss: 0.9473
Epoch[11040/50000]
**Valid**: G Loss: 105.5596, D Loss: 0.7260
Epoch[11050/50000]
**Train**: G Loss: 159.3295, D Loss: 0.6769
Epoch[11050/50000]
**Valid**: G Loss: 126.0624, D Loss: 1.6690
Epoch[11060/50000]
**Train**: G Loss: 81.0868, D Loss: 0.0083
Epoch[11060/50000]
**Valid**: G Loss: 59.2288, D Loss: -1.8552
Epoch[11070/50000]
**Train**: G Loss: 36.1250, D Loss: -0.7653
Epoch[11070/50000]
**Valid**: G Loss: 35.9050, D Loss: 1.2563
Epoch[11080/50000]
**Train**: G Loss: 50.9225, D Loss: 1.3127
Epoch[11080/50000]
**Valid**: G Loss: 71.0705, D Loss: 0.6749
Epoch[11090/50000]
**Train**: G Loss: 139.8071, D Loss: -0.7347
Epoch[11090/50000]
**Valid**: G Loss: 126.2421, D Loss: 1.7023
Epoch[11100/50000]
**Train**: G Loss: 7.0405, D Loss: -0.7561
Epoch[11100/50000]
**Valid**: G Loss: -8.2543, D Loss: -0.2817
Epoch[11110/50000]
**Train**: G Loss: 66.0085, D Loss: 0.9092
Epoch[11110/50000]
**Valid**: G Loss: 109.0591, D Loss: -1.0124
Epoch[11120/50000]
**Train**: G Loss: 150.9655, D Loss: 0.8299
Epoch[11120/50000]
**Valid**: G Loss: 122.4755, D Loss: 1.5098
Epoch[11130/50000]
**Train**: G Loss: 31.6807, D Loss: -0.1533
Epoch[11130/50000]
**Valid**: G Loss: -27.9447, D Loss: -1.3783
Epoch[11140/50000]
**Train**: G Loss: -2.3942, D Loss: 0.5612
Epoch[11140/50000]
**Valid**: G Loss: 40.8483, D Loss: 1.4488
Epoch[11150/50000]
**Train**: G Loss: 174.5018, D Loss: -0.8777
Epoch[11150/50000]
**Valid**: G Loss: 180.0144, D Loss: 0.6521
Epoch[11160/50000]
**Train**: G Loss: 75.5172, D Loss: 0.1430
Epoch[11160/50000]
**Valid**: G Loss: 15.6436, D Loss: -1.4551
Epoch[11170/50000]
**Train**: G Loss: 45.9117, D Loss: 1.1653
Epoch[11170/50000]
**Valid**: G Loss: 94.8624, D Loss: 0.4816
Epoch[11180/50000]
**Train**: G Loss: 123.9987, D Loss: -0.6651
Epoch[11180/50000]
**Valid**: G Loss: 113.8107, D Loss: 1.3588
Epoch[11190/50000]
**Train**: G Loss: 34.5962, D Loss: -0.1821
Epoch[11190/50000]
**Valid**: G Loss: -12.9469, D Loss: -0.8121
Epoch[11200/50000]
**Train**: G Loss: 41.3953, D Loss: 1.3363
Epoch[11200/50000]
**Valid**: G Loss: 71.5527, D Loss: 1.2313
Epoch[11210/50000]
**Train**: G Loss: 140.0800, D Loss: -0.8584
Epoch[11210/50000]
**Valid**: G Loss: 136.5341, D Loss: 0.9141
Epoch[11220/50000]
**Train**: G Loss: 90.7985, D Loss: 1.4151
Epoch[11220/50000]
**Valid**: G Loss: 70.5627, D Loss: -0.6702
Epoch[11230/50000]
**Train**: G Loss: 38.9895, D Loss: 0.1909
Epoch[11230/50000]
**Valid**: G Loss: 42.6107, D Loss: 1.2447
Epoch[11240/50000]
**Train**: G Loss: 124.1563, D Loss: 0.7289
Epoch[11240/50000]
**Valid**: G Loss: 111.9769, D Loss: 0.8428
Epoch[11250/50000]
**Train**: G Loss: 106.1618, D Loss: 0.2152
Epoch[11250/50000]
**Valid**: G Loss: 154.4092, D Loss: -0.1254
Epoch[11260/50000]
**Train**: G Loss: 90.4433, D Loss: 0.1402
Epoch[11260/50000]
**Valid**: G Loss: 129.2485, D Loss: 0.1973
Epoch[11270/50000]
**Train**: G Loss: 118.7188, D Loss: 0.2469
Epoch[11270/50000]
**Valid**: G Loss: 89.3023, D Loss: 0.3029
Epoch[11280/50000]
**Train**: G Loss: 76.9507, D Loss: 0.3497
Epoch[11280/50000]
**Valid**: G Loss: 101.0054, D Loss: 0.2564
Epoch[11290/50000]
**Train**: G Loss: 129.8447, D Loss: 0.8436
Epoch[11290/50000]
**Valid**: G Loss: 102.2796, D Loss: 1.2180
Epoch[11300/50000]
**Train**: G Loss: 77.9600, D Loss: 1.0205
Epoch[11300/50000]
**Valid**: G Loss: 124.0497, D Loss: -1.1710
Epoch[11310/50000]
**Train**: G Loss: 76.0675, D Loss: 0.5647
Epoch[11310/50000]
**Valid**: G Loss: 92.5917, D Loss: -0.3436
Epoch[11320/50000]
**Train**: G Loss: 99.8773, D Loss: 0.1776
Epoch[11320/50000]
**Valid**: G Loss: 108.1800, D Loss: 1.0042
Epoch[11330/50000]
**Train**: G Loss: 105.2418, D Loss: 0.4196
Epoch[11330/50000]
**Valid**: G Loss: 94.5805, D Loss: -0.1813
Epoch[11340/50000]
**Train**: G Loss: 36.0688, D Loss: -0.5886
Epoch[11340/50000]
**Valid**: G Loss: 40.3217, D Loss: 0.6681
Epoch[11350/50000]
**Train**: G Loss: 45.2828, D Loss: -0.4410
Epoch[11350/50000]
**Valid**: G Loss: 41.6972, D Loss: 1.1394
Epoch[11360/50000]
**Train**: G Loss: 84.8422, D Loss: 0.4311
Epoch[11360/50000]
**Valid**: G Loss: 113.2064, D Loss: 0.3076
Epoch[11370/50000]
**Train**: G Loss: 110.1815, D Loss: 0.6055
Epoch[11370/50000]
**Valid**: G Loss: 92.4815, D Loss: -0.1698
Epoch[11380/50000]
**Train**: G Loss: 95.2725, D Loss: 0.6730
Epoch[11380/50000]
**Valid**: G Loss: 93.3291, D Loss: 0.6288
Epoch[11390/50000]
**Train**: G Loss: 118.4778, D Loss: 0.6243
Epoch[11390/50000]
**Valid**: G Loss: 105.3880, D Loss: 0.7355
Epoch[11400/50000]
**Train**: G Loss: 143.7855, D Loss: -0.3658
Epoch[11400/50000]
**Valid**: G Loss: 177.8446, D Loss: -0.1078
Epoch[11410/50000]
**Train**: G Loss: 68.0223, D Loss: -0.0860
Epoch[11410/50000]
**Valid**: G Loss: 75.6531, D Loss: 1.0090
Epoch[11420/50000]
**Train**: G Loss: 130.8461, D Loss: 0.4182
Epoch[11420/50000]
**Valid**: G Loss: 126.2750, D Loss: 1.4516
Epoch[11430/50000]
**Train**: G Loss: 70.3384, D Loss: 0.1861
Epoch[11430/50000]
**Valid**: G Loss: 70.7290, D Loss: 1.2228
Epoch[11440/50000]
**Train**: G Loss: 79.1354, D Loss: 0.1229
Epoch[11440/50000]
**Valid**: G Loss: 56.7097, D Loss: -1.1527
Epoch[11450/50000]
**Train**: G Loss: 85.7796, D Loss: 0.0471
Epoch[11450/50000]
**Valid**: G Loss: 75.9591, D Loss: 1.6994
Epoch[11460/50000]
**Train**: G Loss: 108.4843, D Loss: 0.3827
Epoch[11460/50000]
**Valid**: G Loss: 96.3738, D Loss: 0.9734
Epoch[11470/50000]
**Train**: G Loss: 94.1986, D Loss: 0.0086
Epoch[11470/50000]
**Valid**: G Loss: 114.7473, D Loss: 0.6029
Epoch[11480/50000]
**Train**: G Loss: 72.9079, D Loss: 0.6922
Epoch[11480/50000]
**Valid**: G Loss: 99.3073, D Loss: -0.1149
Epoch[11490/50000]
**Train**: G Loss: 50.0524, D Loss: 0.3272
Epoch[11490/50000]
**Valid**: G Loss: 60.9803, D Loss: 1.2354
Epoch[11500/50000]
**Train**: G Loss: 91.9503, D Loss: -0.2670
Epoch[11500/50000]
**Valid**: G Loss: 83.5329, D Loss: 0.6886
Epoch[11510/50000]
**Train**: G Loss: 73.3539, D Loss: 0.6145
Epoch[11510/50000]
**Valid**: G Loss: 52.4245, D Loss: -0.7247
Epoch[11520/50000]
**Train**: G Loss: 83.8140, D Loss: -0.3049
Epoch[11520/50000]
**Valid**: G Loss: 79.9576, D Loss: 1.0896
Epoch[11530/50000]
**Train**: G Loss: 110.9352, D Loss: 0.3030
Epoch[11530/50000]
**Valid**: G Loss: 96.9220, D Loss: -0.1856
Epoch[11540/50000]
**Train**: G Loss: 58.4091, D Loss: -0.1750
Epoch[11540/50000]
**Valid**: G Loss: 45.3400, D Loss: -0.1326
Epoch[11550/50000]
**Train**: G Loss: 180.0023, D Loss: -0.4922
Epoch[11550/50000]
**Valid**: G Loss: 162.5057, D Loss: 1.4988
Epoch[11560/50000]
**Train**: G Loss: 22.5005, D Loss: -0.2167
Epoch[11560/50000]
**Valid**: G Loss: 32.1834, D Loss: 1.1097
Epoch[11570/50000]
**Train**: G Loss: 57.4786, D Loss: -0.1392
Epoch[11570/50000]
**Valid**: G Loss: 46.1508, D Loss: 0.2422
Epoch[11580/50000]
**Train**: G Loss: 127.1227, D Loss: 0.5497
Epoch[11580/50000]
**Valid**: G Loss: 106.4859, D Loss: 1.9054
Epoch[11590/50000]
**Train**: G Loss: 64.5466, D Loss: 0.6989
Epoch[11590/50000]
**Valid**: G Loss: 94.0502, D Loss: 0.0603
Epoch[11600/50000]
**Train**: G Loss: 39.0683, D Loss: 0.7733
Epoch[11600/50000]
**Valid**: G Loss: 60.3955, D Loss: 1.4261
Epoch[11610/50000]
**Train**: G Loss: 80.7062, D Loss: 0.3192
Epoch[11610/50000]
**Valid**: G Loss: 60.2969, D Loss: -0.0463
Epoch[11620/50000]
**Train**: G Loss: 68.3817, D Loss: 0.4157
Epoch[11620/50000]
**Valid**: G Loss: 41.8130, D Loss: -0.9936
Epoch[11630/50000]
**Train**: G Loss: 123.3125, D Loss: 0.2156
Epoch[11630/50000]
**Valid**: G Loss: 127.6196, D Loss: 1.1354
Epoch[11640/50000]
**Train**: G Loss: 45.8378, D Loss: 0.1743
Epoch[11640/50000]
**Valid**: G Loss: 56.5591, D Loss: 1.6677
Epoch[11650/50000]
**Train**: G Loss: 126.0457, D Loss: 1.0833
Epoch[11650/50000]
**Valid**: G Loss: 106.7574, D Loss: 0.8600
Epoch[11660/50000]
**Train**: G Loss: 113.4651, D Loss: 0.3348
Epoch[11660/50000]
**Valid**: G Loss: 97.9086, D Loss: 1.7545
Epoch[11670/50000]
**Train**: G Loss: 54.2940, D Loss: -0.6437
Epoch[11670/50000]
**Valid**: G Loss: 52.7556, D Loss: 1.2610
Epoch[11680/50000]
**Train**: G Loss: 135.4340, D Loss: -0.1810
Epoch[11680/50000]
**Valid**: G Loss: 154.8642, D Loss: 1.2579
Epoch[11690/50000]
**Train**: G Loss: 37.1596, D Loss: 0.4692
Epoch[11690/50000]
**Valid**: G Loss: 48.8318, D Loss: 1.1143
Epoch[11700/50000]
**Train**: G Loss: 89.0740, D Loss: 0.0443
Epoch[11700/50000]
**Valid**: G Loss: 90.6878, D Loss: 0.6001
Epoch[11710/50000]
**Train**: G Loss: 11.4367, D Loss: -0.9358
Epoch[11710/50000]
**Valid**: G Loss: 3.6711, D Loss: 0.4373
Epoch[11720/50000]
**Train**: G Loss: 135.6610, D Loss: 0.4999
Epoch[11720/50000]
**Valid**: G Loss: 106.8029, D Loss: 1.1646
Epoch[11730/50000]
**Train**: G Loss: 90.9064, D Loss: 0.3367
Epoch[11730/50000]
**Valid**: G Loss: 72.1549, D Loss: 0.1253
Epoch[11740/50000]
**Train**: G Loss: 90.5381, D Loss: 1.1071
Epoch[11740/50000]
**Valid**: G Loss: 57.8813, D Loss: -1.5305
Epoch[11750/50000]
**Train**: G Loss: 95.7916, D Loss: 0.4788
Epoch[11750/50000]
**Valid**: G Loss: 72.6513, D Loss: -0.1603
Epoch[11760/50000]
**Train**: G Loss: 118.2569, D Loss: 0.1364
Epoch[11760/50000]
**Valid**: G Loss: 105.6387, D Loss: 0.3893
Epoch[11770/50000]
**Train**: G Loss: 89.4385, D Loss: 0.0330
Epoch[11770/50000]
**Valid**: G Loss: 87.5791, D Loss: 1.0363
Epoch[11780/50000]
**Train**: G Loss: 96.4602, D Loss: 1.1344
Epoch[11780/50000]
**Valid**: G Loss: 66.6117, D Loss: 0.0577
Epoch[11790/50000]
**Train**: G Loss: 107.4762, D Loss: 0.2813
Epoch[11790/50000]
**Valid**: G Loss: 84.2196, D Loss: 0.0252
Epoch[11800/50000]
**Train**: G Loss: 52.0964, D Loss: -0.0338
Epoch[11800/50000]
**Valid**: G Loss: 60.1272, D Loss: 0.9524
Epoch[11810/50000]
**Train**: G Loss: 83.0000, D Loss: -0.0779
Epoch[11810/50000]
**Valid**: G Loss: 53.0561, D Loss: -0.7367
Epoch[11820/50000]
**Train**: G Loss: 90.4513, D Loss: 0.6028
Epoch[11820/50000]
**Valid**: G Loss: 66.0251, D Loss: -0.4737
Epoch[11830/50000]
**Train**: G Loss: 134.2749, D Loss: 0.1345
Epoch[11830/50000]
**Valid**: G Loss: 112.0388, D Loss: 1.8188
Epoch[11840/50000]
**Train**: G Loss: 124.0698, D Loss: -0.1938
Epoch[11840/50000]
**Valid**: G Loss: 159.8930, D Loss: 0.4580
Epoch[11850/50000]
**Train**: G Loss: 139.6951, D Loss: 0.0491
Epoch[11850/50000]
**Valid**: G Loss: 155.7973, D Loss: 0.8846
Epoch[11860/50000]
**Train**: G Loss: 47.2156, D Loss: 1.0467
Epoch[11860/50000]
**Valid**: G Loss: 100.0589, D Loss: 0.6510
Epoch[11870/50000]
**Train**: G Loss: 139.7930, D Loss: 0.8976
Epoch[11870/50000]
**Valid**: G Loss: 103.3395, D Loss: 1.7272
Epoch[11880/50000]
**Train**: G Loss: 23.1770, D Loss: 0.7857
Epoch[11880/50000]
**Valid**: G Loss: 52.2580, D Loss: 1.4695
Epoch[11890/50000]
**Train**: G Loss: 133.9830, D Loss: -0.7410
Epoch[11890/50000]
**Valid**: G Loss: 117.2573, D Loss: 1.2595
Epoch[11900/50000]
**Train**: G Loss: 64.8042, D Loss: -0.1894
Epoch[11900/50000]
**Valid**: G Loss: 24.9090, D Loss: -1.2765
Epoch[11910/50000]
**Train**: G Loss: 13.4516, D Loss: 1.0779
Epoch[11910/50000]
**Valid**: G Loss: 57.7858, D Loss: 1.3911
Epoch[11920/50000]
**Train**: G Loss: 107.6818, D Loss: 0.7990
Epoch[11920/50000]
**Valid**: G Loss: 68.8885, D Loss: -0.5589
Epoch[11930/50000]
**Train**: G Loss: 90.8216, D Loss: -0.3013
Epoch[11930/50000]
**Valid**: G Loss: 99.4193, D Loss: 0.5359
Epoch[11940/50000]
**Train**: G Loss: 101.7062, D Loss: 0.4833
Epoch[11940/50000]
**Valid**: G Loss: 129.0364, D Loss: -0.3698
Epoch[11950/50000]
**Train**: G Loss: 41.7226, D Loss: 0.1783
Epoch[11950/50000]
**Valid**: G Loss: 48.9353, D Loss: 1.0749
Epoch[11960/50000]
**Train**: G Loss: 129.6007, D Loss: 0.8546
Epoch[11960/50000]
**Valid**: G Loss: 103.7461, D Loss: -0.3492
Epoch[11970/50000]
**Train**: G Loss: 93.2093, D Loss: 0.0002
Epoch[11970/50000]
**Valid**: G Loss: 80.8052, D Loss: 0.1957
Epoch[11980/50000]
**Train**: G Loss: 112.8050, D Loss: 1.0026
Epoch[11980/50000]
**Valid**: G Loss: 104.0566, D Loss: 1.6155
Epoch[11990/50000]
**Train**: G Loss: 46.4343, D Loss: 0.3470
Epoch[11990/50000]
**Valid**: G Loss: 60.8859, D Loss: 1.1366
Epoch[12000/50000]
**Train**: G Loss: 93.2453, D Loss: 0.4967
Epoch[12000/50000]
**Valid**: G Loss: 104.1223, D Loss: 0.1159
Epoch[12010/50000]
**Train**: G Loss: 71.1236, D Loss: 0.8005
Epoch[12010/50000]
**Valid**: G Loss: 101.2881, D Loss: -0.4818
Epoch[12020/50000]
**Train**: G Loss: 68.5709, D Loss: -0.3869
Epoch[12020/50000]
**Valid**: G Loss: 64.6565, D Loss: 1.1344
Epoch[12030/50000]
**Train**: G Loss: 130.3690, D Loss: -0.0950
Epoch[12030/50000]
**Valid**: G Loss: 176.5045, D Loss: 0.3806
Epoch[12040/50000]
**Train**: G Loss: 20.8563, D Loss: 0.8564
Epoch[12040/50000]
**Valid**: G Loss: 47.6260, D Loss: 1.2608
Epoch[12050/50000]
**Train**: G Loss: 93.1072, D Loss: 0.4888
Epoch[12050/50000]
**Valid**: G Loss: 63.8632, D Loss: -0.5240
Epoch[12060/50000]
**Train**: G Loss: 102.8970, D Loss: 0.7719
Epoch[12060/50000]
**Valid**: G Loss: 79.4556, D Loss: 0.5178
Epoch[12070/50000]
**Train**: G Loss: 80.3495, D Loss: 0.4638
Epoch[12070/50000]
**Valid**: G Loss: 129.6120, D Loss: -0.6515
Epoch[12080/50000]
**Train**: G Loss: 50.1457, D Loss: 0.0963
Epoch[12080/50000]
**Valid**: G Loss: 53.7983, D Loss: 1.0058
Epoch[12090/50000]
**Train**: G Loss: 49.8281, D Loss: -0.6109
Epoch[12090/50000]
**Valid**: G Loss: 43.6153, D Loss: 0.5187
Epoch[12100/50000]
**Train**: G Loss: 54.9022, D Loss: 0.0368
Epoch[12100/50000]
**Valid**: G Loss: 48.6926, D Loss: 1.1781
Epoch[12110/50000]
**Train**: G Loss: 79.4276, D Loss: -0.0140
Epoch[12110/50000]
**Valid**: G Loss: 72.2878, D Loss: 0.3522
Epoch[12120/50000]
**Train**: G Loss: 46.8339, D Loss: 0.5230
Epoch[12120/50000]
**Valid**: G Loss: 53.7152, D Loss: 1.1665
Epoch[12130/50000]
**Train**: G Loss: 57.3696, D Loss: 0.2668
Epoch[12130/50000]
**Valid**: G Loss: 59.4448, D Loss: 1.6324
Epoch[12140/50000]
**Train**: G Loss: 3.6422, D Loss: -0.8084
Epoch[12140/50000]
**Valid**: G Loss: -4.8954, D Loss: 0.4286
Epoch[12150/50000]
**Train**: G Loss: 171.6024, D Loss: -0.6382
Epoch[12150/50000]
**Valid**: G Loss: 166.3583, D Loss: 0.8465
Epoch[12160/50000]
**Train**: G Loss: 26.3056, D Loss: 0.0045
Epoch[12160/50000]
**Valid**: G Loss: -44.4949, D Loss: -1.0597
Epoch[12170/50000]
**Train**: G Loss: 36.6313, D Loss: 1.1447
Epoch[12170/50000]
**Valid**: G Loss: 91.9294, D Loss: 0.3352
Epoch[12180/50000]
**Train**: G Loss: 155.3878, D Loss: -0.9304
Epoch[12180/50000]
**Valid**: G Loss: 139.5322, D Loss: 1.2751
Epoch[12190/50000]
**Train**: G Loss: 94.4688, D Loss: 1.1433
Epoch[12190/50000]
**Valid**: G Loss: 44.7601, D Loss: -0.6242
Epoch[12200/50000]
**Train**: G Loss: -36.5011, D Loss: -0.8312
Epoch[12200/50000]
**Valid**: G Loss: -17.8657, D Loss: 1.2481
Epoch[12210/50000]
**Train**: G Loss: 110.1005, D Loss: 0.0876
Epoch[12210/50000]
**Valid**: G Loss: 179.3033, D Loss: -1.0528
Epoch[12220/50000]
**Train**: G Loss: 135.7520, D Loss: 0.8732
Epoch[12220/50000]
**Valid**: G Loss: 108.7652, D Loss: 1.7854
Epoch[12230/50000]
**Train**: G Loss: 14.9402, D Loss: -0.3273
Epoch[12230/50000]
**Valid**: G Loss: -40.4805, D Loss: -1.1267
Epoch[12240/50000]
**Train**: G Loss: 16.9693, D Loss: 1.1291
Epoch[12240/50000]
**Valid**: G Loss: 56.0369, D Loss: 1.1468
Epoch[12250/50000]
**Train**: G Loss: 133.8083, D Loss: 0.2476
Epoch[12250/50000]
**Valid**: G Loss: 109.4335, D Loss: 1.7271
Epoch[12260/50000]
**Train**: G Loss: 27.7141, D Loss: -0.0303
Epoch[12260/50000]
**Valid**: G Loss: -38.4020, D Loss: -1.4052
Epoch[12270/50000]
**Train**: G Loss: -0.8418, D Loss: 0.7398
Epoch[12270/50000]
**Valid**: G Loss: 22.4396, D Loss: 1.4366
Epoch[12280/50000]
**Train**: G Loss: 143.2783, D Loss: -0.7108
Epoch[12280/50000]
**Valid**: G Loss: 144.3084, D Loss: 0.5202
Epoch[12290/50000]
**Train**: G Loss: 81.4380, D Loss: 1.4205
Epoch[12290/50000]
**Valid**: G Loss: 60.7270, D Loss: 0.4897
Epoch[12300/50000]
**Train**: G Loss: -6.9531, D Loss: -0.6288
Epoch[12300/50000]
**Valid**: G Loss: -4.2634, D Loss: 0.9587
Epoch[12310/50000]
**Train**: G Loss: 41.6723, D Loss: 0.7534
Epoch[12310/50000]
**Valid**: G Loss: 93.6298, D Loss: -1.6285
Epoch[12320/50000]
**Train**: G Loss: 71.6160, D Loss: 1.1161
Epoch[12320/50000]
**Valid**: G Loss: 66.8529, D Loss: 0.9792
Epoch[12330/50000]
**Train**: G Loss: 44.5885, D Loss: -0.3696
Epoch[12330/50000]
**Valid**: G Loss: 43.7117, D Loss: 0.8956
Epoch[12340/50000]
**Train**: G Loss: 84.3419, D Loss: 0.6744
Epoch[12340/50000]
**Valid**: G Loss: 75.5022, D Loss: 1.5936
Epoch[12350/50000]
**Train**: G Loss: 42.7207, D Loss: 0.2409
Epoch[12350/50000]
**Valid**: G Loss: 44.8194, D Loss: 0.9856
Epoch[12360/50000]
**Train**: G Loss: 104.6211, D Loss: -0.2346
Epoch[12360/50000]
**Valid**: G Loss: 88.1677, D Loss: 1.8707
Epoch[12370/50000]
**Train**: G Loss: 27.3652, D Loss: 0.2317
Epoch[12370/50000]
**Valid**: G Loss: 31.2781, D Loss: 1.2242
Epoch[12380/50000]
**Train**: G Loss: 112.5503, D Loss: -0.6971
Epoch[12380/50000]
**Valid**: G Loss: 109.7215, D Loss: 0.8802
Epoch[12390/50000]
**Train**: G Loss: 69.6064, D Loss: 0.8959
Epoch[12390/50000]
**Valid**: G Loss: 34.8117, D Loss: -1.6200
Epoch[12400/50000]
**Train**: G Loss: 77.2243, D Loss: 0.0208
Epoch[12400/50000]
**Valid**: G Loss: 96.2111, D Loss: -0.3237
Epoch[12410/50000]
**Train**: G Loss: 69.2523, D Loss: -0.6521
Epoch[12410/50000]
**Valid**: G Loss: 57.5950, D Loss: -0.1024
Epoch[12420/50000]
**Train**: G Loss: 94.0269, D Loss: -0.4642
Epoch[12420/50000]
**Valid**: G Loss: 91.0943, D Loss: 0.4817
Epoch[12430/50000]
**Train**: G Loss: 64.5795, D Loss: -0.5877
Epoch[12430/50000]
**Valid**: G Loss: 60.7982, D Loss: 1.2284
Epoch[12440/50000]
**Train**: G Loss: 99.3064, D Loss: -0.4533
Epoch[12440/50000]
**Valid**: G Loss: 88.3127, D Loss: 1.1333
Epoch[12450/50000]
**Train**: G Loss: 51.8183, D Loss: -0.6639
Epoch[12450/50000]
**Valid**: G Loss: 51.2735, D Loss: 0.7319
Epoch[12460/50000]
**Train**: G Loss: 100.6230, D Loss: 0.1560
Epoch[12460/50000]
**Valid**: G Loss: 161.2823, D Loss: -0.6599
Epoch[12470/50000]
**Train**: G Loss: 51.3911, D Loss: 0.1273
Epoch[12470/50000]
**Valid**: G Loss: -12.0776, D Loss: -1.4521
Epoch[12480/50000]
**Train**: G Loss: 31.4590, D Loss: 0.9474
Epoch[12480/50000]
**Valid**: G Loss: 65.0958, D Loss: 1.3516
Epoch[12490/50000]
**Train**: G Loss: 123.1341, D Loss: -0.7060
Epoch[12490/50000]
**Valid**: G Loss: 114.7573, D Loss: 0.8164
Epoch[12500/50000]
**Train**: G Loss: 66.8698, D Loss: 0.4079
Epoch[12500/50000]
**Valid**: G Loss: 25.0476, D Loss: -1.0439
Epoch[12510/50000]
**Train**: G Loss: 98.1611, D Loss: -0.3926
Epoch[12510/50000]
**Valid**: G Loss: 102.2322, D Loss: 0.2054
Epoch[12520/50000]
**Train**: G Loss: 62.4715, D Loss: -0.7281
Epoch[12520/50000]
**Valid**: G Loss: 54.4116, D Loss: 0.1224
Epoch[12530/50000]
**Train**: G Loss: 79.7069, D Loss: 0.7472
Epoch[12530/50000]
**Valid**: G Loss: 116.2668, D Loss: -1.0760
Epoch[12540/50000]
**Train**: G Loss: 130.2722, D Loss: 0.3716
Epoch[12540/50000]
**Valid**: G Loss: 102.0902, D Loss: 1.5088
Epoch[12550/50000]
**Train**: G Loss: -22.8891, D Loss: -0.8341
Epoch[12550/50000]
**Valid**: G Loss: -23.5765, D Loss: 0.6503
Epoch[12560/50000]
**Train**: G Loss: 86.7610, D Loss: 0.2587
Epoch[12560/50000]
**Valid**: G Loss: 153.0071, D Loss: -1.1749
Epoch[12570/50000]
**Train**: G Loss: 106.9853, D Loss: 1.0734
Epoch[12570/50000]
**Valid**: G Loss: 68.2774, D Loss: 0.6982
Epoch[12580/50000]
**Train**: G Loss: 0.5804, D Loss: 0.4521
Epoch[12580/50000]
**Valid**: G Loss: 30.2823, D Loss: 1.1830
Epoch[12590/50000]
**Train**: G Loss: 124.3245, D Loss: 0.9954
Epoch[12590/50000]
**Valid**: G Loss: 93.7508, D Loss: 1.2640
Epoch[12600/50000]
**Train**: G Loss: -1.3251, D Loss: -0.2121
Epoch[12600/50000]
**Valid**: G Loss: 17.7170, D Loss: 1.4267
Epoch[12610/50000]
**Train**: G Loss: 142.2342, D Loss: -0.6157
Epoch[12610/50000]
**Valid**: G Loss: 137.1276, D Loss: 0.8609
Epoch[12620/50000]
**Train**: G Loss: 50.3270, D Loss: -0.0355
Epoch[12620/50000]
**Valid**: G Loss: -3.0124, D Loss: -1.0991
Epoch[12630/50000]
**Train**: G Loss: 71.8209, D Loss: 0.6539
Epoch[12630/50000]
**Valid**: G Loss: 139.5699, D Loss: -1.1600
Epoch[12640/50000]
**Train**: G Loss: 98.5825, D Loss: 1.1898
Epoch[12640/50000]
**Valid**: G Loss: 60.0755, D Loss: 0.3382
Epoch[12650/50000]
**Train**: G Loss: -10.0519, D Loss: 0.3520
Epoch[12650/50000]
**Valid**: G Loss: 16.1951, D Loss: 1.3406
Epoch[12660/50000]
**Train**: G Loss: 162.2567, D Loss: -0.2245
Epoch[12660/50000]
**Valid**: G Loss: 132.4919, D Loss: 1.4302
Epoch[12670/50000]
**Train**: G Loss: 15.0963, D Loss: -0.6318
Epoch[12670/50000]
**Valid**: G Loss: -25.2517, D Loss: -0.7704
Epoch[12680/50000]
**Train**: G Loss: 50.6652, D Loss: 0.7933
Epoch[12680/50000]
**Valid**: G Loss: 103.0648, D Loss: -0.6944
Epoch[12690/50000]
**Train**: G Loss: 108.0113, D Loss: 0.7011
Epoch[12690/50000]
**Valid**: G Loss: 85.9782, D Loss: 1.4837
Epoch[12700/50000]
**Train**: G Loss: 17.9302, D Loss: -0.5328
Epoch[12700/50000]
**Valid**: G Loss: 13.4173, D Loss: 0.9333
Epoch[12710/50000]
**Train**: G Loss: 89.6028, D Loss: -0.4752
Epoch[12710/50000]
**Valid**: G Loss: 93.2781, D Loss: 0.4194
Epoch[12720/50000]
**Train**: G Loss: 74.6090, D Loss: 0.2078
Epoch[12720/50000]
**Valid**: G Loss: 63.5037, D Loss: -1.1037
Epoch[12730/50000]
**Train**: G Loss: 61.7211, D Loss: 1.0159
Epoch[12730/50000]
**Valid**: G Loss: 71.3372, D Loss: 0.4306
Epoch[12740/50000]
**Train**: G Loss: 77.1744, D Loss: 0.9315
Epoch[12740/50000]
**Valid**: G Loss: 73.3414, D Loss: 1.3547
Epoch[12750/50000]
**Train**: G Loss: 64.8846, D Loss: -0.6849
Epoch[12750/50000]
**Valid**: G Loss: 61.5565, D Loss: 0.8044
Epoch[12760/50000]
**Train**: G Loss: 105.3619, D Loss: -0.3634
Epoch[12760/50000]
**Valid**: G Loss: 98.3060, D Loss: 1.3428
Epoch[12770/50000]
**Train**: G Loss: 44.6739, D Loss: -0.5490
Epoch[12770/50000]
**Valid**: G Loss: 42.9187, D Loss: 0.6152
Epoch[12780/50000]
**Train**: G Loss: 113.9740, D Loss: -0.1772
Epoch[12780/50000]
**Valid**: G Loss: 101.9342, D Loss: 1.4616
Epoch[12790/50000]
**Train**: G Loss: 41.6367, D Loss: 0.1349
Epoch[12790/50000]
**Valid**: G Loss: 44.7620, D Loss: 1.3886
Epoch[12800/50000]
**Train**: G Loss: 98.4285, D Loss: 0.2235
Epoch[12800/50000]
**Valid**: G Loss: 83.8921, D Loss: 1.6652
Epoch[12810/50000]
**Train**: G Loss: 48.7608, D Loss: 0.4453
Epoch[12810/50000]
**Valid**: G Loss: 55.4775, D Loss: 1.0213
Epoch[12820/50000]
**Train**: G Loss: 99.1139, D Loss: 0.6568
Epoch[12820/50000]
**Valid**: G Loss: 86.4263, D Loss: 1.7234
Epoch[12830/50000]
**Train**: G Loss: 41.2760, D Loss: 0.6547
Epoch[12830/50000]
**Valid**: G Loss: 54.9363, D Loss: 1.2777
Epoch[12840/50000]
**Train**: G Loss: 130.5475, D Loss: -0.2823
Epoch[12840/50000]
**Valid**: G Loss: 114.8076, D Loss: 1.4600
Epoch[12850/50000]
**Train**: G Loss: 27.4290, D Loss: -0.5924
Epoch[12850/50000]
**Valid**: G Loss: 10.9496, D Loss: -0.0585
Epoch[12860/50000]
**Train**: G Loss: 87.2245, D Loss: 0.2190
Epoch[12860/50000]
**Valid**: G Loss: 134.3879, D Loss: -0.8411
Epoch[12870/50000]
**Train**: G Loss: 77.1427, D Loss: 0.8629
Epoch[12870/50000]
**Valid**: G Loss: 49.1996, D Loss: -1.1029
Epoch[12880/50000]
**Train**: G Loss: 40.3360, D Loss: 0.7621
Epoch[12880/50000]
**Valid**: G Loss: 61.1179, D Loss: 0.4383
Epoch[12890/50000]
**Train**: G Loss: 73.5505, D Loss: 1.1979
Epoch[12890/50000]
**Valid**: G Loss: 53.2157, D Loss: -0.6101
Epoch[12900/50000]
**Train**: G Loss: 52.5962, D Loss: 0.8436
Epoch[12900/50000]
**Valid**: G Loss: 82.7601, D Loss: -0.0357
Epoch[12910/50000]
**Train**: G Loss: 83.8179, D Loss: 1.0341
Epoch[12910/50000]
**Valid**: G Loss: 78.2164, D Loss: 0.5692
Epoch[12920/50000]
**Train**: G Loss: 69.8681, D Loss: 0.6418
Epoch[12920/50000]
**Valid**: G Loss: 67.0413, D Loss: 0.9876
Epoch[12930/50000]
**Train**: G Loss: 76.4290, D Loss: 0.7061
Epoch[12930/50000]
**Valid**: G Loss: 74.9827, D Loss: -0.8624
Epoch[12940/50000]
**Train**: G Loss: 84.2566, D Loss: 0.4294
Epoch[12940/50000]
**Valid**: G Loss: 103.5025, D Loss: -0.7183
Epoch[12950/50000]
**Train**: G Loss: 53.8789, D Loss: 0.2720
Epoch[12950/50000]
**Valid**: G Loss: 65.8128, D Loss: 1.0380
Epoch[12960/50000]
**Train**: G Loss: 76.8099, D Loss: 0.5301
Epoch[12960/50000]
**Valid**: G Loss: 31.5050, D Loss: -1.0671
Epoch[12970/50000]
**Train**: G Loss: 108.8450, D Loss: 0.1603
Epoch[12970/50000]
**Valid**: G Loss: 158.5116, D Loss: -0.3352
Epoch[12980/50000]
**Train**: G Loss: 59.6503, D Loss: 0.1957
Epoch[12980/50000]
**Valid**: G Loss: 11.1404, D Loss: -1.3128
Epoch[12990/50000]
**Train**: G Loss: 87.8368, D Loss: 0.4600
Epoch[12990/50000]
**Valid**: G Loss: 127.8749, D Loss: -0.8083
Epoch[13000/50000]
**Train**: G Loss: 68.6217, D Loss: 0.3610
Epoch[13000/50000]
**Valid**: G Loss: 39.3578, D Loss: -0.9680
Epoch[13010/50000]
**Train**: G Loss: 71.6466, D Loss: 0.5740
Epoch[13010/50000]
**Valid**: G Loss: 94.5680, D Loss: -0.6897
Epoch[13020/50000]
**Train**: G Loss: 78.0102, D Loss: 0.5705
Epoch[13020/50000]
**Valid**: G Loss: 65.3101, D Loss: -1.1826
Epoch[13030/50000]
**Train**: G Loss: 46.3987, D Loss: 0.7518
Epoch[13030/50000]
**Valid**: G Loss: 63.6371, D Loss: 1.0273
Epoch[13040/50000]
**Train**: G Loss: 94.6508, D Loss: 1.0101
Epoch[13040/50000]
**Valid**: G Loss: 73.6010, D Loss: 0.3997
Epoch[13050/50000]
**Train**: G Loss: 24.6013, D Loss: 0.3102
Epoch[13050/50000]
**Valid**: G Loss: 35.4553, D Loss: 1.1698
Epoch[13060/50000]
**Train**: G Loss: 108.7766, D Loss: 0.3576
Epoch[13060/50000]
**Valid**: G Loss: 90.8741, D Loss: 1.3853
Epoch[13070/50000]
**Train**: G Loss: 66.7256, D Loss: 0.2107
Epoch[13070/50000]
**Valid**: G Loss: 64.8529, D Loss: 1.0335
Epoch[13080/50000]
**Train**: G Loss: 131.5338, D Loss: 0.6450
Epoch[13080/50000]
**Valid**: G Loss: 113.3228, D Loss: 1.3752
Epoch[13090/50000]
**Train**: G Loss: 49.1476, D Loss: 0.2841
Epoch[13090/50000]
**Valid**: G Loss: 57.5539, D Loss: 1.1012
Epoch[13100/50000]
**Train**: G Loss: 128.8150, D Loss: 0.1517
Epoch[13100/50000]
**Valid**: G Loss: 111.6608, D Loss: 1.5632
Epoch[13110/50000]
**Train**: G Loss: 38.7534, D Loss: 0.1011
Epoch[13110/50000]
**Valid**: G Loss: 45.0536, D Loss: 1.0535
Epoch[13120/50000]
**Train**: G Loss: 97.7602, D Loss: 0.9470
Epoch[13120/50000]
**Valid**: G Loss: 82.8661, D Loss: 0.3584
Epoch[13130/50000]
**Train**: G Loss: 53.9714, D Loss: 0.6248
Epoch[13130/50000]
**Valid**: G Loss: 62.9601, D Loss: 1.0649
Epoch[13140/50000]
**Train**: G Loss: 113.7780, D Loss: 0.4452
Epoch[13140/50000]
**Valid**: G Loss: 97.7807, D Loss: 1.5770
Epoch[13150/50000]
**Train**: G Loss: 49.7078, D Loss: -0.1699
Epoch[13150/50000]
**Valid**: G Loss: 54.1212, D Loss: 0.9321
Epoch[13160/50000]
**Train**: G Loss: 125.7753, D Loss: 0.0105
Epoch[13160/50000]
**Valid**: G Loss: 109.5751, D Loss: 1.5734
Epoch[13170/50000]
**Train**: G Loss: 60.4906, D Loss: 0.5565
Epoch[13170/50000]
**Valid**: G Loss: 68.5737, D Loss: 0.6289
Epoch[13180/50000]
**Train**: G Loss: 70.8151, D Loss: 0.2947
Epoch[13180/50000]
**Valid**: G Loss: 31.1889, D Loss: -0.9637
Epoch[13190/50000]
**Train**: G Loss: 131.9680, D Loss: -0.1512
Epoch[13190/50000]
**Valid**: G Loss: 141.3480, D Loss: 0.8827
Epoch[13200/50000]
**Train**: G Loss: 67.4757, D Loss: 0.2805
Epoch[13200/50000]
**Valid**: G Loss: 67.6136, D Loss: 1.1467
Epoch[13210/50000]
**Train**: G Loss: 86.4763, D Loss: 0.5210
Epoch[13210/50000]
**Valid**: G Loss: 81.2743, D Loss: 1.3388
Epoch[13220/50000]
**Train**: G Loss: 90.1659, D Loss: -0.0846
Epoch[13220/50000]
**Valid**: G Loss: 90.8150, D Loss: 1.4075
Epoch[13230/50000]
**Train**: G Loss: 77.7567, D Loss: 0.4730
Epoch[13230/50000]
**Valid**: G Loss: 79.3508, D Loss: 0.6089
Epoch[13240/50000]
**Train**: G Loss: 73.4780, D Loss: 0.6103
Epoch[13240/50000]
**Valid**: G Loss: 85.6129, D Loss: 0.3090
Epoch[13250/50000]
**Train**: G Loss: 64.8084, D Loss: 0.2053
Epoch[13250/50000]
**Valid**: G Loss: 70.5119, D Loss: 1.1845
Epoch[13260/50000]
**Train**: G Loss: 100.2585, D Loss: 0.9716
Epoch[13260/50000]
**Valid**: G Loss: 76.7442, D Loss: -0.1699
Epoch[13270/50000]
**Train**: G Loss: 93.3115, D Loss: 0.2409
Epoch[13270/50000]
**Valid**: G Loss: 115.8173, D Loss: -0.3465
Epoch[13280/50000]
**Train**: G Loss: 69.9582, D Loss: 0.5021
Epoch[13280/50000]
**Valid**: G Loss: 73.7583, D Loss: 0.9254
Epoch[13290/50000]
**Train**: G Loss: 74.5098, D Loss: 0.0594
Epoch[13290/50000]
**Valid**: G Loss: 38.6283, D Loss: -0.7604
Epoch[13300/50000]
**Train**: G Loss: 87.0453, D Loss: 0.6810
Epoch[13300/50000]
**Valid**: G Loss: 144.6435, D Loss: -0.8218
Epoch[13310/50000]
**Train**: G Loss: 93.0404, D Loss: 0.7266
Epoch[13310/50000]
**Valid**: G Loss: 53.7832, D Loss: -1.0315
Epoch[13320/50000]
**Train**: G Loss: 71.5099, D Loss: 0.7982
Epoch[13320/50000]
**Valid**: G Loss: 104.3649, D Loss: -0.2529
Epoch[13330/50000]
**Train**: G Loss: 107.2705, D Loss: 1.1408
Epoch[13330/50000]
**Valid**: G Loss: 89.9679, D Loss: 0.6333
Epoch[13340/50000]
**Train**: G Loss: 46.5133, D Loss: -0.3092
Epoch[13340/50000]
**Valid**: G Loss: 49.2117, D Loss: 1.0400
Epoch[13350/50000]
**Train**: G Loss: 106.5102, D Loss: 0.1854
Epoch[13350/50000]
**Valid**: G Loss: 158.7955, D Loss: -1.0999
Epoch[13360/50000]
**Train**: G Loss: 51.7701, D Loss: 0.1345
Epoch[13360/50000]
**Valid**: G Loss: -12.5452, D Loss: -0.9667
Epoch[13370/50000]
**Train**: G Loss: 100.6390, D Loss: 0.3278
Epoch[13370/50000]
**Valid**: G Loss: 163.0556, D Loss: -0.9067
Epoch[13380/50000]
**Train**: G Loss: 138.3332, D Loss: 0.8232
Epoch[13380/50000]
**Valid**: G Loss: 108.1239, D Loss: 1.3123
Epoch[13390/50000]
**Train**: G Loss: 51.1944, D Loss: -0.7361
Epoch[13390/50000]
**Valid**: G Loss: 22.3943, D Loss: -0.5903
Epoch[13400/50000]
**Train**: G Loss: 44.1083, D Loss: 0.2847
Epoch[13400/50000]
**Valid**: G Loss: 50.9367, D Loss: 1.3798
Epoch[13410/50000]
**Train**: G Loss: 68.6313, D Loss: 1.0054
Epoch[13410/50000]
**Valid**: G Loss: 95.3558, D Loss: 0.0689
Epoch[13420/50000]
**Train**: G Loss: 151.0986, D Loss: -0.5236
Epoch[13420/50000]
**Valid**: G Loss: 140.7048, D Loss: 1.2202
Epoch[13430/50000]
**Train**: G Loss: 95.0611, D Loss: 0.9006
Epoch[13430/50000]
**Valid**: G Loss: 75.7151, D Loss: -0.7627
Epoch[13440/50000]
**Train**: G Loss: 49.7770, D Loss: -0.7882
Epoch[13440/50000]
**Valid**: G Loss: 39.5578, D Loss: 0.2451
Epoch[13450/50000]
**Train**: G Loss: 40.3372, D Loss: 1.0300
Epoch[13450/50000]
**Valid**: G Loss: 71.9392, D Loss: 0.5868
Epoch[13460/50000]
**Train**: G Loss: 142.6306, D Loss: -0.7198
Epoch[13460/50000]
**Valid**: G Loss: 144.9439, D Loss: 0.9168
Epoch[13470/50000]
**Train**: G Loss: 49.1409, D Loss: -0.1019
Epoch[13470/50000]
**Valid**: G Loss: 16.1441, D Loss: -0.3541
Epoch[13480/50000]
**Train**: G Loss: 67.5110, D Loss: 0.9228
Epoch[13480/50000]
**Valid**: G Loss: 95.6441, D Loss: -0.4381
Epoch[13490/50000]
**Train**: G Loss: 96.9127, D Loss: 0.9213
Epoch[13490/50000]
**Valid**: G Loss: 91.5007, D Loss: 1.4293
Epoch[13500/50000]
**Train**: G Loss: 51.5566, D Loss: -0.5178
Epoch[13500/50000]
**Valid**: G Loss: 50.5491, D Loss: 0.8502
Epoch[13510/50000]
**Train**: G Loss: 124.1609, D Loss: -0.5524
Epoch[13510/50000]
**Valid**: G Loss: 137.4767, D Loss: 0.1870
Epoch[13520/50000]
**Train**: G Loss: 86.1774, D Loss: 0.5011
Epoch[13520/50000]
**Valid**: G Loss: 54.7669, D Loss: -1.1290
Epoch[13530/50000]
**Train**: G Loss: 51.5532, D Loss: 0.6182
Epoch[13530/50000]
**Valid**: G Loss: 63.0287, D Loss: 1.2217
Epoch[13540/50000]
**Train**: G Loss: 128.1077, D Loss: -0.4461
Epoch[13540/50000]
**Valid**: G Loss: 152.5533, D Loss: 0.1166
Epoch[13550/50000]
**Train**: G Loss: 113.9075, D Loss: 1.2692
Epoch[13550/50000]
**Valid**: G Loss: 87.3886, D Loss: 0.8576
Epoch[13560/50000]
**Train**: G Loss: 28.9941, D Loss: 0.4341
Epoch[13560/50000]
**Valid**: G Loss: 44.7255, D Loss: 1.2286
Epoch[13570/50000]
**Train**: G Loss: 153.4254, D Loss: -0.2498
Epoch[13570/50000]
**Valid**: G Loss: 129.4057, D Loss: 1.4658
Epoch[13580/50000]
**Train**: G Loss: 8.1751, D Loss: -0.8713
Epoch[13580/50000]
**Valid**: G Loss: -4.0273, D Loss: 0.5193
Epoch[13590/50000]
**Train**: G Loss: 96.2918, D Loss: 0.4039
Epoch[13590/50000]
**Valid**: G Loss: 151.7690, D Loss: -0.7086
Epoch[13600/50000]
**Train**: G Loss: 124.5367, D Loss: 1.1483
Epoch[13600/50000]
**Valid**: G Loss: 90.5645, D Loss: 0.6106
Epoch[13610/50000]
**Train**: G Loss: -5.0261, D Loss: 0.4668
Epoch[13610/50000]
**Valid**: G Loss: 32.8044, D Loss: 1.1869
Epoch[13620/50000]
**Train**: G Loss: 139.1516, D Loss: 0.8244
Epoch[13620/50000]
**Valid**: G Loss: 103.9919, D Loss: 0.9193
Epoch[13630/50000]
**Train**: G Loss: 3.7879, D Loss: 0.5091
Epoch[13630/50000]
**Valid**: G Loss: 39.6215, D Loss: 1.1541
Epoch[13640/50000]
**Train**: G Loss: 170.4501, D Loss: -0.0712
Epoch[13640/50000]
**Valid**: G Loss: 140.0482, D Loss: 1.4708
Epoch[13650/50000]
**Train**: G Loss: 42.1155, D Loss: -0.1036
Epoch[13650/50000]
**Valid**: G Loss: -22.4224, D Loss: -1.1395
Epoch[13660/50000]
**Train**: G Loss: 2.6850, D Loss: 0.4309
Epoch[13660/50000]
**Valid**: G Loss: 25.2436, D Loss: 1.4126
Epoch[13670/50000]
**Train**: G Loss: 102.6412, D Loss: 0.1288
Epoch[13670/50000]
**Valid**: G Loss: 158.2106, D Loss: -1.1147
Epoch[13680/50000]
**Train**: G Loss: 117.3612, D Loss: 0.8010
Epoch[13680/50000]
**Valid**: G Loss: 98.4241, D Loss: 1.4870
Epoch[13690/50000]
**Train**: G Loss: 65.5718, D Loss: -0.7589
Epoch[13690/50000]
**Valid**: G Loss: 52.0237, D Loss: -0.1000
Epoch[13700/50000]
**Train**: G Loss: 69.2002, D Loss: 0.8496
Epoch[13700/50000]
**Valid**: G Loss: 98.2933, D Loss: 0.1007
Epoch[13710/50000]
**Train**: G Loss: 99.1155, D Loss: 1.1104
Epoch[13710/50000]
**Valid**: G Loss: 89.2132, D Loss: 0.6261
Epoch[13720/50000]
**Train**: G Loss: 96.9547, D Loss: -0.0970
Epoch[13720/50000]
**Valid**: G Loss: 108.9103, D Loss: 0.4123
Epoch[13730/50000]
**Train**: G Loss: 69.1486, D Loss: -0.5381
Epoch[13730/50000]
**Valid**: G Loss: 65.8067, D Loss: 0.4363
Epoch[13740/50000]
**Train**: G Loss: 105.5679, D Loss: 0.0224
Epoch[13740/50000]
**Valid**: G Loss: 127.8026, D Loss: 0.1024
Epoch[13750/50000]
**Train**: G Loss: 85.4796, D Loss: 0.2509
Epoch[13750/50000]
**Valid**: G Loss: 60.9002, D Loss: -0.8341
Epoch[13760/50000]
**Train**: G Loss: 51.9714, D Loss: 0.8065
Epoch[13760/50000]
**Valid**: G Loss: 68.8647, D Loss: 1.0579
Epoch[13770/50000]
**Train**: G Loss: 161.4907, D Loss: -0.4906
Epoch[13770/50000]
**Valid**: G Loss: 167.4356, D Loss: 0.8943
Epoch[13780/50000]
**Train**: G Loss: 105.7157, D Loss: 1.1652
Epoch[13780/50000]
**Valid**: G Loss: 84.7529, D Loss: -0.2508
Epoch[13790/50000]
**Train**: G Loss: 49.0948, D Loss: -1.0155
Epoch[13790/50000]
**Valid**: G Loss: 39.7027, D Loss: 0.4732
Epoch[13800/50000]
**Train**: G Loss: 77.6018, D Loss: 0.9791
Epoch[13800/50000]
**Valid**: G Loss: 88.7546, D Loss: 0.4411
Epoch[13810/50000]
**Train**: G Loss: 111.0712, D Loss: 0.3161
Epoch[13810/50000]
**Valid**: G Loss: 97.2050, D Loss: 1.9813
Epoch[13820/50000]
**Train**: G Loss: 73.2138, D Loss: -0.5175
Epoch[13820/50000]
**Valid**: G Loss: 61.7887, D Loss: -0.5907
Epoch[13830/50000]
**Train**: G Loss: 72.6671, D Loss: 0.7971
Epoch[13830/50000]
**Valid**: G Loss: 86.7116, D Loss: 0.4183
Epoch[13840/50000]
**Train**: G Loss: 112.7898, D Loss: 1.1785
Epoch[13840/50000]
**Valid**: G Loss: 96.6613, D Loss: 0.8443
Epoch[13850/50000]
**Train**: G Loss: 58.5479, D Loss: 0.1040
Epoch[13850/50000]
**Valid**: G Loss: 63.2171, D Loss: 0.9550
Epoch[13860/50000]
**Train**: G Loss: 141.4506, D Loss: -0.2273
Epoch[13860/50000]
**Valid**: G Loss: 174.8522, D Loss: 0.0497
Epoch[13870/50000]
**Train**: G Loss: 109.4808, D Loss: 1.1033
Epoch[13870/50000]
**Valid**: G Loss: 69.4089, D Loss: -0.0394
Epoch[13880/50000]
**Train**: G Loss: 101.6395, D Loss: 0.2997
Epoch[13880/50000]
**Valid**: G Loss: 160.4284, D Loss: -0.9175
Epoch[13890/50000]
**Train**: G Loss: 104.0422, D Loss: 1.2487
Epoch[13890/50000]
**Valid**: G Loss: 85.9974, D Loss: 0.1482
Epoch[13900/50000]
**Train**: G Loss: 74.1489, D Loss: -0.5579
Epoch[13900/50000]
**Valid**: G Loss: 68.8270, D Loss: 0.9098
Epoch[13910/50000]
**Train**: G Loss: 111.4612, D Loss: -0.1588
Epoch[13910/50000]
**Valid**: G Loss: 125.2323, D Loss: -0.0208
Epoch[13920/50000]
**Train**: G Loss: 87.2437, D Loss: 0.2014
Epoch[13920/50000]
**Valid**: G Loss: 71.4956, D Loss: -0.3010
Epoch[13930/50000]
**Train**: G Loss: 95.0556, D Loss: 0.3082
Epoch[13930/50000]
**Valid**: G Loss: 79.6393, D Loss: -0.7912
Epoch[13940/50000]
**Train**: G Loss: 112.4823, D Loss: 0.3597
Epoch[13940/50000]
**Valid**: G Loss: 147.3904, D Loss: -0.6613
Epoch[13950/50000]
**Train**: G Loss: 130.0944, D Loss: 0.7565
Epoch[13950/50000]
**Valid**: G Loss: 103.4034, D Loss: 1.4186
Epoch[13960/50000]
**Train**: G Loss: 4.3815, D Loss: -0.8831
Epoch[13960/50000]
**Valid**: G Loss: -3.1113, D Loss: 0.5629
Epoch[13970/50000]
**Train**: G Loss: 114.6296, D Loss: 0.3387
Epoch[13970/50000]
**Valid**: G Loss: 192.4171, D Loss: -1.2117
Epoch[13980/50000]
**Train**: G Loss: 168.4952, D Loss: 0.3359
Epoch[13980/50000]
**Valid**: G Loss: 139.7455, D Loss: 1.5119
Epoch[13990/50000]
**Train**: G Loss: 90.8915, D Loss: 0.6408
Epoch[13990/50000]
**Valid**: G Loss: 46.8738, D Loss: -1.2648
Epoch[14000/50000]
**Train**: G Loss: 49.6272, D Loss: -0.6828
Epoch[14000/50000]
**Valid**: G Loss: 38.6463, D Loss: 1.0144
Epoch[14010/50000]
**Train**: G Loss: 74.6272, D Loss: 1.0238
Epoch[14010/50000]
**Valid**: G Loss: 103.9274, D Loss: -0.0185
Epoch[14020/50000]
**Train**: G Loss: 156.7122, D Loss: -0.4151
Epoch[14020/50000]
**Valid**: G Loss: 144.3234, D Loss: 1.3677
Epoch[14030/50000]
**Train**: G Loss: 45.7253, D Loss: -0.7726
Epoch[14030/50000]
**Valid**: G Loss: 41.2299, D Loss: 0.2187
Epoch[14040/50000]
**Train**: G Loss: 89.9139, D Loss: 0.7303
Epoch[14040/50000]
**Valid**: G Loss: 132.3862, D Loss: -0.5817
Epoch[14050/50000]
**Train**: G Loss: 111.5433, D Loss: 0.9652
Epoch[14050/50000]
**Valid**: G Loss: 86.4598, D Loss: 0.7274
Epoch[14060/50000]
**Train**: G Loss: 51.3340, D Loss: 0.5097
Epoch[14060/50000]
**Valid**: G Loss: 64.2661, D Loss: 1.1725
Epoch[14070/50000]
**Train**: G Loss: 141.2480, D Loss: -0.5153
Epoch[14070/50000]
**Valid**: G Loss: 144.2731, D Loss: 0.9085
Epoch[14080/50000]
**Train**: G Loss: 78.2831, D Loss: -0.6288
Epoch[14080/50000]
**Valid**: G Loss: 69.6430, D Loss: -0.2094
Epoch[14090/50000]
**Train**: G Loss: 101.2998, D Loss: 0.4158
Epoch[14090/50000]
**Valid**: G Loss: 134.5515, D Loss: -0.9480
Epoch[14100/50000]
**Train**: G Loss: 103.3160, D Loss: 0.9428
Epoch[14100/50000]
**Valid**: G Loss: 80.5800, D Loss: -0.8706
Epoch[14110/50000]
**Train**: G Loss: 61.7430, D Loss: 0.7397
Epoch[14110/50000]
**Valid**: G Loss: 75.9145, D Loss: 1.0959
Epoch[14120/50000]
**Train**: G Loss: 172.0965, D Loss: -0.1978
Epoch[14120/50000]
**Valid**: G Loss: 146.0520, D Loss: 1.5221
Epoch[14130/50000]
**Train**: G Loss: 20.5577, D Loss: -0.6141
Epoch[14130/50000]
**Valid**: G Loss: 23.7376, D Loss: 0.7635
Epoch[14140/50000]
**Train**: G Loss: 143.9347, D Loss: -0.3134
Epoch[14140/50000]
**Valid**: G Loss: 165.6392, D Loss: 0.6190
Epoch[14150/50000]
**Train**: G Loss: 68.0669, D Loss: -0.1242
Epoch[14150/50000]
**Valid**: G Loss: 26.7339, D Loss: -0.9523
Epoch[14160/50000]
**Train**: G Loss: 26.9133, D Loss: 0.1682
Epoch[14160/50000]
**Valid**: G Loss: 38.4822, D Loss: 1.1352
Epoch[14170/50000]
**Train**: G Loss: 77.4498, D Loss: 0.8193
Epoch[14170/50000]
**Valid**: G Loss: 110.3949, D Loss: -0.4613
Epoch[14180/50000]
**Train**: G Loss: 116.6310, D Loss: 0.8878
Epoch[14180/50000]
**Valid**: G Loss: 101.1051, D Loss: 1.4299
Epoch[14190/50000]
**Train**: G Loss: 71.6828, D Loss: -0.5526
Epoch[14190/50000]
**Valid**: G Loss: 67.1478, D Loss: 0.6511
Epoch[14200/50000]
**Train**: G Loss: 98.7032, D Loss: 0.0618
Epoch[14200/50000]
**Valid**: G Loss: 119.6409, D Loss: -0.4358
Epoch[14210/50000]
**Train**: G Loss: 114.2630, D Loss: 0.9379
Epoch[14210/50000]
**Valid**: G Loss: 98.3786, D Loss: 1.2437
Epoch[14220/50000]
**Train**: G Loss: 73.8566, D Loss: -0.6509
Epoch[14220/50000]
**Valid**: G Loss: 62.4283, D Loss: -0.3114
Epoch[14230/50000]
**Train**: G Loss: 86.4918, D Loss: 0.8018
Epoch[14230/50000]
**Valid**: G Loss: 113.5275, D Loss: -0.3205
Epoch[14240/50000]
**Train**: G Loss: 144.8642, D Loss: -0.0181
Epoch[14240/50000]
**Valid**: G Loss: 124.0716, D Loss: 1.7223
Epoch[14250/50000]
**Train**: G Loss: 64.7626, D Loss: -0.1107
Epoch[14250/50000]
**Valid**: G Loss: 35.1640, D Loss: -0.8070
Epoch[14260/50000]
**Train**: G Loss: 73.9885, D Loss: 1.0545
Epoch[14260/50000]
**Valid**: G Loss: 93.5283, D Loss: 0.4111
Epoch[14270/50000]
**Train**: G Loss: 134.6315, D Loss: 0.4932
Epoch[14270/50000]
**Valid**: G Loss: 117.0166, D Loss: 1.9868
Epoch[14280/50000]
**Train**: G Loss: 72.2728, D Loss: -0.5639
Epoch[14280/50000]
**Valid**: G Loss: 55.5716, D Loss: -0.4124
Epoch[14290/50000]
**Train**: G Loss: 84.5698, D Loss: 0.9945
Epoch[14290/50000]
**Valid**: G Loss: 98.6824, D Loss: 0.9089
Epoch[14300/50000]
**Train**: G Loss: 171.4508, D Loss: -0.4505
Epoch[14300/50000]
**Valid**: G Loss: 155.6909, D Loss: 1.1362
Epoch[14310/50000]
**Train**: G Loss: 117.8990, D Loss: 1.0788
Epoch[14310/50000]
**Valid**: G Loss: 87.7875, D Loss: -0.0506
Epoch[14320/50000]
**Train**: G Loss: 57.4746, D Loss: -0.3952
Epoch[14320/50000]
**Valid**: G Loss: 63.2644, D Loss: 1.1460
Epoch[14330/50000]
**Train**: G Loss: 83.6625, D Loss: 0.9150
Epoch[14330/50000]
**Valid**: G Loss: 100.4066, D Loss: 0.4171
Epoch[14340/50000]
**Train**: G Loss: 132.7149, D Loss: -0.4703
Epoch[14340/50000]
**Valid**: G Loss: 130.4538, D Loss: 0.7304
Epoch[14350/50000]
**Train**: G Loss: 114.6279, D Loss: 1.2715
Epoch[14350/50000]
**Valid**: G Loss: 105.9437, D Loss: 0.9748
Epoch[14360/50000]
**Train**: G Loss: 80.3618, D Loss: -0.5100
Epoch[14360/50000]
**Valid**: G Loss: 68.3906, D Loss: -0.3113
Epoch[14370/50000]
**Train**: G Loss: 68.8488, D Loss: 0.8016
Epoch[14370/50000]
**Valid**: G Loss: 88.1193, D Loss: 0.9782
Epoch[14380/50000]
**Train**: G Loss: 139.6179, D Loss: -0.4546
Epoch[14380/50000]
**Valid**: G Loss: 137.7273, D Loss: 1.1945
Epoch[14390/50000]
**Train**: G Loss: 103.3223, D Loss: 0.8322
Epoch[14390/50000]
**Valid**: G Loss: 87.8986, D Loss: -1.0092
Epoch[14400/50000]
**Train**: G Loss: 63.5721, D Loss: 0.2923
Epoch[14400/50000]
**Valid**: G Loss: 76.6560, D Loss: 1.2292
Epoch[14410/50000]
**Train**: G Loss: 157.0241, D Loss: 0.5572
Epoch[14410/50000]
**Valid**: G Loss: 121.3411, D Loss: 1.0994
Epoch[14420/50000]
**Train**: G Loss: 55.0191, D Loss: 0.6763
Epoch[14420/50000]
**Valid**: G Loss: 74.0473, D Loss: 1.2432
Epoch[14430/50000]
**Train**: G Loss: 160.6929, D Loss: 0.4499
Epoch[14430/50000]
**Valid**: G Loss: 133.5745, D Loss: 1.8478
Epoch[14440/50000]
**Train**: G Loss: 36.7166, D Loss: -0.8808
Epoch[14440/50000]
**Valid**: G Loss: 29.2135, D Loss: 0.4033
Epoch[14450/50000]
**Train**: G Loss: 83.4698, D Loss: 0.8542
Epoch[14450/50000]
**Valid**: G Loss: 121.6159, D Loss: -0.0490
Epoch[14460/50000]
**Train**: G Loss: 156.9987, D Loss: 0.3811
Epoch[14460/50000]
**Valid**: G Loss: 127.2219, D Loss: 1.3891
Epoch[14470/50000]
**Train**: G Loss: 15.7183, D Loss: -0.7534
Epoch[14470/50000]
**Valid**: G Loss: 4.1151, D Loss: 0.3634
Epoch[14480/50000]
**Train**: G Loss: 84.7973, D Loss: 0.8027
Epoch[14480/50000]
**Valid**: G Loss: 144.3896, D Loss: -0.4136
Epoch[14490/50000]
**Train**: G Loss: 151.4881, D Loss: 0.9734
Epoch[14490/50000]
**Valid**: G Loss: 117.3232, D Loss: 1.4100
Epoch[14500/50000]
**Train**: G Loss: -3.1614, D Loss: -0.3781
Epoch[14500/50000]
**Valid**: G Loss: 15.4256, D Loss: 1.1195
Epoch[14510/50000]
**Train**: G Loss: 95.0224, D Loss: 0.5930
Epoch[14510/50000]
**Valid**: G Loss: 160.0852, D Loss: -1.0840
Epoch[14520/50000]
**Train**: G Loss: 179.0640, D Loss: -0.3848
Epoch[14520/50000]
**Valid**: G Loss: 149.4143, D Loss: 1.4463
Epoch[14530/50000]
**Train**: G Loss: 75.6432, D Loss: 0.3750
Epoch[14530/50000]
**Valid**: G Loss: 29.8285, D Loss: -1.2801
Epoch[14540/50000]
**Train**: G Loss: 19.0396, D Loss: -0.0365
Epoch[14540/50000]
**Valid**: G Loss: 29.2701, D Loss: 1.2152
Epoch[14550/50000]
**Train**: G Loss: 101.0380, D Loss: 0.3207
Epoch[14550/50000]
**Valid**: G Loss: 156.9668, D Loss: -0.9785
Epoch[14560/50000]
**Train**: G Loss: 116.9462, D Loss: 1.0942
Epoch[14560/50000]
**Valid**: G Loss: 92.3082, D Loss: 0.8242
Epoch[14570/50000]
**Train**: G Loss: 45.7569, D Loss: -0.5830
Epoch[14570/50000]
**Valid**: G Loss: 40.0995, D Loss: 0.6764
Epoch[14580/50000]
**Train**: G Loss: 105.6420, D Loss: 0.2267
Epoch[14580/50000]
**Valid**: G Loss: 147.0137, D Loss: -0.4327
Epoch[14590/50000]
**Train**: G Loss: 73.2747, D Loss: 0.1416
Epoch[14590/50000]
**Valid**: G Loss: 45.7048, D Loss: -0.3999
Epoch[14600/50000]
**Train**: G Loss: 79.0527, D Loss: 0.7367
Epoch[14600/50000]
**Valid**: G Loss: 92.2878, D Loss: 0.3132
Epoch[14610/50000]
**Train**: G Loss: 132.9798, D Loss: -0.0367
Epoch[14610/50000]
**Valid**: G Loss: 115.8374, D Loss: 1.5577
Epoch[14620/50000]
**Train**: G Loss: 76.6676, D Loss: -0.6369
Epoch[14620/50000]
**Valid**: G Loss: 62.8927, D Loss: -0.6657
Epoch[14630/50000]
**Train**: G Loss: 53.7499, D Loss: 0.4149
Epoch[14630/50000]
**Valid**: G Loss: 61.5789, D Loss: 1.2372
Epoch[14640/50000]
**Train**: G Loss: 145.4907, D Loss: -0.1658
Epoch[14640/50000]
**Valid**: G Loss: 171.3716, D Loss: 0.2802
Epoch[14650/50000]
**Train**: G Loss: 92.5528, D Loss: 0.4591
Epoch[14650/50000]
**Valid**: G Loss: 53.0105, D Loss: -1.2139
Epoch[14660/50000]
**Train**: G Loss: 97.5539, D Loss: 0.5073
Epoch[14660/50000]
**Valid**: G Loss: 146.0388, D Loss: -0.7164
Epoch[14670/50000]
**Train**: G Loss: 116.5812, D Loss: 1.1201
Epoch[14670/50000]
**Valid**: G Loss: 92.7931, D Loss: 0.2999
Epoch[14680/50000]
**Train**: G Loss: 33.6094, D Loss: -0.5171
Epoch[14680/50000]
**Valid**: G Loss: 38.5408, D Loss: 0.9479
Epoch[14690/50000]
**Train**: G Loss: 117.3955, D Loss: 0.3576
Epoch[14690/50000]
**Valid**: G Loss: 175.5943, D Loss: -0.9410
Epoch[14700/50000]
**Train**: G Loss: 145.9134, D Loss: 0.3036
Epoch[14700/50000]
**Valid**: G Loss: 126.3174, D Loss: 1.4657
Epoch[14710/50000]
**Train**: G Loss: 106.7455, D Loss: 1.0453
Epoch[14710/50000]
**Valid**: G Loss: 98.3012, D Loss: 0.1798
Epoch[14720/50000]
**Train**: G Loss: 85.1496, D Loss: -0.7341
Epoch[14720/50000]
**Valid**: G Loss: 77.4485, D Loss: 0.3731
Epoch[14730/50000]
**Train**: G Loss: 86.1121, D Loss: 0.9490
Epoch[14730/50000]
**Valid**: G Loss: 98.0346, D Loss: 0.4491
Epoch[14740/50000]
**Train**: G Loss: 138.4684, D Loss: -0.6097
Epoch[14740/50000]
**Valid**: G Loss: 147.5300, D Loss: 0.4304
Epoch[14750/50000]
**Train**: G Loss: 103.7074, D Loss: 0.7754
Epoch[14750/50000]
**Valid**: G Loss: 70.5667, D Loss: -0.4180
Epoch[14760/50000]
**Train**: G Loss: 126.2612, D Loss: -0.1659
Epoch[14760/50000]
**Valid**: G Loss: 120.3804, D Loss: 0.9181
Epoch[14770/50000]
**Train**: G Loss: 103.4885, D Loss: 0.2892
Epoch[14770/50000]
**Valid**: G Loss: 94.0120, D Loss: -1.1450
Epoch[14780/50000]
**Train**: G Loss: 92.2595, D Loss: -0.1596
Epoch[14780/50000]
**Valid**: G Loss: 88.8578, D Loss: 1.1961
Epoch[14790/50000]
**Train**: G Loss: 95.6821, D Loss: 0.8920
Epoch[14790/50000]
**Valid**: G Loss: 108.0878, D Loss: 0.1937
Epoch[14800/50000]
**Train**: G Loss: 147.9681, D Loss: -0.4003
Epoch[14800/50000]
**Valid**: G Loss: 148.9433, D Loss: 1.0565
Epoch[14810/50000]
**Train**: G Loss: 120.8514, D Loss: 0.9597
Epoch[14810/50000]
**Valid**: G Loss: 85.3015, D Loss: -0.5387
Epoch[14820/50000]
**Train**: G Loss: 58.3881, D Loss: -0.7753
Epoch[14820/50000]
**Valid**: G Loss: 51.3117, D Loss: 0.5491
Epoch[14830/50000]
**Train**: G Loss: 92.3160, D Loss: 0.6732
Epoch[14830/50000]
**Valid**: G Loss: 124.7941, D Loss: -0.5601
Epoch[14840/50000]
**Train**: G Loss: 130.9662, D Loss: 0.6699
Epoch[14840/50000]
**Valid**: G Loss: 115.7503, D Loss: 1.2952
Epoch[14850/50000]
**Train**: G Loss: 75.5418, D Loss: -0.6505
Epoch[14850/50000]
**Valid**: G Loss: 60.7520, D Loss: -0.0560
Epoch[14860/50000]
**Train**: G Loss: 90.2113, D Loss: 0.7208
Epoch[14860/50000]
**Valid**: G Loss: 120.3101, D Loss: -0.1690
Epoch[14870/50000]
**Train**: G Loss: 124.4009, D Loss: 1.0171
Epoch[14870/50000]
**Valid**: G Loss: 94.3874, D Loss: 0.1140
Epoch[14880/50000]
**Train**: G Loss: 41.2831, D Loss: 0.2838
Epoch[14880/50000]
**Valid**: G Loss: 57.7712, D Loss: 1.1039
Epoch[14890/50000]
**Train**: G Loss: 131.6998, D Loss: 0.1859
Epoch[14890/50000]
**Valid**: G Loss: 191.0458, D Loss: -0.8799
Epoch[14900/50000]
**Train**: G Loss: 150.6766, D Loss: 0.9445
Epoch[14900/50000]
**Valid**: G Loss: 123.3997, D Loss: 1.3423
Epoch[14910/50000]
**Train**: G Loss: 72.1050, D Loss: -0.3580
Epoch[14910/50000]
**Valid**: G Loss: 48.9208, D Loss: -0.4010
Epoch[14920/50000]
**Train**: G Loss: 76.4287, D Loss: 0.5089
Epoch[14920/50000]
**Valid**: G Loss: 81.1293, D Loss: 1.0601
Epoch[14930/50000]
**Train**: G Loss: 120.0397, D Loss: -0.3277
Epoch[14930/50000]
**Valid**: G Loss: 127.2962, D Loss: 0.1926
Epoch[14940/50000]
**Train**: G Loss: 114.6022, D Loss: 0.8441
Epoch[14940/50000]
**Valid**: G Loss: 110.3776, D Loss: 0.9597
Epoch[14950/50000]
**Train**: G Loss: 82.9876, D Loss: -0.6884
Epoch[14950/50000]
**Valid**: G Loss: 67.2366, D Loss: 0.5548
Epoch[14960/50000]
**Train**: G Loss: 64.9846, D Loss: 0.8164
Epoch[14960/50000]
**Valid**: G Loss: 95.5520, D Loss: 0.5652
Epoch[14970/50000]
**Train**: G Loss: 139.2566, D Loss: 0.8835
Epoch[14970/50000]
**Valid**: G Loss: 112.8107, D Loss: 1.0212
Epoch[14980/50000]
**Train**: G Loss: 39.0440, D Loss: -0.1003
Epoch[14980/50000]
**Valid**: G Loss: 46.5469, D Loss: 1.1715
Epoch[14990/50000]
**Train**: G Loss: 114.4469, D Loss: 0.4859
Epoch[14990/50000]
**Valid**: G Loss: 167.0951, D Loss: -1.1619
Epoch[15000/50000]
**Train**: G Loss: 167.0951, D Loss: 0.1803
Epoch[15000/50000]
**Valid**: G Loss: 139.5063, D Loss: 1.4208
Epoch[15010/50000]
**Train**: G Loss: 99.9347, D Loss: 0.4602
Epoch[15010/50000]
**Valid**: G Loss: 71.9424, D Loss: -1.1089
Epoch[15020/50000]
**Train**: G Loss: 40.7483, D Loss: -0.6802
Epoch[15020/50000]
**Valid**: G Loss: 34.2452, D Loss: 0.6332
Epoch[15030/50000]
**Train**: G Loss: 68.9189, D Loss: 0.8687
Epoch[15030/50000]
**Valid**: G Loss: 103.7259, D Loss: 0.0847
Epoch[15040/50000]
**Train**: G Loss: 165.8403, D Loss: -0.2416
Epoch[15040/50000]
**Valid**: G Loss: 153.4048, D Loss: 1.2172
Epoch[15050/50000]
**Train**: G Loss: 95.4001, D Loss: 0.5674
Epoch[15050/50000]
**Valid**: G Loss: 54.1454, D Loss: -1.0784
Epoch[15060/50000]
**Train**: G Loss: 11.9223, D Loss: -0.3441
Epoch[15060/50000]
**Valid**: G Loss: 23.0863, D Loss: 1.3086
Epoch[15070/50000]
**Train**: G Loss: 99.9595, D Loss: 0.0949
Epoch[15070/50000]
**Valid**: G Loss: 130.3905, D Loss: -1.0302
Epoch[15080/50000]
**Train**: G Loss: 103.1636, D Loss: 1.0758
Epoch[15080/50000]
**Valid**: G Loss: 99.1220, D Loss: -0.1635
Epoch[15090/50000]
**Train**: G Loss: 87.6751, D Loss: -0.7917
Epoch[15090/50000]
**Valid**: G Loss: 80.7103, D Loss: 0.6449
Epoch[15100/50000]
**Train**: G Loss: 86.4213, D Loss: 0.8116
Epoch[15100/50000]
**Valid**: G Loss: 99.5081, D Loss: -0.1092
Epoch[15110/50000]
**Train**: G Loss: 113.2436, D Loss: 0.7894
Epoch[15110/50000]
**Valid**: G Loss: 103.3545, D Loss: 1.2754
Epoch[15120/50000]
**Train**: G Loss: 96.4482, D Loss: 0.4022
Epoch[15120/50000]
**Valid**: G Loss: 75.8722, D Loss: -1.1476
Epoch[15130/50000]
**Train**: G Loss: 57.2024, D Loss: 0.0811
Epoch[15130/50000]
**Valid**: G Loss: 62.8932, D Loss: 0.9139
Epoch[15140/50000]
**Train**: G Loss: 113.3343, D Loss: -0.0367
Epoch[15140/50000]
**Valid**: G Loss: 144.7430, D Loss: -0.4799
Epoch[15150/50000]
**Train**: G Loss: 69.1183, D Loss: -0.5573
Epoch[15150/50000]
**Valid**: G Loss: 63.5701, D Loss: 0.4310
Epoch[15160/50000]
**Train**: G Loss: 107.5038, D Loss: 0.4168
Epoch[15160/50000]
**Valid**: G Loss: 140.4493, D Loss: -0.6998
Epoch[15170/50000]
**Train**: G Loss: 148.6509, D Loss: 0.6367
Epoch[15170/50000]
**Valid**: G Loss: 123.2893, D Loss: 1.8224
Epoch[15180/50000]
**Train**: G Loss: 61.1555, D Loss: -0.6807
Epoch[15180/50000]
**Valid**: G Loss: 42.2957, D Loss: -0.1276
Epoch[15190/50000]
**Train**: G Loss: 71.3849, D Loss: 0.8134
Epoch[15190/50000]
**Valid**: G Loss: 97.5555, D Loss: 0.5273
Epoch[15200/50000]
**Train**: G Loss: 135.8142, D Loss: -0.3241
Epoch[15200/50000]
**Valid**: G Loss: 154.0174, D Loss: 0.0731
Epoch[15210/50000]
**Train**: G Loss: 136.3524, D Loss: 0.9878
Epoch[15210/50000]
**Valid**: G Loss: 112.2219, D Loss: 0.9640
Epoch[15220/50000]
**Train**: G Loss: 62.8742, D Loss: -0.9450
Epoch[15220/50000]
**Valid**: G Loss: 51.8360, D Loss: 0.1885
Epoch[15230/50000]
**Train**: G Loss: 84.9123, D Loss: 0.8403
Epoch[15230/50000]
**Valid**: G Loss: 108.3773, D Loss: -0.2447
Epoch[15240/50000]
**Train**: G Loss: 117.6504, D Loss: 1.0167
Epoch[15240/50000]
**Valid**: G Loss: 109.1922, D Loss: 0.9331
Epoch[15250/50000]
**Train**: G Loss: 84.4821, D Loss: 0.6036
Epoch[15250/50000]
**Valid**: G Loss: 90.8519, D Loss: 1.0851
Epoch[15260/50000]
**Train**: G Loss: 105.2524, D Loss: 0.7244
Epoch[15260/50000]
**Valid**: G Loss: 88.1992, D Loss: -0.5352
Epoch[15270/50000]
**Train**: G Loss: 82.1995, D Loss: 0.9771
Epoch[15270/50000]
**Valid**: G Loss: 96.9356, D Loss: 0.9259
Epoch[15280/50000]
**Train**: G Loss: 179.4924, D Loss: 0.0066
Epoch[15280/50000]
**Valid**: G Loss: 154.0103, D Loss: 1.4725
Epoch[15290/50000]
**Train**: G Loss: 94.9211, D Loss: 0.6213
Epoch[15290/50000]
**Valid**: G Loss: 54.0340, D Loss: -1.2680
Epoch[15300/50000]
**Train**: G Loss: 71.0656, D Loss: -0.7961
Epoch[15300/50000]
**Valid**: G Loss: 66.0019, D Loss: 0.6691
Epoch[15310/50000]
**Train**: G Loss: 68.8997, D Loss: 0.9529
Epoch[15310/50000]
**Valid**: G Loss: 89.8013, D Loss: 0.9660
Epoch[15320/50000]
**Train**: G Loss: 154.2801, D Loss: -0.2903
Epoch[15320/50000]
**Valid**: G Loss: 146.6201, D Loss: 1.0215
Epoch[15330/50000]
**Train**: G Loss: 68.3194, D Loss: -0.4552
Epoch[15330/50000]
**Valid**: G Loss: 56.0740, D Loss: 0.2155
Epoch[15340/50000]
**Train**: G Loss: 114.8931, D Loss: 0.1217
Epoch[15340/50000]
**Valid**: G Loss: 147.7435, D Loss: -0.5299
Epoch[15350/50000]
**Train**: G Loss: 108.4431, D Loss: 1.0226
Epoch[15350/50000]
**Valid**: G Loss: 101.3391, D Loss: 0.0608
Epoch[15360/50000]
**Train**: G Loss: 85.2055, D Loss: 0.5146
Epoch[15360/50000]
**Valid**: G Loss: 86.7640, D Loss: 1.3185
Epoch[15370/50000]
**Train**: G Loss: 119.9719, D Loss: -0.3856
Epoch[15370/50000]
**Valid**: G Loss: 118.8583, D Loss: 0.8552
Epoch[15380/50000]
**Train**: G Loss: 112.8300, D Loss: 0.7746
Epoch[15380/50000]
**Valid**: G Loss: 106.6771, D Loss: -0.4988
Epoch[15390/50000]
**Train**: G Loss: 92.0279, D Loss: -0.6164
Epoch[15390/50000]
**Valid**: G Loss: 90.7658, D Loss: 0.8259
Epoch[15400/50000]
**Train**: G Loss: 90.7894, D Loss: 0.8544
Epoch[15400/50000]
**Valid**: G Loss: 122.9599, D Loss: 0.2014
Epoch[15410/50000]
**Train**: G Loss: 152.4459, D Loss: 0.8322
Epoch[15410/50000]
**Valid**: G Loss: 122.6600, D Loss: 1.0429
Epoch[15420/50000]
**Train**: G Loss: 72.3412, D Loss: 0.2455
Epoch[15420/50000]
**Valid**: G Loss: 80.4300, D Loss: 0.8228
Epoch[15430/50000]
**Train**: G Loss: 153.7994, D Loss: -0.2199
Epoch[15430/50000]
**Valid**: G Loss: 150.9273, D Loss: 1.2305
Epoch[15440/50000]
**Train**: G Loss: 89.8978, D Loss: -0.3103
Epoch[15440/50000]
**Valid**: G Loss: 68.6615, D Loss: -0.5405
Epoch[15450/50000]
**Train**: G Loss: 92.8013, D Loss: 0.8251
Epoch[15450/50000]
**Valid**: G Loss: 116.6455, D Loss: 0.2376
Epoch[15460/50000]
**Train**: G Loss: 147.9975, D Loss: 0.8701
Epoch[15460/50000]
**Valid**: G Loss: 118.7071, D Loss: 1.1571
Epoch[15470/50000]
**Train**: G Loss: 47.4880, D Loss: -0.5488
Epoch[15470/50000]
**Valid**: G Loss: 45.2732, D Loss: 0.9514
Epoch[15480/50000]
**Train**: G Loss: 111.2514, D Loss: 0.5243
Epoch[15480/50000]
**Valid**: G Loss: 151.2290, D Loss: -0.8252
Epoch[15490/50000]
**Train**: G Loss: 142.4444, D Loss: 1.0020
Epoch[15490/50000]
**Valid**: G Loss: 120.5024, D Loss: 1.0325
Epoch[15500/50000]
**Train**: G Loss: 86.5070, D Loss: -0.5115
Epoch[15500/50000]
**Valid**: G Loss: 64.4329, D Loss: -0.6549
Epoch[15510/50000]
**Train**: G Loss: 90.8789, D Loss: 0.3927
Epoch[15510/50000]
**Valid**: G Loss: 91.4735, D Loss: 1.0445
Epoch[15520/50000]
**Train**: G Loss: 111.2089, D Loss: 0.4962
Epoch[15520/50000]
**Valid**: G Loss: 142.5629, D Loss: -0.6083
Epoch[15530/50000]
**Train**: G Loss: 172.9179, D Loss: -0.2455
Epoch[15530/50000]
**Valid**: G Loss: 154.1773, D Loss: 1.2347
Epoch[15540/50000]
**Train**: G Loss: 58.2304, D Loss: -0.2428
Epoch[15540/50000]
**Valid**: G Loss: 6.2510, D Loss: -0.2171
Epoch[15550/50000]
**Train**: G Loss: 68.5253, D Loss: 0.8110
Epoch[15550/50000]
**Valid**: G Loss: 95.4392, D Loss: 0.7002
Epoch[15560/50000]
**Train**: G Loss: 186.8092, D Loss: -0.6400
Epoch[15560/50000]
**Valid**: G Loss: 187.4245, D Loss: 0.6819
Epoch[15570/50000]
**Train**: G Loss: 98.6480, D Loss: 0.5599
Epoch[15570/50000]
**Valid**: G Loss: 51.8968, D Loss: -1.2569
Epoch[15580/50000]
**Train**: G Loss: 36.9389, D Loss: -0.7047
Epoch[15580/50000]
**Valid**: G Loss: 36.9530, D Loss: 0.7935
Epoch[15590/50000]
**Train**: G Loss: 114.6408, D Loss: 0.4731
Epoch[15590/50000]
**Valid**: G Loss: 167.6962, D Loss: -0.9569
Epoch[15600/50000]
**Train**: G Loss: 128.2749, D Loss: 1.1676
Epoch[15600/50000]
**Valid**: G Loss: 106.2458, D Loss: 0.9366
Epoch[15610/50000]
**Train**: G Loss: 67.1547, D Loss: -0.3632
Epoch[15610/50000]
**Valid**: G Loss: 66.2184, D Loss: 0.8274
Epoch[15620/50000]
**Train**: G Loss: 109.4786, D Loss: 0.3857
Epoch[15620/50000]
**Valid**: G Loss: 146.8610, D Loss: -0.8438
Epoch[15630/50000]
**Train**: G Loss: 139.6604, D Loss: 0.9658
Epoch[15630/50000]
**Valid**: G Loss: 117.9317, D Loss: 1.1983
Epoch[15640/50000]
**Train**: G Loss: 82.3187, D Loss: -0.7666
Epoch[15640/50000]
**Valid**: G Loss: 70.7774, D Loss: -0.0687
Epoch[15650/50000]
**Train**: G Loss: 91.6032, D Loss: 0.8094
Epoch[15650/50000]
**Valid**: G Loss: 115.0565, D Loss: 0.0605
Epoch[15660/50000]
**Train**: G Loss: 142.6922, D Loss: 0.6662
Epoch[15660/50000]
**Valid**: G Loss: 125.4073, D Loss: 1.6111
Epoch[15670/50000]
**Train**: G Loss: 80.1134, D Loss: -0.3002
Epoch[15670/50000]
**Valid**: G Loss: 55.0554, D Loss: -0.7515
Epoch[15680/50000]
**Train**: G Loss: 62.6671, D Loss: 0.3780
Epoch[15680/50000]
**Valid**: G Loss: 74.8261, D Loss: 1.1935
Epoch[15690/50000]
**Train**: G Loss: 166.6509, D Loss: -0.3377
Epoch[15690/50000]
**Valid**: G Loss: 193.7791, D Loss: 0.3959
Epoch[15700/50000]
**Train**: G Loss: 54.9568, D Loss: -0.3615
Epoch[15700/50000]
**Valid**: G Loss: 29.4229, D Loss: -0.3052
Epoch[15710/50000]
**Train**: G Loss: 93.1057, D Loss: 0.6382
Epoch[15710/50000]
**Valid**: G Loss: 134.2903, D Loss: -0.2574
Epoch[15720/50000]
**Train**: G Loss: 129.6736, D Loss: 1.1138
Epoch[15720/50000]
**Valid**: G Loss: 104.5582, D Loss: 0.8829
Epoch[15730/50000]
**Train**: G Loss: 64.0369, D Loss: -0.2770
Epoch[15730/50000]
**Valid**: G Loss: 65.4912, D Loss: 0.9832
Epoch[15740/50000]
**Train**: G Loss: 143.8404, D Loss: -0.4836
Epoch[15740/50000]
**Valid**: G Loss: 148.0746, D Loss: 0.6398
Epoch[15750/50000]
**Train**: G Loss: 118.0655, D Loss: 1.1823
Epoch[15750/50000]
**Valid**: G Loss: 103.0882, D Loss: -0.0417
Epoch[15760/50000]
**Train**: G Loss: 89.2331, D Loss: -0.8211
Epoch[15760/50000]
**Valid**: G Loss: 82.1428, D Loss: 0.4461
Epoch[15770/50000]
**Train**: G Loss: 99.2720, D Loss: 0.6166
Epoch[15770/50000]
**Valid**: G Loss: 118.7573, D Loss: -0.2216
Epoch[15780/50000]
**Train**: G Loss: 140.2834, D Loss: 0.8705
Epoch[15780/50000]
**Valid**: G Loss: 120.5577, D Loss: 1.2883
Epoch[15790/50000]
**Train**: G Loss: 59.9362, D Loss: -0.6475
Epoch[15790/50000]
**Valid**: G Loss: 60.7863, D Loss: 0.6959
Epoch[15800/50000]
**Train**: G Loss: 129.9300, D Loss: 0.0991
Epoch[15800/50000]
**Valid**: G Loss: 174.5951, D Loss: -0.5538
Epoch[15810/50000]
**Train**: G Loss: 77.9458, D Loss: -0.0517
Epoch[15810/50000]
**Valid**: G Loss: 36.5390, D Loss: -0.8210
Epoch[15820/50000]
**Train**: G Loss: 78.0359, D Loss: 0.7867
Epoch[15820/50000]
**Valid**: G Loss: 114.8716, D Loss: 0.5932
Epoch[15830/50000]
**Train**: G Loss: 164.4456, D Loss: 0.5111
Epoch[15830/50000]
**Valid**: G Loss: 136.8870, D Loss: 1.2386
Epoch[15840/50000]
**Train**: G Loss: 22.2454, D Loss: -0.1870
Epoch[15840/50000]
**Valid**: G Loss: 36.3472, D Loss: 0.8646
Epoch[15850/50000]
**Train**: G Loss: 187.1089, D Loss: -0.2857
Epoch[15850/50000]
**Valid**: G Loss: 176.8531, D Loss: 1.4681
Epoch[15860/50000]
**Train**: G Loss: 101.2884, D Loss: 0.6422
Epoch[15860/50000]
**Valid**: G Loss: 58.6816, D Loss: -1.2900
Epoch[15870/50000]
**Train**: G Loss: 15.2676, D Loss: -0.1081
Epoch[15870/50000]
**Valid**: G Loss: 39.1434, D Loss: 1.0200
Epoch[15880/50000]
**Train**: G Loss: 127.1621, D Loss: 0.0982
Epoch[15880/50000]
**Valid**: G Loss: 185.6359, D Loss: -0.8165
Epoch[15890/50000]
**Train**: G Loss: 163.9683, D Loss: 0.5289
Epoch[15890/50000]
**Valid**: G Loss: 138.1812, D Loss: 1.6022
Epoch[15900/50000]
**Train**: G Loss: 50.0612, D Loss: -0.1906
Epoch[15900/50000]
**Valid**: G Loss: -27.1504, D Loss: -1.0223
Epoch[15910/50000]
**Train**: G Loss: 18.3462, D Loss: 0.6705
Epoch[15910/50000]
**Valid**: G Loss: 53.0571, D Loss: 1.3293
Epoch[15920/50000]
**Train**: G Loss: 176.4627, D Loss: -0.4924
Epoch[15920/50000]
**Valid**: G Loss: 210.7247, D Loss: 0.0361
Epoch[15930/50000]
**Train**: G Loss: 150.1594, D Loss: 1.2136
Epoch[15930/50000]
**Valid**: G Loss: 112.2123, D Loss: 0.7526
Epoch[15940/50000]
**Train**: G Loss: 12.8546, D Loss: -0.9806
Epoch[15940/50000]
**Valid**: G Loss: -10.7381, D Loss: 0.5187
Epoch[15950/50000]
**Train**: G Loss: 137.3781, D Loss: -0.1336
Epoch[15950/50000]
**Valid**: G Loss: 173.3243, D Loss: -0.3494
Epoch[15960/50000]
**Train**: G Loss: 104.6878, D Loss: 0.8347
Epoch[15960/50000]
**Valid**: G Loss: 85.0536, D Loss: -0.9125
Epoch[15970/50000]
**Train**: G Loss: 76.0928, D Loss: 0.5487
Epoch[15970/50000]
**Valid**: G Loss: 83.2020, D Loss: 0.8829
Epoch[15980/50000]
**Train**: G Loss: 128.1941, D Loss: 1.0182
Epoch[15980/50000]
**Valid**: G Loss: 105.9368, D Loss: 0.5663
Epoch[15990/50000]
**Train**: G Loss: 80.1530, D Loss: 0.6288
Epoch[15990/50000]
**Valid**: G Loss: 87.1171, D Loss: 0.9877
Epoch[16000/50000]
**Train**: G Loss: 154.0633, D Loss: -0.1983
Epoch[16000/50000]
**Valid**: G Loss: 137.7460, D Loss: 1.7070
Epoch[16010/50000]
**Train**: G Loss: 81.2554, D Loss: -0.7434
Epoch[16010/50000]
**Valid**: G Loss: 76.1710, D Loss: 0.4216
Epoch[16020/50000]
**Train**: G Loss: 132.8449, D Loss: 0.1066
Epoch[16020/50000]
**Valid**: G Loss: 182.7002, D Loss: -0.4896
Epoch[16030/50000]
**Train**: G Loss: 107.2804, D Loss: 0.4343
Epoch[16030/50000]
**Valid**: G Loss: 78.6036, D Loss: -1.2670
Epoch[16040/50000]
**Train**: G Loss: 67.3047, D Loss: 0.5092
Epoch[16040/50000]
**Valid**: G Loss: 78.8489, D Loss: 1.1409
Epoch[16050/50000]
**Train**: G Loss: 178.3156, D Loss: -0.4855
Epoch[16050/50000]
**Valid**: G Loss: 184.7101, D Loss: 0.7537
Epoch[16060/50000]
**Train**: G Loss: 113.8537, D Loss: 0.2783
Epoch[16060/50000]
**Valid**: G Loss: 90.7705, D Loss: -1.0667
Epoch[16070/50000]
**Train**: G Loss: 88.8967, D Loss: 0.2997
Epoch[16070/50000]
**Valid**: G Loss: 90.3979, D Loss: 1.2925
Epoch[16080/50000]
**Train**: G Loss: 129.7146, D Loss: -0.2651
Epoch[16080/50000]
**Valid**: G Loss: 128.1812, D Loss: 1.2084
Epoch[16090/50000]
**Train**: G Loss: 115.1965, D Loss: -0.2057
Epoch[16090/50000]
**Valid**: G Loss: 111.3255, D Loss: -0.8183
Epoch[16100/50000]
**Train**: G Loss: 110.7900, D Loss: 0.7999
Epoch[16100/50000]
**Valid**: G Loss: 113.3076, D Loss: 0.5215
Epoch[16110/50000]
**Train**: G Loss: 139.4364, D Loss: -0.4060
Epoch[16110/50000]
**Valid**: G Loss: 135.1597, D Loss: 1.1322
Epoch[16120/50000]
**Train**: G Loss: 130.9773, D Loss: 1.2236
Epoch[16120/50000]
**Valid**: G Loss: 117.3068, D Loss: 0.9446
Epoch[16130/50000]
**Train**: G Loss: 109.6766, D Loss: -0.6026
Epoch[16130/50000]
**Valid**: G Loss: 98.3078, D Loss: -0.4466
Epoch[16140/50000]
**Train**: G Loss: 89.8659, D Loss: 0.9434
Epoch[16140/50000]
**Valid**: G Loss: 105.4439, D Loss: 1.0402
Epoch[16150/50000]
**Train**: G Loss: 170.1015, D Loss: -0.5521
Epoch[16150/50000]
**Valid**: G Loss: 179.1449, D Loss: 0.8999
Epoch[16160/50000]
**Train**: G Loss: 149.8408, D Loss: 1.0391
Epoch[16160/50000]
**Valid**: G Loss: 121.9360, D Loss: 0.5180
Epoch[16170/50000]
**Train**: G Loss: 68.8967, D Loss: -0.5837
Epoch[16170/50000]
**Valid**: G Loss: 54.2902, D Loss: 0.2736
Epoch[16180/50000]
**Train**: G Loss: 91.8748, D Loss: 0.6468
Epoch[16180/50000]
**Valid**: G Loss: 128.4637, D Loss: 0.3727
Epoch[16190/50000]
**Train**: G Loss: 177.6562, D Loss: 0.4639
Epoch[16190/50000]
**Valid**: G Loss: 144.7164, D Loss: 1.1346
Epoch[16200/50000]
**Train**: G Loss: 58.3083, D Loss: -0.5960
Epoch[16200/50000]
**Valid**: G Loss: 54.0637, D Loss: 0.4899
Epoch[16210/50000]
**Train**: G Loss: 149.6232, D Loss: -0.2495
Epoch[16210/50000]
**Valid**: G Loss: 179.3232, D Loss: 0.0521
Epoch[16220/50000]
**Train**: G Loss: 114.4076, D Loss: 0.6417
Epoch[16220/50000]
**Valid**: G Loss: 87.6650, D Loss: -0.7390
Epoch[16230/50000]
**Train**: G Loss: 82.8730, D Loss: -0.0237
Epoch[16230/50000]
**Valid**: G Loss: 84.6968, D Loss: 1.1004
Epoch[16240/50000]
**Train**: G Loss: 161.5508, D Loss: -0.1126
Epoch[16240/50000]
**Valid**: G Loss: 194.5019, D Loss: 0.2152
Epoch[16250/50000]
**Train**: G Loss: 136.7535, D Loss: 1.0523
Epoch[16250/50000]
**Valid**: G Loss: 107.3753, D Loss: -0.0002
Epoch[16260/50000]
**Train**: G Loss: 71.8237, D Loss: -0.7296
Epoch[16260/50000]
**Valid**: G Loss: 64.1506, D Loss: 0.5174
Epoch[16270/50000]
**Train**: G Loss: 78.2758, D Loss: 0.5541
Epoch[16270/50000]
**Valid**: G Loss: 83.3671, D Loss: 1.1939
Epoch[16280/50000]
**Train**: G Loss: 121.8704, D Loss: 0.1308
Epoch[16280/50000]
**Valid**: G Loss: 146.6666, D Loss: -0.4951
Epoch[16290/50000]
**Train**: G Loss: 130.7211, D Loss: 0.7701
Epoch[16290/50000]
**Valid**: G Loss: 120.9502, D Loss: 1.2719
Epoch[16300/50000]
**Train**: G Loss: 117.6039, D Loss: 0.3342
Epoch[16300/50000]
**Valid**: G Loss: 105.9303, D Loss: -1.2718
Epoch[16310/50000]
**Train**: G Loss: 95.1847, D Loss: 0.5701
Epoch[16310/50000]
**Valid**: G Loss: 104.1743, D Loss: 1.1164
Epoch[16320/50000]
**Train**: G Loss: 185.2705, D Loss: -0.1229
Epoch[16320/50000]
**Valid**: G Loss: 180.0958, D Loss: 1.3880
Epoch[16330/50000]
**Train**: G Loss: 123.3417, D Loss: 0.8667
Epoch[16330/50000]
**Valid**: G Loss: 90.7025, D Loss: -0.5308
Epoch[16340/50000]
**Train**: G Loss: 54.7589, D Loss: -0.6791
Epoch[16340/50000]
**Valid**: G Loss: 43.9712, D Loss: 0.4692
Epoch[16350/50000]
**Train**: G Loss: 61.0704, D Loss: 0.6160
Epoch[16350/50000]
**Valid**: G Loss: 86.7562, D Loss: 1.0504
Epoch[16360/50000]
**Train**: G Loss: 117.7300, D Loss: 0.5352
Epoch[16360/50000]
**Valid**: G Loss: 165.2415, D Loss: -0.6100
Epoch[16370/50000]
**Train**: G Loss: 130.9874, D Loss: -0.0903
Epoch[16370/50000]
**Valid**: G Loss: 120.8077, D Loss: 1.6519
Epoch[16380/50000]
**Train**: G Loss: 112.5206, D Loss: -0.3546
Epoch[16380/50000]
**Valid**: G Loss: 101.9106, D Loss: -0.8104
Epoch[16390/50000]
**Train**: G Loss: 108.9058, D Loss: -0.0502
Epoch[16390/50000]
**Valid**: G Loss: 107.2890, D Loss: 1.0983
Epoch[16400/50000]
**Train**: G Loss: 110.7256, D Loss: 0.7573
Epoch[16400/50000]
**Valid**: G Loss: 134.6130, D Loss: -0.4145
Epoch[16410/50000]
**Train**: G Loss: 121.7040, D Loss: 0.9988
Epoch[16410/50000]
**Valid**: G Loss: 109.3353, D Loss: 0.1799
Epoch[16420/50000]
**Train**: G Loss: 143.6436, D Loss: -0.1774
Epoch[16420/50000]
**Valid**: G Loss: 156.1470, D Loss: 0.1733
Epoch[16430/50000]
**Train**: G Loss: 132.4757, D Loss: 1.0980
Epoch[16430/50000]
**Valid**: G Loss: 116.5318, D Loss: 0.5556
Epoch[16440/50000]
**Train**: G Loss: 74.1753, D Loss: 0.2663
Epoch[16440/50000]
**Valid**: G Loss: 89.8443, D Loss: 1.0273
Epoch[16450/50000]
**Train**: G Loss: 171.7088, D Loss: -0.4054
Epoch[16450/50000]
**Valid**: G Loss: 209.4607, D Loss: -0.1462
Epoch[16460/50000]
**Train**: G Loss: 144.9312, D Loss: 1.2167
Epoch[16460/50000]
**Valid**: G Loss: 108.0366, D Loss: 0.7048
Epoch[16470/50000]
**Train**: G Loss: 31.1161, D Loss: -0.8532
Epoch[16470/50000]
**Valid**: G Loss: 17.2754, D Loss: 0.2932
Epoch[16480/50000]
**Train**: G Loss: 69.6511, D Loss: 0.9066
Epoch[16480/50000]
**Valid**: G Loss: 115.3065, D Loss: 0.3069
Epoch[16490/50000]
**Train**: G Loss: 195.2546, D Loss: -0.4288
Epoch[16490/50000]
**Valid**: G Loss: 181.8726, D Loss: 1.1517
Epoch[16500/50000]
**Train**: G Loss: 117.0541, D Loss: 1.0993
Epoch[16500/50000]
**Valid**: G Loss: 76.1130, D Loss: -0.6459
Epoch[16510/50000]
**Train**: G Loss: 30.2425, D Loss: -0.2766
Epoch[16510/50000]
**Valid**: G Loss: 37.0515, D Loss: 0.9293
Epoch[16520/50000]
**Train**: G Loss: 102.0826, D Loss: 0.5923
Epoch[16520/50000]
**Valid**: G Loss: 151.7192, D Loss: -0.8127
Epoch[16530/50000]
**Train**: G Loss: 122.2651, D Loss: 0.9908
Epoch[16530/50000]
**Valid**: G Loss: 109.1592, D Loss: 1.0062
Epoch[16540/50000]
**Train**: G Loss: 69.2180, D Loss: -0.3631
Epoch[16540/50000]
**Valid**: G Loss: 66.9820, D Loss: 0.6589
Epoch[16550/50000]
**Train**: G Loss: 130.7489, D Loss: -0.1488
Epoch[16550/50000]
**Valid**: G Loss: 157.4121, D Loss: -0.0059
Epoch[16560/50000]
**Train**: G Loss: 105.0350, D Loss: 0.3298
Epoch[16560/50000]
**Valid**: G Loss: 85.9251, D Loss: -1.2015
Epoch[16570/50000]
**Train**: G Loss: 81.3576, D Loss: 0.6910
Epoch[16570/50000]
**Valid**: G Loss: 88.2000, D Loss: 1.0758
Epoch[16580/50000]
**Train**: G Loss: 153.6574, D Loss: -0.2492
Epoch[16580/50000]
**Valid**: G Loss: 158.1756, D Loss: 1.1688
Epoch[16590/50000]
**Train**: G Loss: 107.0742, D Loss: 0.6131
Epoch[16590/50000]
**Valid**: G Loss: 81.0285, D Loss: -0.8940
Epoch[16600/50000]
**Train**: G Loss: 67.7227, D Loss: 0.6191
Epoch[16600/50000]
**Valid**: G Loss: 79.0043, D Loss: 0.8571
Epoch[16610/50000]
**Train**: G Loss: 161.1539, D Loss: -0.2287
Epoch[16610/50000]
**Valid**: G Loss: 174.8452, D Loss: 0.4658
Epoch[16620/50000]
**Train**: G Loss: 85.6691, D Loss: -0.1034
Epoch[16620/50000]
**Valid**: G Loss: 49.5235, D Loss: -0.5382
Epoch[16630/50000]
**Train**: G Loss: 83.7666, D Loss: 0.9261
Epoch[16630/50000]
**Valid**: G Loss: 109.1499, D Loss: 0.7280
Epoch[16640/50000]
**Train**: G Loss: 151.5847, D Loss: 0.2106
Epoch[16640/50000]
**Valid**: G Loss: 131.2483, D Loss: 1.6532
Epoch[16650/50000]
**Train**: G Loss: 98.0553, D Loss: -0.6138
Epoch[16650/50000]
**Valid**: G Loss: 88.5669, D Loss: 0.1039
Epoch[16660/50000]
**Train**: G Loss: 120.2008, D Loss: 0.7750
Epoch[16660/50000]
**Valid**: G Loss: 137.4990, D Loss: 0.0207
Epoch[16670/50000]
**Train**: G Loss: 162.9686, D Loss: 0.1659
Epoch[16670/50000]
**Valid**: G Loss: 144.2293, D Loss: 1.5647
Epoch[16680/50000]
**Train**: G Loss: 70.9004, D Loss: -0.5175
Epoch[16680/50000]
**Valid**: G Loss: 64.6038, D Loss: 0.3945
Epoch[16690/50000]
**Train**: G Loss: 111.9629, D Loss: 0.6401
Epoch[16690/50000]
**Valid**: G Loss: 163.2570, D Loss: -0.5391
Epoch[16700/50000]
**Train**: G Loss: 152.0446, D Loss: 1.0309
Epoch[16700/50000]
**Valid**: G Loss: 129.2144, D Loss: 1.3976
Epoch[16710/50000]
**Train**: G Loss: 72.0768, D Loss: -0.7628
Epoch[16710/50000]
**Valid**: G Loss: 63.4297, D Loss: 0.4758
Epoch[16720/50000]
**Train**: G Loss: 101.2995, D Loss: 0.7268
Epoch[16720/50000]
**Valid**: G Loss: 129.2373, D Loss: -0.0015
Epoch[16730/50000]
**Train**: G Loss: 158.1612, D Loss: 0.1023
Epoch[16730/50000]
**Valid**: G Loss: 138.8878, D Loss: 1.4906
Epoch[16740/50000]
**Train**: G Loss: 75.4148, D Loss: -0.5144
Epoch[16740/50000]
**Valid**: G Loss: 71.0967, D Loss: 0.5588
Epoch[16750/50000]
**Train**: G Loss: 122.0413, D Loss: 0.0594
Epoch[16750/50000]
**Valid**: G Loss: 146.2242, D Loss: -0.6571
Epoch[16760/50000]
**Train**: G Loss: 123.6371, D Loss: 1.2068
Epoch[16760/50000]
**Valid**: G Loss: 111.0344, D Loss: 0.6781
Epoch[16770/50000]
**Train**: G Loss: 59.4836, D Loss: -0.5214
Epoch[16770/50000]
**Valid**: G Loss: 63.1832, D Loss: 0.9772
Epoch[16780/50000]
**Train**: G Loss: 168.5610, D Loss: -0.0704
Epoch[16780/50000]
**Valid**: G Loss: 229.1906, D Loss: 0.5424
Epoch[16790/50000]
**Train**: G Loss: 115.2243, D Loss: 0.9006
Epoch[16790/50000]
**Valid**: G Loss: 66.2447, D Loss: -0.6456
Epoch[16800/50000]
**Train**: G Loss: 57.7256, D Loss: 0.7382
Epoch[16800/50000]
**Valid**: G Loss: 89.8539, D Loss: 0.8547
Epoch[16810/50000]
**Train**: G Loss: 193.8571, D Loss: -0.0659
Epoch[16810/50000]
**Valid**: G Loss: 174.8925, D Loss: 1.3821
Epoch[16820/50000]
**Train**: G Loss: 81.7536, D Loss: -0.0063
Epoch[16820/50000]
**Valid**: G Loss: 28.6441, D Loss: -0.9053
Epoch[16830/50000]
**Train**: G Loss: 66.7121, D Loss: 0.8101
Epoch[16830/50000]
**Valid**: G Loss: 91.5282, D Loss: 0.8399
Epoch[16840/50000]
**Train**: G Loss: 144.6668, D Loss: -0.3914
Epoch[16840/50000]
**Valid**: G Loss: 146.2465, D Loss: 0.6911
Epoch[16850/50000]
**Train**: G Loss: 118.4710, D Loss: 1.1302
Epoch[16850/50000]
**Valid**: G Loss: 120.1463, D Loss: -0.3654
Epoch[16860/50000]
**Train**: G Loss: 113.6654, D Loss: -0.1188
Epoch[16860/50000]
**Valid**: G Loss: 109.4257, D Loss: 0.9363
Epoch[16870/50000]
**Train**: G Loss: 121.6829, D Loss: 0.7325
Epoch[16870/50000]
**Valid**: G Loss: 136.0694, D Loss: -0.0446
Epoch[16880/50000]
**Train**: G Loss: 149.7899, D Loss: 0.4234
Epoch[16880/50000]
**Valid**: G Loss: 137.0034, D Loss: 1.4884
Epoch[16890/50000]
**Train**: G Loss: 104.1488, D Loss: -0.3132
Epoch[16890/50000]
**Valid**: G Loss: 84.9550, D Loss: -0.4976
Epoch[16900/50000]
**Train**: G Loss: 135.9969, D Loss: 0.3044
Epoch[16900/50000]
**Valid**: G Loss: 178.6073, D Loss: -0.6459
Epoch[16910/50000]
**Train**: G Loss: 123.3850, D Loss: 0.7239
Epoch[16910/50000]
**Valid**: G Loss: 93.7250, D Loss: -1.0101
Epoch[16920/50000]
**Train**: G Loss: 84.0574, D Loss: 0.0514
Epoch[16920/50000]
**Valid**: G Loss: 89.3596, D Loss: 0.9414
Epoch[16930/50000]
**Train**: G Loss: 138.6537, D Loss: 0.1341
Epoch[16930/50000]
**Valid**: G Loss: 180.0095, D Loss: -0.7482
Epoch[16940/50000]
**Train**: G Loss: 158.3548, D Loss: 1.1051
Epoch[16940/50000]
**Valid**: G Loss: 131.9504, D Loss: 1.1498
Epoch[16950/50000]
**Train**: G Loss: 60.2372, D Loss: -0.6386
Epoch[16950/50000]
**Valid**: G Loss: 47.4867, D Loss: 0.2443
Epoch[16960/50000]
**Train**: G Loss: 112.4201, D Loss: 0.6122
Epoch[16960/50000]
**Valid**: G Loss: 163.9744, D Loss: -0.4879
Epoch[16970/50000]
**Train**: G Loss: 171.9695, D Loss: 0.8363
Epoch[16970/50000]
**Valid**: G Loss: 139.9604, D Loss: 1.0977
Epoch[16980/50000]
**Train**: G Loss: 70.9353, D Loss: -0.4402
Epoch[16980/50000]
**Valid**: G Loss: 29.0123, D Loss: -0.7704
Epoch[16990/50000]
**Train**: G Loss: 46.4452, D Loss: 0.5299
Epoch[16990/50000]
**Valid**: G Loss: 71.2369, D Loss: 1.1051
Epoch[17000/50000]
**Train**: G Loss: 178.4134, D Loss: -0.4189
Epoch[17000/50000]
**Valid**: G Loss: 203.5876, D Loss: 0.3894
Epoch[17010/50000]
**Train**: G Loss: 140.4051, D Loss: 1.0930
Epoch[17010/50000]
**Valid**: G Loss: 115.6745, D Loss: 0.1952
Epoch[17020/50000]
**Train**: G Loss: 76.5487, D Loss: -0.7430
Epoch[17020/50000]
**Valid**: G Loss: 60.4771, D Loss: 0.2218
Epoch[17030/50000]
**Train**: G Loss: 95.4841, D Loss: 0.7138
Epoch[17030/50000]
**Valid**: G Loss: 100.1601, D Loss: 0.7574
Epoch[17040/50000]
**Train**: G Loss: 127.2650, D Loss: -0.2651
Epoch[17040/50000]
**Valid**: G Loss: 137.2571, D Loss: 0.1992
Epoch[17050/50000]
**Train**: G Loss: 119.4427, D Loss: 1.0928
Epoch[17050/50000]
**Valid**: G Loss: 119.4920, D Loss: 0.0069
Epoch[17060/50000]
**Train**: G Loss: 94.2067, D Loss: -0.3898
Epoch[17060/50000]
**Valid**: G Loss: 92.6324, D Loss: 1.0026
Epoch[17070/50000]
**Train**: G Loss: 108.1399, D Loss: 0.7089
Epoch[17070/50000]
**Valid**: G Loss: 128.1693, D Loss: -0.0046
Epoch[17080/50000]
**Train**: G Loss: 167.2412, D Loss: -0.2271
Epoch[17080/50000]
**Valid**: G Loss: 169.8063, D Loss: 1.1544
Epoch[17090/50000]
**Train**: G Loss: 145.6610, D Loss: 0.9925
Epoch[17090/50000]
**Valid**: G Loss: 128.4326, D Loss: 1.0558
Epoch[17100/50000]
**Train**: G Loss: 121.8291, D Loss: 0.4391
Epoch[17100/50000]
**Valid**: G Loss: 108.6104, D Loss: -0.8175
Epoch[17110/50000]
**Train**: G Loss: 105.9803, D Loss: -0.4715
Epoch[17110/50000]
**Valid**: G Loss: 100.4339, D Loss: 0.8129
Epoch[17120/50000]
**Train**: G Loss: 113.1946, D Loss: 0.8646
Epoch[17120/50000]
**Valid**: G Loss: 119.5471, D Loss: 0.1654
Epoch[17130/50000]
**Train**: G Loss: 120.3847, D Loss: -0.4504
Epoch[17130/50000]
**Valid**: G Loss: 115.3836, D Loss: 0.8570
Epoch[17140/50000]
**Train**: G Loss: 125.5251, D Loss: 1.2117
Epoch[17140/50000]
**Valid**: G Loss: 117.9158, D Loss: 0.9042
Epoch[17150/50000]
**Train**: G Loss: 110.5466, D Loss: 0.0443
Epoch[17150/50000]
**Valid**: G Loss: 89.5843, D Loss: -0.3657
Epoch[17160/50000]
**Train**: G Loss: 92.0711, D Loss: 0.5854
Epoch[17160/50000]
**Valid**: G Loss: 102.6224, D Loss: 0.8923
Epoch[17170/50000]
**Train**: G Loss: 145.5250, D Loss: -0.0634
Epoch[17170/50000]
**Valid**: G Loss: 173.5319, D Loss: -0.5849
Epoch[17180/50000]
**Train**: G Loss: 164.3508, D Loss: 0.2820
Epoch[17180/50000]
**Valid**: G Loss: 149.5190, D Loss: 1.6507
Epoch[17190/50000]
**Train**: G Loss: 120.0322, D Loss: 1.0615
Epoch[17190/50000]
**Valid**: G Loss: 104.4708, D Loss: -0.0122
Epoch[17200/50000]
**Train**: G Loss: 69.1786, D Loss: -0.8036
Epoch[17200/50000]
**Valid**: G Loss: 54.1068, D Loss: 0.2656
Epoch[17210/50000]
**Train**: G Loss: 51.2966, D Loss: 0.5068
Epoch[17210/50000]
**Valid**: G Loss: 81.9575, D Loss: 1.1493
Epoch[17220/50000]
**Train**: G Loss: 166.8115, D Loss: -0.5216
Epoch[17220/50000]
**Valid**: G Loss: 170.7770, D Loss: 0.6121
Epoch[17230/50000]
**Train**: G Loss: 107.2492, D Loss: 0.7133
Epoch[17230/50000]
**Valid**: G Loss: 102.4184, D Loss: -0.7545
Epoch[17240/50000]
**Train**: G Loss: 97.9300, D Loss: 0.1876
Epoch[17240/50000]
**Valid**: G Loss: 99.2507, D Loss: 1.6463
Epoch[17250/50000]
**Train**: G Loss: 140.5610, D Loss: 0.1397
Epoch[17250/50000]
**Valid**: G Loss: 178.6481, D Loss: -0.3789
Epoch[17260/50000]
**Train**: G Loss: 182.1426, D Loss: 0.6908
Epoch[17260/50000]
**Valid**: G Loss: 152.6158, D Loss: 1.5331
Epoch[17270/50000]
**Train**: G Loss: 117.5107, D Loss: 0.8836
Epoch[17270/50000]
**Valid**: G Loss: 81.8963, D Loss: -0.9107
Epoch[17280/50000]
**Train**: G Loss: 101.7374, D Loss: -0.6524
Epoch[17280/50000]
**Valid**: G Loss: 95.6424, D Loss: 0.7457
Epoch[17290/50000]
**Train**: G Loss: 108.2720, D Loss: 0.7959
Epoch[17290/50000]
**Valid**: G Loss: 119.1406, D Loss: 0.3505
Epoch[17300/50000]
**Train**: G Loss: 143.8387, D Loss: -0.1667
Epoch[17300/50000]
**Valid**: G Loss: 165.2526, D Loss: -0.0857
Epoch[17310/50000]
**Train**: G Loss: 184.4522, D Loss: 0.1161
Epoch[17310/50000]
**Valid**: G Loss: 158.6987, D Loss: 1.5012
Epoch[17320/50000]
**Train**: G Loss: 116.2727, D Loss: 0.1262
Epoch[17320/50000]
**Valid**: G Loss: 99.1797, D Loss: -0.8872
Epoch[17330/50000]
**Train**: G Loss: 99.9912, D Loss: 0.3221
Epoch[17330/50000]
**Valid**: G Loss: 99.3888, D Loss: 0.9677
Epoch[17340/50000]
**Train**: G Loss: 144.3660, D Loss: -0.1012
Epoch[17340/50000]
**Valid**: G Loss: 142.0178, D Loss: 0.9195
Epoch[17350/50000]
**Train**: G Loss: 99.6547, D Loss: -0.3692
Epoch[17350/50000]
**Valid**: G Loss: 94.3867, D Loss: 0.7310
Epoch[17360/50000]
**Train**: G Loss: 121.8351, D Loss: 0.2177
Epoch[17360/50000]
**Valid**: G Loss: 152.6174, D Loss: -0.6994
Epoch[17370/50000]
**Train**: G Loss: 152.1312, D Loss: 0.9556
Epoch[17370/50000]
**Valid**: G Loss: 125.0558, D Loss: 0.3095
Epoch[17380/50000]
**Train**: G Loss: 85.9151, D Loss: -0.4747
Epoch[17380/50000]
**Valid**: G Loss: 80.1929, D Loss: 0.4701
Epoch[17390/50000]
**Train**: G Loss: 106.7573, D Loss: 0.8423
Epoch[17390/50000]
**Valid**: G Loss: 118.1985, D Loss: 0.6745
Epoch[17400/50000]
**Train**: G Loss: 194.7626, D Loss: -0.2119
Epoch[17400/50000]
**Valid**: G Loss: 198.2258, D Loss: 1.1126
Epoch[17410/50000]
**Train**: G Loss: 81.2352, D Loss: -0.4413
Epoch[17410/50000]
**Valid**: G Loss: 59.7453, D Loss: -0.0211
Epoch[17420/50000]
**Train**: G Loss: 87.8999, D Loss: 0.8754
Epoch[17420/50000]
**Valid**: G Loss: 112.9026, D Loss: 0.6589
Epoch[17430/50000]
**Train**: G Loss: 147.6722, D Loss: -0.2403
Epoch[17430/50000]
**Valid**: G Loss: 172.8724, D Loss: -0.0503
Epoch[17440/50000]
**Train**: G Loss: 138.6159, D Loss: 0.7734
Epoch[17440/50000]
**Valid**: G Loss: 125.4012, D Loss: 1.4317
Epoch[17450/50000]
**Train**: G Loss: 113.4293, D Loss: -0.2327
Epoch[17450/50000]
**Valid**: G Loss: 102.0916, D Loss: -0.6649
Epoch[17460/50000]
**Train**: G Loss: 100.6305, D Loss: 0.5467
Epoch[17460/50000]
**Valid**: G Loss: 101.1463, D Loss: 0.9939
Epoch[17470/50000]
**Train**: G Loss: 126.0242, D Loss: 0.1244
Epoch[17470/50000]
**Valid**: G Loss: 145.1460, D Loss: -0.5623
Epoch[17480/50000]
**Train**: G Loss: 146.2686, D Loss: 0.6882
Epoch[17480/50000]
**Valid**: G Loss: 133.6449, D Loss: 1.3282
Epoch[17490/50000]
**Train**: G Loss: 98.5134, D Loss: -0.4472
Epoch[17490/50000]
**Valid**: G Loss: 82.7052, D Loss: -0.1732
Epoch[17500/50000]
**Train**: G Loss: 89.2096, D Loss: 0.4456
Epoch[17500/50000]
**Valid**: G Loss: 96.4880, D Loss: 1.1148
Epoch[17510/50000]
**Train**: G Loss: 130.3337, D Loss: 0.2471
Epoch[17510/50000]
**Valid**: G Loss: 159.1785, D Loss: -0.5658
Epoch[17520/50000]
**Train**: G Loss: 178.2217, D Loss: -0.3722
Epoch[17520/50000]
**Valid**: G Loss: 172.3368, D Loss: 1.3121
Epoch[17530/50000]
**Train**: G Loss: 143.0089, D Loss: 1.1669
Epoch[17530/50000]
**Valid**: G Loss: 122.6913, D Loss: 0.7246
Epoch[17540/50000]
**Train**: G Loss: 106.3260, D Loss: 0.2386
Epoch[17540/50000]
**Valid**: G Loss: 72.8629, D Loss: -1.0185
Epoch[17550/50000]
**Train**: G Loss: 59.2407, D Loss: -0.4722
Epoch[17550/50000]
**Valid**: G Loss: 61.7766, D Loss: 1.0726
Epoch[17560/50000]
**Train**: G Loss: 87.8519, D Loss: 0.9388
Epoch[17560/50000]
**Valid**: G Loss: 112.9107, D Loss: 0.7239
Epoch[17570/50000]
**Train**: G Loss: 147.6779, D Loss: -0.3639
Epoch[17570/50000]
**Valid**: G Loss: 162.6346, D Loss: 0.5212
Epoch[17580/50000]
**Train**: G Loss: 116.2841, D Loss: 0.7200
Epoch[17580/50000]
**Valid**: G Loss: 110.9969, D Loss: -0.6577
Epoch[17590/50000]
**Train**: G Loss: 116.3316, D Loss: 0.0475
Epoch[17590/50000]
**Valid**: G Loss: 111.1720, D Loss: 1.0178
Epoch[17600/50000]
**Train**: G Loss: 129.3965, D Loss: -0.2613
Epoch[17600/50000]
**Valid**: G Loss: 138.1732, D Loss: 0.0918
Epoch[17610/50000]
**Train**: G Loss: 126.5476, D Loss: 1.0398
Epoch[17610/50000]
**Valid**: G Loss: 125.0804, D Loss: -0.0249
Epoch[17620/50000]
**Train**: G Loss: 136.9252, D Loss: -0.1275
Epoch[17620/50000]
**Valid**: G Loss: 141.2642, D Loss: 0.5308
Epoch[17630/50000]
**Train**: G Loss: 120.0093, D Loss: 0.2611
Epoch[17630/50000]
**Valid**: G Loss: 108.2221, D Loss: -0.8994
Epoch[17640/50000]
**Train**: G Loss: 108.4655, D Loss: 0.8924
Epoch[17640/50000]
**Valid**: G Loss: 118.5887, D Loss: 0.7537
Epoch[17650/50000]
**Train**: G Loss: 154.5148, D Loss: -0.3777
Epoch[17650/50000]
**Valid**: G Loss: 153.7964, D Loss: 0.9932
Epoch[17660/50000]
**Train**: G Loss: 126.3533, D Loss: 0.8263
Epoch[17660/50000]
**Valid**: G Loss: 110.6871, D Loss: -0.6590
Epoch[17670/50000]
**Train**: G Loss: 100.2395, D Loss: -0.5466
Epoch[17670/50000]
**Valid**: G Loss: 95.6150, D Loss: 0.6676
Epoch[17680/50000]
**Train**: G Loss: 101.7249, D Loss: 0.7375
Epoch[17680/50000]
**Valid**: G Loss: 114.3916, D Loss: 0.7813
Epoch[17690/50000]
**Train**: G Loss: 149.5907, D Loss: -0.1790
Epoch[17690/50000]
**Valid**: G Loss: 172.9863, D Loss: -0.2006
Epoch[17700/50000]
**Train**: G Loss: 166.2138, D Loss: 0.2526
Epoch[17700/50000]
**Valid**: G Loss: 150.9021, D Loss: 1.3800
Epoch[17710/50000]
**Train**: G Loss: 143.5136, D Loss: 1.2257
Epoch[17710/50000]
**Valid**: G Loss: 129.1126, D Loss: 0.5164
Epoch[17720/50000]
**Train**: G Loss: 109.8692, D Loss: -0.5204
Epoch[17720/50000]
**Valid**: G Loss: 102.0065, D Loss: 0.3280
Epoch[17730/50000]
**Train**: G Loss: 108.0772, D Loss: 0.9186
Epoch[17730/50000]
**Valid**: G Loss: 118.7803, D Loss: 0.6897
Epoch[17740/50000]
**Train**: G Loss: 196.9292, D Loss: -0.3713
Epoch[17740/50000]
**Valid**: G Loss: 200.9102, D Loss: 1.1815
Epoch[17750/50000]
**Train**: G Loss: 122.7260, D Loss: 0.5422
Epoch[17750/50000]
**Valid**: G Loss: 88.5084, D Loss: -0.7649
Epoch[17760/50000]
**Train**: G Loss: 67.6266, D Loss: -0.7433
Epoch[17760/50000]
**Valid**: G Loss: 61.3170, D Loss: 0.4631
Epoch[17770/50000]
**Train**: G Loss: 104.5611, D Loss: 0.7064
Epoch[17770/50000]
**Valid**: G Loss: 135.3331, D Loss: -0.1974
Epoch[17780/50000]
**Train**: G Loss: 169.9966, D Loss: 0.0540
Epoch[17780/50000]
**Valid**: G Loss: 154.4129, D Loss: 1.5996
Epoch[17790/50000]
**Train**: G Loss: 114.7797, D Loss: 0.5602
Epoch[17790/50000]
**Valid**: G Loss: 84.1723, D Loss: -1.1381
Epoch[17800/50000]
**Train**: G Loss: 78.3204, D Loss: 0.4956
Epoch[17800/50000]
**Valid**: G Loss: 94.7593, D Loss: 0.8826
Epoch[17810/50000]
**Train**: G Loss: 193.4917, D Loss: -0.3832
Epoch[17810/50000]
**Valid**: G Loss: 192.2317, D Loss: 0.8852
Epoch[17820/50000]
**Train**: G Loss: 125.5196, D Loss: 0.9263
Epoch[17820/50000]
**Valid**: G Loss: 83.5307, D Loss: -0.7138
Epoch[17830/50000]
**Train**: G Loss: 47.0496, D Loss: -0.6280
Epoch[17830/50000]
**Valid**: G Loss: 41.1926, D Loss: 0.6049
Epoch[17840/50000]
**Train**: G Loss: 82.6445, D Loss: 0.8832
Epoch[17840/50000]
**Valid**: G Loss: 102.6844, D Loss: 0.6192
Epoch[17850/50000]
**Train**: G Loss: 132.2405, D Loss: -0.3419
Epoch[17850/50000]
**Valid**: G Loss: 151.2990, D Loss: 0.2767
Epoch[17860/50000]
**Train**: G Loss: 123.5778, D Loss: 0.9016
Epoch[17860/50000]
**Valid**: G Loss: 121.3729, D Loss: 0.1009
Epoch[17870/50000]
**Train**: G Loss: 110.5025, D Loss: 0.2106
Epoch[17870/50000]
**Valid**: G Loss: 108.2838, D Loss: 1.0987
Epoch[17880/50000]
**Train**: G Loss: 115.1200, D Loss: 0.8657
Epoch[17880/50000]
**Valid**: G Loss: 124.4447, D Loss: 0.3647
Epoch[17890/50000]
**Train**: G Loss: 169.8761, D Loss: -0.0803
Epoch[17890/50000]
**Valid**: G Loss: 197.7720, D Loss: 0.1876
Epoch[17900/50000]
**Train**: G Loss: 146.7020, D Loss: 0.9736
Epoch[17900/50000]
**Valid**: G Loss: 114.6719, D Loss: -0.2542
Epoch[17910/50000]
**Train**: G Loss: 67.3070, D Loss: -0.1204
Epoch[17910/50000]
**Valid**: G Loss: 79.2952, D Loss: 0.9965
Epoch[17920/50000]
**Train**: G Loss: 210.2464, D Loss: -0.0432
Epoch[17920/50000]
**Valid**: G Loss: 199.9835, D Loss: 1.8483
Epoch[17930/50000]
**Train**: G Loss: 85.6831, D Loss: -0.5807
Epoch[17930/50000]
**Valid**: G Loss: 83.0433, D Loss: 0.6342
Epoch[17940/50000]
**Train**: G Loss: 151.4588, D Loss: 0.3079
Epoch[17940/50000]
**Valid**: G Loss: 206.5349, D Loss: -0.3556
Epoch[17950/50000]
**Train**: G Loss: 140.7117, D Loss: 0.7958
Epoch[17950/50000]
**Valid**: G Loss: 110.4726, D Loss: -0.5597
Epoch[17960/50000]
**Train**: G Loss: 89.8242, D Loss: -0.0614
Epoch[17960/50000]
**Valid**: G Loss: 91.6687, D Loss: 1.0948
Epoch[17970/50000]
**Train**: G Loss: 118.5404, D Loss: 0.6841
Epoch[17970/50000]
**Valid**: G Loss: 143.4862, D Loss: -0.0118
Epoch[17980/50000]
**Train**: G Loss: 195.8041, D Loss: -0.2391
Epoch[17980/50000]
**Valid**: G Loss: 196.4753, D Loss: 1.1515
Epoch[17990/50000]
**Train**: G Loss: 116.4990, D Loss: 0.2003
Epoch[17990/50000]
**Valid**: G Loss: 79.2084, D Loss: -1.0683
Epoch[18000/50000]
**Train**: G Loss: 89.2474, D Loss: 0.7977
Epoch[18000/50000]
**Valid**: G Loss: 105.5330, D Loss: 1.0673
Epoch[18010/50000]
**Train**: G Loss: 196.4110, D Loss: -0.2955
Epoch[18010/50000]
**Valid**: G Loss: 202.1460, D Loss: 1.1918
Epoch[18020/50000]
**Train**: G Loss: 151.2271, D Loss: 1.1440
Epoch[18020/50000]
**Valid**: G Loss: 128.6540, D Loss: 0.4954
Epoch[18030/50000]
**Train**: G Loss: 102.8205, D Loss: -0.4587
Epoch[18030/50000]
**Valid**: G Loss: 79.3532, D Loss: -0.6105
Epoch[18040/50000]
**Train**: G Loss: 80.3467, D Loss: 0.6955
Epoch[18040/50000]
**Valid**: G Loss: 97.5720, D Loss: 1.0997
Epoch[18050/50000]
**Train**: G Loss: 161.0952, D Loss: -0.1902
Epoch[18050/50000]
**Valid**: G Loss: 187.8838, D Loss: -0.0241
Epoch[18060/50000]
**Train**: G Loss: 165.1132, D Loss: 1.1642
Epoch[18060/50000]
**Valid**: G Loss: 143.4290, D Loss: 1.3726
Epoch[18070/50000]
**Train**: G Loss: 108.0535, D Loss: -0.6732
Epoch[18070/50000]
**Valid**: G Loss: 102.2549, D Loss: 0.5253
Epoch[18080/50000]
**Train**: G Loss: 105.8336, D Loss: 0.8531
Epoch[18080/50000]
**Valid**: G Loss: 121.7758, D Loss: 0.5419
Epoch[18090/50000]
**Train**: G Loss: 181.4538, D Loss: -0.0292
Epoch[18090/50000]
**Valid**: G Loss: 176.3466, D Loss: 1.7015
Epoch[18100/50000]
**Train**: G Loss: 132.8304, D Loss: 0.4951
Epoch[18100/50000]
**Valid**: G Loss: 119.4992, D Loss: -0.9444
Epoch[18110/50000]
**Train**: G Loss: 80.5498, D Loss: 0.0479
Epoch[18110/50000]
**Valid**: G Loss: 90.1570, D Loss: 1.0838
Epoch[18120/50000]
**Train**: G Loss: 188.9113, D Loss: -0.3052
Epoch[18120/50000]
**Valid**: G Loss: 230.6445, D Loss: 0.3320
Epoch[18130/50000]
**Train**: G Loss: 65.0365, D Loss: -0.3669
Epoch[18130/50000]
**Valid**: G Loss: 68.7560, D Loss: 1.1471
Epoch[18140/50000]
**Train**: G Loss: 172.1414, D Loss: -0.1471
Epoch[18140/50000]
**Valid**: G Loss: 213.3418, D Loss: -0.0161
Epoch[18150/50000]
**Train**: G Loss: 144.3759, D Loss: 0.9174
Epoch[18150/50000]
**Valid**: G Loss: 122.6439, D Loss: -0.3333
Epoch[18160/50000]
**Train**: G Loss: 108.7805, D Loss: 0.2332
Epoch[18160/50000]
**Valid**: G Loss: 107.6055, D Loss: 1.1268
Epoch[18170/50000]
**Train**: G Loss: 141.0456, D Loss: 0.0652
Epoch[18170/50000]
**Valid**: G Loss: 159.4910, D Loss: -0.4575
Epoch[18180/50000]
**Train**: G Loss: 158.1716, D Loss: 0.6165
Epoch[18180/50000]
**Valid**: G Loss: 146.7337, D Loss: 1.5094
Epoch[18190/50000]
**Train**: G Loss: 123.5357, D Loss: -0.5245
Epoch[18190/50000]
**Valid**: G Loss: 111.4298, D Loss: -0.5391
Epoch[18200/50000]
**Train**: G Loss: 110.0691, D Loss: 0.6993
Epoch[18200/50000]
**Valid**: G Loss: 120.1852, D Loss: 1.1381
Epoch[18210/50000]
**Train**: G Loss: 188.1877, D Loss: -0.2924
Epoch[18210/50000]
**Valid**: G Loss: 231.1758, D Loss: -0.1194
Epoch[18220/50000]
**Train**: G Loss: 171.4022, D Loss: 1.1398
Epoch[18220/50000]
**Valid**: G Loss: 137.6610, D Loss: 0.5162
Epoch[18230/50000]
**Train**: G Loss: 88.3205, D Loss: -0.1947
Epoch[18230/50000]
**Valid**: G Loss: 94.5012, D Loss: 1.1750
Epoch[18240/50000]
**Train**: G Loss: 193.1512, D Loss: -0.2118
Epoch[18240/50000]
**Valid**: G Loss: 230.4818, D Loss: 0.3489
Epoch[18250/50000]
**Train**: G Loss: 147.3474, D Loss: 0.8007
Epoch[18250/50000]
**Valid**: G Loss: 114.1394, D Loss: -0.8523
Epoch[18260/50000]
**Train**: G Loss: 81.8322, D Loss: 0.0841
Epoch[18260/50000]
**Valid**: G Loss: 88.6954, D Loss: 1.0458
Epoch[18270/50000]
**Train**: G Loss: 140.3610, D Loss: 0.4678
Epoch[18270/50000]
**Valid**: G Loss: 181.4208, D Loss: -0.5184
Epoch[18280/50000]
**Train**: G Loss: 201.4160, D Loss: 0.4493
Epoch[18280/50000]
**Valid**: G Loss: 167.9703, D Loss: 1.5104
Epoch[18290/50000]
**Train**: G Loss: 105.2220, D Loss: -0.3284
Epoch[18290/50000]
**Valid**: G Loss: 70.4534, D Loss: -0.6327
Epoch[18300/50000]
**Train**: G Loss: 77.5691, D Loss: 0.7673
Epoch[18300/50000]
**Valid**: G Loss: 101.8715, D Loss: 0.9245
Epoch[18310/50000]
**Train**: G Loss: 180.6522, D Loss: -0.3242
Epoch[18310/50000]
**Valid**: G Loss: 186.7628, D Loss: 1.0889
Epoch[18320/50000]
**Train**: G Loss: 139.8910, D Loss: 0.4267
Epoch[18320/50000]
**Valid**: G Loss: 124.5502, D Loss: -0.8090
Epoch[18330/50000]
**Train**: G Loss: 116.8617, D Loss: 0.5039
Epoch[18330/50000]
**Valid**: G Loss: 118.1984, D Loss: 1.1736
Epoch[18340/50000]
**Train**: G Loss: 151.4408, D Loss: -0.0760
Epoch[18340/50000]
**Valid**: G Loss: 169.6735, D Loss: -0.3123
Epoch[18350/50000]
**Train**: G Loss: 170.3350, D Loss: 0.8253
Epoch[18350/50000]
**Valid**: G Loss: 152.2147, D Loss: 1.5252
Epoch[18360/50000]
**Train**: G Loss: 123.3266, D Loss: -0.4464
Epoch[18360/50000]
**Valid**: G Loss: 110.3616, D Loss: -0.0177
Epoch[18370/50000]
**Train**: G Loss: 178.0967, D Loss: -0.2481
Epoch[18370/50000]
**Valid**: G Loss: 185.6640, D Loss: 1.0237
Epoch[18380/50000]
**Train**: G Loss: 117.4224, D Loss: -0.5428
Epoch[18380/50000]
**Valid**: G Loss: 112.2058, D Loss: 0.7271
Epoch[18390/50000]
**Train**: G Loss: 174.1258, D Loss: -0.1279
Epoch[18390/50000]
**Valid**: G Loss: 169.1882, D Loss: 1.2626
Epoch[18400/50000]
**Train**: G Loss: 140.9425, D Loss: -0.0446
Epoch[18400/50000]
**Valid**: G Loss: 134.4522, D Loss: -0.6730
Epoch[18410/50000]
**Train**: G Loss: 119.3327, D Loss: 0.6883
Epoch[18410/50000]
**Valid**: G Loss: 133.7482, D Loss: 0.5193
Epoch[18420/50000]
**Train**: G Loss: 173.8451, D Loss: -0.2912
Epoch[18420/50000]
**Valid**: G Loss: 176.6710, D Loss: 0.8588
Epoch[18430/50000]
**Train**: G Loss: 173.3156, D Loss: 1.0512
Epoch[18430/50000]
**Valid**: G Loss: 153.0126, D Loss: 1.3148
Epoch[18440/50000]
**Train**: G Loss: 147.6745, D Loss: 0.8493
Epoch[18440/50000]
**Valid**: G Loss: 135.0355, D Loss: -0.4617
Epoch[18450/50000]
**Train**: G Loss: 134.3640, D Loss: 0.3215
Epoch[18450/50000]
**Valid**: G Loss: 128.2790, D Loss: 1.0828
Epoch[18460/50000]
**Train**: G Loss: 143.8988, D Loss: 0.7030
Epoch[18460/50000]
**Valid**: G Loss: 155.7835, D Loss: -0.1525
Epoch[18470/50000]
**Train**: G Loss: 170.8868, D Loss: 0.5125
Epoch[18470/50000]
**Valid**: G Loss: 157.3430, D Loss: 1.3219
Epoch[18480/50000]
**Train**: G Loss: 128.8015, D Loss: -0.3737
Epoch[18480/50000]
**Valid**: G Loss: 118.4996, D Loss: 0.1288
Epoch[18490/50000]
**Train**: G Loss: 132.5064, D Loss: 0.9161
Epoch[18490/50000]
**Valid**: G Loss: 152.8345, D Loss: 0.1170
Epoch[18500/50000]
**Train**: G Loss: 215.2073, D Loss: -0.2361
Epoch[18500/50000]
**Valid**: G Loss: 202.3136, D Loss: 1.2388
Epoch[18510/50000]
**Train**: G Loss: 136.8941, D Loss: 0.2986
Epoch[18510/50000]
**Valid**: G Loss: 105.9555, D Loss: -0.8081
Epoch[18520/50000]
**Train**: G Loss: 99.5485, D Loss: 0.5838
Epoch[18520/50000]
**Valid**: G Loss: 116.4554, D Loss: 1.0143
Epoch[18530/50000]
**Train**: G Loss: 211.3015, D Loss: -0.4124
Epoch[18530/50000]
**Valid**: G Loss: 222.8467, D Loss: 0.8051
Epoch[18540/50000]
**Train**: G Loss: 166.2512, D Loss: 1.0045
Epoch[18540/50000]
**Valid**: G Loss: 134.9216, D Loss: -0.0422
Epoch[18550/50000]
**Train**: G Loss: 112.7659, D Loss: -0.4895
Epoch[18550/50000]
**Valid**: G Loss: 95.1149, D Loss: 0.1655
Epoch[18560/50000]
**Train**: G Loss: 128.2755, D Loss: 0.8321
Epoch[18560/50000]
**Valid**: G Loss: 139.5087, D Loss: 0.6105
Epoch[18570/50000]
**Train**: G Loss: 165.1455, D Loss: -0.0008
Epoch[18570/50000]
**Valid**: G Loss: 187.5863, D Loss: -0.0805
Epoch[18580/50000]
**Train**: G Loss: 161.2061, D Loss: 0.5632
Epoch[18580/50000]
**Valid**: G Loss: 150.5447, D Loss: 1.0836
Epoch[18590/50000]
**Train**: G Loss: 140.6486, D Loss: 0.2196
Epoch[18590/50000]
**Valid**: G Loss: 129.4393, D Loss: -0.8540
Epoch[18600/50000]
**Train**: G Loss: 120.1290, D Loss: -0.4125
Epoch[18600/50000]
**Valid**: G Loss: 116.3789, D Loss: 0.6695
Epoch[18610/50000]
**Train**: G Loss: 114.6931, D Loss: 0.5768
Epoch[18610/50000]
**Valid**: G Loss: 120.8122, D Loss: 1.1462
Epoch[18620/50000]
**Train**: G Loss: 161.8941, D Loss: 0.1052
Epoch[18620/50000]
**Valid**: G Loss: 190.2338, D Loss: -0.4257
Epoch[18630/50000]
**Train**: G Loss: 177.5246, D Loss: 0.6834
Epoch[18630/50000]
**Valid**: G Loss: 161.7822, D Loss: 1.3554
Epoch[18640/50000]
**Train**: G Loss: 144.4349, D Loss: 0.0948
Epoch[18640/50000]
**Valid**: G Loss: 131.8087, D Loss: -0.9298
Epoch[18650/50000]
**Train**: G Loss: 123.7698, D Loss: -0.2577
Epoch[18650/50000]
**Valid**: G Loss: 118.7754, D Loss: 1.0052
Epoch[18660/50000]
**Train**: G Loss: 135.3782, D Loss: 0.8490
Epoch[18660/50000]
**Valid**: G Loss: 155.2269, D Loss: 0.1460
Epoch[18670/50000]
**Train**: G Loss: 210.1628, D Loss: 0.0649
Epoch[18670/50000]
**Valid**: G Loss: 187.2048, D Loss: 1.6522
Epoch[18680/50000]
**Train**: G Loss: 141.9161, D Loss: 0.4999
Epoch[18680/50000]
**Valid**: G Loss: 109.3334, D Loss: -0.9301
Epoch[18690/50000]
**Train**: G Loss: 70.2729, D Loss: -0.5742
Epoch[18690/50000]
**Valid**: G Loss: 68.1622, D Loss: 1.1001
Epoch[18700/50000]
**Train**: G Loss: 98.9690, D Loss: 0.5703
Epoch[18700/50000]
**Valid**: G Loss: 107.9781, D Loss: 1.0779
Epoch[18710/50000]
**Train**: G Loss: 121.5863, D Loss: 0.9185
Epoch[18710/50000]
**Valid**: G Loss: 135.6967, D Loss: 0.6953
Epoch[18720/50000]
**Train**: G Loss: 153.5874, D Loss: -0.3607
Epoch[18720/50000]
**Valid**: G Loss: 161.1821, D Loss: 0.0247
Epoch[18730/50000]
**Train**: G Loss: 162.1348, D Loss: 0.6472
Epoch[18730/50000]
**Valid**: G Loss: 151.3176, D Loss: 1.5079
Epoch[18740/50000]
**Train**: G Loss: 146.6827, D Loss: 0.8955
Epoch[18740/50000]
**Valid**: G Loss: 134.5518, D Loss: -0.7267
Epoch[18750/50000]
**Train**: G Loss: 131.5844, D Loss: -0.6154
Epoch[18750/50000]
**Valid**: G Loss: 121.8386, D Loss: 0.2064
Epoch[18760/50000]
**Train**: G Loss: 124.7732, D Loss: -0.6830
Epoch[18760/50000]
**Valid**: G Loss: 118.7529, D Loss: 0.8074
Epoch[18770/50000]
**Train**: G Loss: 115.8977, D Loss: 0.5918
Epoch[18770/50000]
**Valid**: G Loss: 122.9412, D Loss: 1.1827
Epoch[18780/50000]
**Train**: G Loss: 147.5315, D Loss: 0.5595
Epoch[18780/50000]
**Valid**: G Loss: 182.1241, D Loss: -0.4684
Epoch[18790/50000]
**Train**: G Loss: 223.2983, D Loss: -0.1740
Epoch[18790/50000]
**Valid**: G Loss: 208.9266, D Loss: 1.3946
Epoch[18800/50000]
**Train**: G Loss: 135.9893, D Loss: 0.2821
Epoch[18800/50000]
**Valid**: G Loss: 93.0879, D Loss: -0.8323
Epoch[18810/50000]
**Train**: G Loss: 79.7638, D Loss: 0.1940
Epoch[18810/50000]
**Valid**: G Loss: 92.8369, D Loss: 1.1477
Epoch[18820/50000]
**Train**: G Loss: 154.0801, D Loss: 0.3476
Epoch[18820/50000]
**Valid**: G Loss: 197.9674, D Loss: -0.5311
Epoch[18830/50000]
**Train**: G Loss: 204.1192, D Loss: 0.0272
Epoch[18830/50000]
**Valid**: G Loss: 200.1986, D Loss: 1.5175
Epoch[18840/50000]
**Train**: G Loss: 172.7965, D Loss: 1.0781
Epoch[18840/50000]
**Valid**: G Loss: 156.3071, D Loss: 0.6018
Epoch[18850/50000]
**Train**: G Loss: 147.4825, D Loss: 0.2033
Epoch[18850/50000]
**Valid**: G Loss: 137.9753, D Loss: -0.8253
Epoch[18860/50000]
**Train**: G Loss: 135.1564, D Loss: -0.6188
Epoch[18860/50000]
**Valid**: G Loss: 129.5862, D Loss: 0.4177
Epoch[18870/50000]
**Train**: G Loss: 123.3122, D Loss: 0.3332
Epoch[18870/50000]
**Valid**: G Loss: 125.0420, D Loss: 1.0893
Epoch[18880/50000]
**Train**: G Loss: 157.4149, D Loss: 0.0850
Epoch[18880/50000]
**Valid**: G Loss: 173.5156, D Loss: 0.4595
Epoch[18890/50000]
**Train**: G Loss: 122.8940, D Loss: 0.3395
Epoch[18890/50000]
**Valid**: G Loss: 126.0180, D Loss: 0.9123
Epoch[18900/50000]
**Train**: G Loss: 186.5251, D Loss: -0.2482
Epoch[18900/50000]
**Valid**: G Loss: 182.1388, D Loss: 1.2315
Epoch[18910/50000]
**Train**: G Loss: 165.9991, D Loss: 1.0624
Epoch[18910/50000]
**Valid**: G Loss: 150.8446, D Loss: 0.1651
Epoch[18920/50000]
**Train**: G Loss: 138.0570, D Loss: -0.3736
Epoch[18920/50000]
**Valid**: G Loss: 128.1405, D Loss: 0.0257
Epoch[18930/50000]
**Train**: G Loss: 122.2832, D Loss: 0.2449
Epoch[18930/50000]
**Valid**: G Loss: 123.7019, D Loss: 1.0751
Epoch[18940/50000]
**Train**: G Loss: 137.4784, D Loss: 0.9009
Epoch[18940/50000]
**Valid**: G Loss: 150.6761, D Loss: 0.4483
Epoch[18950/50000]
**Train**: G Loss: 160.4802, D Loss: 0.2138
Epoch[18950/50000]
**Valid**: G Loss: 193.0416, D Loss: -0.7254
Epoch[18960/50000]
**Train**: G Loss: 212.0103, D Loss: -0.2830
Epoch[18960/50000]
**Valid**: G Loss: 222.9628, D Loss: 0.7775
Epoch[18970/50000]
**Train**: G Loss: 194.3103, D Loss: 1.0311
Epoch[18970/50000]
**Valid**: G Loss: 164.8017, D Loss: 1.0844
Epoch[18980/50000]
**Train**: G Loss: 133.8809, D Loss: -0.1852
Epoch[18980/50000]
**Valid**: G Loss: 111.0258, D Loss: -0.5362
Epoch[18990/50000]
**Train**: G Loss: 112.8552, D Loss: -0.4340
Epoch[18990/50000]
**Valid**: G Loss: 105.8384, D Loss: 0.7558
Epoch[19000/50000]
**Train**: G Loss: 111.8819, D Loss: 0.6863
Epoch[19000/50000]
**Valid**: G Loss: 118.9565, D Loss: 1.0156
Epoch[19010/50000]
**Train**: G Loss: 127.3601, D Loss: 0.9219
Epoch[19010/50000]
**Valid**: G Loss: 140.7259, D Loss: 0.5707
Epoch[19020/50000]
**Train**: G Loss: 137.0249, D Loss: 0.7199
Epoch[19020/50000]
**Valid**: G Loss: 158.8236, D Loss: -0.1130
Epoch[19030/50000]
**Train**: G Loss: 153.7925, D Loss: 0.0279
Epoch[19030/50000]
**Valid**: G Loss: 169.2400, D Loss: -0.2393
Epoch[19040/50000]
**Train**: G Loss: 170.0115, D Loss: -0.1329
Epoch[19040/50000]
**Valid**: G Loss: 169.2578, D Loss: 0.9529
Epoch[19050/50000]
**Train**: G Loss: 179.0014, D Loss: 1.0175
Epoch[19050/50000]
**Valid**: G Loss: 161.6611, D Loss: 1.3151
Epoch[19060/50000]
**Train**: G Loss: 126.3831, D Loss: 0.1083
Epoch[19060/50000]
**Valid**: G Loss: 99.9325, D Loss: 0.0605
Epoch[19070/50000]
**Train**: G Loss: 152.6148, D Loss: 0.3636
Epoch[19070/50000]
**Valid**: G Loss: 189.6111, D Loss: -0.5067
Epoch[19080/50000]
**Train**: G Loss: 157.5752, D Loss: 1.0640
Epoch[19080/50000]
**Valid**: G Loss: 127.8931, D Loss: -0.5819
Epoch[19090/50000]
**Train**: G Loss: 94.7525, D Loss: -0.1897
Epoch[19090/50000]
**Valid**: G Loss: 98.5063, D Loss: 1.2363
Epoch[19100/50000]
**Train**: G Loss: 124.0809, D Loss: 0.8422
Epoch[19100/50000]
**Valid**: G Loss: 150.1846, D Loss: 0.2081
Epoch[19110/50000]
**Train**: G Loss: 205.8523, D Loss: -0.4692
Epoch[19110/50000]
**Valid**: G Loss: 226.8098, D Loss: 0.7987
Epoch[19120/50000]
**Train**: G Loss: 190.0759, D Loss: 0.6942
Epoch[19120/50000]
**Valid**: G Loss: 169.7537, D Loss: 1.6648
Epoch[19130/50000]
**Train**: G Loss: 151.7058, D Loss: 1.0120
Epoch[19130/50000]
**Valid**: G Loss: 128.5603, D Loss: -0.4291
Epoch[19140/50000]
**Train**: G Loss: 124.3348, D Loss: -0.5268
Epoch[19140/50000]
**Valid**: G Loss: 106.4900, D Loss: -0.5353
Epoch[19150/50000]
**Train**: G Loss: 122.3941, D Loss: -0.5798
Epoch[19150/50000]
**Valid**: G Loss: 118.0093, D Loss: 0.9686
Epoch[19160/50000]
**Train**: G Loss: 133.9268, D Loss: 0.7123
Epoch[19160/50000]
**Valid**: G Loss: 136.4352, D Loss: 0.8564
Epoch[19170/50000]
**Train**: G Loss: 170.0689, D Loss: 0.1912
Epoch[19170/50000]
**Valid**: G Loss: 207.6101, D Loss: -0.3435
Epoch[19180/50000]
**Train**: G Loss: 188.3966, D Loss: 0.7189
Epoch[19180/50000]
**Valid**: G Loss: 166.0876, D Loss: 1.6223
Epoch[19190/50000]
**Train**: G Loss: 138.9531, D Loss: 0.3933
Epoch[19190/50000]
**Valid**: G Loss: 111.9360, D Loss: -1.0209
Epoch[19200/50000]
**Train**: G Loss: 116.0843, D Loss: 0.6294
Epoch[19200/50000]
**Valid**: G Loss: 124.7131, D Loss: 1.2021
Epoch[19210/50000]
**Train**: G Loss: 178.6045, D Loss: -0.3528
Epoch[19210/50000]
**Valid**: G Loss: 185.4662, D Loss: 0.7590
Epoch[19220/50000]
**Train**: G Loss: 155.6744, D Loss: 0.9970
Epoch[19220/50000]
**Valid**: G Loss: 138.4282, D Loss: -0.1835
Epoch[19230/50000]
**Train**: G Loss: 112.0743, D Loss: -0.6138
Epoch[19230/50000]
**Valid**: G Loss: 109.7235, D Loss: 1.0652
Epoch[19240/50000]
**Train**: G Loss: 131.6833, D Loss: 0.7654
Epoch[19240/50000]
**Valid**: G Loss: 154.6809, D Loss: -0.0720
Epoch[19250/50000]
**Train**: G Loss: 191.3849, D Loss: -0.3551
Epoch[19250/50000]
**Valid**: G Loss: 203.6398, D Loss: 0.7633
Epoch[19260/50000]
**Train**: G Loss: 196.7956, D Loss: 0.6623
Epoch[19260/50000]
**Valid**: G Loss: 179.4284, D Loss: 1.5859
Epoch[19270/50000]
**Train**: G Loss: 178.0627, D Loss: 1.3127
Epoch[19270/50000]
**Valid**: G Loss: 156.4206, D Loss: 1.0802
Epoch[19280/50000]
**Train**: G Loss: 183.5480, D Loss: 1.1625
Epoch[19280/50000]
**Valid**: G Loss: 158.0776, D Loss: 0.9286
Epoch[19290/50000]
**Train**: G Loss: 165.7997, D Loss: 1.1604
Epoch[19290/50000]
**Valid**: G Loss: 139.2924, D Loss: 0.3709
Epoch[19300/50000]
**Train**: G Loss: 126.9350, D Loss: 0.4528
Epoch[19300/50000]
**Valid**: G Loss: 89.0944, D Loss: -1.0977
Epoch[19310/50000]
**Train**: G Loss: 113.9492, D Loss: -0.4977
Epoch[19310/50000]
**Valid**: G Loss: 95.1244, D Loss: -0.1297
Epoch[19320/50000]
**Train**: G Loss: 121.4364, D Loss: -0.1945
Epoch[19320/50000]
**Valid**: G Loss: 113.6108, D Loss: 0.9799
Epoch[19330/50000]
**Train**: G Loss: 130.8000, D Loss: 0.6779
Epoch[19330/50000]
**Valid**: G Loss: 139.6226, D Loss: 0.1154
Epoch[19340/50000]
**Train**: G Loss: 168.4332, D Loss: 0.2530
Epoch[19340/50000]
**Valid**: G Loss: 158.6569, D Loss: 1.4110
Epoch[19350/50000]
**Train**: G Loss: 164.2055, D Loss: 1.0503
Epoch[19350/50000]
**Valid**: G Loss: 152.0406, D Loss: 1.0034
Epoch[19360/50000]
**Train**: G Loss: 153.1728, D Loss: 0.6331
Epoch[19360/50000]
**Valid**: G Loss: 139.7462, D Loss: -0.6457
Epoch[19370/50000]
**Train**: G Loss: 141.2548, D Loss: -0.3661
Epoch[19370/50000]
**Valid**: G Loss: 129.9113, D Loss: -0.2534
Epoch[19380/50000]
**Train**: G Loss: 129.2691, D Loss: -0.2022
Epoch[19380/50000]
**Valid**: G Loss: 127.1188, D Loss: 1.1753
Epoch[19390/50000]
**Train**: G Loss: 124.7502, D Loss: 0.7628
Epoch[19390/50000]
**Valid**: G Loss: 134.9562, D Loss: 0.8911
Epoch[19400/50000]
**Train**: G Loss: 141.4535, D Loss: 0.6848
Epoch[19400/50000]
**Valid**: G Loss: 161.8291, D Loss: -0.3022
Epoch[19410/50000]
**Train**: G Loss: 166.9294, D Loss: -0.0601
Epoch[19410/50000]
**Valid**: G Loss: 188.1257, D Loss: -0.3120
Epoch[19420/50000]
**Train**: G Loss: 184.2804, D Loss: -0.2610
Epoch[19420/50000]
**Valid**: G Loss: 184.1151, D Loss: 0.9504
Epoch[19430/50000]
**Train**: G Loss: 163.9058, D Loss: 1.2256
Epoch[19430/50000]
**Valid**: G Loss: 150.4663, D Loss: 0.9123
Epoch[19440/50000]
**Train**: G Loss: 145.2818, D Loss: 0.2907
Epoch[19440/50000]
**Valid**: G Loss: 132.0395, D Loss: -0.9722
Epoch[19450/50000]
**Train**: G Loss: 119.3163, D Loss: -0.6065
Epoch[19450/50000]
**Valid**: G Loss: 110.7122, D Loss: 0.8172
Epoch[19460/50000]
**Train**: G Loss: 83.8074, D Loss: 0.5190
Epoch[19460/50000]
**Valid**: G Loss: 99.7524, D Loss: 1.3728
Epoch[19470/50000]
**Train**: G Loss: 118.0691, D Loss: 0.7895
Epoch[19470/50000]
**Valid**: G Loss: 147.2236, D Loss: 0.3305
Epoch[19480/50000]
**Train**: G Loss: 132.8440, D Loss: 0.7850
Epoch[19480/50000]
**Valid**: G Loss: 155.7306, D Loss: -0.0284
Epoch[19490/50000]
**Train**: G Loss: 149.0499, D Loss: 0.1485
Epoch[19490/50000]
**Valid**: G Loss: 162.9077, D Loss: -0.6771
Epoch[19500/50000]
**Train**: G Loss: 168.3662, D Loss: -0.3553
Epoch[19500/50000]
**Valid**: G Loss: 172.7345, D Loss: 0.3593
Epoch[19510/50000]
**Train**: G Loss: 169.6626, D Loss: 1.0058
Epoch[19510/50000]
**Valid**: G Loss: 154.6315, D Loss: 0.9254
Epoch[19520/50000]
**Train**: G Loss: 157.7967, D Loss: 0.8277
Epoch[19520/50000]
**Valid**: G Loss: 148.7860, D Loss: -0.2041
Epoch[19530/50000]
**Train**: G Loss: 147.0213, D Loss: 0.2419
Epoch[19530/50000]
**Valid**: G Loss: 137.2882, D Loss: -0.5962
Epoch[19540/50000]
**Train**: G Loss: 131.5514, D Loss: -0.7227
Epoch[19540/50000]
**Valid**: G Loss: 121.5947, D Loss: 0.2159
Epoch[19550/50000]
**Train**: G Loss: 127.9227, D Loss: 0.5519
Epoch[19550/50000]
**Valid**: G Loss: 128.2712, D Loss: 1.1523
Epoch[19560/50000]
**Train**: G Loss: 145.3438, D Loss: 0.6705
Epoch[19560/50000]
**Valid**: G Loss: 165.9303, D Loss: -0.1831
Epoch[19570/50000]
**Train**: G Loss: 158.5505, D Loss: 0.0431
Epoch[19570/50000]
**Valid**: G Loss: 177.6442, D Loss: -0.1751
Epoch[19580/50000]
**Train**: G Loss: 177.7198, D Loss: -0.3070
Epoch[19580/50000]
**Valid**: G Loss: 183.7086, D Loss: 0.6577
Epoch[19590/50000]
**Train**: G Loss: 190.9448, D Loss: 0.6426
Epoch[19590/50000]
**Valid**: G Loss: 173.8927, D Loss: 1.5204
Epoch[19600/50000]
**Train**: G Loss: 158.7491, D Loss: 1.0865
Epoch[19600/50000]
**Valid**: G Loss: 150.0246, D Loss: 0.3273
Epoch[19610/50000]
**Train**: G Loss: 141.5401, D Loss: -0.0096
Epoch[19610/50000]
**Valid**: G Loss: 125.5287, D Loss: -0.7449
Epoch[19620/50000]
**Train**: G Loss: 124.3671, D Loss: -0.3658
Epoch[19620/50000]
**Valid**: G Loss: 116.4529, D Loss: 0.6799
Epoch[19630/50000]
**Train**: G Loss: 135.3422, D Loss: 0.3729
Epoch[19630/50000]
**Valid**: G Loss: 131.2207, D Loss: 0.9112
Epoch[19640/50000]
**Train**: G Loss: 147.4642, D Loss: 0.7966
Epoch[19640/50000]
**Valid**: G Loss: 162.5362, D Loss: -0.0256
Epoch[19650/50000]
**Train**: G Loss: 173.2217, D Loss: 0.0188
Epoch[19650/50000]
**Valid**: G Loss: 205.7420, D Loss: -0.3296
Epoch[19660/50000]
**Train**: G Loss: 192.6200, D Loss: -0.1134
Epoch[19660/50000]
**Valid**: G Loss: 189.3698, D Loss: 1.0052
Epoch[19670/50000]
**Train**: G Loss: 168.5523, D Loss: 1.1621
Epoch[19670/50000]
**Valid**: G Loss: 155.7134, D Loss: 1.2634
Epoch[19680/50000]
**Train**: G Loss: 151.6769, D Loss: 0.5502
Epoch[19680/50000]
**Valid**: G Loss: 124.3417, D Loss: -0.6102
Epoch[19690/50000]
**Train**: G Loss: 120.3192, D Loss: -0.5049
Epoch[19690/50000]
**Valid**: G Loss: 105.2811, D Loss: 0.2199
Epoch[19700/50000]
**Train**: G Loss: 128.8110, D Loss: 0.5328
Epoch[19700/50000]
**Valid**: G Loss: 133.6935, D Loss: 1.0822
Epoch[19710/50000]
**Train**: G Loss: 150.3060, D Loss: 0.6883
Epoch[19710/50000]
**Valid**: G Loss: 171.0855, D Loss: -0.2697
Epoch[19720/50000]
**Train**: G Loss: 200.8106, D Loss: -0.2945
Epoch[19720/50000]
**Valid**: G Loss: 219.2384, D Loss: 0.7246
Epoch[19730/50000]
**Train**: G Loss: 107.4228, D Loss: -0.5385
Epoch[19730/50000]
**Valid**: G Loss: 82.5017, D Loss: 0.0416
Epoch[19740/50000]
**Train**: G Loss: 113.3231, D Loss: 0.8922
Epoch[19740/50000]
**Valid**: G Loss: 132.1832, D Loss: 0.6840
Epoch[19750/50000]
**Train**: G Loss: 185.7678, D Loss: -0.3406
Epoch[19750/50000]
**Valid**: G Loss: 205.3614, D Loss: 0.2966
Epoch[19760/50000]
**Train**: G Loss: 161.8125, D Loss: 1.0984
Epoch[19760/50000]
**Valid**: G Loss: 146.8832, D Loss: -0.2080
Epoch[19770/50000]
**Train**: G Loss: 122.3454, D Loss: -0.4306
Epoch[19770/50000]
**Valid**: G Loss: 116.4363, D Loss: 0.8293
Epoch[19780/50000]
**Train**: G Loss: 133.8481, D Loss: 0.8740
Epoch[19780/50000]
**Valid**: G Loss: 145.2639, D Loss: 0.1853
Epoch[19790/50000]
**Train**: G Loss: 178.8123, D Loss: -0.1672
Epoch[19790/50000]
**Valid**: G Loss: 196.1808, D Loss: 0.3969
Epoch[19800/50000]
**Train**: G Loss: 191.8320, D Loss: 0.0413
Epoch[19800/50000]
**Valid**: G Loss: 187.9384, D Loss: 1.5312
Epoch[19810/50000]
**Train**: G Loss: 181.1033, D Loss: 1.0967
Epoch[19810/50000]
**Valid**: G Loss: 154.2185, D Loss: 0.8236
Epoch[19820/50000]
**Train**: G Loss: 133.5190, D Loss: 0.0366
Epoch[19820/50000]
**Valid**: G Loss: 102.1700, D Loss: -0.9891
Epoch[19830/50000]
**Train**: G Loss: 103.4353, D Loss: -0.5752
Epoch[19830/50000]
**Valid**: G Loss: 85.8028, D Loss: 0.1423
Epoch[19840/50000]
**Train**: G Loss: 96.8463, D Loss: -0.5875
Epoch[19840/50000]
**Valid**: G Loss: 89.9680, D Loss: 0.7212
Epoch[19850/50000]
**Train**: G Loss: 99.1829, D Loss: 0.4527
Epoch[19850/50000]
**Valid**: G Loss: 105.7528, D Loss: 1.2289
Epoch[19860/50000]
**Train**: G Loss: 105.1478, D Loss: 0.9295
Epoch[19860/50000]
**Valid**: G Loss: 130.7961, D Loss: 0.6171
Epoch[19870/50000]
**Train**: G Loss: 148.1056, D Loss: 0.3968
Epoch[19870/50000]
**Valid**: G Loss: 178.9463, D Loss: -0.4495
Epoch[19880/50000]
**Train**: G Loss: 177.1167, D Loss: -0.2111
Epoch[19880/50000]
**Valid**: G Loss: 202.6619, D Loss: 0.0302
Epoch[19890/50000]
**Train**: G Loss: 184.8560, D Loss: -0.1500
Epoch[19890/50000]
**Valid**: G Loss: 177.4775, D Loss: 1.3065
Epoch[19900/50000]
**Train**: G Loss: 151.8259, D Loss: 1.1229
Epoch[19900/50000]
**Valid**: G Loss: 144.7925, D Loss: 0.9207
Epoch[19910/50000]
**Train**: G Loss: 142.5221, D Loss: 0.5664
Epoch[19910/50000]
**Valid**: G Loss: 139.1620, D Loss: -0.9293
Epoch[19920/50000]
**Train**: G Loss: 129.2826, D Loss: -0.5397
Epoch[19920/50000]
**Valid**: G Loss: 123.8488, D Loss: 0.7057
Epoch[19930/50000]
**Train**: G Loss: 122.3129, D Loss: 0.6482
Epoch[19930/50000]
**Valid**: G Loss: 125.5268, D Loss: 1.0878
Epoch[19940/50000]
**Train**: G Loss: 127.8205, D Loss: 0.8416
Epoch[19940/50000]
**Valid**: G Loss: 146.7686, D Loss: 0.3199
Epoch[19950/50000]
**Train**: G Loss: 157.5759, D Loss: 0.2943
Epoch[19950/50000]
**Valid**: G Loss: 183.3207, D Loss: -0.3208
Epoch[19960/50000]
**Train**: G Loss: 177.4462, D Loss: -0.4222
Epoch[19960/50000]
**Valid**: G Loss: 190.5385, D Loss: 0.3600
Epoch[19970/50000]
**Train**: G Loss: 182.9253, D Loss: 0.0597
Epoch[19970/50000]
**Valid**: G Loss: 177.7758, D Loss: 1.4062
Epoch[19980/50000]
**Train**: G Loss: 172.0971, D Loss: 0.9787
Epoch[19980/50000]
**Valid**: G Loss: 159.7273, D Loss: 1.2405
Epoch[19990/50000]
**Train**: G Loss: 159.4158, D Loss: 1.1142
Epoch[19990/50000]
**Valid**: G Loss: 150.2599, D Loss: 0.5248
Epoch[20000/50000]
**Train**: G Loss: 145.6181, D Loss: -0.3580
Epoch[20000/50000]
**Valid**: G Loss: 134.6956, D Loss: 0.4548
Epoch[20010/50000]
**Train**: G Loss: 131.9049, D Loss: 0.4502
Epoch[20010/50000]
**Valid**: G Loss: 137.0302, D Loss: 1.1287
Epoch[20020/50000]
**Train**: G Loss: 136.8740, D Loss: 0.9028
Epoch[20020/50000]
**Valid**: G Loss: 147.8702, D Loss: 0.6420
Epoch[20030/50000]
**Train**: G Loss: 150.1036, D Loss: 0.5353
Epoch[20030/50000]
**Valid**: G Loss: 172.1330, D Loss: -0.3013
Epoch[20040/50000]
**Train**: G Loss: 188.5079, D Loss: -0.1738
Epoch[20040/50000]
**Valid**: G Loss: 200.6445, D Loss: 0.7170
Epoch[20050/50000]
**Train**: G Loss: 190.6219, D Loss: 0.7884
Epoch[20050/50000]
**Valid**: G Loss: 172.4475, D Loss: 1.2029
Epoch[20060/50000]
**Train**: G Loss: 154.4010, D Loss: 0.9338
Epoch[20060/50000]
**Valid**: G Loss: 129.6334, D Loss: -0.4232
Epoch[20070/50000]
**Train**: G Loss: 107.9242, D Loss: -0.4167
Epoch[20070/50000]
**Valid**: G Loss: 86.2814, D Loss: -0.0637
Epoch[20080/50000]
**Train**: G Loss: 122.3017, D Loss: 0.7300
Epoch[20080/50000]
**Valid**: G Loss: 140.4530, D Loss: 0.2785
Epoch[20090/50000]
**Train**: G Loss: 188.4357, D Loss: -0.3552
Epoch[20090/50000]
**Valid**: G Loss: 215.0305, D Loss: 0.2196
Epoch[20100/50000]
**Train**: G Loss: 175.3042, D Loss: 0.8259
Epoch[20100/50000]
**Valid**: G Loss: 160.3189, D Loss: 1.5573
Epoch[20110/50000]
**Train**: G Loss: 148.1892, D Loss: 0.4156
Epoch[20110/50000]
**Valid**: G Loss: 134.4264, D Loss: -0.8743
Epoch[20120/50000]
**Train**: G Loss: 125.5399, D Loss: -0.5841
Epoch[20120/50000]
**Valid**: G Loss: 108.2932, D Loss: -0.1150
Epoch[20130/50000]
**Train**: G Loss: 123.4094, D Loss: -0.5070
Epoch[20130/50000]
**Valid**: G Loss: 114.5607, D Loss: 0.5335
Epoch[20140/50000]
**Train**: G Loss: 112.0885, D Loss: -0.2342
Epoch[20140/50000]
**Valid**: G Loss: 110.4690, D Loss: 0.8457
Epoch[20150/50000]
**Train**: G Loss: 130.0154, D Loss: 0.4627
Epoch[20150/50000]
**Valid**: G Loss: 131.1999, D Loss: 1.0404
Epoch[20160/50000]
**Train**: G Loss: 164.1434, D Loss: -0.0145
Epoch[20160/50000]
**Valid**: G Loss: 165.9395, D Loss: 0.5357
Epoch[20170/50000]
**Train**: G Loss: 165.4102, D Loss: 1.0025
Epoch[20170/50000]
**Valid**: G Loss: 155.8659, D Loss: -0.0130
Epoch[20180/50000]
**Train**: G Loss: 147.8596, D Loss: -0.1022
Epoch[20180/50000]
**Valid**: G Loss: 134.4703, D Loss: -0.1156
Epoch[20190/50000]
**Train**: G Loss: 130.3941, D Loss: -0.4062
Epoch[20190/50000]
**Valid**: G Loss: 125.4857, D Loss: 0.6792
Epoch[20200/50000]
**Train**: G Loss: 136.4631, D Loss: 0.5650
Epoch[20200/50000]
**Valid**: G Loss: 141.7164, D Loss: 0.8129
Epoch[20210/50000]
**Train**: G Loss: 163.1806, D Loss: 0.4682
Epoch[20210/50000]
**Valid**: G Loss: 183.5652, D Loss: -0.0975
Epoch[20220/50000]
**Train**: G Loss: 208.3761, D Loss: -0.0302
Epoch[20220/50000]
**Valid**: G Loss: 202.8796, D Loss: 1.3965
Epoch[20230/50000]
**Train**: G Loss: 180.7540, D Loss: 1.1298
Epoch[20230/50000]
**Valid**: G Loss: 150.1599, D Loss: -0.0278
Epoch[20240/50000]
**Train**: G Loss: 118.8549, D Loss: -0.3972
Epoch[20240/50000]
**Valid**: G Loss: 110.7359, D Loss: 0.6648
Epoch[20250/50000]
**Train**: G Loss: 136.5264, D Loss: 0.4629
Epoch[20250/50000]
**Valid**: G Loss: 136.0374, D Loss: 1.2910
Epoch[20260/50000]
**Train**: G Loss: 147.5257, D Loss: 0.9382
Epoch[20260/50000]
**Valid**: G Loss: 154.7805, D Loss: 0.6132
Epoch[20270/50000]
**Train**: G Loss: 159.6504, D Loss: 0.3482
Epoch[20270/50000]
**Valid**: G Loss: 180.6714, D Loss: -0.2941
Epoch[20280/50000]
**Train**: G Loss: 205.9581, D Loss: -0.1797
Epoch[20280/50000]
**Valid**: G Loss: 211.0098, D Loss: 1.1684
Epoch[20290/50000]
**Train**: G Loss: 197.2271, D Loss: 0.8153
Epoch[20290/50000]
**Valid**: G Loss: 176.3425, D Loss: 1.2456
Epoch[20300/50000]
**Train**: G Loss: 167.1377, D Loss: 0.8523
Epoch[20300/50000]
**Valid**: G Loss: 159.7777, D Loss: -0.1187
Epoch[20310/50000]
**Train**: G Loss: 149.2968, D Loss: -0.1746
Epoch[20310/50000]
**Valid**: G Loss: 140.2119, D Loss: 0.1442
Epoch[20320/50000]
**Train**: G Loss: 129.6698, D Loss: 0.3278
Epoch[20320/50000]
**Valid**: G Loss: 136.2131, D Loss: 0.8393
Epoch[20330/50000]
**Train**: G Loss: 159.3645, D Loss: 0.5572
Epoch[20330/50000]
**Valid**: G Loss: 186.4467, D Loss: -0.1311
Epoch[20340/50000]
**Train**: G Loss: 207.1989, D Loss: 0.0840
Epoch[20340/50000]
**Valid**: G Loss: 207.3516, D Loss: 1.1194
Epoch[20350/50000]
**Train**: G Loss: 178.0551, D Loss: 0.9102
Epoch[20350/50000]
**Valid**: G Loss: 165.3481, D Loss: 0.1292
Epoch[20360/50000]
**Train**: G Loss: 124.3512, D Loss: -0.4460
Epoch[20360/50000]
**Valid**: G Loss: 113.2747, D Loss: 0.5501
Epoch[20370/50000]
**Train**: G Loss: 128.4639, D Loss: 0.9851
Epoch[20370/50000]
**Valid**: G Loss: 137.8399, D Loss: 1.0599
Epoch[20380/50000]
**Train**: G Loss: 156.8366, D Loss: 0.4537
Epoch[20380/50000]
**Valid**: G Loss: 164.6477, D Loss: -0.1228
Epoch[20390/50000]
**Train**: G Loss: 181.1401, D Loss: 0.3953
Epoch[20390/50000]
**Valid**: G Loss: 174.9025, D Loss: 1.1802
Epoch[20400/50000]
**Train**: G Loss: 165.5858, D Loss: 0.6201
Epoch[20400/50000]
**Valid**: G Loss: 153.2176, D Loss: -0.7297
Epoch[20410/50000]
**Train**: G Loss: 145.7003, D Loss: -0.2025
Epoch[20410/50000]
**Valid**: G Loss: 139.6239, D Loss: 0.7846
Epoch[20420/50000]
**Train**: G Loss: 146.6485, D Loss: 0.8435
Epoch[20420/50000]
**Valid**: G Loss: 155.0008, D Loss: 0.5028
Epoch[20430/50000]
**Train**: G Loss: 188.5522, D Loss: 0.0446
Epoch[20430/50000]
**Valid**: G Loss: 207.0016, D Loss: 0.4170
Epoch[20440/50000]
**Train**: G Loss: 194.8529, D Loss: 1.0103
Epoch[20440/50000]
**Valid**: G Loss: 173.1119, D Loss: 0.6775
Epoch[20450/50000]
**Train**: G Loss: 149.2878, D Loss: -0.1754
Epoch[20450/50000]
**Valid**: G Loss: 134.0821, D Loss: -0.4377
Epoch[20460/50000]
**Train**: G Loss: 133.2392, D Loss: -0.1049
Epoch[20460/50000]
**Valid**: G Loss: 130.4151, D Loss: 0.9308
Epoch[20470/50000]
**Train**: G Loss: 144.6020, D Loss: 0.6558
Epoch[20470/50000]
**Valid**: G Loss: 169.7456, D Loss: 0.0769
Epoch[20480/50000]
**Train**: G Loss: 208.6790, D Loss: 0.4793
Epoch[20480/50000]
**Valid**: G Loss: 193.5497, D Loss: 1.2104
Epoch[20490/50000]
**Train**: G Loss: 161.8963, D Loss: 0.0554
Epoch[20490/50000]
**Valid**: G Loss: 150.8831, D Loss: -0.6245
Epoch[20500/50000]
**Train**: G Loss: 150.3972, D Loss: -0.0497
Epoch[20500/50000]
**Valid**: G Loss: 146.5962, D Loss: 1.0106
Epoch[20510/50000]
**Train**: G Loss: 148.2262, D Loss: 0.9479
Epoch[20510/50000]
**Valid**: G Loss: 157.6177, D Loss: 0.6054
Epoch[20520/50000]
**Train**: G Loss: 185.0285, D Loss: -0.0209
Epoch[20520/50000]
**Valid**: G Loss: 206.8112, D Loss: -0.1574
Epoch[20530/50000]
**Train**: G Loss: 190.8991, D Loss: 0.5451
Epoch[20530/50000]
**Valid**: G Loss: 180.7784, D Loss: 1.1151
Epoch[20540/50000]
**Train**: G Loss: 159.5456, D Loss: -0.1108
Epoch[20540/50000]
**Valid**: G Loss: 149.7026, D Loss: -0.4089
Epoch[20550/50000]
**Train**: G Loss: 144.0919, D Loss: 0.5700
Epoch[20550/50000]
**Valid**: G Loss: 148.0417, D Loss: 0.9744
Epoch[20560/50000]
**Train**: G Loss: 181.2299, D Loss: 0.0003
Epoch[20560/50000]
**Valid**: G Loss: 197.6383, D Loss: -0.1363
Epoch[20570/50000]
**Train**: G Loss: 197.7928, D Loss: 0.7622
Epoch[20570/50000]
**Valid**: G Loss: 183.5268, D Loss: 1.0622
Epoch[20580/50000]
**Train**: G Loss: 158.0635, D Loss: 0.2404
Epoch[20580/50000]
**Valid**: G Loss: 140.5466, D Loss: -0.1340
Epoch[20590/50000]
**Train**: G Loss: 125.8424, D Loss: 0.5214
Epoch[20590/50000]
**Valid**: G Loss: 139.4892, D Loss: 0.9576
Epoch[20600/50000]
**Train**: G Loss: 210.0191, D Loss: -0.1598
Epoch[20600/50000]
**Valid**: G Loss: 237.1644, D Loss: 0.4104
Epoch[20610/50000]
**Train**: G Loss: 183.2000, D Loss: 1.0642
Epoch[20610/50000]
**Valid**: G Loss: 169.3726, D Loss: 0.2110
Epoch[20620/50000]
**Train**: G Loss: 154.8331, D Loss: -0.2094
Epoch[20620/50000]
**Valid**: G Loss: 147.8934, D Loss: 0.6726
Epoch[20630/50000]
**Train**: G Loss: 153.1585, D Loss: 0.7808
Epoch[20630/50000]
**Valid**: G Loss: 165.8398, D Loss: 0.3306
Epoch[20640/50000]
**Train**: G Loss: 192.5525, D Loss: -0.1527
Epoch[20640/50000]
**Valid**: G Loss: 213.2795, D Loss: 0.2876
Epoch[20650/50000]
**Train**: G Loss: 194.8281, D Loss: 0.7876
Epoch[20650/50000]
**Valid**: G Loss: 185.2328, D Loss: 0.7459
Epoch[20660/50000]
**Train**: G Loss: 165.6111, D Loss: 0.0183
Epoch[20660/50000]
**Valid**: G Loss: 160.1550, D Loss: -0.0311
Epoch[20670/50000]
**Train**: G Loss: 154.9211, D Loss: 0.6375
Epoch[20670/50000]
**Valid**: G Loss: 164.6834, D Loss: 0.5103
Epoch[20680/50000]
**Train**: G Loss: 200.2325, D Loss: -0.0240
Epoch[20680/50000]
**Valid**: G Loss: 207.3058, D Loss: 0.7762
Epoch[20690/50000]
**Train**: G Loss: 186.9313, D Loss: 0.6829
Epoch[20690/50000]
**Valid**: G Loss: 171.5435, D Loss: 0.0198
Epoch[20700/50000]
**Train**: G Loss: 152.4916, D Loss: -0.1338
Epoch[20700/50000]
**Valid**: G Loss: 148.7202, D Loss: 0.8640
Epoch[20710/50000]
**Train**: G Loss: 158.2890, D Loss: 0.6667
Epoch[20710/50000]
**Valid**: G Loss: 175.0456, D Loss: 0.3753
Epoch[20720/50000]
**Train**: G Loss: 219.3131, D Loss: 0.1858
Epoch[20720/50000]
**Valid**: G Loss: 216.1598, D Loss: 1.3343
Epoch[20730/50000]
**Train**: G Loss: 174.7826, D Loss: 0.4320
Epoch[20730/50000]
**Valid**: G Loss: 157.3592, D Loss: -0.5013
Epoch[20740/50000]
**Train**: G Loss: 134.9410, D Loss: 0.2921
Epoch[20740/50000]
**Valid**: G Loss: 138.3390, D Loss: 1.0883
Epoch[20750/50000]
**Train**: G Loss: 163.8562, D Loss: 0.2878
Epoch[20750/50000]
**Valid**: G Loss: 186.3426, D Loss: -0.3208
Epoch[20760/50000]
**Train**: G Loss: 210.8508, D Loss: 0.3859
Epoch[20760/50000]
**Valid**: G Loss: 203.8876, D Loss: 1.1981
Epoch[20770/50000]
**Train**: G Loss: 180.9787, D Loss: 0.5861
Epoch[20770/50000]
**Valid**: G Loss: 170.8542, D Loss: -0.4222
Epoch[20780/50000]
**Train**: G Loss: 156.3333, D Loss: -0.1626
Epoch[20780/50000]
**Valid**: G Loss: 149.9561, D Loss: 0.9213
Epoch[20790/50000]
**Train**: G Loss: 162.4911, D Loss: 0.7479
Epoch[20790/50000]
**Valid**: G Loss: 178.9834, D Loss: -0.1051
Epoch[20800/50000]
**Train**: G Loss: 200.8331, D Loss: 0.4865
Epoch[20800/50000]
**Valid**: G Loss: 187.5145, D Loss: 1.5082
Epoch[20810/50000]
**Train**: G Loss: 143.3289, D Loss: -0.5921
Epoch[20810/50000]
**Valid**: G Loss: 134.8744, D Loss: 1.0652
Epoch[20820/50000]
**Train**: G Loss: 155.4088, D Loss: 0.7573
Epoch[20820/50000]
**Valid**: G Loss: 165.0134, D Loss: 0.3937
Epoch[20830/50000]
**Train**: G Loss: 203.4584, D Loss: -0.2549
Epoch[20830/50000]
**Valid**: G Loss: 212.5572, D Loss: 0.7051
Epoch[20840/50000]
**Train**: G Loss: 195.4120, D Loss: 1.0594
Epoch[20840/50000]
**Valid**: G Loss: 177.4270, D Loss: 0.9069
Epoch[20850/50000]
**Train**: G Loss: 162.0849, D Loss: -0.0467
Epoch[20850/50000]
**Valid**: G Loss: 147.4022, D Loss: -0.2664
Epoch[20860/50000]
**Train**: G Loss: 150.6055, D Loss: 0.5768
Epoch[20860/50000]
**Valid**: G Loss: 154.4557, D Loss: 0.9899
Epoch[20870/50000]
**Train**: G Loss: 198.1780, D Loss: -0.0681
Epoch[20870/50000]
**Valid**: G Loss: 223.9238, D Loss: 0.6474
Epoch[20880/50000]
**Train**: G Loss: 186.1943, D Loss: 0.7504
Epoch[20880/50000]
**Valid**: G Loss: 167.5117, D Loss: 0.0120
Epoch[20890/50000]
**Train**: G Loss: 151.3966, D Loss: -0.1887
Epoch[20890/50000]
**Valid**: G Loss: 143.3916, D Loss: 0.7322
Epoch[20900/50000]
**Train**: G Loss: 154.6843, D Loss: 0.6925
Epoch[20900/50000]
**Valid**: G Loss: 163.6500, D Loss: 0.4089
Epoch[20910/50000]
**Train**: G Loss: 195.7816, D Loss: -0.0997
Epoch[20910/50000]
**Valid**: G Loss: 208.7135, D Loss: 0.2359
Epoch[20920/50000]
**Train**: G Loss: 196.3107, D Loss: 0.6764
Epoch[20920/50000]
**Valid**: G Loss: 185.6589, D Loss: 1.1227
Epoch[20930/50000]
**Train**: G Loss: 158.8738, D Loss: -0.2100
Epoch[20930/50000]
**Valid**: G Loss: 153.6835, D Loss: 0.7984
Epoch[20940/50000]
**Train**: G Loss: 178.1224, D Loss: 0.2506
Epoch[20940/50000]
**Valid**: G Loss: 193.3083, D Loss: -0.2346
Epoch[20950/50000]
**Train**: G Loss: 198.7793, D Loss: 0.7143
Epoch[20950/50000]
**Valid**: G Loss: 188.5314, D Loss: 1.3463
Epoch[20960/50000]
**Train**: G Loss: 175.1345, D Loss: 0.3034
Epoch[20960/50000]
**Valid**: G Loss: 162.9562, D Loss: -0.5393
Epoch[20970/50000]
**Train**: G Loss: 149.6031, D Loss: -0.0551
Epoch[20970/50000]
**Valid**: G Loss: 147.4175, D Loss: 0.8835
Epoch[20980/50000]
**Train**: G Loss: 165.7102, D Loss: 0.6445
Epoch[20980/50000]
**Valid**: G Loss: 184.4463, D Loss: 0.2246
Epoch[20990/50000]
**Train**: G Loss: 169.2729, D Loss: 0.3062
Epoch[20990/50000]
**Valid**: G Loss: 153.0816, D Loss: -0.5938
Epoch[21000/50000]
**Train**: G Loss: 145.9621, D Loss: 0.6203
Epoch[21000/50000]
**Valid**: G Loss: 153.8476, D Loss: 0.8807
Epoch[21010/50000]
**Train**: G Loss: 189.5869, D Loss: -0.1730
Epoch[21010/50000]
**Valid**: G Loss: 208.8499, D Loss: -0.0686
Epoch[21020/50000]
**Train**: G Loss: 205.6606, D Loss: 0.7197
Epoch[21020/50000]
**Valid**: G Loss: 193.3356, D Loss: 1.2135
Epoch[21030/50000]
**Train**: G Loss: 174.1175, D Loss: 0.1290
Epoch[21030/50000]
**Valid**: G Loss: 159.3465, D Loss: -0.2798
Epoch[21040/50000]
**Train**: G Loss: 156.2432, D Loss: 0.5786
Epoch[21040/50000]
**Valid**: G Loss: 156.6995, D Loss: 0.9190
Epoch[21050/50000]
**Train**: G Loss: 195.6561, D Loss: 0.3089
Epoch[21050/50000]
**Valid**: G Loss: 189.2454, D Loss: 1.5592
Epoch[21060/50000]
**Train**: G Loss: 180.3069, D Loss: 0.3237
Epoch[21060/50000]
**Valid**: G Loss: 169.9805, D Loss: -0.4034
Epoch[21070/50000]
**Train**: G Loss: 151.5670, D Loss: 0.0569
Epoch[21070/50000]
**Valid**: G Loss: 151.8888, D Loss: 1.0185
Epoch[21080/50000]
**Train**: G Loss: 184.7185, D Loss: 0.1601
Epoch[21080/50000]
**Valid**: G Loss: 209.0053, D Loss: -0.1829
Epoch[21090/50000]
**Train**: G Loss: 210.5183, D Loss: 0.5765
Epoch[21090/50000]
**Valid**: G Loss: 195.4067, D Loss: 1.1519
Epoch[21100/50000]
**Train**: G Loss: 173.3463, D Loss: 0.0693
Epoch[21100/50000]
**Valid**: G Loss: 160.4969, D Loss: -0.4377
Epoch[21110/50000]
**Train**: G Loss: 154.6759, D Loss: 0.2779
Epoch[21110/50000]
**Valid**: G Loss: 155.7028, D Loss: 1.0464
Epoch[21120/50000]
**Train**: G Loss: 179.6193, D Loss: 0.3294
Epoch[21120/50000]
**Valid**: G Loss: 203.1715, D Loss: -0.3015
Epoch[21130/50000]
**Train**: G Loss: 211.5265, D Loss: 0.0236
Epoch[21130/50000]
**Valid**: G Loss: 209.3568, D Loss: 1.2539
Epoch[21140/50000]
**Train**: G Loss: 188.8590, D Loss: 0.7884
Epoch[21140/50000]
**Valid**: G Loss: 176.2810, D Loss: -0.0295
Epoch[21150/50000]
**Train**: G Loss: 173.9617, D Loss: -0.2853
Epoch[21150/50000]
**Valid**: G Loss: 167.3676, D Loss: 0.0979
Epoch[21160/50000]
**Train**: G Loss: 161.5743, D Loss: 0.7418
Epoch[21160/50000]
**Valid**: G Loss: 168.6232, D Loss: 0.6292
Epoch[21170/50000]
**Train**: G Loss: 207.5229, D Loss: 0.4485
Epoch[21170/50000]
**Valid**: G Loss: 196.0221, D Loss: 1.3021
Epoch[21180/50000]
**Train**: G Loss: 163.6256, D Loss: -0.1076
Epoch[21180/50000]
**Valid**: G Loss: 149.9205, D Loss: -0.0663
Epoch[21190/50000]
**Train**: G Loss: 170.1588, D Loss: 0.5502
Epoch[21190/50000]
**Valid**: G Loss: 186.6326, D Loss: -0.2812
Epoch[21200/50000]
**Train**: G Loss: 215.4453, D Loss: 0.0542
Epoch[21200/50000]
**Valid**: G Loss: 211.7437, D Loss: 1.2156
Epoch[21210/50000]
**Train**: G Loss: 182.2413, D Loss: 0.4357
Epoch[21210/50000]
**Valid**: G Loss: 172.7109, D Loss: -0.1942
Epoch[21220/50000]
**Train**: G Loss: 157.1329, D Loss: 0.2382
Epoch[21220/50000]
**Valid**: G Loss: 158.8782, D Loss: 0.9012
Epoch[21230/50000]
**Train**: G Loss: 183.0545, D Loss: 0.2285
Epoch[21230/50000]
**Valid**: G Loss: 206.6875, D Loss: -0.2028
Epoch[21240/50000]
**Train**: G Loss: 206.0828, D Loss: 0.7559
Epoch[21240/50000]
**Valid**: G Loss: 191.1037, D Loss: 1.2520
Epoch[21250/50000]
**Train**: G Loss: 159.6367, D Loss: -0.3542
Epoch[21250/50000]
**Valid**: G Loss: 149.6772, D Loss: 0.2682
Epoch[21260/50000]
**Train**: G Loss: 203.9426, D Loss: -0.0668
Epoch[21260/50000]
**Valid**: G Loss: 213.5180, D Loss: 0.8365
Epoch[21270/50000]
**Train**: G Loss: 178.5077, D Loss: 0.4770
Epoch[21270/50000]
**Valid**: G Loss: 163.8464, D Loss: -0.4529
Epoch[21280/50000]
**Train**: G Loss: 150.7159, D Loss: 0.3554
Epoch[21280/50000]
**Valid**: G Loss: 152.0195, D Loss: 1.0370
Epoch[21290/50000]
**Train**: G Loss: 179.9907, D Loss: 0.4134
Epoch[21290/50000]
**Valid**: G Loss: 201.4132, D Loss: -0.3804
Epoch[21300/50000]
**Train**: G Loss: 211.4784, D Loss: 0.3975
Epoch[21300/50000]
**Valid**: G Loss: 201.3333, D Loss: 1.1269
Epoch[21310/50000]
**Train**: G Loss: 168.9177, D Loss: 0.2616
Epoch[21310/50000]
**Valid**: G Loss: 155.0569, D Loss: -0.2012
Epoch[21320/50000]
**Train**: G Loss: 138.6270, D Loss: 0.6324
Epoch[21320/50000]
**Valid**: G Loss: 147.6463, D Loss: 1.0530
Epoch[21330/50000]
**Train**: G Loss: 191.3923, D Loss: 0.0627
Epoch[21330/50000]
**Valid**: G Loss: 218.7535, D Loss: 0.1751
Epoch[21340/50000]
**Train**: G Loss: 202.9314, D Loss: 0.9623
Epoch[21340/50000]
**Valid**: G Loss: 178.6091, D Loss: 0.7491
Epoch[21350/50000]
**Train**: G Loss: 139.8507, D Loss: -0.5142
Epoch[21350/50000]
**Valid**: G Loss: 133.0297, D Loss: 0.5056
Epoch[21360/50000]
**Train**: G Loss: 152.6120, D Loss: 0.8567
Epoch[21360/50000]
**Valid**: G Loss: 167.8147, D Loss: 0.4462
Epoch[21370/50000]
**Train**: G Loss: 201.7907, D Loss: -0.2807
Epoch[21370/50000]
**Valid**: G Loss: 208.3105, D Loss: 0.9120
Epoch[21380/50000]
**Train**: G Loss: 187.3820, D Loss: 0.7822
Epoch[21380/50000]
**Valid**: G Loss: 173.0912, D Loss: -0.2675
Epoch[21390/50000]
**Train**: G Loss: 157.9900, D Loss: -0.2915
Epoch[21390/50000]
**Valid**: G Loss: 152.7379, D Loss: 0.7293
Epoch[21400/50000]
**Train**: G Loss: 166.2656, D Loss: 0.5594
Epoch[21400/50000]
**Valid**: G Loss: 182.0344, D Loss: -0.1379
Epoch[21410/50000]
**Train**: G Loss: 203.6206, D Loss: 0.0762
Epoch[21410/50000]
**Valid**: G Loss: 205.2893, D Loss: 0.9073
Epoch[21420/50000]
**Train**: G Loss: 186.5147, D Loss: 0.6538
Epoch[21420/50000]
**Valid**: G Loss: 175.5281, D Loss: -0.3488
Epoch[21430/50000]
**Train**: G Loss: 173.7274, D Loss: 0.3818
Epoch[21430/50000]
**Valid**: G Loss: 198.4233, D Loss: -0.4490
Epoch[21440/50000]
**Train**: G Loss: 200.0935, D Loss: 0.7834
Epoch[21440/50000]
**Valid**: G Loss: 185.0962, D Loss: 0.7473
Epoch[21450/50000]
**Train**: G Loss: 172.8712, D Loss: -0.0090
Epoch[21450/50000]
**Valid**: G Loss: 163.6333, D Loss: -0.1935
Epoch[21460/50000]
**Train**: G Loss: 160.2476, D Loss: 0.4255
Epoch[21460/50000]
**Valid**: G Loss: 159.6348, D Loss: 0.9405
Epoch[21470/50000]
**Train**: G Loss: 182.0666, D Loss: 0.2636
Epoch[21470/50000]
**Valid**: G Loss: 197.6663, D Loss: 0.0446
Epoch[21480/50000]
**Train**: G Loss: 203.6106, D Loss: 0.5586
Epoch[21480/50000]
**Valid**: G Loss: 194.2858, D Loss: 1.2949
Epoch[21490/50000]
**Train**: G Loss: 166.7732, D Loss: -0.0142
Epoch[21490/50000]
**Valid**: G Loss: 160.4710, D Loss: 0.1499
Epoch[21500/50000]
**Train**: G Loss: 163.1142, D Loss: 0.6806
Epoch[21500/50000]
**Valid**: G Loss: 171.6912, D Loss: 0.4467
Epoch[21510/50000]
**Train**: G Loss: 201.8754, D Loss: -0.1399
Epoch[21510/50000]
**Valid**: G Loss: 218.6522, D Loss: 0.2591
Epoch[21520/50000]
**Train**: G Loss: 196.6411, D Loss: 0.7648
Epoch[21520/50000]
**Valid**: G Loss: 185.8229, D Loss: 0.7477
Epoch[21530/50000]
**Train**: G Loss: 168.8576, D Loss: -0.0766
Epoch[21530/50000]
**Valid**: G Loss: 160.4156, D Loss: 0.2300
Epoch[21540/50000]
**Train**: G Loss: 164.3966, D Loss: 0.9247
Epoch[21540/50000]
**Valid**: G Loss: 171.1056, D Loss: 0.7270
Epoch[21550/50000]
**Train**: G Loss: 202.1351, D Loss: 0.0048
Epoch[21550/50000]
**Valid**: G Loss: 219.7122, D Loss: 0.3194
Epoch[21560/50000]
**Train**: G Loss: 180.0958, D Loss: 0.2548
Epoch[21560/50000]
**Valid**: G Loss: 167.5831, D Loss: -0.3671
Epoch[21570/50000]
**Train**: G Loss: 160.4568, D Loss: 0.7576
Epoch[21570/50000]
**Valid**: G Loss: 167.6518, D Loss: 0.7671
Epoch[21580/50000]
**Train**: G Loss: 210.3487, D Loss: -0.0261
Epoch[21580/50000]
**Valid**: G Loss: 230.8352, D Loss: 0.0396
Epoch[21590/50000]
**Train**: G Loss: 198.2945, D Loss: 0.8828
Epoch[21590/50000]
**Valid**: G Loss: 186.1157, D Loss: 0.0595
Epoch[21600/50000]
**Train**: G Loss: 174.0772, D Loss: -0.1964
Epoch[21600/50000]
**Valid**: G Loss: 168.1699, D Loss: 0.7248
Epoch[21610/50000]
**Train**: G Loss: 179.6999, D Loss: 0.4110
Epoch[21610/50000]
**Valid**: G Loss: 190.2378, D Loss: -0.0148
Epoch[21620/50000]
**Train**: G Loss: 211.6700, D Loss: 0.3403
Epoch[21620/50000]
**Valid**: G Loss: 207.2999, D Loss: 1.4252
Epoch[21630/50000]
**Train**: G Loss: 182.8100, D Loss: 0.3375
Epoch[21630/50000]
**Valid**: G Loss: 172.9332, D Loss: -0.4015
Epoch[21640/50000]
**Train**: G Loss: 162.3178, D Loss: 0.5580
Epoch[21640/50000]
**Valid**: G Loss: 168.0754, D Loss: 0.6542
Epoch[21650/50000]
**Train**: G Loss: 196.0109, D Loss: -0.1248
Epoch[21650/50000]
**Valid**: G Loss: 209.2175, D Loss: 0.5524
Epoch[21660/50000]
**Train**: G Loss: 187.4274, D Loss: 0.5399
Epoch[21660/50000]
**Valid**: G Loss: 182.8709, D Loss: -0.2639
Epoch[21670/50000]
**Train**: G Loss: 165.3572, D Loss: 0.1183
Epoch[21670/50000]
**Valid**: G Loss: 166.4998, D Loss: 1.4754
Epoch[21680/50000]
**Train**: G Loss: 196.4471, D Loss: 0.1483
Epoch[21680/50000]
**Valid**: G Loss: 217.9447, D Loss: -0.1628
Epoch[21690/50000]
**Train**: G Loss: 213.4637, D Loss: 0.8672
Epoch[21690/50000]
**Valid**: G Loss: 192.2331, D Loss: 0.6690
Epoch[21700/50000]
**Train**: G Loss: 154.1606, D Loss: -0.1393
Epoch[21700/50000]
**Valid**: G Loss: 148.6941, D Loss: 0.8085
Epoch[21710/50000]
**Train**: G Loss: 171.9718, D Loss: 0.7654
Epoch[21710/50000]
**Valid**: G Loss: 193.6151, D Loss: 0.1412
Epoch[21720/50000]
**Train**: G Loss: 217.7906, D Loss: -0.0825
Epoch[21720/50000]
**Valid**: G Loss: 219.5205, D Loss: 1.2202
Epoch[21730/50000]
**Train**: G Loss: 203.7248, D Loss: 0.7795
Epoch[21730/50000]
**Valid**: G Loss: 194.5751, D Loss: 0.6122
Epoch[21740/50000]
**Train**: G Loss: 181.4811, D Loss: -0.2967
Epoch[21740/50000]
**Valid**: G Loss: 176.9527, D Loss: 0.3763
Epoch[21750/50000]
**Train**: G Loss: 172.8884, D Loss: 0.5532
Epoch[21750/50000]
**Valid**: G Loss: 182.4166, D Loss: 0.0785
Epoch[21760/50000]
**Train**: G Loss: 208.3045, D Loss: 0.1202
Epoch[21760/50000]
**Valid**: G Loss: 214.0353, D Loss: 0.8844
Epoch[21770/50000]
**Train**: G Loss: 200.3348, D Loss: 0.6895
Epoch[21770/50000]
**Valid**: G Loss: 187.5833, D Loss: -0.0128
Epoch[21780/50000]
**Train**: G Loss: 164.2576, D Loss: 0.3128
Epoch[21780/50000]
**Valid**: G Loss: 164.3427, D Loss: 0.9388
Epoch[21790/50000]
**Train**: G Loss: 193.7031, D Loss: 0.1729
Epoch[21790/50000]
**Valid**: G Loss: 214.3208, D Loss: 0.0736
Epoch[21800/50000]
**Train**: G Loss: 196.6773, D Loss: 0.8494
Epoch[21800/50000]
**Valid**: G Loss: 184.1599, D Loss: 0.1801
Epoch[21810/50000]
**Train**: G Loss: 161.9608, D Loss: 0.0288
Epoch[21810/50000]
**Valid**: G Loss: 159.4301, D Loss: 1.0002
Epoch[21820/50000]
**Train**: G Loss: 204.2809, D Loss: 0.1761
Epoch[21820/50000]
**Valid**: G Loss: 225.0467, D Loss: 0.4345
Epoch[21830/50000]
**Train**: G Loss: 189.6162, D Loss: 0.2363
Epoch[21830/50000]
**Valid**: G Loss: 175.4865, D Loss: -0.3418
Epoch[21840/50000]
**Train**: G Loss: 166.8237, D Loss: 0.4421
Epoch[21840/50000]
**Valid**: G Loss: 171.3302, D Loss: 0.5319
Epoch[21850/50000]
**Train**: G Loss: 200.3652, D Loss: 0.0066
Epoch[21850/50000]
**Valid**: G Loss: 214.0840, D Loss: 0.2817
Epoch[21860/50000]
**Train**: G Loss: 202.5764, D Loss: 0.9563
Epoch[21860/50000]
**Valid**: G Loss: 189.7967, D Loss: 0.4015
Epoch[21870/50000]
**Train**: G Loss: 214.0519, D Loss: -0.1931
Epoch[21870/50000]
**Valid**: G Loss: 229.7995, D Loss: 1.0562
Epoch[21880/50000]
**Train**: G Loss: 163.8587, D Loss: -0.3117
Epoch[21880/50000]
**Valid**: G Loss: 156.4681, D Loss: 0.7016
Epoch[21890/50000]
**Train**: G Loss: 179.5715, D Loss: 0.5637
Epoch[21890/50000]
**Valid**: G Loss: 201.4695, D Loss: -0.3894
Epoch[21900/50000]
**Train**: G Loss: 218.9583, D Loss: 0.6769
Epoch[21900/50000]
**Valid**: G Loss: 201.4451, D Loss: 0.7306
Epoch[21910/50000]
**Train**: G Loss: 168.2798, D Loss: 0.1204
Epoch[21910/50000]
**Valid**: G Loss: 168.5229, D Loss: 0.9718
Epoch[21920/50000]
**Train**: G Loss: 203.5147, D Loss: 0.1067
Epoch[21920/50000]
**Valid**: G Loss: 223.6258, D Loss: -0.0105
Epoch[21930/50000]
**Train**: G Loss: 212.8596, D Loss: 0.6942
Epoch[21930/50000]
**Valid**: G Loss: 198.3959, D Loss: 0.2627
Epoch[21940/50000]
**Train**: G Loss: 174.9827, D Loss: 0.1068
Epoch[21940/50000]
**Valid**: G Loss: 173.1887, D Loss: 0.5582
Epoch[21950/50000]
**Train**: G Loss: 199.3497, D Loss: 0.1998
Epoch[21950/50000]
**Valid**: G Loss: 217.9699, D Loss: 0.0625
Epoch[21960/50000]
**Train**: G Loss: 209.9096, D Loss: 0.8389
Epoch[21960/50000]
**Valid**: G Loss: 198.8209, D Loss: 0.9584
Epoch[21970/50000]
**Train**: G Loss: 176.0592, D Loss: -0.0191
Epoch[21970/50000]
**Valid**: G Loss: 168.9388, D Loss: 0.5331
Epoch[21980/50000]
**Train**: G Loss: 178.5020, D Loss: 0.7039
Epoch[21980/50000]
**Valid**: G Loss: 192.4663, D Loss: 0.1084
Epoch[21990/50000]
**Train**: G Loss: 221.5806, D Loss: 0.4724
Epoch[21990/50000]
**Valid**: G Loss: 209.1602, D Loss: 1.2353
Epoch[22000/50000]
**Train**: G Loss: 182.6326, D Loss: -0.1331
Epoch[22000/50000]
**Valid**: G Loss: 174.0337, D Loss: 0.2121
Epoch[22010/50000]
**Train**: G Loss: 173.1193, D Loss: 0.7182
Epoch[22010/50000]
**Valid**: G Loss: 179.0940, D Loss: 0.6587
Epoch[22020/50000]
**Train**: G Loss: 209.5522, D Loss: 0.5769
Epoch[22020/50000]
**Valid**: G Loss: 198.8281, D Loss: 1.0728
Epoch[22030/50000]
**Train**: G Loss: 176.2863, D Loss: -0.1318
Epoch[22030/50000]
**Valid**: G Loss: 166.2801, D Loss: 0.0119
Epoch[22040/50000]
**Train**: G Loss: 172.8060, D Loss: 0.8666
Epoch[22040/50000]
**Valid**: G Loss: 179.8471, D Loss: 0.3832
Epoch[22050/50000]
**Train**: G Loss: 208.9598, D Loss: 0.1970
Epoch[22050/50000]
**Valid**: G Loss: 209.5501, D Loss: 1.0060
Epoch[22060/50000]
**Train**: G Loss: 184.0335, D Loss: 0.1311
Epoch[22060/50000]
**Valid**: G Loss: 174.5903, D Loss: -0.0708
Epoch[22070/50000]
**Train**: G Loss: 168.8697, D Loss: 0.7508
Epoch[22070/50000]
**Valid**: G Loss: 174.3021, D Loss: 0.5385
Epoch[22080/50000]
**Train**: G Loss: 212.8940, D Loss: 0.0029
Epoch[22080/50000]
**Valid**: G Loss: 223.8876, D Loss: 0.8548
Epoch[22090/50000]
**Train**: G Loss: 187.5337, D Loss: 0.2871
Epoch[22090/50000]
**Valid**: G Loss: 174.9779, D Loss: -0.3131
Epoch[22100/50000]
**Train**: G Loss: 167.1217, D Loss: 0.5528
Epoch[22100/50000]
**Valid**: G Loss: 171.0687, D Loss: 0.6349
Epoch[22110/50000]
**Train**: G Loss: 219.4039, D Loss: -0.3564
Epoch[22110/50000]
**Valid**: G Loss: 219.8475, D Loss: 0.8923
Epoch[22120/50000]
**Train**: G Loss: 177.2274, D Loss: 0.0323
Epoch[22120/50000]
**Valid**: G Loss: 166.2291, D Loss: -0.2664
Epoch[22130/50000]
**Train**: G Loss: 161.1368, D Loss: 0.9001
Epoch[22130/50000]
**Valid**: G Loss: 172.1018, D Loss: 0.5465
Epoch[22140/50000]
**Train**: G Loss: 227.9266, D Loss: 0.0246
Epoch[22140/50000]
**Valid**: G Loss: 225.7381, D Loss: 1.2027
Epoch[22150/50000]
**Train**: G Loss: 189.5674, D Loss: 0.5487
Epoch[22150/50000]
**Valid**: G Loss: 175.3265, D Loss: -0.3936
Epoch[22160/50000]
**Train**: G Loss: 170.6762, D Loss: 0.5614
Epoch[22160/50000]
**Valid**: G Loss: 170.9976, D Loss: 0.9163
Epoch[22170/50000]
**Train**: G Loss: 213.5463, D Loss: -0.0684
Epoch[22170/50000]
**Valid**: G Loss: 219.4217, D Loss: 0.8627
Epoch[22180/50000]
**Train**: G Loss: 186.8674, D Loss: 0.1783
Epoch[22180/50000]
**Valid**: G Loss: 174.4463, D Loss: -0.4183
Epoch[22190/50000]
**Train**: G Loss: 169.5102, D Loss: 0.8766
Epoch[22190/50000]
**Valid**: G Loss: 178.1825, D Loss: 0.4809
Epoch[22200/50000]
**Train**: G Loss: 218.0166, D Loss: 0.2415
Epoch[22200/50000]
**Valid**: G Loss: 218.1373, D Loss: 1.1873
Epoch[22210/50000]
**Train**: G Loss: 190.2336, D Loss: 0.2503
Epoch[22210/50000]
**Valid**: G Loss: 179.2876, D Loss: -0.4619
Epoch[22220/50000]
**Train**: G Loss: 184.7269, D Loss: 0.6107
Epoch[22220/50000]
**Valid**: G Loss: 216.6307, D Loss: -0.3172
Epoch[22230/50000]
**Train**: G Loss: 170.3221, D Loss: -0.0387
Epoch[22230/50000]
**Valid**: G Loss: 167.4248, D Loss: 1.2836
Epoch[22240/50000]
**Train**: G Loss: 200.9517, D Loss: -0.0051
Epoch[22240/50000]
**Valid**: G Loss: 225.2021, D Loss: -0.2441
Epoch[22250/50000]
**Train**: G Loss: 209.8428, D Loss: 0.9480
Epoch[22250/50000]
**Valid**: G Loss: 195.8649, D Loss: 0.2814
Epoch[22260/50000]
**Train**: G Loss: 177.1054, D Loss: 0.0885
Epoch[22260/50000]
**Valid**: G Loss: 175.1940, D Loss: 0.8502
Epoch[22270/50000]
**Train**: G Loss: 194.2799, D Loss: 0.4077
Epoch[22270/50000]
**Valid**: G Loss: 215.2579, D Loss: -0.0836
Epoch[22280/50000]
**Train**: G Loss: 215.3617, D Loss: 0.8167
Epoch[22280/50000]
**Valid**: G Loss: 203.4049, D Loss: 0.6576
Epoch[22290/50000]
**Train**: G Loss: 178.9448, D Loss: 0.0332
Epoch[22290/50000]
**Valid**: G Loss: 173.9565, D Loss: 0.5793
Epoch[22300/50000]
**Train**: G Loss: 191.6417, D Loss: 0.6466
Epoch[22300/50000]
**Valid**: G Loss: 208.6330, D Loss: 0.0963
Epoch[22310/50000]
**Train**: G Loss: 215.1005, D Loss: 0.7937
Epoch[22310/50000]
**Valid**: G Loss: 202.7402, D Loss: 0.9061
Epoch[22320/50000]
**Train**: G Loss: 182.7196, D Loss: 0.0560
Epoch[22320/50000]
**Valid**: G Loss: 176.7291, D Loss: 0.6600
Epoch[22330/50000]
**Train**: G Loss: 187.1053, D Loss: 0.4417
Epoch[22330/50000]
**Valid**: G Loss: 200.0093, D Loss: 0.1083
Epoch[22340/50000]
**Train**: G Loss: 201.1340, D Loss: 0.6710
Epoch[22340/50000]
**Valid**: G Loss: 194.1434, D Loss: 1.0457
Epoch[22350/50000]
**Train**: G Loss: 177.3484, D Loss: -0.0943
Epoch[22350/50000]
**Valid**: G Loss: 171.9633, D Loss: 0.9312
Epoch[22360/50000]
**Train**: G Loss: 186.6792, D Loss: 0.5262
Epoch[22360/50000]
**Valid**: G Loss: 204.8529, D Loss: -0.1308
Epoch[22370/50000]
**Train**: G Loss: 215.9881, D Loss: 0.7812
Epoch[22370/50000]
**Valid**: G Loss: 202.7857, D Loss: 0.8534
Epoch[22380/50000]
**Train**: G Loss: 175.5903, D Loss: -0.1070
Epoch[22380/50000]
**Valid**: G Loss: 166.0211, D Loss: 0.2913
Epoch[22390/50000]
**Train**: G Loss: 182.9043, D Loss: 0.5921
Epoch[22390/50000]
**Valid**: G Loss: 207.2125, D Loss: -0.0172
Epoch[22400/50000]
**Train**: G Loss: 211.3638, D Loss: 0.8939
Epoch[22400/50000]
**Valid**: G Loss: 194.4064, D Loss: 0.4621
Epoch[22410/50000]
**Train**: G Loss: 161.5954, D Loss: 0.3746
Epoch[22410/50000]
**Valid**: G Loss: 164.8911, D Loss: 1.1520
Epoch[22420/50000]
**Train**: G Loss: 210.3240, D Loss: -0.0652
Epoch[22420/50000]
**Valid**: G Loss: 228.9040, D Loss: -0.0026
Epoch[22430/50000]
**Train**: G Loss: 211.9485, D Loss: 0.7960
Epoch[22430/50000]
**Valid**: G Loss: 197.3117, D Loss: 0.1636
Epoch[22440/50000]
**Train**: G Loss: 181.9620, D Loss: 0.0430
Epoch[22440/50000]
**Valid**: G Loss: 176.8184, D Loss: 0.8712
Epoch[22450/50000]
**Train**: G Loss: 193.1510, D Loss: 0.2105
Epoch[22450/50000]
**Valid**: G Loss: 210.3943, D Loss: -0.1480
Epoch[22460/50000]
**Train**: G Loss: 211.4750, D Loss: 0.6281
Epoch[22460/50000]
**Valid**: G Loss: 203.0921, D Loss: 1.0985
Epoch[22470/50000]
**Train**: G Loss: 185.7314, D Loss: -0.1302
Epoch[22470/50000]
**Valid**: G Loss: 177.1335, D Loss: 0.1439
Epoch[22480/50000]
**Train**: G Loss: 173.3724, D Loss: 0.6433
Epoch[22480/50000]
**Valid**: G Loss: 184.5363, D Loss: 0.1813
Epoch[22490/50000]
**Train**: G Loss: 195.9025, D Loss: 0.5631
Epoch[22490/50000]
**Valid**: G Loss: 188.1102, D Loss: 0.8639
Epoch[22500/50000]
**Train**: G Loss: 174.9178, D Loss: -0.0806
Epoch[22500/50000]
**Valid**: G Loss: 166.9378, D Loss: 0.8286
Epoch[22510/50000]
**Train**: G Loss: 185.8654, D Loss: 0.3775
Epoch[22510/50000]
**Valid**: G Loss: 195.3186, D Loss: -0.0919
Epoch[22520/50000]
**Train**: G Loss: 195.5021, D Loss: 0.8584
Epoch[22520/50000]
**Valid**: G Loss: 180.9729, D Loss: 0.1057
Epoch[22530/50000]
**Train**: G Loss: 226.8748, D Loss: -0.0857
Epoch[22530/50000]
**Valid**: G Loss: 246.3213, D Loss: 1.1155
Epoch[22540/50000]
**Train**: G Loss: 153.6329, D Loss: -0.3271
Epoch[22540/50000]
**Valid**: G Loss: 148.9760, D Loss: 0.6765
Epoch[22550/50000]
**Train**: G Loss: 211.7155, D Loss: -0.0224
Epoch[22550/50000]
**Valid**: G Loss: 245.1935, D Loss: 0.0795
Epoch[22560/50000]
**Train**: G Loss: 212.6499, D Loss: 0.8444
Epoch[22560/50000]
**Valid**: G Loss: 187.6092, D Loss: -0.1842
Epoch[22570/50000]
**Train**: G Loss: 166.2244, D Loss: -0.0953
Epoch[22570/50000]
**Valid**: G Loss: 161.2159, D Loss: 0.9031
Epoch[22580/50000]
**Train**: G Loss: 185.6395, D Loss: 0.4218
Epoch[22580/50000]
**Valid**: G Loss: 204.2165, D Loss: -0.1234
Epoch[22590/50000]
**Train**: G Loss: 220.3643, D Loss: 0.4188
Epoch[22590/50000]
**Valid**: G Loss: 215.9678, D Loss: 1.0214
Epoch[22600/50000]
**Train**: G Loss: 193.2377, D Loss: 0.1307
Epoch[22600/50000]
**Valid**: G Loss: 182.9022, D Loss: -0.1963
Epoch[22610/50000]
**Train**: G Loss: 169.5909, D Loss: 0.6248
Epoch[22610/50000]
**Valid**: G Loss: 174.2053, D Loss: 0.9648
Epoch[22620/50000]
**Train**: G Loss: 213.6487, D Loss: 0.0718
Epoch[22620/50000]
**Valid**: G Loss: 223.2449, D Loss: 0.6382
Epoch[22630/50000]
**Train**: G Loss: 200.2286, D Loss: 0.6824
Epoch[22630/50000]
**Valid**: G Loss: 191.1682, D Loss: -0.1233
Epoch[22640/50000]
**Train**: G Loss: 178.7209, D Loss: 0.5225
Epoch[22640/50000]
**Valid**: G Loss: 177.6796, D Loss: 0.9051
Epoch[22650/50000]
**Train**: G Loss: 213.7468, D Loss: -0.0385
Epoch[22650/50000]
**Valid**: G Loss: 225.2421, D Loss: 0.6055
Epoch[22660/50000]
**Train**: G Loss: 202.4901, D Loss: 0.6118
Epoch[22660/50000]
**Valid**: G Loss: 190.1740, D Loss: -0.3744
Epoch[22670/50000]
**Train**: G Loss: 173.2976, D Loss: 0.6655
Epoch[22670/50000]
**Valid**: G Loss: 179.1970, D Loss: 0.8404
Epoch[22680/50000]
**Train**: G Loss: 222.2363, D Loss: 0.1335
Epoch[22680/50000]
**Valid**: G Loss: 225.9697, D Loss: 1.2047
Epoch[22690/50000]
**Train**: G Loss: 191.6607, D Loss: 0.0887
Epoch[22690/50000]
**Valid**: G Loss: 181.6484, D Loss: -0.2074
Epoch[22700/50000]
**Train**: G Loss: 180.7595, D Loss: 0.8018
Epoch[22700/50000]
**Valid**: G Loss: 188.4527, D Loss: 0.4269
Epoch[22710/50000]
**Train**: G Loss: 224.3615, D Loss: 0.2657
Epoch[22710/50000]
**Valid**: G Loss: 220.1839, D Loss: 1.0446
Epoch[22720/50000]
**Train**: G Loss: 173.2590, D Loss: -0.0725
Epoch[22720/50000]
**Valid**: G Loss: 159.7891, D Loss: 0.1977
Epoch[22730/50000]
**Train**: G Loss: 204.3473, D Loss: 0.0247
Epoch[22730/50000]
**Valid**: G Loss: 235.0071, D Loss: -0.3276
Epoch[22740/50000]
**Train**: G Loss: 197.3704, D Loss: 0.6813
Epoch[22740/50000]
**Valid**: G Loss: 169.8005, D Loss: -0.5692
Epoch[22750/50000]
**Train**: G Loss: 161.7743, D Loss: 0.5502
Epoch[22750/50000]
**Valid**: G Loss: 169.1187, D Loss: 0.8126
Epoch[22760/50000]
**Train**: G Loss: 218.1981, D Loss: -0.1061
Epoch[22760/50000]
**Valid**: G Loss: 231.0598, D Loss: 0.5032
Epoch[22770/50000]
**Train**: G Loss: 198.5736, D Loss: 0.6721
Epoch[22770/50000]
**Valid**: G Loss: 183.0604, D Loss: -0.3733
Epoch[22780/50000]
**Train**: G Loss: 167.8524, D Loss: 0.3677
Epoch[22780/50000]
**Valid**: G Loss: 167.3661, D Loss: 1.0538
Epoch[22790/50000]
**Train**: G Loss: 200.7301, D Loss: -0.0306
Epoch[22790/50000]
**Valid**: G Loss: 218.1071, D Loss: -0.0668
Epoch[22800/50000]
**Train**: G Loss: 218.0517, D Loss: 0.8096
Epoch[22800/50000]
**Valid**: G Loss: 205.0113, D Loss: 0.6426
Epoch[22810/50000]
**Train**: G Loss: 179.2662, D Loss: 0.0744
Epoch[22810/50000]
**Valid**: G Loss: 172.5606, D Loss: 0.7266
Epoch[22820/50000]
**Train**: G Loss: 189.5559, D Loss: 0.4867
Epoch[22820/50000]
**Valid**: G Loss: 206.1337, D Loss: -0.0575
Epoch[22830/50000]
**Train**: G Loss: 218.6492, D Loss: 0.6953
Epoch[22830/50000]
**Valid**: G Loss: 207.4974, D Loss: 1.0273
Epoch[22840/50000]
**Train**: G Loss: 181.7724, D Loss: 0.0406
Epoch[22840/50000]
**Valid**: G Loss: 173.5526, D Loss: 0.4666
Epoch[22850/50000]
**Train**: G Loss: 189.6156, D Loss: 0.6012
Epoch[22850/50000]
**Valid**: G Loss: 205.8197, D Loss: 0.0764
Epoch[22860/50000]
**Train**: G Loss: 219.0782, D Loss: 0.8466
Epoch[22860/50000]
**Valid**: G Loss: 202.7480, D Loss: 0.5531
Epoch[22870/50000]
**Train**: G Loss: 169.0482, D Loss: 0.0359
Epoch[22870/50000]
**Valid**: G Loss: 168.7295, D Loss: 0.8835
Epoch[22880/50000]
**Train**: G Loss: 218.6687, D Loss: 0.0799
Epoch[22880/50000]
**Valid**: G Loss: 228.2665, D Loss: 0.7928
Epoch[22890/50000]
**Train**: G Loss: 182.6996, D Loss: -0.1346
Epoch[22890/50000]
**Valid**: G Loss: 167.1363, D Loss: -0.1886
Epoch[22900/50000]
**Train**: G Loss: 197.9380, D Loss: 0.2496
Epoch[22900/50000]
**Valid**: G Loss: 223.1195, D Loss: -0.1347
Epoch[22910/50000]
**Train**: G Loss: 208.9691, D Loss: 0.8278
Epoch[22910/50000]
**Valid**: G Loss: 190.6828, D Loss: -0.0943
Epoch[22920/50000]
**Train**: G Loss: 171.6354, D Loss: 0.1519
Epoch[22920/50000]
**Valid**: G Loss: 170.7643, D Loss: 1.0002
Epoch[22930/50000]
**Train**: G Loss: 211.5437, D Loss: 0.2352
Epoch[22930/50000]
**Valid**: G Loss: 228.8144, D Loss: 0.2437
Epoch[22940/50000]
**Train**: G Loss: 204.8694, D Loss: 0.3526
Epoch[22940/50000]
**Valid**: G Loss: 192.1276, D Loss: -0.2707
Epoch[22950/50000]
**Train**: G Loss: 180.9239, D Loss: 0.6831
Epoch[22950/50000]
**Valid**: G Loss: 194.6525, D Loss: 0.2136
Epoch[22960/50000]
**Train**: G Loss: 220.8375, D Loss: 0.5903
Epoch[22960/50000]
**Valid**: G Loss: 213.0805, D Loss: 1.2254
Epoch[22970/50000]
**Train**: G Loss: 180.6888, D Loss: -0.2594
Epoch[22970/50000]
**Valid**: G Loss: 170.8612, D Loss: 0.2949
Epoch[22980/50000]
**Train**: G Loss: 193.4860, D Loss: 0.6009
Epoch[22980/50000]
**Valid**: G Loss: 206.9070, D Loss: -0.0542
Epoch[22990/50000]
**Train**: G Loss: 216.5177, D Loss: 0.8729
Epoch[22990/50000]
**Valid**: G Loss: 204.2448, D Loss: 0.7137
Epoch[23000/50000]
**Train**: G Loss: 172.9834, D Loss: 0.0595
Epoch[23000/50000]
**Valid**: G Loss: 168.8837, D Loss: 0.6092
Epoch[23010/50000]
**Train**: G Loss: 204.1086, D Loss: 0.3055
Epoch[23010/50000]
**Valid**: G Loss: 224.5846, D Loss: 0.0928
Epoch[23020/50000]
**Train**: G Loss: 211.6730, D Loss: 0.6492
Epoch[23020/50000]
**Valid**: G Loss: 201.0113, D Loss: 0.0275
Epoch[23030/50000]
**Train**: G Loss: 177.3386, D Loss: 0.7755
Epoch[23030/50000]
**Valid**: G Loss: 183.9661, D Loss: 0.8793
Epoch[23040/50000]
**Train**: G Loss: 227.0645, D Loss: 0.0482
Epoch[23040/50000]
**Valid**: G Loss: 225.1506, D Loss: 1.1794
Epoch[23050/50000]
**Train**: G Loss: 198.8301, D Loss: 0.1279
Epoch[23050/50000]
**Valid**: G Loss: 191.1904, D Loss: -0.3141
Epoch[23060/50000]
**Train**: G Loss: 184.9251, D Loss: 0.7159
Epoch[23060/50000]
**Valid**: G Loss: 191.3305, D Loss: 0.3261
Epoch[23070/50000]
**Train**: G Loss: 223.9070, D Loss: 0.3701
Epoch[23070/50000]
**Valid**: G Loss: 219.2429, D Loss: 1.0240
Epoch[23080/50000]
**Train**: G Loss: 189.4233, D Loss: 0.0001
Epoch[23080/50000]
**Valid**: G Loss: 180.3184, D Loss: 0.2992
Epoch[23090/50000]
**Train**: G Loss: 191.5311, D Loss: 0.5542
Epoch[23090/50000]
**Valid**: G Loss: 209.2881, D Loss: -0.0357
Epoch[23100/50000]
**Train**: G Loss: 216.1676, D Loss: 0.9045
Epoch[23100/50000]
**Valid**: G Loss: 201.8104, D Loss: 0.3725
Epoch[23110/50000]
**Train**: G Loss: 184.7824, D Loss: -0.1393
Epoch[23110/50000]
**Valid**: G Loss: 179.1013, D Loss: 0.7076
Epoch[23120/50000]
**Train**: G Loss: 200.6064, D Loss: 0.3626
Epoch[23120/50000]
**Valid**: G Loss: 211.9108, D Loss: 0.1028
Epoch[23130/50000]
**Train**: G Loss: 203.2959, D Loss: 0.6616
Epoch[23130/50000]
**Valid**: G Loss: 195.0570, D Loss: -0.0997
Epoch[23140/50000]
**Train**: G Loss: 180.4703, D Loss: 0.6907
Epoch[23140/50000]
**Valid**: G Loss: 190.6714, D Loss: 0.2252
Epoch[23150/50000]
**Train**: G Loss: 176.1870, D Loss: -0.1752
Epoch[23150/50000]
**Valid**: G Loss: 163.9994, D Loss: -0.3849
Epoch[23160/50000]
**Train**: G Loss: 204.8677, D Loss: 0.1269
Epoch[23160/50000]
**Valid**: G Loss: 233.3649, D Loss: -0.1578
Epoch[23170/50000]
**Train**: G Loss: 215.7414, D Loss: 0.8203
Epoch[23170/50000]
**Valid**: G Loss: 199.7533, D Loss: -0.0291
Epoch[23180/50000]
**Train**: G Loss: 177.9702, D Loss: 0.1931
Epoch[23180/50000]
**Valid**: G Loss: 175.5997, D Loss: 0.9663
Epoch[23190/50000]
**Train**: G Loss: 203.0325, D Loss: 0.0613
Epoch[23190/50000]
**Valid**: G Loss: 216.9485, D Loss: 0.1140
Epoch[23200/50000]
**Train**: G Loss: 216.2931, D Loss: 0.5827
Epoch[23200/50000]
**Valid**: G Loss: 204.1148, D Loss: 0.5082
Epoch[23210/50000]
**Train**: G Loss: 182.6437, D Loss: 0.1252
Epoch[23210/50000]
**Valid**: G Loss: 177.4377, D Loss: 0.9805
Epoch[23220/50000]
**Train**: G Loss: 204.2034, D Loss: 0.1882
Epoch[23220/50000]
**Valid**: G Loss: 224.4654, D Loss: -0.1688
Epoch[23230/50000]
**Train**: G Loss: 214.5754, D Loss: 0.8280
Epoch[23230/50000]
**Valid**: G Loss: 200.6029, D Loss: 0.1640
Epoch[23240/50000]
**Train**: G Loss: 178.0739, D Loss: -0.0117
Epoch[23240/50000]
**Valid**: G Loss: 174.4907, D Loss: 0.7447
Epoch[23250/50000]
**Train**: G Loss: 210.9936, D Loss: 0.1345
Epoch[23250/50000]
**Valid**: G Loss: 228.9427, D Loss: -0.0118
Epoch[23260/50000]
**Train**: G Loss: 202.3764, D Loss: 0.5471
Epoch[23260/50000]
**Valid**: G Loss: 191.7097, D Loss: -0.2593
Epoch[23270/50000]
**Train**: G Loss: 173.2015, D Loss: 0.6973
Epoch[23270/50000]
**Valid**: G Loss: 179.8384, D Loss: 0.6492
Epoch[23280/50000]
**Train**: G Loss: 235.2026, D Loss: 0.0724
Epoch[23280/50000]
**Valid**: G Loss: 237.8999, D Loss: 1.2649
Epoch[23290/50000]
**Train**: G Loss: 191.3914, D Loss: 0.0286
Epoch[23290/50000]
**Valid**: G Loss: 178.4052, D Loss: -0.1599
Epoch[23300/50000]
**Train**: G Loss: 179.6718, D Loss: 0.7026
Epoch[23300/50000]
**Valid**: G Loss: 190.6901, D Loss: 0.4031
Epoch[23310/50000]
**Train**: G Loss: 230.4625, D Loss: 0.5762
Epoch[23310/50000]
**Valid**: G Loss: 223.8979, D Loss: 1.3921
Epoch[23320/50000]
**Train**: G Loss: 188.7509, D Loss: -0.0486
Epoch[23320/50000]
**Valid**: G Loss: 178.1123, D Loss: 0.0224
Epoch[23330/50000]
**Train**: G Loss: 194.5857, D Loss: 0.6299
Epoch[23330/50000]
**Valid**: G Loss: 214.4317, D Loss: -0.2222
Epoch[23340/50000]
**Train**: G Loss: 218.2005, D Loss: 0.6798
Epoch[23340/50000]
**Valid**: G Loss: 207.5915, D Loss: 1.3111
Epoch[23350/50000]
**Train**: G Loss: 180.9192, D Loss: -0.2647
Epoch[23350/50000]
**Valid**: G Loss: 172.8794, D Loss: 0.3343
Epoch[23360/50000]
**Train**: G Loss: 190.8102, D Loss: 0.4426
Epoch[23360/50000]
**Valid**: G Loss: 206.9108, D Loss: -0.2128
Epoch[23370/50000]
**Train**: G Loss: 176.2955, D Loss: 0.2369
Epoch[23370/50000]
**Valid**: G Loss: 164.3635, D Loss: 0.5576
Epoch[23380/50000]
**Train**: G Loss: 210.3819, D Loss: 0.0162
Epoch[23380/50000]
**Valid**: G Loss: 207.4293, D Loss: 1.1719
Epoch[23390/50000]
**Train**: G Loss: 183.4982, D Loss: -0.2489
Epoch[23390/50000]
**Valid**: G Loss: 176.8796, D Loss: 0.1512
Epoch[23400/50000]
**Train**: G Loss: 179.8416, D Loss: 0.6295
Epoch[23400/50000]
**Valid**: G Loss: 195.9199, D Loss: -0.1941
Epoch[23410/50000]
**Train**: G Loss: 215.5561, D Loss: 0.5000
Epoch[23410/50000]
**Valid**: G Loss: 207.9929, D Loss: 0.8292
Epoch[23420/50000]
**Train**: G Loss: 180.4910, D Loss: 0.0799
Epoch[23420/50000]
**Valid**: G Loss: 175.7470, D Loss: 0.8411
Epoch[23430/50000]
**Train**: G Loss: 191.9589, D Loss: 0.5077
Epoch[23430/50000]
**Valid**: G Loss: 206.3393, D Loss: 0.2383
Epoch[23440/50000]
**Train**: G Loss: 220.0962, D Loss: 0.6816
Epoch[23440/50000]
**Valid**: G Loss: 206.0891, D Loss: 1.0406
Epoch[23450/50000]
**Train**: G Loss: 184.5510, D Loss: -0.1172
Epoch[23450/50000]
**Valid**: G Loss: 177.4581, D Loss: 0.3045
Epoch[23460/50000]
**Train**: G Loss: 189.9318, D Loss: 0.4491
Epoch[23460/50000]
**Valid**: G Loss: 206.0901, D Loss: -0.1211
Epoch[23470/50000]
**Train**: G Loss: 208.8858, D Loss: 0.6499
Epoch[23470/50000]
**Valid**: G Loss: 198.0921, D Loss: 0.5333
Epoch[23480/50000]
**Train**: G Loss: 179.1102, D Loss: 0.3678
Epoch[23480/50000]
**Valid**: G Loss: 178.3550, D Loss: 0.8092
Epoch[23490/50000]
**Train**: G Loss: 225.0893, D Loss: 0.1650
Epoch[23490/50000]
**Valid**: G Loss: 227.4160, D Loss: 1.1319
Epoch[23500/50000]
**Train**: G Loss: 166.7307, D Loss: -0.1999
Epoch[23500/50000]
**Valid**: G Loss: 160.9367, D Loss: 0.8767
Epoch[23510/50000]
**Train**: G Loss: 219.8048, D Loss: -0.1722
Epoch[23510/50000]
**Valid**: G Loss: 232.9654, D Loss: 0.7948
Epoch[23520/50000]
**Train**: G Loss: 189.9188, D Loss: 0.1754
Epoch[23520/50000]
**Valid**: G Loss: 174.7932, D Loss: -0.4270
Epoch[23530/50000]
**Train**: G Loss: 175.7706, D Loss: 0.5724
Epoch[23530/50000]
**Valid**: G Loss: 188.1493, D Loss: 0.4190
Epoch[23540/50000]
**Train**: G Loss: 231.3215, D Loss: 0.1452
Epoch[23540/50000]
**Valid**: G Loss: 229.2137, D Loss: 1.1562
Epoch[23550/50000]
**Train**: G Loss: 192.6247, D Loss: 0.0458
Epoch[23550/50000]
**Valid**: G Loss: 181.2557, D Loss: 0.0624
Epoch[23560/50000]
**Train**: G Loss: 183.6464, D Loss: 0.7825
Epoch[23560/50000]
**Valid**: G Loss: 190.1569, D Loss: 0.6316
Epoch[23570/50000]
**Train**: G Loss: 216.8903, D Loss: 0.1413
Epoch[23570/50000]
**Valid**: G Loss: 218.9145, D Loss: 0.9879
Epoch[23580/50000]
**Train**: G Loss: 187.8315, D Loss: 0.0441
Epoch[23580/50000]
**Valid**: G Loss: 178.5192, D Loss: 0.4013
Epoch[23590/50000]
**Train**: G Loss: 213.8996, D Loss: 0.0941
Epoch[23590/50000]
**Valid**: G Loss: 228.3379, D Loss: 0.4517
Epoch[23600/50000]
**Train**: G Loss: 195.2076, D Loss: 0.0925
Epoch[23600/50000]
**Valid**: G Loss: 185.4045, D Loss: -0.2124
Epoch[23610/50000]
**Train**: G Loss: 188.8634, D Loss: 0.6844
Epoch[23610/50000]
**Valid**: G Loss: 204.8340, D Loss: 0.0507
Epoch[23620/50000]
**Train**: G Loss: 227.3313, D Loss: 0.5402
Epoch[23620/50000]
**Valid**: G Loss: 217.1528, D Loss: 0.8868
Epoch[23630/50000]
**Train**: G Loss: 195.4661, D Loss: 0.0226
Epoch[23630/50000]
**Valid**: G Loss: 191.2560, D Loss: 0.4647
Epoch[23640/50000]
**Train**: G Loss: 201.7285, D Loss: 0.4314
Epoch[23640/50000]
**Valid**: G Loss: 216.2835, D Loss: -0.2209
Epoch[23650/50000]
**Train**: G Loss: 223.5171, D Loss: 0.7741
Epoch[23650/50000]
**Valid**: G Loss: 214.4267, D Loss: 0.9367
Epoch[23660/50000]
**Train**: G Loss: 187.9275, D Loss: 0.1296
Epoch[23660/50000]
**Valid**: G Loss: 184.4932, D Loss: 1.0021
Epoch[23670/50000]
**Train**: G Loss: 224.9905, D Loss: -0.0862
Epoch[23670/50000]
**Valid**: G Loss: 233.7735, D Loss: 0.7475
Epoch[23680/50000]
**Train**: G Loss: 203.4495, D Loss: 0.4195
Epoch[23680/50000]
**Valid**: G Loss: 194.6748, D Loss: -0.0362
Epoch[23690/50000]
**Train**: G Loss: 193.6855, D Loss: 0.7473
Epoch[23690/50000]
**Valid**: G Loss: 199.7678, D Loss: 0.3498
Epoch[23700/50000]
**Train**: G Loss: 224.0242, D Loss: 0.7670
Epoch[23700/50000]
**Valid**: G Loss: 212.7096, D Loss: 0.5797
Epoch[23710/50000]
**Train**: G Loss: 185.7540, D Loss: -0.0456
Epoch[23710/50000]
**Valid**: G Loss: 181.4109, D Loss: 0.6212
Epoch[23720/50000]
**Train**: G Loss: 201.5711, D Loss: 0.3069
Epoch[23720/50000]
**Valid**: G Loss: 219.2322, D Loss: -0.0120
Epoch[23730/50000]
**Train**: G Loss: 214.2451, D Loss: 0.6853
Epoch[23730/50000]
**Valid**: G Loss: 199.8226, D Loss: -0.0295
Epoch[23740/50000]
**Train**: G Loss: 185.1043, D Loss: 0.6803
Epoch[23740/50000]
**Valid**: G Loss: 189.6517, D Loss: 0.7730
Epoch[23750/50000]
**Train**: G Loss: 227.0474, D Loss: 0.3065
Epoch[23750/50000]
**Valid**: G Loss: 224.5085, D Loss: 1.0061
Epoch[23760/50000]
**Train**: G Loss: 189.9300, D Loss: -0.1048
Epoch[23760/50000]
**Valid**: G Loss: 184.1618, D Loss: 0.5397
Epoch[23770/50000]
**Train**: G Loss: 219.7094, D Loss: 0.0450
Epoch[23770/50000]
**Valid**: G Loss: 229.7744, D Loss: 0.7676
Epoch[23780/50000]
**Train**: G Loss: 193.6866, D Loss: -0.0089
Epoch[23780/50000]
**Valid**: G Loss: 185.5122, D Loss: 0.1818
Epoch[23790/50000]
**Train**: G Loss: 205.1702, D Loss: 0.4471
Epoch[23790/50000]
**Valid**: G Loss: 224.2615, D Loss: -0.0389
Epoch[23800/50000]
**Train**: G Loss: 218.8516, D Loss: 0.8761
Epoch[23800/50000]
**Valid**: G Loss: 205.9630, D Loss: 0.3302
Epoch[23810/50000]
**Train**: G Loss: 187.8103, D Loss: 0.5109
Epoch[23810/50000]
**Valid**: G Loss: 188.7672, D Loss: 0.7193
Epoch[23820/50000]
**Train**: G Loss: 226.1895, D Loss: 0.3412
Epoch[23820/50000]
**Valid**: G Loss: 225.2178, D Loss: 1.0420
Epoch[23830/50000]
**Train**: G Loss: 189.8720, D Loss: -0.1746
Epoch[23830/50000]
**Valid**: G Loss: 186.0159, D Loss: 0.5327
Epoch[23840/50000]
**Train**: G Loss: 215.5064, D Loss: 0.1834
Epoch[23840/50000]
**Valid**: G Loss: 234.6130, D Loss: 0.1183
Epoch[23850/50000]
**Train**: G Loss: 207.0340, D Loss: 0.3595
Epoch[23850/50000]
**Valid**: G Loss: 197.9427, D Loss: 0.0381
Epoch[23860/50000]
**Train**: G Loss: 195.7703, D Loss: 0.7286
Epoch[23860/50000]
**Valid**: G Loss: 208.4589, D Loss: 0.1184
Epoch[23870/50000]
**Train**: G Loss: 228.5591, D Loss: 0.6261
Epoch[23870/50000]
**Valid**: G Loss: 214.7325, D Loss: 0.4968
Epoch[23880/50000]
**Train**: G Loss: 182.9996, D Loss: 0.6397
Epoch[23880/50000]
**Valid**: G Loss: 185.4669, D Loss: 0.9430
Epoch[23890/50000]
**Train**: G Loss: 231.7659, D Loss: 0.1213
Epoch[23890/50000]
**Valid**: G Loss: 231.1636, D Loss: 1.7893
Epoch[23900/50000]
**Train**: G Loss: 192.1044, D Loss: 0.0340
Epoch[23900/50000]
**Valid**: G Loss: 184.2883, D Loss: 0.4252
Epoch[23910/50000]
**Train**: G Loss: 205.9630, D Loss: 0.2650
Epoch[23910/50000]
**Valid**: G Loss: 222.9291, D Loss: 0.2154
Epoch[23920/50000]
**Train**: G Loss: 218.9427, D Loss: 0.7924
Epoch[23920/50000]
**Valid**: G Loss: 208.4029, D Loss: 0.2302
Epoch[23930/50000]
**Train**: G Loss: 196.1034, D Loss: 0.7521
Epoch[23930/50000]
**Valid**: G Loss: 208.3030, D Loss: 0.1817
Epoch[23940/50000]
**Train**: G Loss: 215.4803, D Loss: 0.7673
Epoch[23940/50000]
**Valid**: G Loss: 204.4900, D Loss: 0.1259
Epoch[23950/50000]
**Train**: G Loss: 192.4088, D Loss: 0.4263
Epoch[23950/50000]
**Valid**: G Loss: 199.4919, D Loss: 0.3129
Epoch[23960/50000]
**Train**: G Loss: 227.5014, D Loss: 0.6435
Epoch[23960/50000]
**Valid**: G Loss: 219.3511, D Loss: 0.9197
Epoch[23970/50000]
**Train**: G Loss: 187.8898, D Loss: 0.1041
Epoch[23970/50000]
**Valid**: G Loss: 184.4241, D Loss: 0.7831
Epoch[23980/50000]
**Train**: G Loss: 229.8888, D Loss: 0.1781
Epoch[23980/50000]
**Valid**: G Loss: 228.5214, D Loss: 1.0878
Epoch[23990/50000]
**Train**: G Loss: 195.1090, D Loss: 0.0298
Epoch[23990/50000]
**Valid**: G Loss: 187.9348, D Loss: 0.4491
Epoch[24000/50000]
**Train**: G Loss: 228.9409, D Loss: 0.0317
Epoch[24000/50000]
**Valid**: G Loss: 241.2825, D Loss: 0.6472
Epoch[24010/50000]
**Train**: G Loss: 194.7258, D Loss: -0.0339
Epoch[24010/50000]
**Valid**: G Loss: 185.3717, D Loss: 0.1686
Epoch[24020/50000]
**Train**: G Loss: 207.9284, D Loss: 0.3436
Epoch[24020/50000]
**Valid**: G Loss: 225.6233, D Loss: -0.1440
Epoch[24030/50000]
**Train**: G Loss: 213.8596, D Loss: 0.5873
Epoch[24030/50000]
**Valid**: G Loss: 203.7438, D Loss: -0.1304
Epoch[24040/50000]
**Train**: G Loss: 197.3730, D Loss: 0.5224
Epoch[24040/50000]
**Valid**: G Loss: 203.6229, D Loss: 0.2496
Epoch[24050/50000]
**Train**: G Loss: 227.7386, D Loss: 0.5873
Epoch[24050/50000]
**Valid**: G Loss: 219.9562, D Loss: 0.9029
Epoch[24060/50000]
**Train**: G Loss: 198.6494, D Loss: 0.0478
Epoch[24060/50000]
**Valid**: G Loss: 196.8498, D Loss: 0.7202
Epoch[24070/50000]
**Train**: G Loss: 228.7017, D Loss: 0.3237
Epoch[24070/50000]
**Valid**: G Loss: 227.2963, D Loss: 1.1972
Epoch[24080/50000]
**Train**: G Loss: 200.0396, D Loss: -0.0593
Epoch[24080/50000]
**Valid**: G Loss: 193.9831, D Loss: 0.5347
Epoch[24090/50000]
**Train**: G Loss: 226.0712, D Loss: 0.0669
Epoch[24090/50000]
**Valid**: G Loss: 235.2403, D Loss: 0.7746
Epoch[24100/50000]
**Train**: G Loss: 202.0247, D Loss: 0.0122
Epoch[24100/50000]
**Valid**: G Loss: 194.0186, D Loss: 0.1873
Epoch[24110/50000]
**Train**: G Loss: 216.6140, D Loss: 0.2772
Epoch[24110/50000]
**Valid**: G Loss: 235.2165, D Loss: 0.3127
Epoch[24120/50000]
**Train**: G Loss: 209.8394, D Loss: 0.2488
Epoch[24120/50000]
**Valid**: G Loss: 200.1358, D Loss: -0.1374
Epoch[24130/50000]
**Train**: G Loss: 203.8947, D Loss: 0.5781
Epoch[24130/50000]
**Valid**: G Loss: 216.2107, D Loss: 0.1653
Epoch[24140/50000]
**Train**: G Loss: 214.6097, D Loss: 0.4677
Epoch[24140/50000]
**Valid**: G Loss: 208.7810, D Loss: -0.2551
Epoch[24150/50000]
**Train**: G Loss: 200.7087, D Loss: 0.5362
Epoch[24150/50000]
**Valid**: G Loss: 214.9844, D Loss: -0.0401
Epoch[24160/50000]
**Train**: G Loss: 226.9687, D Loss: 0.7926
Epoch[24160/50000]
**Valid**: G Loss: 214.4895, D Loss: 0.4495
Epoch[24170/50000]
**Train**: G Loss: 185.9020, D Loss: 0.5378
Epoch[24170/50000]
**Valid**: G Loss: 192.5369, D Loss: 0.7515
Epoch[24180/50000]
**Train**: G Loss: 238.3094, D Loss: 0.8007
Epoch[24180/50000]
**Valid**: G Loss: 222.4655, D Loss: 0.9049
Epoch[24190/50000]
**Train**: G Loss: 193.3479, D Loss: 0.3020
Epoch[24190/50000]
**Valid**: G Loss: 192.6413, D Loss: 1.0660
Epoch[24200/50000]
**Train**: G Loss: 241.8124, D Loss: 0.3601
Epoch[24200/50000]
**Valid**: G Loss: 240.2006, D Loss: 1.3571
Epoch[24210/50000]
**Train**: G Loss: 195.3291, D Loss: -0.0764
Epoch[24210/50000]
**Valid**: G Loss: 186.2571, D Loss: 1.0883
Epoch[24220/50000]
**Train**: G Loss: 214.1932, D Loss: 0.1706
Epoch[24220/50000]
**Valid**: G Loss: 232.8065, D Loss: -0.0214
Epoch[24230/50000]
**Train**: G Loss: 214.3098, D Loss: 0.6604
Epoch[24230/50000]
**Valid**: G Loss: 202.9615, D Loss: 0.0891
Epoch[24240/50000]
**Train**: G Loss: 191.7151, D Loss: 0.6384
Epoch[24240/50000]
**Valid**: G Loss: 196.3996, D Loss: 0.6290
Epoch[24250/50000]
**Train**: G Loss: 233.0770, D Loss: 0.6169
Epoch[24250/50000]
**Valid**: G Loss: 223.9918, D Loss: 0.8712
Epoch[24260/50000]
**Train**: G Loss: 201.7338, D Loss: 0.4065
Epoch[24260/50000]
**Valid**: G Loss: 200.8080, D Loss: 0.9143
Epoch[24270/50000]
**Train**: G Loss: 230.7285, D Loss: 0.5467
Epoch[24270/50000]
**Valid**: G Loss: 224.6651, D Loss: 0.8522
Epoch[24280/50000]
**Train**: G Loss: 196.4622, D Loss: 0.3310
Epoch[24280/50000]
**Valid**: G Loss: 195.3257, D Loss: 0.8640
Epoch[24290/50000]
**Train**: G Loss: 233.3806, D Loss: 0.2029
Epoch[24290/50000]
**Valid**: G Loss: 231.6646, D Loss: 1.2233
Epoch[24300/50000]
**Train**: G Loss: 200.5340, D Loss: -0.1216
Epoch[24300/50000]
**Valid**: G Loss: 194.0699, D Loss: 0.4362
Epoch[24310/50000]
**Train**: G Loss: 224.9782, D Loss: 0.0917
Epoch[24310/50000]
**Valid**: G Loss: 235.0905, D Loss: 0.6652
Epoch[24320/50000]
**Train**: G Loss: 203.0735, D Loss: 0.0767
Epoch[24320/50000]
**Valid**: G Loss: 195.2393, D Loss: 0.6192
Epoch[24330/50000]
**Train**: G Loss: 220.1598, D Loss: 0.0506
Epoch[24330/50000]
**Valid**: G Loss: 236.5700, D Loss: 0.1033
Epoch[24340/50000]
**Train**: G Loss: 210.4813, D Loss: 0.3135
Epoch[24340/50000]
**Valid**: G Loss: 201.4179, D Loss: -0.1229
Epoch[24350/50000]
**Train**: G Loss: 209.0900, D Loss: 0.5498
Epoch[24350/50000]
**Valid**: G Loss: 224.4728, D Loss: -0.0047
Epoch[24360/50000]
**Train**: G Loss: 219.7486, D Loss: 0.6774
Epoch[24360/50000]
**Valid**: G Loss: 208.3621, D Loss: -0.1104
Epoch[24370/50000]
**Train**: G Loss: 200.9045, D Loss: 0.7356
Epoch[24370/50000]
**Valid**: G Loss: 208.8960, D Loss: 0.2919
Epoch[24380/50000]
**Train**: G Loss: 227.5723, D Loss: 0.7884
Epoch[24380/50000]
**Valid**: G Loss: 219.7400, D Loss: 0.7604
Epoch[24390/50000]
**Train**: G Loss: 193.7779, D Loss: 0.3083
Epoch[24390/50000]
**Valid**: G Loss: 192.1995, D Loss: 1.1118
Epoch[24400/50000]
**Train**: G Loss: 235.3629, D Loss: 0.3623
Epoch[24400/50000]
**Valid**: G Loss: 233.9773, D Loss: 1.2534
Epoch[24410/50000]
**Train**: G Loss: 200.4253, D Loss: 0.2174
Epoch[24410/50000]
**Valid**: G Loss: 196.4857, D Loss: 0.7849
Epoch[24420/50000]
**Train**: G Loss: 231.4908, D Loss: -0.0302
Epoch[24420/50000]
**Valid**: G Loss: 242.6504, D Loss: 0.4713
Epoch[24430/50000]
**Train**: G Loss: 205.3774, D Loss: 0.1603
Epoch[24430/50000]
**Valid**: G Loss: 197.9341, D Loss: 0.6870
Epoch[24440/50000]
**Train**: G Loss: 214.4355, D Loss: 0.2842
Epoch[24440/50000]
**Valid**: G Loss: 226.9579, D Loss: 0.1805
Epoch[24450/50000]
**Train**: G Loss: 212.0661, D Loss: 0.6665
Epoch[24450/50000]
**Valid**: G Loss: 203.8535, D Loss: 0.0197
Epoch[24460/50000]
**Train**: G Loss: 206.9477, D Loss: 0.6451
Epoch[24460/50000]
**Valid**: G Loss: 213.4878, D Loss: 0.2285
Epoch[24470/50000]
**Train**: G Loss: 218.0912, D Loss: 0.4917
Epoch[24470/50000]
**Valid**: G Loss: 209.0622, D Loss: -0.1678
Epoch[24480/50000]
**Train**: G Loss: 200.1288, D Loss: 0.5629
Epoch[24480/50000]
**Valid**: G Loss: 218.5138, D Loss: -0.2651
Epoch[24490/50000]
**Train**: G Loss: 227.9747, D Loss: 0.7943
Epoch[24490/50000]
**Valid**: G Loss: 215.6075, D Loss: 0.1909
Epoch[24500/50000]
**Train**: G Loss: 202.6212, D Loss: 0.6315
Epoch[24500/50000]
**Valid**: G Loss: 210.8372, D Loss: 0.5235
Epoch[24510/50000]
**Train**: G Loss: 225.8427, D Loss: 0.8403
Epoch[24510/50000]
**Valid**: G Loss: 217.0248, D Loss: 0.6345
Epoch[24520/50000]
**Train**: G Loss: 194.8582, D Loss: 0.6514
Epoch[24520/50000]
**Valid**: G Loss: 197.8248, D Loss: 0.6685
Epoch[24530/50000]
**Train**: G Loss: 237.8992, D Loss: 0.5364
Epoch[24530/50000]
**Valid**: G Loss: 227.7865, D Loss: 0.4930
Epoch[24540/50000]
**Train**: G Loss: 197.8802, D Loss: 0.6021
Epoch[24540/50000]
**Valid**: G Loss: 203.1528, D Loss: 0.8149
Epoch[24550/50000]
**Train**: G Loss: 235.2451, D Loss: 0.6629
Epoch[24550/50000]
**Valid**: G Loss: 225.8924, D Loss: 0.9939
Epoch[24560/50000]
**Train**: G Loss: 197.2288, D Loss: 0.2894
Epoch[24560/50000]
**Valid**: G Loss: 195.8747, D Loss: 1.0212
Epoch[24570/50000]
**Train**: G Loss: 227.5492, D Loss: 0.0195
Epoch[24570/50000]
**Valid**: G Loss: 235.1814, D Loss: 0.5488
Epoch[24580/50000]
**Train**: G Loss: 203.5216, D Loss: 0.2364
Epoch[24580/50000]
**Valid**: G Loss: 199.0170, D Loss: 0.5015
Epoch[24590/50000]
**Train**: G Loss: 221.8505, D Loss: 0.1826
Epoch[24590/50000]
**Valid**: G Loss: 232.5740, D Loss: 0.4258
Epoch[24600/50000]
**Train**: G Loss: 211.9318, D Loss: 0.1802
Epoch[24600/50000]
**Valid**: G Loss: 204.0060, D Loss: 0.2543
Epoch[24610/50000]
**Train**: G Loss: 218.2877, D Loss: 0.1092
Epoch[24610/50000]
**Valid**: G Loss: 232.3226, D Loss: 0.2878
Epoch[24620/50000]
**Train**: G Loss: 207.8453, D Loss: 0.2086
Epoch[24620/50000]
**Valid**: G Loss: 200.6298, D Loss: 0.4767
Epoch[24630/50000]
**Train**: G Loss: 216.4044, D Loss: 0.2070
Epoch[24630/50000]
**Valid**: G Loss: 229.1887, D Loss: 0.0869
Epoch[24640/50000]
**Train**: G Loss: 215.2209, D Loss: 0.2818
Epoch[24640/50000]
**Valid**: G Loss: 207.5098, D Loss: -0.1913
Epoch[24650/50000]
**Train**: G Loss: 218.9830, D Loss: 0.2130
Epoch[24650/50000]
**Valid**: G Loss: 234.4741, D Loss: 0.0978
Epoch[24660/50000]
**Train**: G Loss: 210.1081, D Loss: 0.2127
Epoch[24660/50000]
**Valid**: G Loss: 199.5516, D Loss: 0.1002
Epoch[24670/50000]
**Train**: G Loss: 226.2005, D Loss: 0.1828
Epoch[24670/50000]
**Valid**: G Loss: 241.4026, D Loss: 0.1037
Epoch[24680/50000]
**Train**: G Loss: 208.6873, D Loss: 0.0195
Epoch[24680/50000]
**Valid**: G Loss: 200.8273, D Loss: 0.2689
Epoch[24690/50000]
**Train**: G Loss: 217.5618, D Loss: 0.1975
Epoch[24690/50000]
**Valid**: G Loss: 229.3231, D Loss: 0.1865
Epoch[24700/50000]
**Train**: G Loss: 214.2252, D Loss: 0.1774
Epoch[24700/50000]
**Valid**: G Loss: 208.2408, D Loss: 0.1308
Epoch[24710/50000]
**Train**: G Loss: 228.2909, D Loss: 0.1263
Epoch[24710/50000]
**Valid**: G Loss: 241.8780, D Loss: 0.2947
Epoch[24720/50000]
**Train**: G Loss: 204.8891, D Loss: -0.2282
Epoch[24720/50000]
**Valid**: G Loss: 196.3351, D Loss: 0.2448
Epoch[24730/50000]
**Train**: G Loss: 239.8778, D Loss: 0.2960
Epoch[24730/50000]
**Valid**: G Loss: 240.5047, D Loss: 1.2261
Epoch[24740/50000]
**Train**: G Loss: 198.4691, D Loss: 0.4143
Epoch[24740/50000]
**Valid**: G Loss: 196.5732, D Loss: 1.1998
Epoch[24750/50000]
**Train**: G Loss: 236.7605, D Loss: 0.3938
Epoch[24750/50000]
**Valid**: G Loss: 229.8836, D Loss: 0.8220
Epoch[24760/50000]
**Train**: G Loss: 198.4952, D Loss: 0.6004
Epoch[24760/50000]
**Valid**: G Loss: 199.3949, D Loss: 0.8722
Epoch[24770/50000]
**Train**: G Loss: 224.2359, D Loss: 0.9562
Epoch[24770/50000]
**Valid**: G Loss: 214.4096, D Loss: 0.5029
Epoch[24780/50000]
**Train**: G Loss: 205.3987, D Loss: 0.5986
Epoch[24780/50000]
**Valid**: G Loss: 210.0313, D Loss: 0.3632
Epoch[24790/50000]
**Train**: G Loss: 232.0010, D Loss: 0.7793
Epoch[24790/50000]
**Valid**: G Loss: 222.3032, D Loss: 0.6010
Epoch[24800/50000]
**Train**: G Loss: 206.3731, D Loss: 0.6002
Epoch[24800/50000]
**Valid**: G Loss: 210.1709, D Loss: 0.3620
Epoch[24810/50000]
**Train**: G Loss: 231.4324, D Loss: 0.4241
Epoch[24810/50000]
**Valid**: G Loss: 227.0163, D Loss: 0.9608
Epoch[24820/50000]
**Train**: G Loss: 198.2335, D Loss: 0.6502
Epoch[24820/50000]
**Valid**: G Loss: 196.5790, D Loss: 0.9177
Epoch[24830/50000]
**Train**: G Loss: 237.3575, D Loss: 0.4899
Epoch[24830/50000]
**Valid**: G Loss: 229.1616, D Loss: 0.8518
Epoch[24840/50000]
**Train**: G Loss: 194.6417, D Loss: 0.4186
Epoch[24840/50000]
**Valid**: G Loss: 196.7499, D Loss: 0.6737
Epoch[24850/50000]
**Train**: G Loss: 238.6050, D Loss: 0.6688
Epoch[24850/50000]
**Valid**: G Loss: 223.1702, D Loss: 0.3950
Epoch[24860/50000]
**Train**: G Loss: 204.1427, D Loss: 0.6350
Epoch[24860/50000]
**Valid**: G Loss: 218.0776, D Loss: 0.1241
Epoch[24870/50000]
**Train**: G Loss: 226.8434, D Loss: 0.6219
Epoch[24870/50000]
**Valid**: G Loss: 214.0733, D Loss: 0.2387
Epoch[24880/50000]
**Train**: G Loss: 209.2197, D Loss: 0.4701
Epoch[24880/50000]
**Valid**: G Loss: 219.2260, D Loss: 0.1645
Epoch[24890/50000]
**Train**: G Loss: 224.0819, D Loss: 0.5525
Epoch[24890/50000]
**Valid**: G Loss: 215.3390, D Loss: 0.1032
Epoch[24900/50000]
**Train**: G Loss: 216.8649, D Loss: 0.1925
Epoch[24900/50000]
**Valid**: G Loss: 233.1203, D Loss: 0.1898
Epoch[24910/50000]
**Train**: G Loss: 218.7903, D Loss: 0.4095
Epoch[24910/50000]
**Valid**: G Loss: 211.1362, D Loss: 0.1013
Epoch[24920/50000]
**Train**: G Loss: 217.3866, D Loss: 0.2841
Epoch[24920/50000]
**Valid**: G Loss: 230.2995, D Loss: 0.1738
Epoch[24930/50000]
**Train**: G Loss: 218.4411, D Loss: 0.3452
Epoch[24930/50000]
**Valid**: G Loss: 213.4614, D Loss: -0.0196
Epoch[24940/50000]
**Train**: G Loss: 215.1677, D Loss: 0.5528
Epoch[24940/50000]
**Valid**: G Loss: 224.3681, D Loss: 0.2448
Epoch[24950/50000]
**Train**: G Loss: 211.5406, D Loss: 0.4180
Epoch[24950/50000]
**Valid**: G Loss: 204.3522, D Loss: 0.2722
Epoch[24960/50000]
**Train**: G Loss: 222.5776, D Loss: 0.1619
Epoch[24960/50000]
**Valid**: G Loss: 231.5267, D Loss: 0.2538
Epoch[24970/50000]
**Train**: G Loss: 209.4751, D Loss: 0.2017
Epoch[24970/50000]
**Valid**: G Loss: 199.6868, D Loss: 0.4195
Epoch[24980/50000]
**Train**: G Loss: 221.6463, D Loss: 0.6065
Epoch[24980/50000]
**Valid**: G Loss: 212.9561, D Loss: -0.4546
Epoch[24990/50000]
**Train**: G Loss: 219.1201, D Loss: 0.3557
Epoch[24990/50000]
**Valid**: G Loss: 234.2329, D Loss: -0.0090
Epoch[25000/50000]
**Train**: G Loss: 215.1686, D Loss: 0.0744
Epoch[25000/50000]
**Valid**: G Loss: 206.7309, D Loss: 0.7721
Epoch[25010/50000]
**Train**: G Loss: 237.2297, D Loss: 0.3358
Epoch[25010/50000]
**Valid**: G Loss: 232.2847, D Loss: 0.9636
Epoch[25020/50000]
**Train**: G Loss: 215.8322, D Loss: 0.6573
Epoch[25020/50000]
**Valid**: G Loss: 224.6014, D Loss: 0.2944
Epoch[25030/50000]
**Train**: G Loss: 221.6578, D Loss: 0.5712
Epoch[25030/50000]
**Valid**: G Loss: 211.7933, D Loss: 0.0405
Epoch[25040/50000]
**Train**: G Loss: 219.1039, D Loss: 0.4897
Epoch[25040/50000]
**Valid**: G Loss: 235.7434, D Loss: 0.0636
Epoch[25050/50000]
**Train**: G Loss: 217.6444, D Loss: 0.1037
Epoch[25050/50000]
**Valid**: G Loss: 208.9499, D Loss: 0.1219
Epoch[25060/50000]
**Train**: G Loss: 238.2087, D Loss: -0.0150
Epoch[25060/50000]
**Valid**: G Loss: 245.2409, D Loss: 0.6479
Epoch[25070/50000]
**Train**: G Loss: 201.9595, D Loss: 0.4353
Epoch[25070/50000]
**Valid**: G Loss: 196.5669, D Loss: 0.9650
Epoch[25080/50000]
**Train**: G Loss: 235.9038, D Loss: 0.5447
Epoch[25080/50000]
**Valid**: G Loss: 231.3043, D Loss: 1.1244
Epoch[25090/50000]
**Train**: G Loss: 202.1757, D Loss: 0.5086
Epoch[25090/50000]
**Valid**: G Loss: 205.1088, D Loss: 0.6136
Epoch[25100/50000]
**Train**: G Loss: 231.1552, D Loss: 0.8087
Epoch[25100/50000]
**Valid**: G Loss: 224.8924, D Loss: 0.6744
Epoch[25110/50000]
**Train**: G Loss: 201.4715, D Loss: 0.5522
Epoch[25110/50000]
**Valid**: G Loss: 206.0364, D Loss: 0.5997
Epoch[25120/50000]
**Train**: G Loss: 235.1194, D Loss: 0.6230
Epoch[25120/50000]
**Valid**: G Loss: 226.0873, D Loss: 0.7077
Epoch[25130/50000]
**Train**: G Loss: 199.5808, D Loss: 0.5708
Epoch[25130/50000]
**Valid**: G Loss: 202.2028, D Loss: 0.5791
Epoch[25140/50000]
**Train**: G Loss: 238.7739, D Loss: 0.6760
Epoch[25140/50000]
**Valid**: G Loss: 227.5713, D Loss: 0.9065
Epoch[25150/50000]
**Train**: G Loss: 196.3861, D Loss: 0.6742
Epoch[25150/50000]
**Valid**: G Loss: 200.9532, D Loss: 0.5236
Epoch[25160/50000]
**Train**: G Loss: 236.6859, D Loss: 0.6351
Epoch[25160/50000]
**Valid**: G Loss: 227.2540, D Loss: 0.5686
Epoch[25170/50000]
**Train**: G Loss: 210.1422, D Loss: 0.5534
Epoch[25170/50000]
**Valid**: G Loss: 218.5582, D Loss: 0.2382
Epoch[25180/50000]
**Train**: G Loss: 218.5184, D Loss: 0.4782
Epoch[25180/50000]
**Valid**: G Loss: 208.3645, D Loss: 0.1887
Epoch[25190/50000]
**Train**: G Loss: 231.8957, D Loss: 0.1100
Epoch[25190/50000]
**Valid**: G Loss: 242.3561, D Loss: 0.5940
Epoch[25200/50000]
**Train**: G Loss: 195.4795, D Loss: 0.6606
Epoch[25200/50000]
**Valid**: G Loss: 205.6608, D Loss: 0.6322
Epoch[25210/50000]
**Train**: G Loss: 192.3866, D Loss: -0.0759
Epoch[25210/50000]
**Valid**: G Loss: 186.0055, D Loss: 0.8251
Epoch[25220/50000]
**Train**: G Loss: 241.7195, D Loss: 0.1587
Epoch[25220/50000]
**Valid**: G Loss: 235.4435, D Loss: 1.0578
Epoch[25230/50000]
**Train**: G Loss: 204.4475, D Loss: 0.4138
Epoch[25230/50000]
**Valid**: G Loss: 203.2438, D Loss: 1.0036
Epoch[25240/50000]
**Train**: G Loss: 237.4743, D Loss: 0.6315
Epoch[25240/50000]
**Valid**: G Loss: 228.2463, D Loss: 0.8866
Epoch[25250/50000]
**Train**: G Loss: 205.7192, D Loss: 0.6799
Epoch[25250/50000]
**Valid**: G Loss: 211.4998, D Loss: 0.5397
Epoch[25260/50000]
**Train**: G Loss: 226.6165, D Loss: 0.7377
Epoch[25260/50000]
**Valid**: G Loss: 216.7050, D Loss: 0.0818
Epoch[25270/50000]
**Train**: G Loss: 205.6429, D Loss: 0.6566
Epoch[25270/50000]
**Valid**: G Loss: 213.5262, D Loss: 0.1147
Epoch[25280/50000]
**Train**: G Loss: 227.9645, D Loss: 0.8102
Epoch[25280/50000]
**Valid**: G Loss: 218.3081, D Loss: 0.5066
Epoch[25290/50000]
**Train**: G Loss: 205.5328, D Loss: 0.4326
Epoch[25290/50000]
**Valid**: G Loss: 212.1167, D Loss: 0.2450
Epoch[25300/50000]
**Train**: G Loss: 223.4404, D Loss: 0.6925
Epoch[25300/50000]
**Valid**: G Loss: 216.4514, D Loss: 0.1526
Epoch[25310/50000]
**Train**: G Loss: 208.1924, D Loss: 0.5635
Epoch[25310/50000]
**Valid**: G Loss: 216.3411, D Loss: 0.1467
Epoch[25320/50000]
**Train**: G Loss: 219.1476, D Loss: 0.3611
Epoch[25320/50000]
**Valid**: G Loss: 211.0601, D Loss: 0.0096
Epoch[25330/50000]
**Train**: G Loss: 227.3724, D Loss: 0.2354
Epoch[25330/50000]
**Valid**: G Loss: 240.9435, D Loss: 0.4769
Epoch[25340/50000]
**Train**: G Loss: 205.0515, D Loss: 0.1682
Epoch[25340/50000]
**Valid**: G Loss: 197.9103, D Loss: 0.7690
Epoch[25350/50000]
**Train**: G Loss: 240.1523, D Loss: 0.8170
Epoch[25350/50000]
**Valid**: G Loss: 224.7982, D Loss: 0.5541
Epoch[25360/50000]
**Train**: G Loss: 206.8680, D Loss: 0.6814
Epoch[25360/50000]
**Valid**: G Loss: 210.4381, D Loss: 0.5406
Epoch[25370/50000]
**Train**: G Loss: 228.1457, D Loss: 0.6370
Epoch[25370/50000]
**Valid**: G Loss: 221.9289, D Loss: 0.2256
Epoch[25380/50000]
**Train**: G Loss: 210.8197, D Loss: 0.4886
Epoch[25380/50000]
**Valid**: G Loss: 218.7892, D Loss: 0.2018
Epoch[25390/50000]
**Train**: G Loss: 218.6905, D Loss: 0.3339
Epoch[25390/50000]
**Valid**: G Loss: 214.3007, D Loss: 0.0341
Epoch[25400/50000]
**Train**: G Loss: 217.4977, D Loss: 0.3577
Epoch[25400/50000]
**Valid**: G Loss: 230.5529, D Loss: 0.0880
Epoch[25410/50000]
**Train**: G Loss: 213.9014, D Loss: 0.3703
Epoch[25410/50000]
**Valid**: G Loss: 206.1828, D Loss: 0.5447
Epoch[25420/50000]
**Train**: G Loss: 230.7817, D Loss: 0.2744
Epoch[25420/50000]
**Valid**: G Loss: 244.4251, D Loss: 0.5479
Epoch[25430/50000]
**Train**: G Loss: 197.6152, D Loss: 0.0240
Epoch[25430/50000]
**Valid**: G Loss: 188.7363, D Loss: 0.5545
Epoch[25440/50000]
**Train**: G Loss: 229.9373, D Loss: 0.1839
Epoch[25440/50000]
**Valid**: G Loss: 235.2718, D Loss: 0.6730
Epoch[25450/50000]
**Train**: G Loss: 201.5322, D Loss: 0.2771
Epoch[25450/50000]
**Valid**: G Loss: 198.3643, D Loss: 0.7920
Epoch[25460/50000]
**Train**: G Loss: 239.6191, D Loss: 0.6824
Epoch[25460/50000]
**Valid**: G Loss: 228.6419, D Loss: 0.7491
Epoch[25470/50000]
**Train**: G Loss: 203.7608, D Loss: 0.5814
Epoch[25470/50000]
**Valid**: G Loss: 205.9128, D Loss: 0.4463
Epoch[25480/50000]
**Train**: G Loss: 222.4752, D Loss: 0.5439
Epoch[25480/50000]
**Valid**: G Loss: 218.7573, D Loss: 0.0417
Epoch[25490/50000]
**Train**: G Loss: 209.7568, D Loss: 0.3930
Epoch[25490/50000]
**Valid**: G Loss: 226.2069, D Loss: -0.1186
Epoch[25500/50000]
**Train**: G Loss: 216.0421, D Loss: 0.0770
Epoch[25500/50000]
**Valid**: G Loss: 207.8106, D Loss: 0.2103
Epoch[25510/50000]
**Train**: G Loss: 226.3686, D Loss: 0.0979
Epoch[25510/50000]
**Valid**: G Loss: 240.2728, D Loss: 0.2431
Epoch[25520/50000]
**Train**: G Loss: 208.6705, D Loss: 0.0495
Epoch[25520/50000]
**Valid**: G Loss: 201.1026, D Loss: 0.4977
Epoch[25530/50000]
**Train**: G Loss: 240.1478, D Loss: 0.3945
Epoch[25530/50000]
**Valid**: G Loss: 235.1212, D Loss: 0.9617
Epoch[25540/50000]
**Train**: G Loss: 198.0376, D Loss: 0.6031
Epoch[25540/50000]
**Valid**: G Loss: 199.8759, D Loss: 0.8653
Epoch[25550/50000]
**Train**: G Loss: 239.1604, D Loss: 0.5262
Epoch[25550/50000]
**Valid**: G Loss: 228.0287, D Loss: 0.5590
Epoch[25560/50000]
**Train**: G Loss: 206.0546, D Loss: 0.6732
Epoch[25560/50000]
**Valid**: G Loss: 215.3113, D Loss: 0.0510
Epoch[25570/50000]
**Train**: G Loss: 225.8702, D Loss: 0.6368
Epoch[25570/50000]
**Valid**: G Loss: 214.0899, D Loss: -0.0856
Epoch[25580/50000]
**Train**: G Loss: 209.7594, D Loss: 0.4468
Epoch[25580/50000]
**Valid**: G Loss: 225.2525, D Loss: 0.0080
Epoch[25590/50000]
**Train**: G Loss: 215.6730, D Loss: 0.3783
Epoch[25590/50000]
**Valid**: G Loss: 203.1870, D Loss: 0.1198
Epoch[25600/50000]
**Train**: G Loss: 212.2736, D Loss: 0.3738
Epoch[25600/50000]
**Valid**: G Loss: 222.5375, D Loss: 0.0194
Epoch[25610/50000]
**Train**: G Loss: 222.3713, D Loss: 0.5737
Epoch[25610/50000]
**Valid**: G Loss: 216.3686, D Loss: 0.4777
Epoch[25620/50000]
**Train**: G Loss: 196.5104, D Loss: 0.5832
Epoch[25620/50000]
**Valid**: G Loss: 199.9985, D Loss: 0.5055
Epoch[25630/50000]
**Train**: G Loss: 225.1569, D Loss: 0.7235
Epoch[25630/50000]
**Valid**: G Loss: 217.0553, D Loss: 0.3252
Epoch[25640/50000]
**Train**: G Loss: 208.0872, D Loss: 0.4904
Epoch[25640/50000]
**Valid**: G Loss: 219.5278, D Loss: 0.1041
Epoch[25650/50000]
**Train**: G Loss: 213.6147, D Loss: 0.4078
Epoch[25650/50000]
**Valid**: G Loss: 204.2340, D Loss: -0.0022
Epoch[25660/50000]
**Train**: G Loss: 227.8399, D Loss: 0.1969
Epoch[25660/50000]
**Valid**: G Loss: 239.3122, D Loss: 0.4980
Epoch[25670/50000]
**Train**: G Loss: 203.2042, D Loss: 0.3625
Epoch[25670/50000]
**Valid**: G Loss: 200.7433, D Loss: 0.9276
Epoch[25680/50000]
**Train**: G Loss: 239.6572, D Loss: 0.6162
Epoch[25680/50000]
**Valid**: G Loss: 229.9473, D Loss: 0.7722
Epoch[25690/50000]
**Train**: G Loss: 215.8845, D Loss: 0.4515
Epoch[25690/50000]
**Valid**: G Loss: 229.8045, D Loss: 0.0771
Epoch[25700/50000]
**Train**: G Loss: 217.0923, D Loss: 0.0642
Epoch[25700/50000]
**Valid**: G Loss: 210.8552, D Loss: 0.5042
Epoch[25710/50000]
**Train**: G Loss: 237.4278, D Loss: 0.2492
Epoch[25710/50000]
**Valid**: G Loss: 239.2688, D Loss: 1.0634
Epoch[25720/50000]
**Train**: G Loss: 206.9760, D Loss: 0.2948
Epoch[25720/50000]
**Valid**: G Loss: 206.8626, D Loss: 0.6597
Epoch[25730/50000]
**Train**: G Loss: 239.5086, D Loss: 0.7366
Epoch[25730/50000]
**Valid**: G Loss: 225.7395, D Loss: 0.4458
Epoch[25740/50000]
**Train**: G Loss: 212.1291, D Loss: 0.6798
Epoch[25740/50000]
**Valid**: G Loss: 220.3996, D Loss: 0.3757
Epoch[25750/50000]
**Train**: G Loss: 223.4647, D Loss: 0.4867
Epoch[25750/50000]
**Valid**: G Loss: 214.9113, D Loss: 0.0963
Epoch[25760/50000]
**Train**: G Loss: 226.1493, D Loss: 0.3822
Epoch[25760/50000]
**Valid**: G Loss: 238.1714, D Loss: 0.5391
Epoch[25770/50000]
**Train**: G Loss: 211.0040, D Loss: 0.1604
Epoch[25770/50000]
**Valid**: G Loss: 206.2247, D Loss: 0.6698
Epoch[25780/50000]
**Train**: G Loss: 239.7475, D Loss: 0.4294
Epoch[25780/50000]
**Valid**: G Loss: 238.4516, D Loss: 1.0611
Epoch[25790/50000]
**Train**: G Loss: 206.7648, D Loss: 0.6905
Epoch[25790/50000]
**Valid**: G Loss: 211.6316, D Loss: 0.4065
Epoch[25800/50000]
**Train**: G Loss: 236.4989, D Loss: 0.7093
Epoch[25800/50000]
**Valid**: G Loss: 221.1108, D Loss: 0.1616
Epoch[25810/50000]
**Train**: G Loss: 211.9750, D Loss: 0.6442
Epoch[25810/50000]
**Valid**: G Loss: 224.4287, D Loss: 0.0428
Epoch[25820/50000]
**Train**: G Loss: 222.4956, D Loss: 0.4487
Epoch[25820/50000]
**Valid**: G Loss: 211.9949, D Loss: 0.0450
Epoch[25830/50000]
**Train**: G Loss: 213.0112, D Loss: 0.4077
Epoch[25830/50000]
**Valid**: G Loss: 226.4590, D Loss: -0.3002
Epoch[25840/50000]
**Train**: G Loss: 218.4728, D Loss: 0.4427
Epoch[25840/50000]
**Valid**: G Loss: 213.7592, D Loss: 0.1223
Epoch[25850/50000]
**Train**: G Loss: 223.5133, D Loss: 0.3915
Epoch[25850/50000]
**Valid**: G Loss: 235.6892, D Loss: 0.4628
Epoch[25860/50000]
**Train**: G Loss: 215.9957, D Loss: 0.0556
Epoch[25860/50000]
**Valid**: G Loss: 209.1558, D Loss: 0.4651
Epoch[25870/50000]
**Train**: G Loss: 235.5767, D Loss: 0.4129
Epoch[25870/50000]
**Valid**: G Loss: 238.3299, D Loss: 0.7675
Epoch[25880/50000]
**Train**: G Loss: 209.3577, D Loss: 0.1839
Epoch[25880/50000]
**Valid**: G Loss: 210.4153, D Loss: 0.6348
Epoch[25890/50000]
**Train**: G Loss: 231.1442, D Loss: 0.7742
Epoch[25890/50000]
**Valid**: G Loss: 220.6302, D Loss: 0.0624
Epoch[25900/50000]
**Train**: G Loss: 230.8434, D Loss: 0.1829
Epoch[25900/50000]
**Valid**: G Loss: 246.4434, D Loss: 0.0267
Epoch[25910/50000]
**Train**: G Loss: 209.5024, D Loss: 0.0988
Epoch[25910/50000]
**Valid**: G Loss: 203.7268, D Loss: 0.7916
Epoch[25920/50000]
**Train**: G Loss: 249.0031, D Loss: 0.8324
Epoch[25920/50000]
**Valid**: G Loss: 232.8592, D Loss: 0.6297
Epoch[25930/50000]
**Train**: G Loss: 205.5394, D Loss: 0.6997
Epoch[25930/50000]
**Valid**: G Loss: 209.4760, D Loss: 0.6819
Epoch[25940/50000]
**Train**: G Loss: 230.2001, D Loss: 0.6064
Epoch[25940/50000]
**Valid**: G Loss: 221.8399, D Loss: 0.2924
Epoch[25950/50000]
**Train**: G Loss: 210.5795, D Loss: 0.5960
Epoch[25950/50000]
**Valid**: G Loss: 218.0677, D Loss: 0.2580
Epoch[25960/50000]
**Train**: G Loss: 220.3345, D Loss: 0.6534
Epoch[25960/50000]
**Valid**: G Loss: 214.0901, D Loss: 0.4010
Epoch[25970/50000]
**Train**: G Loss: 209.1993, D Loss: 0.4910
Epoch[25970/50000]
**Valid**: G Loss: 221.8806, D Loss: -0.1510
Epoch[25980/50000]
**Train**: G Loss: 222.2176, D Loss: 0.5902
Epoch[25980/50000]
**Valid**: G Loss: 214.1676, D Loss: 0.2071
Epoch[25990/50000]
**Train**: G Loss: 208.3107, D Loss: 0.5591
Epoch[25990/50000]
**Valid**: G Loss: 219.4702, D Loss: 0.1440
Epoch[26000/50000]
**Train**: G Loss: 220.5981, D Loss: 0.4209
Epoch[26000/50000]
**Valid**: G Loss: 212.3575, D Loss: -0.1055
Epoch[26010/50000]
**Train**: G Loss: 220.2332, D Loss: 0.3394
Epoch[26010/50000]
**Valid**: G Loss: 232.6465, D Loss: 0.3018
Epoch[26020/50000]
**Train**: G Loss: 209.4050, D Loss: -0.0067
Epoch[26020/50000]
**Valid**: G Loss: 204.3712, D Loss: 0.4995
Epoch[26030/50000]
**Train**: G Loss: 236.7439, D Loss: 0.5397
Epoch[26030/50000]
**Valid**: G Loss: 228.9710, D Loss: 0.8487
Epoch[26040/50000]
**Train**: G Loss: 203.8917, D Loss: 0.7494
Epoch[26040/50000]
**Valid**: G Loss: 212.3266, D Loss: 0.3981
Epoch[26050/50000]
**Train**: G Loss: 224.2620, D Loss: 0.4134
Epoch[26050/50000]
**Valid**: G Loss: 214.2351, D Loss: 0.0562
Epoch[26060/50000]
**Train**: G Loss: 228.5803, D Loss: 0.0893
Epoch[26060/50000]
**Valid**: G Loss: 239.8373, D Loss: 0.1137
Epoch[26070/50000]
**Train**: G Loss: 211.3881, D Loss: 0.1347
Epoch[26070/50000]
**Valid**: G Loss: 202.9742, D Loss: 0.5715
Epoch[26080/50000]
**Train**: G Loss: 238.3156, D Loss: 0.4096
Epoch[26080/50000]
**Valid**: G Loss: 233.0243, D Loss: 1.0774
Epoch[26090/50000]
**Train**: G Loss: 202.0881, D Loss: 0.7572
Epoch[26090/50000]
**Valid**: G Loss: 208.0044, D Loss: 0.6844
Epoch[26100/50000]
**Train**: G Loss: 227.1185, D Loss: 0.5550
Epoch[26100/50000]
**Valid**: G Loss: 217.3448, D Loss: -0.2283
Epoch[26110/50000]
**Train**: G Loss: 225.2953, D Loss: 0.2334
Epoch[26110/50000]
**Valid**: G Loss: 241.3126, D Loss: 0.2540
Epoch[26120/50000]
**Train**: G Loss: 214.4927, D Loss: -0.1038
Epoch[26120/50000]
**Valid**: G Loss: 209.2985, D Loss: 0.5566
Epoch[26130/50000]
**Train**: G Loss: 240.1698, D Loss: 0.3371
Epoch[26130/50000]
**Valid**: G Loss: 236.3753, D Loss: 1.0447
Epoch[26140/50000]
**Train**: G Loss: 201.1155, D Loss: 0.3716
Epoch[26140/50000]
**Valid**: G Loss: 198.9556, D Loss: 0.9344
Epoch[26150/50000]
**Train**: G Loss: 233.1944, D Loss: 0.6198
Epoch[26150/50000]
**Valid**: G Loss: 225.5668, D Loss: 0.7251
Epoch[26160/50000]
**Train**: G Loss: 205.4140, D Loss: 0.5065
Epoch[26160/50000]
**Valid**: G Loss: 206.6489, D Loss: 0.6359
Epoch[26170/50000]
**Train**: G Loss: 231.5030, D Loss: 0.6416
Epoch[26170/50000]
**Valid**: G Loss: 224.6302, D Loss: 0.1334
Epoch[26180/50000]
**Train**: G Loss: 210.6399, D Loss: 0.5694
Epoch[26180/50000]
**Valid**: G Loss: 221.5974, D Loss: 0.3397
Epoch[26190/50000]
**Train**: G Loss: 228.1442, D Loss: 0.3838
Epoch[26190/50000]
**Valid**: G Loss: 221.3098, D Loss: -0.0725
Epoch[26200/50000]
**Train**: G Loss: 218.0972, D Loss: 0.3669
Epoch[26200/50000]
**Valid**: G Loss: 232.4611, D Loss: 0.0074
Epoch[26210/50000]
**Train**: G Loss: 218.5187, D Loss: 0.2724
Epoch[26210/50000]
**Valid**: G Loss: 211.6217, D Loss: 0.1112
Epoch[26220/50000]
**Train**: G Loss: 232.9171, D Loss: 0.2404
Epoch[26220/50000]
**Valid**: G Loss: 244.5013, D Loss: 0.7273
Epoch[26230/50000]
**Train**: G Loss: 205.4201, D Loss: 0.1924
Epoch[26230/50000]
**Valid**: G Loss: 200.8091, D Loss: 0.7801
Epoch[26240/50000]
**Train**: G Loss: 245.2370, D Loss: 0.1562
Epoch[26240/50000]
**Valid**: G Loss: 239.1802, D Loss: 0.6317
Epoch[26250/50000]
**Train**: G Loss: 207.8630, D Loss: 0.4591
Epoch[26250/50000]
**Valid**: G Loss: 208.9909, D Loss: 0.8735
Epoch[26260/50000]
**Train**: G Loss: 241.8116, D Loss: 0.6101
Epoch[26260/50000]
**Valid**: G Loss: 232.3055, D Loss: 0.6202
Epoch[26270/50000]
**Train**: G Loss: 211.8799, D Loss: 0.5800
Epoch[26270/50000]
**Valid**: G Loss: 221.4752, D Loss: 0.1737
Epoch[26280/50000]
**Train**: G Loss: 224.5017, D Loss: 0.2434
Epoch[26280/50000]
**Valid**: G Loss: 213.0439, D Loss: 0.3185
Epoch[26290/50000]
**Train**: G Loss: 224.3242, D Loss: 0.2655
Epoch[26290/50000]
**Valid**: G Loss: 242.9026, D Loss: 0.1547
Epoch[26300/50000]
**Train**: G Loss: 221.4833, D Loss: 0.1742
Epoch[26300/50000]
**Valid**: G Loss: 215.0203, D Loss: 0.3989
Epoch[26310/50000]
**Train**: G Loss: 228.5561, D Loss: 0.1099
Epoch[26310/50000]
**Valid**: G Loss: 237.9813, D Loss: 0.3884
Epoch[26320/50000]
**Train**: G Loss: 215.9725, D Loss: 0.2475
Epoch[26320/50000]
**Valid**: G Loss: 211.5412, D Loss: 0.9320
Epoch[26330/50000]
**Train**: G Loss: 238.9258, D Loss: 0.5931
Epoch[26330/50000]
**Valid**: G Loss: 231.9623, D Loss: 0.8598
Epoch[26340/50000]
**Train**: G Loss: 208.7256, D Loss: 0.5643
Epoch[26340/50000]
**Valid**: G Loss: 211.7507, D Loss: 0.5270
Epoch[26350/50000]
**Train**: G Loss: 231.8000, D Loss: 0.7182
Epoch[26350/50000]
**Valid**: G Loss: 221.7227, D Loss: 0.2850
Epoch[26360/50000]
**Train**: G Loss: 208.4387, D Loss: 0.6410
Epoch[26360/50000]
**Valid**: G Loss: 216.8976, D Loss: 0.2634
Epoch[26370/50000]
**Train**: G Loss: 223.2683, D Loss: 0.4276
Epoch[26370/50000]
**Valid**: G Loss: 213.6690, D Loss: -0.0768
Epoch[26380/50000]
**Train**: G Loss: 231.8870, D Loss: 0.2162
Epoch[26380/50000]
**Valid**: G Loss: 245.6067, D Loss: 0.4682
Epoch[26390/50000]
**Train**: G Loss: 204.8709, D Loss: 0.1708
Epoch[26390/50000]
**Valid**: G Loss: 202.1185, D Loss: 0.9149
Epoch[26400/50000]
**Train**: G Loss: 245.3779, D Loss: 0.6380
Epoch[26400/50000]
**Valid**: G Loss: 235.1726, D Loss: 0.7276
Epoch[26410/50000]
**Train**: G Loss: 216.5673, D Loss: 0.4908
Epoch[26410/50000]
**Valid**: G Loss: 231.8751, D Loss: 0.0443
Epoch[26420/50000]
**Train**: G Loss: 215.2525, D Loss: 0.1342
Epoch[26420/50000]
**Valid**: G Loss: 205.2892, D Loss: 0.1734
Epoch[26430/50000]
**Train**: G Loss: 235.2018, D Loss: 0.0392
Epoch[26430/50000]
**Valid**: G Loss: 248.4417, D Loss: 0.3668
Epoch[26440/50000]
**Train**: G Loss: 210.9020, D Loss: 0.1050
Epoch[26440/50000]
**Valid**: G Loss: 207.0456, D Loss: 0.6705
Epoch[26450/50000]
**Train**: G Loss: 238.7406, D Loss: 0.5725
Epoch[26450/50000]
**Valid**: G Loss: 233.4202, D Loss: 0.6606
Epoch[26460/50000]
**Train**: G Loss: 210.3833, D Loss: 0.5390
Epoch[26460/50000]
**Valid**: G Loss: 211.5819, D Loss: 0.5319
Epoch[26470/50000]
**Train**: G Loss: 233.2198, D Loss: 0.6349
Epoch[26470/50000]
**Valid**: G Loss: 226.2309, D Loss: 0.4346
Epoch[26480/50000]
**Train**: G Loss: 211.0196, D Loss: 0.6050
Epoch[26480/50000]
**Valid**: G Loss: 219.9419, D Loss: 0.2204
Epoch[26490/50000]
**Train**: G Loss: 223.1277, D Loss: 0.2032
Epoch[26490/50000]
**Valid**: G Loss: 215.9168, D Loss: -0.1151
Epoch[26500/50000]
**Train**: G Loss: 226.5121, D Loss: 0.1322
Epoch[26500/50000]
**Valid**: G Loss: 237.2512, D Loss: 0.2870
Epoch[26510/50000]
**Train**: G Loss: 209.9437, D Loss: 0.3266
Epoch[26510/50000]
**Valid**: G Loss: 204.0681, D Loss: 0.6799
Epoch[26520/50000]
**Train**: G Loss: 242.3085, D Loss: 0.5854
Epoch[26520/50000]
**Valid**: G Loss: 234.6566, D Loss: 0.6616
Epoch[26530/50000]
**Train**: G Loss: 215.5346, D Loss: 0.8290
Epoch[26530/50000]
**Valid**: G Loss: 219.4082, D Loss: 0.6547
Epoch[26540/50000]
**Train**: G Loss: 228.5898, D Loss: 0.3445
Epoch[26540/50000]
**Valid**: G Loss: 217.5475, D Loss: -0.0519
Epoch[26550/50000]
**Train**: G Loss: 240.4175, D Loss: -0.1398
Epoch[26550/50000]
**Valid**: G Loss: 256.8317, D Loss: 0.2846
Epoch[26560/50000]
**Train**: G Loss: 217.1479, D Loss: 0.2204
Epoch[26560/50000]
**Valid**: G Loss: 211.4717, D Loss: 0.9810
Epoch[26570/50000]
**Train**: G Loss: 240.2823, D Loss: 0.6886
Epoch[26570/50000]
**Valid**: G Loss: 231.9214, D Loss: 0.7496
Epoch[26580/50000]
**Train**: G Loss: 210.7870, D Loss: 0.5543
Epoch[26580/50000]
**Valid**: G Loss: 212.7881, D Loss: 0.5641
Epoch[26590/50000]
**Train**: G Loss: 234.2489, D Loss: 0.6011
Epoch[26590/50000]
**Valid**: G Loss: 225.9841, D Loss: 0.7258
Epoch[26600/50000]
**Train**: G Loss: 212.6811, D Loss: 0.5717
Epoch[26600/50000]
**Valid**: G Loss: 219.7562, D Loss: 0.3962
Epoch[26610/50000]
**Train**: G Loss: 222.1101, D Loss: 0.5005
Epoch[26610/50000]
**Valid**: G Loss: 213.5949, D Loss: 0.0619
Epoch[26620/50000]
**Train**: G Loss: 225.8142, D Loss: 0.1997
Epoch[26620/50000]
**Valid**: G Loss: 240.0117, D Loss: 0.2861
Epoch[26630/50000]
**Train**: G Loss: 216.7834, D Loss: -0.0426
Epoch[26630/50000]
**Valid**: G Loss: 209.0634, D Loss: 0.5638
Epoch[26640/50000]
**Train**: G Loss: 251.0134, D Loss: 0.5606
Epoch[26640/50000]
**Valid**: G Loss: 231.2488, D Loss: 0.7560
Epoch[26650/50000]
**Train**: G Loss: 232.6894, D Loss: 0.1404
Epoch[26650/50000]
**Valid**: G Loss: 251.6964, D Loss: 0.0914
Epoch[26660/50000]
**Train**: G Loss: 215.1064, D Loss: -0.1289
Epoch[26660/50000]
**Valid**: G Loss: 207.4140, D Loss: 0.4736
Epoch[26670/50000]
**Train**: G Loss: 242.4203, D Loss: 0.1162
Epoch[26670/50000]
**Valid**: G Loss: 250.0487, D Loss: 0.8418
Epoch[26680/50000]
**Train**: G Loss: 212.8671, D Loss: 0.1262
Epoch[26680/50000]
**Valid**: G Loss: 207.4639, D Loss: 0.6964
Epoch[26690/50000]
**Train**: G Loss: 236.6980, D Loss: 0.1434
Epoch[26690/50000]
**Valid**: G Loss: 241.7729, D Loss: 0.5719
Epoch[26700/50000]
**Train**: G Loss: 213.3415, D Loss: 0.1603
Epoch[26700/50000]
**Valid**: G Loss: 209.1586, D Loss: 0.8067
Epoch[26710/50000]
**Train**: G Loss: 235.2699, D Loss: 0.5261
Epoch[26710/50000]
**Valid**: G Loss: 230.6147, D Loss: 1.3421
Epoch[26720/50000]
**Train**: G Loss: 205.0306, D Loss: 0.5904
Epoch[26720/50000]
**Valid**: G Loss: 206.0165, D Loss: 0.6915
Epoch[26730/50000]
**Train**: G Loss: 236.3952, D Loss: 0.7472
Epoch[26730/50000]
**Valid**: G Loss: 230.2889, D Loss: 0.7516
Epoch[26740/50000]
**Train**: G Loss: 212.0596, D Loss: 0.6370
Epoch[26740/50000]
**Valid**: G Loss: 214.7234, D Loss: 0.6401
Epoch[26750/50000]
**Train**: G Loss: 237.2604, D Loss: 0.7119
Epoch[26750/50000]
**Valid**: G Loss: 227.7606, D Loss: 0.7759
Epoch[26760/50000]
**Train**: G Loss: 212.0612, D Loss: 0.6284
Epoch[26760/50000]
**Valid**: G Loss: 221.1364, D Loss: 0.1439
Epoch[26770/50000]
**Train**: G Loss: 235.7027, D Loss: 0.6439
Epoch[26770/50000]
**Valid**: G Loss: 229.6234, D Loss: 0.4511
Epoch[26780/50000]
**Train**: G Loss: 211.9524, D Loss: 0.6836
Epoch[26780/50000]
**Valid**: G Loss: 217.0318, D Loss: 0.4960
Epoch[26790/50000]
**Train**: G Loss: 239.5076, D Loss: 0.6091
Epoch[26790/50000]
**Valid**: G Loss: 227.1885, D Loss: 0.2713
Epoch[26800/50000]
**Train**: G Loss: 216.1933, D Loss: 0.7459
Epoch[26800/50000]
**Valid**: G Loss: 225.6543, D Loss: 0.2728
Epoch[26810/50000]
**Train**: G Loss: 227.0241, D Loss: 0.5857
Epoch[26810/50000]
**Valid**: G Loss: 221.7032, D Loss: -0.0101
Epoch[26820/50000]
**Train**: G Loss: 220.4257, D Loss: 0.4527
Epoch[26820/50000]
**Valid**: G Loss: 229.6617, D Loss: 0.0736
Epoch[26830/50000]
**Train**: G Loss: 223.2702, D Loss: 0.5072
Epoch[26830/50000]
**Valid**: G Loss: 215.3099, D Loss: 0.3549
Epoch[26840/50000]
**Train**: G Loss: 246.9839, D Loss: 0.4708
Epoch[26840/50000]
**Valid**: G Loss: 237.1564, D Loss: 1.3044
Epoch[26850/50000]
**Train**: G Loss: 201.3342, D Loss: 0.7177
Epoch[26850/50000]
**Valid**: G Loss: 211.2372, D Loss: 0.3749
Epoch[26860/50000]
**Train**: G Loss: 235.6547, D Loss: 0.7210
Epoch[26860/50000]
**Valid**: G Loss: 222.4327, D Loss: 0.0312
Epoch[26870/50000]
**Train**: G Loss: 208.4725, D Loss: 0.5803
Epoch[26870/50000]
**Valid**: G Loss: 217.1611, D Loss: 0.3077
Epoch[26880/50000]
**Train**: G Loss: 234.4280, D Loss: 0.7512
Epoch[26880/50000]
**Valid**: G Loss: 225.5019, D Loss: 0.3777
Epoch[26890/50000]
**Train**: G Loss: 210.9156, D Loss: 0.4389
Epoch[26890/50000]
**Valid**: G Loss: 219.8893, D Loss: 0.2009
Epoch[26900/50000]
**Train**: G Loss: 226.3833, D Loss: 0.5592
Epoch[26900/50000]
**Valid**: G Loss: 217.4170, D Loss: -0.0208
Epoch[26910/50000]
**Train**: G Loss: 217.7922, D Loss: 0.3358
Epoch[26910/50000]
**Valid**: G Loss: 230.2957, D Loss: 0.0811
Epoch[26920/50000]
**Train**: G Loss: 224.0237, D Loss: 0.0689
Epoch[26920/50000]
**Valid**: G Loss: 218.1497, D Loss: 0.2495
Epoch[26930/50000]
**Train**: G Loss: 234.1731, D Loss: 0.1202
Epoch[26930/50000]
**Valid**: G Loss: 242.0392, D Loss: 0.8002
Epoch[26940/50000]
**Train**: G Loss: 221.6088, D Loss: 0.2032
Epoch[26940/50000]
**Valid**: G Loss: 217.2362, D Loss: 0.6559
Epoch[26950/50000]
**Train**: G Loss: 240.0246, D Loss: 0.7393
Epoch[26950/50000]
**Valid**: G Loss: 232.2843, D Loss: 0.9196
Epoch[26960/50000]
**Train**: G Loss: 216.0596, D Loss: 0.7161
Epoch[26960/50000]
**Valid**: G Loss: 223.0718, D Loss: 0.3802
Epoch[26970/50000]
**Train**: G Loss: 233.4510, D Loss: 0.6519
Epoch[26970/50000]
**Valid**: G Loss: 226.4370, D Loss: -0.0102
Epoch[26980/50000]
**Train**: G Loss: 213.2781, D Loss: 0.7984
Epoch[26980/50000]
**Valid**: G Loss: 223.9678, D Loss: 0.1039
Epoch[26990/50000]
**Train**: G Loss: 223.3591, D Loss: 0.4253
Epoch[26990/50000]
**Valid**: G Loss: 212.2519, D Loss: 0.0557
Epoch[27000/50000]
**Train**: G Loss: 222.5431, D Loss: 0.2517
Epoch[27000/50000]
**Valid**: G Loss: 237.9293, D Loss: -0.0753
Epoch[27010/50000]
**Train**: G Loss: 223.4276, D Loss: 0.4048
Epoch[27010/50000]
**Valid**: G Loss: 215.6643, D Loss: 0.0228
Epoch[27020/50000]
**Train**: G Loss: 224.8587, D Loss: 0.1692
Epoch[27020/50000]
**Valid**: G Loss: 240.3665, D Loss: -0.0646
Epoch[27030/50000]
**Train**: G Loss: 219.0707, D Loss: 0.0713
Epoch[27030/50000]
**Valid**: G Loss: 212.6442, D Loss: 0.0104
Epoch[27040/50000]
**Train**: G Loss: 223.4546, D Loss: 0.3497
Epoch[27040/50000]
**Valid**: G Loss: 233.5629, D Loss: 0.2386
Epoch[27050/50000]
**Train**: G Loss: 217.6464, D Loss: 0.2888
Epoch[27050/50000]
**Valid**: G Loss: 210.5859, D Loss: 0.1026
Epoch[27060/50000]
**Train**: G Loss: 214.9265, D Loss: 0.6105
Epoch[27060/50000]
**Valid**: G Loss: 224.1207, D Loss: 0.3004
Epoch[27070/50000]
**Train**: G Loss: 223.3310, D Loss: 0.5793
Epoch[27070/50000]
**Valid**: G Loss: 214.7625, D Loss: 0.2423
Epoch[27080/50000]
**Train**: G Loss: 213.4960, D Loss: 0.4440
Epoch[27080/50000]
**Valid**: G Loss: 225.7556, D Loss: 0.0378
Epoch[27090/50000]
**Train**: G Loss: 216.9746, D Loss: 0.4490
Epoch[27090/50000]
**Valid**: G Loss: 210.9691, D Loss: 0.3483
Epoch[27100/50000]
**Train**: G Loss: 213.0280, D Loss: 0.4959
Epoch[27100/50000]
**Valid**: G Loss: 228.6911, D Loss: 0.2105
Epoch[27110/50000]
**Train**: G Loss: 218.2000, D Loss: 0.3971
Epoch[27110/50000]
**Valid**: G Loss: 207.8327, D Loss: -0.0870
Epoch[27120/50000]
**Train**: G Loss: 209.4862, D Loss: 0.4936
Epoch[27120/50000]
**Valid**: G Loss: 221.8497, D Loss: 0.1338
Epoch[27130/50000]
**Train**: G Loss: 232.2209, D Loss: 0.6390
Epoch[27130/50000]
**Valid**: G Loss: 222.8248, D Loss: 0.3566
Epoch[27140/50000]
**Train**: G Loss: 210.0414, D Loss: 0.4790
Epoch[27140/50000]
**Valid**: G Loss: 214.5987, D Loss: 0.4388
Epoch[27150/50000]
**Train**: G Loss: 229.7548, D Loss: 0.7788
Epoch[27150/50000]
**Valid**: G Loss: 223.9467, D Loss: 0.7722
Epoch[27160/50000]
**Train**: G Loss: 210.1041, D Loss: 0.6556
Epoch[27160/50000]
**Valid**: G Loss: 215.9884, D Loss: 0.4116
Epoch[27170/50000]
**Train**: G Loss: 231.9362, D Loss: 0.7170
Epoch[27170/50000]
**Valid**: G Loss: 223.4815, D Loss: 0.2851
Epoch[27180/50000]
**Train**: G Loss: 202.7106, D Loss: 0.6962
Epoch[27180/50000]
**Valid**: G Loss: 212.1074, D Loss: 0.3165
Epoch[27190/50000]
**Train**: G Loss: 231.2409, D Loss: 0.5559
Epoch[27190/50000]
**Valid**: G Loss: 224.1189, D Loss: 0.2653
Epoch[27200/50000]
**Train**: G Loss: 208.5402, D Loss: 0.5246
Epoch[27200/50000]
**Valid**: G Loss: 219.6316, D Loss: 0.0156
Epoch[27210/50000]
**Train**: G Loss: 228.3596, D Loss: 0.7956
Epoch[27210/50000]
**Valid**: G Loss: 220.0429, D Loss: 0.3056
Epoch[27220/50000]
**Train**: G Loss: 205.3808, D Loss: 0.7607
Epoch[27220/50000]
**Valid**: G Loss: 213.0551, D Loss: 0.4784
Epoch[27230/50000]
**Train**: G Loss: 234.0486, D Loss: 0.6872
Epoch[27230/50000]
**Valid**: G Loss: 224.7904, D Loss: 0.6763
Epoch[27240/50000]
**Train**: G Loss: 207.7011, D Loss: 0.6867
Epoch[27240/50000]
**Valid**: G Loss: 213.5275, D Loss: 0.2948
Epoch[27250/50000]
**Train**: G Loss: 234.4878, D Loss: 0.7661
Epoch[27250/50000]
**Valid**: G Loss: 222.0368, D Loss: 0.5298
Epoch[27260/50000]
**Train**: G Loss: 212.7491, D Loss: 0.6809
Epoch[27260/50000]
**Valid**: G Loss: 217.2018, D Loss: 0.6241
Epoch[27270/50000]
**Train**: G Loss: 233.1757, D Loss: 0.6605
Epoch[27270/50000]
**Valid**: G Loss: 224.9181, D Loss: 0.1718
Epoch[27280/50000]
**Train**: G Loss: 231.8216, D Loss: 0.1593
Epoch[27280/50000]
**Valid**: G Loss: 246.1377, D Loss: 0.0738
Epoch[27290/50000]
**Train**: G Loss: 219.1272, D Loss: 0.1481
Epoch[27290/50000]
**Valid**: G Loss: 211.1012, D Loss: 0.2059
Epoch[27300/50000]
**Train**: G Loss: 241.0102, D Loss: 0.2898
Epoch[27300/50000]
**Valid**: G Loss: 243.4979, D Loss: 0.8442
Epoch[27310/50000]
**Train**: G Loss: 209.8954, D Loss: 0.5009
Epoch[27310/50000]
**Valid**: G Loss: 209.4371, D Loss: 0.8642
Epoch[27320/50000]
**Train**: G Loss: 242.4368, D Loss: 0.6339
Epoch[27320/50000]
**Valid**: G Loss: 234.4528, D Loss: 0.7603
Epoch[27330/50000]
**Train**: G Loss: 215.7104, D Loss: 0.6818
Epoch[27330/50000]
**Valid**: G Loss: 226.9637, D Loss: 0.2117
Epoch[27340/50000]
**Train**: G Loss: 225.9303, D Loss: 0.3224
Epoch[27340/50000]
**Valid**: G Loss: 219.3266, D Loss: 0.0294
Epoch[27350/50000]
**Train**: G Loss: 227.5800, D Loss: 0.2260
Epoch[27350/50000]
**Valid**: G Loss: 239.6865, D Loss: 0.1906
Epoch[27360/50000]
**Train**: G Loss: 217.3355, D Loss: 0.2204
Epoch[27360/50000]
**Valid**: G Loss: 209.4430, D Loss: 0.5071
Epoch[27370/50000]
**Train**: G Loss: 238.3910, D Loss: 0.2363
Epoch[27370/50000]
**Valid**: G Loss: 248.9499, D Loss: 0.4818
Epoch[27380/50000]
**Train**: G Loss: 210.0757, D Loss: 0.2016
Epoch[27380/50000]
**Valid**: G Loss: 203.1364, D Loss: 0.7546
Epoch[27390/50000]
**Train**: G Loss: 238.5708, D Loss: 0.2580
Epoch[27390/50000]
**Valid**: G Loss: 246.2619, D Loss: 0.6314
Epoch[27400/50000]
**Train**: G Loss: 219.8720, D Loss: 0.2584
Epoch[27400/50000]
**Valid**: G Loss: 212.9830, D Loss: 0.1666
Epoch[27410/50000]
**Train**: G Loss: 225.9664, D Loss: 0.2389
Epoch[27410/50000]
**Valid**: G Loss: 238.2817, D Loss: 0.3190
Epoch[27420/50000]
**Train**: G Loss: 217.4998, D Loss: 0.2616
Epoch[27420/50000]
**Valid**: G Loss: 211.4614, D Loss: 0.3830
Epoch[27430/50000]
**Train**: G Loss: 228.1593, D Loss: 0.1975
Epoch[27430/50000]
**Valid**: G Loss: 234.3150, D Loss: 0.6320
Epoch[27440/50000]
**Train**: G Loss: 208.0568, D Loss: 0.0909
Epoch[27440/50000]
**Valid**: G Loss: 202.1864, D Loss: 0.8394
Epoch[27450/50000]
**Train**: G Loss: 237.7793, D Loss: 0.4826
Epoch[27450/50000]
**Valid**: G Loss: 236.2331, D Loss: 0.9485
Epoch[27460/50000]
**Train**: G Loss: 204.6844, D Loss: 0.2621
Epoch[27460/50000]
**Valid**: G Loss: 203.9031, D Loss: 0.6912
Epoch[27470/50000]
**Train**: G Loss: 242.5740, D Loss: 0.2711
Epoch[27470/50000]
**Valid**: G Loss: 242.1195, D Loss: 0.8263
Epoch[27480/50000]
**Train**: G Loss: 204.9544, D Loss: 0.5133
Epoch[27480/50000]
**Valid**: G Loss: 204.4395, D Loss: 0.8794
Epoch[27490/50000]
**Train**: G Loss: 237.8150, D Loss: 0.4195
Epoch[27490/50000]
**Valid**: G Loss: 235.9460, D Loss: 1.0607
Epoch[27500/50000]
**Train**: G Loss: 211.2761, D Loss: 0.3123
Epoch[27500/50000]
**Valid**: G Loss: 208.5658, D Loss: 0.6601
Epoch[27510/50000]
**Train**: G Loss: 236.2258, D Loss: 0.4276
Epoch[27510/50000]
**Valid**: G Loss: 231.0473, D Loss: 0.9264
Epoch[27520/50000]
**Train**: G Loss: 198.2234, D Loss: 0.3352
Epoch[27520/50000]
**Valid**: G Loss: 195.1215, D Loss: 0.8122
Epoch[27530/50000]
**Train**: G Loss: 243.5069, D Loss: 0.2740
Epoch[27530/50000]
**Valid**: G Loss: 245.1062, D Loss: 0.8136
Epoch[27540/50000]
**Train**: G Loss: 207.0481, D Loss: 0.3923
Epoch[27540/50000]
**Valid**: G Loss: 202.1035, D Loss: 0.8263
Epoch[27550/50000]
**Train**: G Loss: 244.9810, D Loss: 0.5747
Epoch[27550/50000]
**Valid**: G Loss: 238.4582, D Loss: 1.0040
Epoch[27560/50000]
**Train**: G Loss: 208.7480, D Loss: 0.8105
Epoch[27560/50000]
**Valid**: G Loss: 212.0061, D Loss: 0.8078
Epoch[27570/50000]
**Train**: G Loss: 233.0943, D Loss: 0.6532
Epoch[27570/50000]
**Valid**: G Loss: 224.7113, D Loss: 0.1639
Epoch[27580/50000]
**Train**: G Loss: 230.3562, D Loss: 0.3036
Epoch[27580/50000]
**Valid**: G Loss: 244.9750, D Loss: -0.0711
Epoch[27590/50000]
**Train**: G Loss: 219.9599, D Loss: 0.1826
Epoch[27590/50000]
**Valid**: G Loss: 212.5811, D Loss: 0.3505
Epoch[27600/50000]
**Train**: G Loss: 224.6900, D Loss: 0.2436
Epoch[27600/50000]
**Valid**: G Loss: 233.0827, D Loss: 0.3050
Epoch[27610/50000]
**Train**: G Loss: 210.1498, D Loss: 0.1380
Epoch[27610/50000]
**Valid**: G Loss: 204.7329, D Loss: 0.4065
Epoch[27620/50000]
**Train**: G Loss: 222.1563, D Loss: 0.3652
Epoch[27620/50000]
**Valid**: G Loss: 222.8963, D Loss: 0.7988
Epoch[27630/50000]
**Train**: G Loss: 202.9008, D Loss: 0.1471
Epoch[27630/50000]
**Valid**: G Loss: 199.0313, D Loss: 0.7273
Epoch[27640/50000]
**Train**: G Loss: 230.3594, D Loss: 0.3780
Epoch[27640/50000]
**Valid**: G Loss: 227.7211, D Loss: 0.9058
Epoch[27650/50000]
**Train**: G Loss: 198.6768, D Loss: 0.4874
Epoch[27650/50000]
**Valid**: G Loss: 194.0294, D Loss: 0.9487
Epoch[27660/50000]
**Train**: G Loss: 229.1927, D Loss: 0.5169
Epoch[27660/50000]
**Valid**: G Loss: 224.6153, D Loss: 1.2272
Epoch[27670/50000]
**Train**: G Loss: 200.1398, D Loss: 0.2426
Epoch[27670/50000]
**Valid**: G Loss: 197.3422, D Loss: 0.7702
Epoch[27680/50000]
**Train**: G Loss: 227.3260, D Loss: 0.5853
Epoch[27680/50000]
**Valid**: G Loss: 222.5878, D Loss: 0.6421
Epoch[27690/50000]
**Train**: G Loss: 196.0711, D Loss: 0.6808
Epoch[27690/50000]
**Valid**: G Loss: 195.8156, D Loss: 0.7134
Epoch[27700/50000]
**Train**: G Loss: 229.3529, D Loss: 0.4977
Epoch[27700/50000]
**Valid**: G Loss: 222.9929, D Loss: 1.0198
Epoch[27710/50000]
**Train**: G Loss: 192.7641, D Loss: 0.2147
Epoch[27710/50000]
**Valid**: G Loss: 188.8469, D Loss: 0.7483
Epoch[27720/50000]
**Train**: G Loss: 235.3683, D Loss: 0.5707
Epoch[27720/50000]
**Valid**: G Loss: 224.7837, D Loss: 0.9785
Epoch[27730/50000]
**Train**: G Loss: 202.3414, D Loss: 0.6700
Epoch[27730/50000]
**Valid**: G Loss: 209.1781, D Loss: 0.6267
Epoch[27740/50000]
**Train**: G Loss: 222.5934, D Loss: 0.7241
Epoch[27740/50000]
**Valid**: G Loss: 209.9133, D Loss: -0.0292
Epoch[27750/50000]
**Train**: G Loss: 201.1779, D Loss: 0.8397
Epoch[27750/50000]
**Valid**: G Loss: 209.2485, D Loss: 0.4517
Epoch[27760/50000]
**Train**: G Loss: 223.6806, D Loss: 0.7177
Epoch[27760/50000]
**Valid**: G Loss: 215.3882, D Loss: 0.2759
Epoch[27770/50000]
**Train**: G Loss: 201.8158, D Loss: 0.8249
Epoch[27770/50000]
**Valid**: G Loss: 210.4337, D Loss: 0.5864
Epoch[27780/50000]
**Train**: G Loss: 218.8143, D Loss: 0.8528
Epoch[27780/50000]
**Valid**: G Loss: 209.7880, D Loss: 0.1136
Epoch[27790/50000]
**Train**: G Loss: 198.6969, D Loss: 0.5543
Epoch[27790/50000]
**Valid**: G Loss: 203.3402, D Loss: 0.5181
Epoch[27800/50000]
**Train**: G Loss: 221.3041, D Loss: 0.6724
Epoch[27800/50000]
**Valid**: G Loss: 213.6945, D Loss: 0.4567
Epoch[27810/50000]
**Train**: G Loss: 192.9772, D Loss: 0.6547
Epoch[27810/50000]
**Valid**: G Loss: 191.8567, D Loss: 1.0299
Epoch[27820/50000]
**Train**: G Loss: 229.0618, D Loss: 0.7659
Epoch[27820/50000]
**Valid**: G Loss: 223.7132, D Loss: 1.0460
Epoch[27830/50000]
**Train**: G Loss: 195.7029, D Loss: 0.4617
Epoch[27830/50000]
**Valid**: G Loss: 196.6883, D Loss: 0.7658
Epoch[27840/50000]
**Train**: G Loss: 232.3876, D Loss: 0.6048
Epoch[27840/50000]
**Valid**: G Loss: 223.9785, D Loss: 1.1107
Epoch[27850/50000]
**Train**: G Loss: 203.2691, D Loss: 0.3775
Epoch[27850/50000]
**Valid**: G Loss: 202.2771, D Loss: 0.8006
Epoch[27860/50000]
**Train**: G Loss: 231.2290, D Loss: 0.5891
Epoch[27860/50000]
**Valid**: G Loss: 224.3117, D Loss: 0.8681
Epoch[27870/50000]
**Train**: G Loss: 196.1246, D Loss: 0.6312
Epoch[27870/50000]
**Valid**: G Loss: 203.1029, D Loss: 0.4004
Epoch[27880/50000]
**Train**: G Loss: 222.9265, D Loss: 0.8139
Epoch[27880/50000]
**Valid**: G Loss: 215.6267, D Loss: 0.6606
Epoch[27890/50000]
**Train**: G Loss: 199.3668, D Loss: 0.5535
Epoch[27890/50000]
**Valid**: G Loss: 201.2413, D Loss: 0.7547
Epoch[27900/50000]
**Train**: G Loss: 226.9719, D Loss: 0.5244
Epoch[27900/50000]
**Valid**: G Loss: 222.7153, D Loss: 0.9248
Epoch[27910/50000]
**Train**: G Loss: 198.3272, D Loss: 0.4005
Epoch[27910/50000]
**Valid**: G Loss: 193.8190, D Loss: 0.8828
Epoch[27920/50000]
**Train**: G Loss: 229.1414, D Loss: 0.3165
Epoch[27920/50000]
**Valid**: G Loss: 231.1753, D Loss: 0.9435
Epoch[27930/50000]
**Train**: G Loss: 204.8049, D Loss: 0.0783
Epoch[27930/50000]
**Valid**: G Loss: 198.4327, D Loss: 0.5729
Epoch[27940/50000]
**Train**: G Loss: 226.2728, D Loss: 0.2696
Epoch[27940/50000]
**Valid**: G Loss: 229.9155, D Loss: 0.7880
Epoch[27950/50000]
**Train**: G Loss: 205.8933, D Loss: 0.0925
Epoch[27950/50000]
**Valid**: G Loss: 200.8760, D Loss: 0.8483
Epoch[27960/50000]
**Train**: G Loss: 221.7722, D Loss: 0.2998
Epoch[27960/50000]
**Valid**: G Loss: 226.7113, D Loss: 0.8319
Epoch[27970/50000]
**Train**: G Loss: 202.2232, D Loss: 0.1679
Epoch[27970/50000]
**Valid**: G Loss: 194.6638, D Loss: 0.4132
Epoch[27980/50000]
**Train**: G Loss: 224.6875, D Loss: 0.2239
Epoch[27980/50000]
**Valid**: G Loss: 230.0589, D Loss: 0.6673
Epoch[27990/50000]
**Train**: G Loss: 198.8833, D Loss: 0.1076
Epoch[27990/50000]
**Valid**: G Loss: 192.8902, D Loss: 0.7588
Epoch[28000/50000]
**Train**: G Loss: 232.8300, D Loss: 0.1388
Epoch[28000/50000]
**Valid**: G Loss: 236.4105, D Loss: 0.7831
Epoch[28010/50000]
**Train**: G Loss: 203.1470, D Loss: 0.2508
Epoch[28010/50000]
**Valid**: G Loss: 198.0678, D Loss: 0.9024
Epoch[28020/50000]
**Train**: G Loss: 231.8823, D Loss: 0.1737
Epoch[28020/50000]
**Valid**: G Loss: 235.8173, D Loss: 0.6667
Epoch[28030/50000]
**Train**: G Loss: 208.4354, D Loss: 0.1345
Epoch[28030/50000]
**Valid**: G Loss: 201.7178, D Loss: 0.4856
Epoch[28040/50000]
**Train**: G Loss: 229.2088, D Loss: 0.2208
Epoch[28040/50000]
**Valid**: G Loss: 240.2159, D Loss: 0.4487
Epoch[28050/50000]
**Train**: G Loss: 219.3844, D Loss: 0.0083
Epoch[28050/50000]
**Valid**: G Loss: 215.8721, D Loss: 0.2788
Epoch[28060/50000]
**Train**: G Loss: 223.7580, D Loss: 0.3094
Epoch[28060/50000]
**Valid**: G Loss: 233.2910, D Loss: 0.6022
Epoch[28070/50000]
**Train**: G Loss: 213.5528, D Loss: 0.3585
Epoch[28070/50000]
**Valid**: G Loss: 207.0286, D Loss: 0.2587
Epoch[28080/50000]
**Train**: G Loss: 219.2482, D Loss: 0.3923
Epoch[28080/50000]
**Valid**: G Loss: 229.9761, D Loss: 0.3419
Epoch[28090/50000]
**Train**: G Loss: 213.9809, D Loss: 0.2792
Epoch[28090/50000]
**Valid**: G Loss: 207.5273, D Loss: 0.3822
Epoch[28100/50000]
**Train**: G Loss: 232.0575, D Loss: 0.3380
Epoch[28100/50000]
**Valid**: G Loss: 236.1078, D Loss: 0.9016
Epoch[28110/50000]
**Train**: G Loss: 207.7663, D Loss: 0.3293
Epoch[28110/50000]
**Valid**: G Loss: 202.5714, D Loss: 0.9541
Epoch[28120/50000]
**Train**: G Loss: 234.4576, D Loss: 0.4485
Epoch[28120/50000]
**Valid**: G Loss: 228.2828, D Loss: 0.9801
Epoch[28130/50000]
**Train**: G Loss: 208.5377, D Loss: 0.5072
Epoch[28130/50000]
**Valid**: G Loss: 212.1467, D Loss: 0.5624
Epoch[28140/50000]
**Train**: G Loss: 226.8419, D Loss: 0.8121
Epoch[28140/50000]
**Valid**: G Loss: 218.4945, D Loss: 0.4814
Epoch[28150/50000]
**Train**: G Loss: 204.9529, D Loss: 0.6697
Epoch[28150/50000]
**Valid**: G Loss: 214.1189, D Loss: 0.2652
Epoch[28160/50000]
**Train**: G Loss: 220.2300, D Loss: 0.4131
Epoch[28160/50000]
**Valid**: G Loss: 210.2091, D Loss: -0.2021
Epoch[28170/50000]
**Train**: G Loss: 232.0204, D Loss: 0.1304
Epoch[28170/50000]
**Valid**: G Loss: 242.1048, D Loss: 0.7478
Epoch[28180/50000]
**Train**: G Loss: 209.8394, D Loss: 0.0323
Epoch[28180/50000]
**Valid**: G Loss: 204.1284, D Loss: 0.8034
Epoch[28190/50000]
**Train**: G Loss: 236.8974, D Loss: 0.3210
Epoch[28190/50000]
**Valid**: G Loss: 238.0305, D Loss: 0.8704
Epoch[28200/50000]
**Train**: G Loss: 208.6496, D Loss: 0.4947
Epoch[28200/50000]
**Valid**: G Loss: 207.6319, D Loss: 0.7016
Epoch[28210/50000]
**Train**: G Loss: 237.5575, D Loss: 0.7046
Epoch[28210/50000]
**Valid**: G Loss: 228.7463, D Loss: 0.5187
Epoch[28220/50000]
**Train**: G Loss: 215.0825, D Loss: 0.6241
Epoch[28220/50000]
**Valid**: G Loss: 224.9713, D Loss: 0.3684
Epoch[28230/50000]
**Train**: G Loss: 224.0780, D Loss: 0.4189
Epoch[28230/50000]
**Valid**: G Loss: 219.1040, D Loss: 0.2769
Epoch[28240/50000]
**Train**: G Loss: 233.7508, D Loss: 0.2914
Epoch[28240/50000]
**Valid**: G Loss: 240.5826, D Loss: 0.5457
Epoch[28250/50000]
**Train**: G Loss: 215.7104, D Loss: 0.2146
Epoch[28250/50000]
**Valid**: G Loss: 210.5966, D Loss: 0.3475
Epoch[28260/50000]
**Train**: G Loss: 237.9071, D Loss: 0.2155
Epoch[28260/50000]
**Valid**: G Loss: 242.2132, D Loss: 0.8338
Epoch[28270/50000]
**Train**: G Loss: 205.0429, D Loss: 0.0580
Epoch[28270/50000]
**Valid**: G Loss: 200.9702, D Loss: 0.8380
Epoch[28280/50000]
**Train**: G Loss: 246.8346, D Loss: 0.4293
Epoch[28280/50000]
**Valid**: G Loss: 239.6065, D Loss: 0.9437
Epoch[28290/50000]
**Train**: G Loss: 206.3928, D Loss: 0.4635
Epoch[28290/50000]
**Valid**: G Loss: 204.6025, D Loss: 1.2323
Epoch[28300/50000]
**Train**: G Loss: 245.0035, D Loss: 0.6163
Epoch[28300/50000]
**Valid**: G Loss: 239.1284, D Loss: 0.9432
Epoch[28310/50000]
**Train**: G Loss: 208.3264, D Loss: 0.7395
Epoch[28310/50000]
**Valid**: G Loss: 210.1464, D Loss: 0.7787
Epoch[28320/50000]
**Train**: G Loss: 231.2594, D Loss: 0.7112
Epoch[28320/50000]
**Valid**: G Loss: 223.3518, D Loss: 0.0855
Epoch[28330/50000]
**Train**: G Loss: 214.2806, D Loss: 0.6002
Epoch[28330/50000]
**Valid**: G Loss: 222.2827, D Loss: 0.2758
Epoch[28340/50000]
**Train**: G Loss: 225.7648, D Loss: 0.7405
Epoch[28340/50000]
**Valid**: G Loss: 220.8993, D Loss: 0.1687
Epoch[28350/50000]
**Train**: G Loss: 212.4861, D Loss: 0.5665
Epoch[28350/50000]
**Valid**: G Loss: 216.4423, D Loss: 0.3349
Epoch[28360/50000]
**Train**: G Loss: 225.4516, D Loss: 0.5131
Epoch[28360/50000]
**Valid**: G Loss: 221.2611, D Loss: 0.1803
Epoch[28370/50000]
**Train**: G Loss: 212.9242, D Loss: 0.4771
Epoch[28370/50000]
**Valid**: G Loss: 220.4241, D Loss: 0.1298
Epoch[28380/50000]
**Train**: G Loss: 228.6255, D Loss: 0.6432
Epoch[28380/50000]
**Valid**: G Loss: 222.4010, D Loss: 0.1572
Epoch[28390/50000]
**Train**: G Loss: 205.1236, D Loss: 0.7122
Epoch[28390/50000]
**Valid**: G Loss: 209.5828, D Loss: 0.5618
Epoch[28400/50000]
**Train**: G Loss: 232.9522, D Loss: 0.8040
Epoch[28400/50000]
**Valid**: G Loss: 221.4980, D Loss: 0.5345
Epoch[28410/50000]
**Train**: G Loss: 207.6645, D Loss: 0.5974
Epoch[28410/50000]
**Valid**: G Loss: 217.3991, D Loss: 0.2565
Epoch[28420/50000]
**Train**: G Loss: 227.9400, D Loss: 0.6373
Epoch[28420/50000]
**Valid**: G Loss: 219.4450, D Loss: 0.0060
Epoch[28430/50000]
**Train**: G Loss: 214.7618, D Loss: 0.5807
Epoch[28430/50000]
**Valid**: G Loss: 224.8052, D Loss: 0.1460
Epoch[28440/50000]
**Train**: G Loss: 228.6277, D Loss: 0.7362
Epoch[28440/50000]
**Valid**: G Loss: 220.5839, D Loss: 0.2178
Epoch[28450/50000]
**Train**: G Loss: 218.0461, D Loss: 0.5077
Epoch[28450/50000]
**Valid**: G Loss: 228.2140, D Loss: 0.2293
Epoch[28460/50000]
**Train**: G Loss: 220.2630, D Loss: 0.2172
Epoch[28460/50000]
**Valid**: G Loss: 212.4509, D Loss: 0.0825
Epoch[28470/50000]
**Train**: G Loss: 226.6285, D Loss: 0.3072
Epoch[28470/50000]
**Valid**: G Loss: 238.6690, D Loss: 0.2406
Epoch[28480/50000]
**Train**: G Loss: 215.8720, D Loss: -0.0647
Epoch[28480/50000]
**Valid**: G Loss: 208.6595, D Loss: 0.5956
Epoch[28490/50000]
**Train**: G Loss: 242.0841, D Loss: 0.3492
Epoch[28490/50000]
**Valid**: G Loss: 243.5192, D Loss: 0.8658
Epoch[28500/50000]
**Train**: G Loss: 216.6515, D Loss: 0.1072
Epoch[28500/50000]
**Valid**: G Loss: 211.0981, D Loss: 0.6036
Epoch[28510/50000]
**Train**: G Loss: 245.6745, D Loss: 0.2089
Epoch[28510/50000]
**Valid**: G Loss: 253.1452, D Loss: 0.7805
Epoch[28520/50000]
**Train**: G Loss: 212.6945, D Loss: 0.2088
Epoch[28520/50000]
**Valid**: G Loss: 207.1200, D Loss: 0.7179
Epoch[28530/50000]
**Train**: G Loss: 246.7868, D Loss: 0.0846
Epoch[28530/50000]
**Valid**: G Loss: 253.3667, D Loss: 0.8546
Epoch[28540/50000]
**Train**: G Loss: 218.5907, D Loss: 0.1585
Epoch[28540/50000]
**Valid**: G Loss: 214.6600, D Loss: 0.9795
Epoch[28550/50000]
**Train**: G Loss: 246.7348, D Loss: 0.5201
Epoch[28550/50000]
**Valid**: G Loss: 242.1068, D Loss: 1.0181
Epoch[28560/50000]
**Train**: G Loss: 212.0883, D Loss: 0.5250
Epoch[28560/50000]
**Valid**: G Loss: 210.4218, D Loss: 0.7686
Epoch[28570/50000]
**Train**: G Loss: 238.4952, D Loss: 0.7152
Epoch[28570/50000]
**Valid**: G Loss: 230.3502, D Loss: 0.7721
Epoch[28580/50000]
**Train**: G Loss: 213.4849, D Loss: 0.3463
Epoch[28580/50000]
**Valid**: G Loss: 212.9960, D Loss: 0.4779
Epoch[28590/50000]
**Train**: G Loss: 239.3550, D Loss: 0.4106
Epoch[28590/50000]
**Valid**: G Loss: 233.5242, D Loss: 0.4323
Epoch[28600/50000]
**Train**: G Loss: 215.0362, D Loss: 0.5410
Epoch[28600/50000]
**Valid**: G Loss: 214.8163, D Loss: 0.6405
Epoch[28610/50000]
**Train**: G Loss: 236.8516, D Loss: 0.7225
Epoch[28610/50000]
**Valid**: G Loss: 228.6303, D Loss: 0.5755
Epoch[28620/50000]
**Train**: G Loss: 210.9366, D Loss: 0.6103
Epoch[28620/50000]
**Valid**: G Loss: 216.5590, D Loss: 0.4415
Epoch[28630/50000]
**Train**: G Loss: 236.5108, D Loss: 0.6412
Epoch[28630/50000]
**Valid**: G Loss: 227.4845, D Loss: -0.0140
Epoch[28640/50000]
**Train**: G Loss: 215.8542, D Loss: 0.6359
Epoch[28640/50000]
**Valid**: G Loss: 228.9404, D Loss: 0.0526
Epoch[28650/50000]
**Train**: G Loss: 231.8402, D Loss: 0.6161
Epoch[28650/50000]
**Valid**: G Loss: 220.2069, D Loss: 0.1197
Epoch[28660/50000]
**Train**: G Loss: 209.6238, D Loss: 0.5260
Epoch[28660/50000]
**Valid**: G Loss: 218.9283, D Loss: 0.2198
Epoch[28670/50000]
**Train**: G Loss: 232.6256, D Loss: 0.6567
Epoch[28670/50000]
**Valid**: G Loss: 224.2381, D Loss: 0.4027
Epoch[28680/50000]
**Train**: G Loss: 210.8761, D Loss: 0.4531
Epoch[28680/50000]
**Valid**: G Loss: 222.5524, D Loss: 0.0647
Epoch[28690/50000]
**Train**: G Loss: 232.7881, D Loss: 0.6050
Epoch[28690/50000]
**Valid**: G Loss: 225.0860, D Loss: 0.2712
Epoch[28700/50000]
**Train**: G Loss: 209.3025, D Loss: 0.5705
Epoch[28700/50000]
**Valid**: G Loss: 215.7987, D Loss: 0.3807
Epoch[28710/50000]
**Train**: G Loss: 238.4470, D Loss: 0.5346
Epoch[28710/50000]
**Valid**: G Loss: 231.6384, D Loss: 0.7089
Epoch[28720/50000]
**Train**: G Loss: 217.5683, D Loss: 0.6783
Epoch[28720/50000]
**Valid**: G Loss: 224.1701, D Loss: 0.3840
Epoch[28730/50000]
**Train**: G Loss: 229.5846, D Loss: 0.4041
Epoch[28730/50000]
**Valid**: G Loss: 222.4492, D Loss: 0.2377
Epoch[28740/50000]
**Train**: G Loss: 210.7319, D Loss: 0.6379
Epoch[28740/50000]
**Valid**: G Loss: 218.9431, D Loss: 0.2570
Epoch[28750/50000]
**Train**: G Loss: 224.7959, D Loss: 0.6514
Epoch[28750/50000]
**Valid**: G Loss: 215.1147, D Loss: -0.0248
Epoch[28760/50000]
**Train**: G Loss: 218.5595, D Loss: 0.5756
Epoch[28760/50000]
**Valid**: G Loss: 235.3109, D Loss: 0.1975
Epoch[28770/50000]
**Train**: G Loss: 224.0566, D Loss: 0.5573
Epoch[28770/50000]
**Valid**: G Loss: 214.2311, D Loss: -0.1168
Epoch[28780/50000]
**Train**: G Loss: 217.4854, D Loss: 0.3557
Epoch[28780/50000]
**Valid**: G Loss: 231.0657, D Loss: -0.0960
Epoch[28790/50000]
**Train**: G Loss: 220.4897, D Loss: 0.4937
Epoch[28790/50000]
**Valid**: G Loss: 211.4912, D Loss: -0.1782
Epoch[28800/50000]
**Train**: G Loss: 228.3679, D Loss: 0.2671
Epoch[28800/50000]
**Valid**: G Loss: 239.5255, D Loss: 0.3396
Epoch[28810/50000]
**Train**: G Loss: 210.5957, D Loss: 0.1614
Epoch[28810/50000]
**Valid**: G Loss: 203.9420, D Loss: 0.6255
Epoch[28820/50000]
**Train**: G Loss: 237.0793, D Loss: 0.6016
Epoch[28820/50000]
**Valid**: G Loss: 228.5002, D Loss: 1.0141
Epoch[28830/50000]
**Train**: G Loss: 203.8827, D Loss: 0.5566
Epoch[28830/50000]
**Valid**: G Loss: 203.3245, D Loss: 0.8670
Epoch[28840/50000]
**Train**: G Loss: 240.7501, D Loss: 0.4168
Epoch[28840/50000]
**Valid**: G Loss: 235.0044, D Loss: 0.9248
Epoch[28850/50000]
**Train**: G Loss: 208.4758, D Loss: 0.4610
Epoch[28850/50000]
**Valid**: G Loss: 208.5351, D Loss: 0.7264
Epoch[28860/50000]
**Train**: G Loss: 237.7902, D Loss: 0.7449
Epoch[28860/50000]
**Valid**: G Loss: 229.2374, D Loss: 0.7469
Epoch[28870/50000]
**Train**: G Loss: 210.9307, D Loss: 0.7618
Epoch[28870/50000]
**Valid**: G Loss: 215.5645, D Loss: 0.5673
Epoch[28880/50000]
**Train**: G Loss: 238.9541, D Loss: 0.8008
Epoch[28880/50000]
**Valid**: G Loss: 227.8378, D Loss: 0.4290
Epoch[28890/50000]
**Train**: G Loss: 206.6355, D Loss: 0.4996
Epoch[28890/50000]
**Valid**: G Loss: 208.7860, D Loss: 0.5037
Epoch[28900/50000]
**Train**: G Loss: 240.1276, D Loss: 0.5422
Epoch[28900/50000]
**Valid**: G Loss: 235.7877, D Loss: 0.9818
Epoch[28910/50000]
**Train**: G Loss: 207.5810, D Loss: 0.5217
Epoch[28910/50000]
**Valid**: G Loss: 204.6053, D Loss: 1.0954
Epoch[28920/50000]
**Train**: G Loss: 242.5901, D Loss: 0.6596
Epoch[28920/50000]
**Valid**: G Loss: 232.7300, D Loss: 0.9522
Epoch[28930/50000]
**Train**: G Loss: 204.5568, D Loss: 0.6254
Epoch[28930/50000]
**Valid**: G Loss: 208.9376, D Loss: 0.5269
Epoch[28940/50000]
**Train**: G Loss: 235.4938, D Loss: 0.7968
Epoch[28940/50000]
**Valid**: G Loss: 227.5928, D Loss: 0.4152
Epoch[28950/50000]
**Train**: G Loss: 212.6848, D Loss: 0.6878
Epoch[28950/50000]
**Valid**: G Loss: 215.0987, D Loss: 0.5121
Epoch[28960/50000]
**Train**: G Loss: 239.5892, D Loss: 0.7651
Epoch[28960/50000]
**Valid**: G Loss: 231.5807, D Loss: 0.4150
Epoch[28970/50000]
**Train**: G Loss: 212.4701, D Loss: 0.6996
Epoch[28970/50000]
**Valid**: G Loss: 219.5069, D Loss: 0.2616
Epoch[28980/50000]
**Train**: G Loss: 234.8738, D Loss: 0.9027
Epoch[28980/50000]
**Valid**: G Loss: 224.4291, D Loss: 0.5418
Epoch[28990/50000]
**Train**: G Loss: 213.0797, D Loss: 0.6506
Epoch[28990/50000]
**Valid**: G Loss: 217.4924, D Loss: 0.6237
Epoch[29000/50000]
**Train**: G Loss: 235.9056, D Loss: 0.6543
Epoch[29000/50000]
**Valid**: G Loss: 228.2619, D Loss: 0.2503
Epoch[29010/50000]
**Train**: G Loss: 212.5680, D Loss: 0.6475
Epoch[29010/50000]
**Valid**: G Loss: 220.2944, D Loss: 0.3602
Epoch[29020/50000]
**Train**: G Loss: 231.0301, D Loss: 0.4290
Epoch[29020/50000]
**Valid**: G Loss: 222.0395, D Loss: 0.0548
Epoch[29030/50000]
**Train**: G Loss: 223.6778, D Loss: 0.3332
Epoch[29030/50000]
**Valid**: G Loss: 239.0372, D Loss: 0.0033
Epoch[29040/50000]
**Train**: G Loss: 222.1242, D Loss: 0.0976
Epoch[29040/50000]
**Valid**: G Loss: 213.1042, D Loss: 0.3166
Epoch[29050/50000]
**Train**: G Loss: 239.8109, D Loss: 0.2821
Epoch[29050/50000]
**Valid**: G Loss: 247.3483, D Loss: 0.7928
Epoch[29060/50000]
**Train**: G Loss: 218.5088, D Loss: 0.1917
Epoch[29060/50000]
**Valid**: G Loss: 212.9177, D Loss: 0.5327
Epoch[29070/50000]
**Train**: G Loss: 240.1453, D Loss: 0.3683
Epoch[29070/50000]
**Valid**: G Loss: 238.5105, D Loss: 1.0332
Epoch[29080/50000]
**Train**: G Loss: 219.7384, D Loss: 0.0803
Epoch[29080/50000]
**Valid**: G Loss: 214.5135, D Loss: 0.7928
Epoch[29090/50000]
**Train**: G Loss: 232.8247, D Loss: 0.3390
Epoch[29090/50000]
**Valid**: G Loss: 236.2826, D Loss: 0.7760
Epoch[29100/50000]
**Train**: G Loss: 214.4421, D Loss: -0.0411
Epoch[29100/50000]
**Valid**: G Loss: 209.4317, D Loss: 0.7482
Epoch[29110/50000]
**Train**: G Loss: 238.3307, D Loss: 0.4637
Epoch[29110/50000]
**Valid**: G Loss: 238.0181, D Loss: 1.2157
Epoch[29120/50000]
**Train**: G Loss: 216.2242, D Loss: 0.3767
Epoch[29120/50000]
**Valid**: G Loss: 211.5465, D Loss: 0.9547
Epoch[29130/50000]
**Train**: G Loss: 242.0920, D Loss: 0.8188
Epoch[29130/50000]
**Valid**: G Loss: 232.5980, D Loss: 0.9444
Epoch[29140/50000]
**Train**: G Loss: 212.6517, D Loss: 0.4642
Epoch[29140/50000]
**Valid**: G Loss: 213.4405, D Loss: 0.7396
Epoch[29150/50000]
**Train**: G Loss: 242.3959, D Loss: 0.6447
Epoch[29150/50000]
**Valid**: G Loss: 234.9792, D Loss: 0.7666
Epoch[29160/50000]
**Train**: G Loss: 210.0818, D Loss: 0.5399
Epoch[29160/50000]
**Valid**: G Loss: 209.9566, D Loss: 0.9427
Epoch[29170/50000]
**Train**: G Loss: 247.6999, D Loss: 0.5309
Epoch[29170/50000]
**Valid**: G Loss: 238.5507, D Loss: 0.6586
Epoch[29180/50000]
**Train**: G Loss: 205.9888, D Loss: 0.6871
Epoch[29180/50000]
**Valid**: G Loss: 210.6842, D Loss: 0.4656
Epoch[29190/50000]
**Train**: G Loss: 237.7829, D Loss: 0.5567
Epoch[29190/50000]
**Valid**: G Loss: 232.5804, D Loss: 0.8357
Epoch[29200/50000]
**Train**: G Loss: 215.8188, D Loss: 0.7262
Epoch[29200/50000]
**Valid**: G Loss: 217.9644, D Loss: 0.8736
Epoch[29210/50000]
**Train**: G Loss: 238.4762, D Loss: 0.6907
Epoch[29210/50000]
**Valid**: G Loss: 229.1067, D Loss: 0.3161
Epoch[29220/50000]
**Train**: G Loss: 215.5588, D Loss: 0.6170
Epoch[29220/50000]
**Valid**: G Loss: 227.2552, D Loss: 0.1592
Epoch[29230/50000]
**Train**: G Loss: 227.6070, D Loss: 0.5936
Epoch[29230/50000]
**Valid**: G Loss: 222.2758, D Loss: 0.1711
Epoch[29240/50000]
**Train**: G Loss: 217.6806, D Loss: 0.5422
Epoch[29240/50000]
**Valid**: G Loss: 224.4753, D Loss: 0.2385
Epoch[29250/50000]
**Train**: G Loss: 222.9447, D Loss: 0.4565
Epoch[29250/50000]
**Valid**: G Loss: 217.4266, D Loss: 0.1202
Epoch[29260/50000]
**Train**: G Loss: 210.1037, D Loss: 0.6940
Epoch[29260/50000]
**Valid**: G Loss: 216.1592, D Loss: 0.4171
Epoch[29270/50000]
**Train**: G Loss: 231.4227, D Loss: 0.8278
Epoch[29270/50000]
**Valid**: G Loss: 226.1543, D Loss: 0.3796
Epoch[29280/50000]
**Train**: G Loss: 214.9204, D Loss: 0.6194
Epoch[29280/50000]
**Valid**: G Loss: 221.0453, D Loss: 0.3385
Epoch[29290/50000]
**Train**: G Loss: 232.5138, D Loss: 0.4397
Epoch[29290/50000]
**Valid**: G Loss: 219.5688, D Loss: -0.1017
Epoch[29300/50000]
**Train**: G Loss: 209.6212, D Loss: 0.6913
Epoch[29300/50000]
**Valid**: G Loss: 216.8622, D Loss: 0.5632
Epoch[29310/50000]
**Train**: G Loss: 237.9466, D Loss: 0.6594
Epoch[29310/50000]
**Valid**: G Loss: 228.8890, D Loss: 0.1398
Epoch[29320/50000]
**Train**: G Loss: 209.6986, D Loss: 0.6579
Epoch[29320/50000]
**Valid**: G Loss: 211.1806, D Loss: 0.7693
Epoch[29330/50000]
**Train**: G Loss: 246.0018, D Loss: 0.2654
Epoch[29330/50000]
**Valid**: G Loss: 242.9511, D Loss: 0.7262
Epoch[29340/50000]
**Train**: G Loss: 214.9369, D Loss: 0.4323
Epoch[29340/50000]
**Valid**: G Loss: 212.0855, D Loss: 0.8357
Epoch[29350/50000]
**Train**: G Loss: 242.8851, D Loss: 0.1121
Epoch[29350/50000]
**Valid**: G Loss: 244.1330, D Loss: 0.8201
Epoch[29360/50000]
**Train**: G Loss: 224.3556, D Loss: -0.0758
Epoch[29360/50000]
**Valid**: G Loss: 217.8124, D Loss: 0.0889
Epoch[29370/50000]
**Train**: G Loss: 221.5723, D Loss: 0.4417
Epoch[29370/50000]
**Valid**: G Loss: 236.6783, D Loss: -0.0037
Epoch[29380/50000]
**Train**: G Loss: 238.7639, D Loss: 0.8612
Epoch[29380/50000]
**Valid**: G Loss: 230.7690, D Loss: 0.4837
Epoch[29390/50000]
**Train**: G Loss: 213.0285, D Loss: 0.6979
Epoch[29390/50000]
**Valid**: G Loss: 215.5508, D Loss: 0.6469
Epoch[29400/50000]
**Train**: G Loss: 243.1173, D Loss: 0.1992
Epoch[29400/50000]
**Valid**: G Loss: 245.9555, D Loss: 1.1613
Epoch[29410/50000]
**Train**: G Loss: 219.9022, D Loss: 0.1126
Epoch[29410/50000]
**Valid**: G Loss: 213.9909, D Loss: 0.6107
Epoch[29420/50000]
**Train**: G Loss: 227.7552, D Loss: 0.1437
Epoch[29420/50000]
**Valid**: G Loss: 239.7414, D Loss: 0.1398
Epoch[29430/50000]
**Train**: G Loss: 227.3341, D Loss: 0.4758
Epoch[29430/50000]
**Valid**: G Loss: 220.4902, D Loss: 0.0586
Epoch[29440/50000]
**Train**: G Loss: 210.7510, D Loss: 0.6758
Epoch[29440/50000]
**Valid**: G Loss: 219.8482, D Loss: 0.0982
Epoch[29450/50000]
**Train**: G Loss: 235.9293, D Loss: 0.5679
Epoch[29450/50000]
**Valid**: G Loss: 229.0461, D Loss: 0.4415
Epoch[29460/50000]
**Train**: G Loss: 217.2402, D Loss: 0.5537
Epoch[29460/50000]
**Valid**: G Loss: 227.5740, D Loss: 0.1733
Epoch[29470/50000]
**Train**: G Loss: 221.5567, D Loss: 0.3301
Epoch[29470/50000]
**Valid**: G Loss: 209.4710, D Loss: -0.3495
Epoch[29480/50000]
**Train**: G Loss: 228.4777, D Loss: 0.1721
Epoch[29480/50000]
**Valid**: G Loss: 242.5929, D Loss: -0.0989
Epoch[29490/50000]
**Train**: G Loss: 235.4654, D Loss: 0.8036
Epoch[29490/50000]
**Valid**: G Loss: 228.0766, D Loss: 0.2275
Epoch[29500/50000]
**Train**: G Loss: 213.8272, D Loss: 0.6712
Epoch[29500/50000]
**Valid**: G Loss: 220.0430, D Loss: 0.4923
Epoch[29510/50000]
**Train**: G Loss: 244.1640, D Loss: 0.8236
Epoch[29510/50000]
**Valid**: G Loss: 234.3887, D Loss: 0.4009
Epoch[29520/50000]
**Train**: G Loss: 215.4989, D Loss: 0.7192
Epoch[29520/50000]
**Valid**: G Loss: 219.3744, D Loss: 0.6955
Epoch[29530/50000]
**Train**: G Loss: 247.4753, D Loss: 0.5035
Epoch[29530/50000]
**Valid**: G Loss: 242.3094, D Loss: 1.0308
Epoch[29540/50000]
**Train**: G Loss: 216.4063, D Loss: -0.0549
Epoch[29540/50000]
**Valid**: G Loss: 209.6519, D Loss: 0.5904
Epoch[29550/50000]
**Train**: G Loss: 231.9992, D Loss: 0.3545
Epoch[29550/50000]
**Valid**: G Loss: 242.8460, D Loss: 0.3531
Epoch[29560/50000]
**Train**: G Loss: 223.8427, D Loss: 0.5827
Epoch[29560/50000]
**Valid**: G Loss: 214.8854, D Loss: 0.1192
Epoch[29570/50000]
**Train**: G Loss: 215.1929, D Loss: 0.4241
Epoch[29570/50000]
**Valid**: G Loss: 224.4411, D Loss: 0.2943
Epoch[29580/50000]
**Train**: G Loss: 230.1925, D Loss: 0.5282
Epoch[29580/50000]
**Valid**: G Loss: 224.9272, D Loss: 0.2329
Epoch[29590/50000]
**Train**: G Loss: 227.3848, D Loss: 0.3688
Epoch[29590/50000]
**Valid**: G Loss: 241.3677, D Loss: -0.0933
Epoch[29600/50000]
**Train**: G Loss: 229.0120, D Loss: 0.5408
Epoch[29600/50000]
**Valid**: G Loss: 218.6794, D Loss: -0.2129
Epoch[29610/50000]
**Train**: G Loss: 217.2113, D Loss: 0.5255
Epoch[29610/50000]
**Valid**: G Loss: 230.0437, D Loss: -0.1141
Epoch[29620/50000]
**Train**: G Loss: 234.1529, D Loss: 0.6756
Epoch[29620/50000]
**Valid**: G Loss: 223.0231, D Loss: -0.0084
Epoch[29630/50000]
**Train**: G Loss: 222.3881, D Loss: 0.6326
Epoch[29630/50000]
**Valid**: G Loss: 236.7737, D Loss: 0.1732
Epoch[29640/50000]
**Train**: G Loss: 232.8344, D Loss: 0.7666
Epoch[29640/50000]
**Valid**: G Loss: 221.7908, D Loss: 0.0692
Epoch[29650/50000]
**Train**: G Loss: 209.5664, D Loss: 0.8978
Epoch[29650/50000]
**Valid**: G Loss: 216.4169, D Loss: 0.5592
Epoch[29660/50000]
**Train**: G Loss: 237.9734, D Loss: 0.5559
Epoch[29660/50000]
**Valid**: G Loss: 232.8497, D Loss: 0.6430
Epoch[29670/50000]
**Train**: G Loss: 216.9031, D Loss: 0.2022
Epoch[29670/50000]
**Valid**: G Loss: 213.7917, D Loss: 0.6821
Epoch[29680/50000]
**Train**: G Loss: 234.0735, D Loss: 0.3663
Epoch[29680/50000]
**Valid**: G Loss: 236.7386, D Loss: 1.0567
Epoch[29690/50000]
**Train**: G Loss: 216.5690, D Loss: -0.0586
Epoch[29690/50000]
**Valid**: G Loss: 209.1147, D Loss: 0.5851
Epoch[29700/50000]
**Train**: G Loss: 238.8294, D Loss: 0.1029
Epoch[29700/50000]
**Valid**: G Loss: 248.7084, D Loss: 0.4158
Epoch[29710/50000]
**Train**: G Loss: 225.0217, D Loss: 0.3591
Epoch[29710/50000]
**Valid**: G Loss: 219.2501, D Loss: 0.2333
Epoch[29720/50000]
**Train**: G Loss: 224.3596, D Loss: 0.3483
Epoch[29720/50000]
**Valid**: G Loss: 239.0507, D Loss: 0.0851
Epoch[29730/50000]
**Train**: G Loss: 224.8928, D Loss: 0.3289
Epoch[29730/50000]
**Valid**: G Loss: 219.9148, D Loss: 0.1456
Epoch[29740/50000]
**Train**: G Loss: 221.4919, D Loss: 0.4472
Epoch[29740/50000]
**Valid**: G Loss: 231.8032, D Loss: -0.0106
Epoch[29750/50000]
**Train**: G Loss: 226.2425, D Loss: 0.6147
Epoch[29750/50000]
**Valid**: G Loss: 219.4028, D Loss: 0.1334
Epoch[29760/50000]
**Train**: G Loss: 220.5862, D Loss: 0.5091
Epoch[29760/50000]
**Valid**: G Loss: 232.3965, D Loss: 0.2231
Epoch[29770/50000]
**Train**: G Loss: 233.5084, D Loss: 0.6468
Epoch[29770/50000]
**Valid**: G Loss: 224.3622, D Loss: -0.0881
Epoch[29780/50000]
**Train**: G Loss: 211.3335, D Loss: 0.6594
Epoch[29780/50000]
**Valid**: G Loss: 210.4487, D Loss: 0.7313
Epoch[29790/50000]
**Train**: G Loss: 239.9385, D Loss: 0.3453
Epoch[29790/50000]
**Valid**: G Loss: 241.2789, D Loss: 0.8768
Epoch[29800/50000]
**Train**: G Loss: 222.3654, D Loss: 0.2988
Epoch[29800/50000]
**Valid**: G Loss: 217.5228, D Loss: 0.2996
Epoch[29810/50000]
**Train**: G Loss: 221.2401, D Loss: 0.3690
Epoch[29810/50000]
**Valid**: G Loss: 230.2547, D Loss: 0.2339
Epoch[29820/50000]
**Train**: G Loss: 194.4202, D Loss: 0.5581
Epoch[29820/50000]
**Valid**: G Loss: 195.4724, D Loss: 0.9538
Epoch[29830/50000]
**Train**: G Loss: 244.8168, D Loss: 0.8336
Epoch[29830/50000]
**Valid**: G Loss: 230.9304, D Loss: 0.6025
Epoch[29840/50000]
**Train**: G Loss: 208.0753, D Loss: 0.7075
Epoch[29840/50000]
**Valid**: G Loss: 211.3242, D Loss: 0.6000
Epoch[29850/50000]
**Train**: G Loss: 242.2419, D Loss: 0.7177
Epoch[29850/50000]
**Valid**: G Loss: 232.5633, D Loss: 0.6584
Epoch[29860/50000]
**Train**: G Loss: 207.8723, D Loss: 0.6716
Epoch[29860/50000]
**Valid**: G Loss: 207.9958, D Loss: 0.8117
Epoch[29870/50000]
**Train**: G Loss: 240.8058, D Loss: 0.6754
Epoch[29870/50000]
**Valid**: G Loss: 236.8808, D Loss: 0.9734
Epoch[29880/50000]
**Train**: G Loss: 208.6725, D Loss: 0.1612
Epoch[29880/50000]
**Valid**: G Loss: 203.0118, D Loss: 0.7421
Epoch[29890/50000]
**Train**: G Loss: 233.2585, D Loss: 0.2394
Epoch[29890/50000]
**Valid**: G Loss: 242.9631, D Loss: 0.5815
Epoch[29900/50000]
**Train**: G Loss: 216.3024, D Loss: 0.1747
Epoch[29900/50000]
**Valid**: G Loss: 210.0547, D Loss: 0.4892
Epoch[29910/50000]
**Train**: G Loss: 234.9304, D Loss: 0.1953
Epoch[29910/50000]
**Valid**: G Loss: 243.1644, D Loss: 0.4075
Epoch[29920/50000]
**Train**: G Loss: 220.2707, D Loss: 0.1420
Epoch[29920/50000]
**Valid**: G Loss: 214.1566, D Loss: 0.2017
Epoch[29930/50000]
**Train**: G Loss: 223.9377, D Loss: 0.2666
Epoch[29930/50000]
**Valid**: G Loss: 238.0328, D Loss: 0.1726
Epoch[29940/50000]
**Train**: G Loss: 219.2658, D Loss: 0.2425
Epoch[29940/50000]
**Valid**: G Loss: 214.6089, D Loss: 0.4042
Epoch[29950/50000]
**Train**: G Loss: 231.0068, D Loss: 0.2136
Epoch[29950/50000]
**Valid**: G Loss: 242.4900, D Loss: 0.4814
Epoch[29960/50000]
**Train**: G Loss: 215.3073, D Loss: 0.1394
Epoch[29960/50000]
**Valid**: G Loss: 208.3036, D Loss: 0.6235
Epoch[29970/50000]
**Train**: G Loss: 245.0572, D Loss: -0.0362
Epoch[29970/50000]
**Valid**: G Loss: 248.6917, D Loss: 0.7789
Epoch[29980/50000]
**Train**: G Loss: 212.0966, D Loss: 0.3454
Epoch[29980/50000]
**Valid**: G Loss: 208.6325, D Loss: 0.9009
Epoch[29990/50000]
**Train**: G Loss: 248.3312, D Loss: 0.5096
Epoch[29990/50000]
**Valid**: G Loss: 242.3611, D Loss: 1.1629
Epoch[30000/50000]
**Train**: G Loss: 219.7194, D Loss: 0.0908
Epoch[30000/50000]
**Valid**: G Loss: 215.8832, D Loss: 0.7115
Epoch[30010/50000]
**Train**: G Loss: 245.6565, D Loss: 0.4211
Epoch[30010/50000]
**Valid**: G Loss: 244.5122, D Loss: 0.9904
Epoch[30020/50000]
**Train**: G Loss: 214.6272, D Loss: 0.4376
Epoch[30020/50000]
**Valid**: G Loss: 210.2769, D Loss: 1.0145
Epoch[30030/50000]
**Train**: G Loss: 243.6200, D Loss: 0.7103
Epoch[30030/50000]
**Valid**: G Loss: 238.4354, D Loss: 1.1683
Epoch[30040/50000]
**Train**: G Loss: 211.7161, D Loss: 0.3641
Epoch[30040/50000]
**Valid**: G Loss: 209.4808, D Loss: 0.8919
Epoch[30050/50000]
**Train**: G Loss: 251.1234, D Loss: 0.3921
Epoch[30050/50000]
**Valid**: G Loss: 249.2884, D Loss: 1.2817
Epoch[30060/50000]
**Train**: G Loss: 206.3304, D Loss: 0.2395
Epoch[30060/50000]
**Valid**: G Loss: 205.0952, D Loss: 0.9236
Epoch[30070/50000]
**Train**: G Loss: 249.5531, D Loss: 0.2857
Epoch[30070/50000]
**Valid**: G Loss: 248.9380, D Loss: 1.1314
Epoch[30080/50000]
**Train**: G Loss: 219.3646, D Loss: 0.1452
Epoch[30080/50000]
**Valid**: G Loss: 212.6007, D Loss: 0.9261
Epoch[30090/50000]
**Train**: G Loss: 236.4150, D Loss: 0.1774
Epoch[30090/50000]
**Valid**: G Loss: 249.2553, D Loss: 0.5167
Epoch[30100/50000]
**Train**: G Loss: 222.1451, D Loss: 0.3206
Epoch[30100/50000]
**Valid**: G Loss: 213.8565, D Loss: -0.2326
Epoch[30110/50000]
**Train**: G Loss: 235.8847, D Loss: -0.1012
Epoch[30110/50000]
**Valid**: G Loss: 252.7613, D Loss: 0.1983
Epoch[30120/50000]
**Train**: G Loss: 220.3603, D Loss: 0.4435
Epoch[30120/50000]
**Valid**: G Loss: 212.0248, D Loss: 0.1680
Epoch[30130/50000]
**Train**: G Loss: 208.1996, D Loss: 0.5184
Epoch[30130/50000]
**Valid**: G Loss: 215.4616, D Loss: 0.1974
Epoch[30140/50000]
**Train**: G Loss: 233.2221, D Loss: 0.4059
Epoch[30140/50000]
**Valid**: G Loss: 233.0301, D Loss: 0.9262
Epoch[30150/50000]
**Train**: G Loss: 216.3228, D Loss: 0.3938
Epoch[30150/50000]
**Valid**: G Loss: 210.3464, D Loss: 0.5487
Epoch[30160/50000]
**Train**: G Loss: 208.9746, D Loss: 0.4027
Epoch[30160/50000]
**Valid**: G Loss: 216.1567, D Loss: 0.3110
Epoch[30170/50000]
**Train**: G Loss: 230.7728, D Loss: 0.7261
Epoch[30170/50000]
**Valid**: G Loss: 221.8280, D Loss: 0.2974
Epoch[30180/50000]
**Train**: G Loss: 203.0448, D Loss: 0.7070
Epoch[30180/50000]
**Valid**: G Loss: 212.7132, D Loss: 0.3424
Epoch[30190/50000]
**Train**: G Loss: 233.4316, D Loss: 0.5587
Epoch[30190/50000]
**Valid**: G Loss: 229.4723, D Loss: 0.9438
Epoch[30200/50000]
**Train**: G Loss: 211.2388, D Loss: 0.1308
Epoch[30200/50000]
**Valid**: G Loss: 204.8588, D Loss: 0.9630
Epoch[30210/50000]
**Train**: G Loss: 238.2617, D Loss: 0.0304
Epoch[30210/50000]
**Valid**: G Loss: 246.4854, D Loss: 0.6458
Epoch[30220/50000]
**Train**: G Loss: 215.2512, D Loss: -0.0784
Epoch[30220/50000]
**Valid**: G Loss: 205.3532, D Loss: 0.5139
Epoch[30230/50000]
**Train**: G Loss: 228.4790, D Loss: 0.3789
Epoch[30230/50000]
**Valid**: G Loss: 241.4954, D Loss: 0.3210
Epoch[30240/50000]
**Train**: G Loss: 224.1972, D Loss: 0.2358
Epoch[30240/50000]
**Valid**: G Loss: 218.8874, D Loss: 0.0110
Epoch[30250/50000]
**Train**: G Loss: 213.1386, D Loss: 0.6693
Epoch[30250/50000]
**Valid**: G Loss: 222.9843, D Loss: 0.1213
Epoch[30260/50000]
**Train**: G Loss: 239.1390, D Loss: 0.8241
Epoch[30260/50000]
**Valid**: G Loss: 232.2666, D Loss: 0.5924
Epoch[30270/50000]
**Train**: G Loss: 208.4291, D Loss: 0.7246
Epoch[30270/50000]
**Valid**: G Loss: 211.4482, D Loss: 0.6715
Epoch[30280/50000]
**Train**: G Loss: 239.9278, D Loss: 0.4105
Epoch[30280/50000]
**Valid**: G Loss: 236.3054, D Loss: 1.0711
Epoch[30290/50000]
**Train**: G Loss: 215.4905, D Loss: 0.3379
Epoch[30290/50000]
**Valid**: G Loss: 211.9201, D Loss: 0.6436
Epoch[30300/50000]
**Train**: G Loss: 236.4689, D Loss: 0.3143
Epoch[30300/50000]
**Valid**: G Loss: 238.6003, D Loss: 0.6960
Epoch[30310/50000]
**Train**: G Loss: 214.4057, D Loss: 0.2810
Epoch[30310/50000]
**Valid**: G Loss: 210.3441, D Loss: 0.9060
Epoch[30320/50000]
**Train**: G Loss: 229.5141, D Loss: 0.2799
Epoch[30320/50000]
**Valid**: G Loss: 240.4466, D Loss: 0.7229
Epoch[30330/50000]
**Train**: G Loss: 222.4156, D Loss: 0.3950
Epoch[30330/50000]
**Valid**: G Loss: 213.3370, D Loss: 0.0643
Epoch[30340/50000]
**Train**: G Loss: 215.0063, D Loss: 0.6181
Epoch[30340/50000]
**Valid**: G Loss: 224.8958, D Loss: 0.1342
Epoch[30350/50000]
**Train**: G Loss: 236.3352, D Loss: 0.7455
Epoch[30350/50000]
**Valid**: G Loss: 227.7953, D Loss: 0.1464
Epoch[30360/50000]
**Train**: G Loss: 208.4421, D Loss: 0.7689
Epoch[30360/50000]
**Valid**: G Loss: 213.9984, D Loss: 0.7540
Epoch[30370/50000]
**Train**: G Loss: 241.5823, D Loss: 0.6767
Epoch[30370/50000]
**Valid**: G Loss: 234.8764, D Loss: 0.9573
Epoch[30380/50000]
**Train**: G Loss: 212.9514, D Loss: 0.2825
Epoch[30380/50000]
**Valid**: G Loss: 207.1579, D Loss: 0.9289
Epoch[30390/50000]
**Train**: G Loss: 232.9615, D Loss: 0.1527
Epoch[30390/50000]
**Valid**: G Loss: 240.6056, D Loss: 0.6561
Epoch[30400/50000]
**Train**: G Loss: 217.7932, D Loss: 0.4253
Epoch[30400/50000]
**Valid**: G Loss: 210.6363, D Loss: 0.0292
Epoch[30410/50000]
**Train**: G Loss: 200.5353, D Loss: 0.6446
Epoch[30410/50000]
**Valid**: G Loss: 206.0166, D Loss: 0.4339
Epoch[30420/50000]
**Train**: G Loss: 227.7691, D Loss: 0.6528
Epoch[30420/50000]
**Valid**: G Loss: 223.8150, D Loss: 1.0166
Epoch[30430/50000]
**Train**: G Loss: 212.4317, D Loss: 0.3439
Epoch[30430/50000]
**Valid**: G Loss: 208.1275, D Loss: 0.6577
Epoch[30440/50000]
**Train**: G Loss: 215.5016, D Loss: 0.3735
Epoch[30440/50000]
**Valid**: G Loss: 226.4488, D Loss: 0.0934
Epoch[30450/50000]
**Train**: G Loss: 230.2006, D Loss: 0.7052
Epoch[30450/50000]
**Valid**: G Loss: 223.3322, D Loss: 0.2283
Epoch[30460/50000]
**Train**: G Loss: 206.8911, D Loss: 0.8152
Epoch[30460/50000]
**Valid**: G Loss: 215.1393, D Loss: 0.2578
Epoch[30470/50000]
**Train**: G Loss: 240.1696, D Loss: 0.6609
Epoch[30470/50000]
**Valid**: G Loss: 230.9616, D Loss: 0.6269
Epoch[30480/50000]
**Train**: G Loss: 216.4720, D Loss: 0.7179
Epoch[30480/50000]
**Valid**: G Loss: 218.3173, D Loss: 0.6352
Epoch[30490/50000]
**Train**: G Loss: 239.2026, D Loss: 0.5876
Epoch[30490/50000]
**Valid**: G Loss: 231.7504, D Loss: 0.2525
Epoch[30500/50000]
**Train**: G Loss: 207.9230, D Loss: 0.6976
Epoch[30500/50000]
**Valid**: G Loss: 212.4573, D Loss: 0.5722
Epoch[30510/50000]
**Train**: G Loss: 245.0929, D Loss: 0.4422
Epoch[30510/50000]
**Valid**: G Loss: 235.3168, D Loss: 0.6700
Epoch[30520/50000]
**Train**: G Loss: 200.7674, D Loss: 0.6607
Epoch[30520/50000]
**Valid**: G Loss: 202.6634, D Loss: 0.8536
Epoch[30530/50000]
**Train**: G Loss: 239.4182, D Loss: 0.6948
Epoch[30530/50000]
**Valid**: G Loss: 234.8049, D Loss: 0.8897
Epoch[30540/50000]
**Train**: G Loss: 216.0155, D Loss: 0.3047
Epoch[30540/50000]
**Valid**: G Loss: 213.1577, D Loss: 1.0550
Epoch[30550/50000]
**Train**: G Loss: 243.0922, D Loss: 0.2522
Epoch[30550/50000]
**Valid**: G Loss: 244.1771, D Loss: 0.7829
Epoch[30560/50000]
**Train**: G Loss: 219.9763, D Loss: 0.2748
Epoch[30560/50000]
**Valid**: G Loss: 211.7483, D Loss: 0.3830
Epoch[30570/50000]
**Train**: G Loss: 219.3226, D Loss: 0.4335
Epoch[30570/50000]
**Valid**: G Loss: 230.3528, D Loss: 0.2148
Epoch[30580/50000]
**Train**: G Loss: 230.1114, D Loss: 0.5166
Epoch[30580/50000]
**Valid**: G Loss: 224.8870, D Loss: 0.3341
Epoch[30590/50000]
**Train**: G Loss: 206.0892, D Loss: 0.3266
Epoch[30590/50000]
**Valid**: G Loss: 202.7900, D Loss: 0.7256
Epoch[30600/50000]
**Train**: G Loss: 230.6654, D Loss: 0.0207
Epoch[30600/50000]
**Valid**: G Loss: 237.6720, D Loss: 0.3075
Epoch[30610/50000]
**Train**: G Loss: 215.4357, D Loss: 0.0727
Epoch[30610/50000]
**Valid**: G Loss: 205.7104, D Loss: 0.3269
Epoch[30620/50000]
**Train**: G Loss: 236.3735, D Loss: 0.1606
Epoch[30620/50000]
**Valid**: G Loss: 247.7218, D Loss: 0.3686
Epoch[30630/50000]
**Train**: G Loss: 228.9204, D Loss: 0.2924
Epoch[30630/50000]
**Valid**: G Loss: 219.9675, D Loss: -0.0426
Epoch[30640/50000]
**Train**: G Loss: 224.5775, D Loss: 0.4721
Epoch[30640/50000]
**Valid**: G Loss: 235.6438, D Loss: 0.1337
Epoch[30650/50000]
**Train**: G Loss: 230.1981, D Loss: 0.7255
Epoch[30650/50000]
**Valid**: G Loss: 220.5670, D Loss: -0.1083
Epoch[30660/50000]
**Train**: G Loss: 207.0289, D Loss: 0.7331
Epoch[30660/50000]
**Valid**: G Loss: 214.0686, D Loss: 0.3703
Epoch[30670/50000]
**Train**: G Loss: 245.5355, D Loss: 0.2425
Epoch[30670/50000]
**Valid**: G Loss: 245.4833, D Loss: 1.0085
Epoch[30680/50000]
**Train**: G Loss: 215.7504, D Loss: 0.0470
Epoch[30680/50000]
**Valid**: G Loss: 209.6848, D Loss: 0.3015
Epoch[30690/50000]
**Train**: G Loss: 234.7865, D Loss: 0.3287
Epoch[30690/50000]
**Valid**: G Loss: 244.5203, D Loss: 0.6676
Epoch[30700/50000]
**Train**: G Loss: 220.9259, D Loss: 0.1551
Epoch[30700/50000]
**Valid**: G Loss: 213.4133, D Loss: 0.2495
Epoch[30710/50000]
**Train**: G Loss: 212.6042, D Loss: 0.5878
Epoch[30710/50000]
**Valid**: G Loss: 227.1300, D Loss: 0.0159
Epoch[30720/50000]
**Train**: G Loss: 236.2147, D Loss: 0.4969
Epoch[30720/50000]
**Valid**: G Loss: 230.7407, D Loss: 0.7976
Epoch[30730/50000]
**Train**: G Loss: 208.6738, D Loss: 0.2525
Epoch[30730/50000]
**Valid**: G Loss: 204.4841, D Loss: 0.5614
Epoch[30740/50000]
**Train**: G Loss: 223.8330, D Loss: 0.3091
Epoch[30740/50000]
**Valid**: G Loss: 235.6425, D Loss: 0.0772
Epoch[30750/50000]
**Train**: G Loss: 227.7276, D Loss: 0.7596
Epoch[30750/50000]
**Valid**: G Loss: 220.5545, D Loss: 0.0527
Epoch[30760/50000]
**Train**: G Loss: 199.7691, D Loss: 0.5597
Epoch[30760/50000]
**Valid**: G Loss: 204.3074, D Loss: 0.5188
Epoch[30770/50000]
**Train**: G Loss: 234.7404, D Loss: 0.3039
Epoch[30770/50000]
**Valid**: G Loss: 231.7424, D Loss: 1.1202
Epoch[30780/50000]
**Train**: G Loss: 206.3517, D Loss: 0.2929
Epoch[30780/50000]
**Valid**: G Loss: 201.6687, D Loss: 0.6477
Epoch[30790/50000]
**Train**: G Loss: 228.6749, D Loss: 0.2730
Epoch[30790/50000]
**Valid**: G Loss: 234.7080, D Loss: 0.8531
Epoch[30800/50000]
**Train**: G Loss: 213.3228, D Loss: 0.3046
Epoch[30800/50000]
**Valid**: G Loss: 203.7750, D Loss: 0.2824
Epoch[30810/50000]
**Train**: G Loss: 207.6655, D Loss: 0.4537
Epoch[30810/50000]
**Valid**: G Loss: 217.8049, D Loss: 0.0643
Epoch[30820/50000]
**Train**: G Loss: 235.0902, D Loss: 0.6581
Epoch[30820/50000]
**Valid**: G Loss: 227.2948, D Loss: 0.6272
Epoch[30830/50000]
**Train**: G Loss: 207.7449, D Loss: 0.6564
Epoch[30830/50000]
**Valid**: G Loss: 215.0736, D Loss: 0.1928
Epoch[30840/50000]
**Train**: G Loss: 231.2464, D Loss: 0.8334
Epoch[30840/50000]
**Valid**: G Loss: 225.1825, D Loss: 0.4645
Epoch[30850/50000]
**Train**: G Loss: 215.5753, D Loss: 0.3151
Epoch[30850/50000]
**Valid**: G Loss: 219.3530, D Loss: 0.3747
Epoch[30860/50000]
**Train**: G Loss: 240.2546, D Loss: 0.5816
Epoch[30860/50000]
**Valid**: G Loss: 231.3057, D Loss: 0.7654
Epoch[30870/50000]
**Train**: G Loss: 214.4605, D Loss: 0.3434
Epoch[30870/50000]
**Valid**: G Loss: 210.1939, D Loss: 1.2473
Epoch[30880/50000]
**Train**: G Loss: 232.1537, D Loss: 0.3071
Epoch[30880/50000]
**Valid**: G Loss: 236.7392, D Loss: 0.6616
Epoch[30890/50000]
**Train**: G Loss: 218.5771, D Loss: -0.0774
Epoch[30890/50000]
**Valid**: G Loss: 214.2160, D Loss: 0.3122
Epoch[30900/50000]
**Train**: G Loss: 221.7213, D Loss: 0.4299
Epoch[30900/50000]
**Valid**: G Loss: 232.6020, D Loss: 0.2657
Epoch[30910/50000]
**Train**: G Loss: 218.0764, D Loss: 0.2473
Epoch[30910/50000]
**Valid**: G Loss: 211.1083, D Loss: 0.1197
Epoch[30920/50000]
**Train**: G Loss: 215.6472, D Loss: 0.5526
Epoch[30920/50000]
**Valid**: G Loss: 231.5390, D Loss: -0.0042
Epoch[30930/50000]
**Train**: G Loss: 240.3056, D Loss: 0.7059
Epoch[30930/50000]
**Valid**: G Loss: 232.6528, D Loss: 0.5590
Epoch[30940/50000]
**Train**: G Loss: 217.6713, D Loss: 0.3747
Epoch[30940/50000]
**Valid**: G Loss: 217.5896, D Loss: 0.7492
Epoch[30950/50000]
**Train**: G Loss: 241.6186, D Loss: 0.3218
Epoch[30950/50000]
**Valid**: G Loss: 239.2705, D Loss: 0.8671
Epoch[30960/50000]
**Train**: G Loss: 211.7504, D Loss: 0.2123
Epoch[30960/50000]
**Valid**: G Loss: 206.7955, D Loss: 0.8461
Epoch[30970/50000]
**Train**: G Loss: 236.2500, D Loss: 0.3649
Epoch[30970/50000]
**Valid**: G Loss: 238.8526, D Loss: 0.7564
Epoch[30980/50000]
**Train**: G Loss: 220.6374, D Loss: 0.0068
Epoch[30980/50000]
**Valid**: G Loss: 214.8305, D Loss: 0.4345
Epoch[30990/50000]
**Train**: G Loss: 232.4677, D Loss: 0.1551
Epoch[30990/50000]
**Valid**: G Loss: 242.4774, D Loss: 0.3797
Epoch[31000/50000]
**Train**: G Loss: 220.4818, D Loss: 0.0912
Epoch[31000/50000]
**Valid**: G Loss: 214.2771, D Loss: 0.2498
Epoch[31010/50000]
**Train**: G Loss: 219.4088, D Loss: 0.3512
Epoch[31010/50000]
**Valid**: G Loss: 238.1636, D Loss: -0.2763
Epoch[31020/50000]
**Train**: G Loss: 235.1321, D Loss: 0.5943
Epoch[31020/50000]
**Valid**: G Loss: 227.3319, D Loss: 0.2919
Epoch[31030/50000]
**Train**: G Loss: 210.9290, D Loss: 0.6282
Epoch[31030/50000]
**Valid**: G Loss: 212.4693, D Loss: 0.8994
Epoch[31040/50000]
**Train**: G Loss: 240.1026, D Loss: 0.4116
Epoch[31040/50000]
**Valid**: G Loss: 237.8318, D Loss: 1.2990
Epoch[31050/50000]
**Train**: G Loss: 211.1289, D Loss: 0.0898
Epoch[31050/50000]
**Valid**: G Loss: 203.5753, D Loss: 0.8475
Epoch[31060/50000]
**Train**: G Loss: 228.9994, D Loss: 0.3104
Epoch[31060/50000]
**Valid**: G Loss: 239.2227, D Loss: 0.6273
Epoch[31070/50000]
**Train**: G Loss: 220.0274, D Loss: 0.2758
Epoch[31070/50000]
**Valid**: G Loss: 212.3709, D Loss: 0.1903
Epoch[31080/50000]
**Train**: G Loss: 213.7061, D Loss: 0.6189
Epoch[31080/50000]
**Valid**: G Loss: 220.5208, D Loss: 0.1814
Epoch[31090/50000]
**Train**: G Loss: 228.7165, D Loss: 0.6024
Epoch[31090/50000]
**Valid**: G Loss: 223.3612, D Loss: 0.2213
Epoch[31100/50000]
**Train**: G Loss: 199.8111, D Loss: 0.6314
Epoch[31100/50000]
**Valid**: G Loss: 200.8426, D Loss: 0.8070
Epoch[31110/50000]
**Train**: G Loss: 242.9127, D Loss: 0.0695
Epoch[31110/50000]
**Valid**: G Loss: 240.8529, D Loss: 1.0850
Epoch[31120/50000]
**Train**: G Loss: 205.4750, D Loss: 0.0548
Epoch[31120/50000]
**Valid**: G Loss: 200.3281, D Loss: 0.9736
Epoch[31130/50000]
**Train**: G Loss: 234.3917, D Loss: 0.2396
Epoch[31130/50000]
**Valid**: G Loss: 240.3342, D Loss: 0.8476
Epoch[31140/50000]
**Train**: G Loss: 220.4665, D Loss: 0.2161
Epoch[31140/50000]
**Valid**: G Loss: 218.2225, D Loss: 0.4075
Epoch[31150/50000]
**Train**: G Loss: 227.7510, D Loss: 0.2620
Epoch[31150/50000]
**Valid**: G Loss: 239.8032, D Loss: 0.2304
Epoch[31160/50000]
**Train**: G Loss: 223.0711, D Loss: 0.4478
Epoch[31160/50000]
**Valid**: G Loss: 215.7764, D Loss: 0.2683
Epoch[31170/50000]
**Train**: G Loss: 215.9302, D Loss: 0.6130
Epoch[31170/50000]
**Valid**: G Loss: 229.1262, D Loss: 0.0152
Epoch[31180/50000]
**Train**: G Loss: 230.9835, D Loss: 0.7020
Epoch[31180/50000]
**Valid**: G Loss: 223.9024, D Loss: 0.1367
Epoch[31190/50000]
**Train**: G Loss: 204.9681, D Loss: 0.6519
Epoch[31190/50000]
**Valid**: G Loss: 209.5627, D Loss: 0.5316
Epoch[31200/50000]
**Train**: G Loss: 240.1281, D Loss: 0.6363
Epoch[31200/50000]
**Valid**: G Loss: 231.6832, D Loss: 0.8623
Epoch[31210/50000]
**Train**: G Loss: 206.7541, D Loss: 0.3947
Epoch[31210/50000]
**Valid**: G Loss: 203.5217, D Loss: 1.0469
Epoch[31220/50000]
**Train**: G Loss: 229.6506, D Loss: 0.1695
Epoch[31220/50000]
**Valid**: G Loss: 237.2938, D Loss: 0.4610
Epoch[31230/50000]
**Train**: G Loss: 223.4337, D Loss: 0.3471
Epoch[31230/50000]
**Valid**: G Loss: 215.6599, D Loss: -0.3388
Epoch[31240/50000]
**Train**: G Loss: 206.7881, D Loss: 0.6404
Epoch[31240/50000]
**Valid**: G Loss: 208.9732, D Loss: 0.6605
Epoch[31250/50000]
**Train**: G Loss: 230.7024, D Loss: 0.2827
Epoch[31250/50000]
**Valid**: G Loss: 234.4025, D Loss: 0.9526
Epoch[31260/50000]
**Train**: G Loss: 219.7060, D Loss: 0.3618
Epoch[31260/50000]
**Valid**: G Loss: 214.9538, D Loss: 0.1335
Epoch[31270/50000]
**Train**: G Loss: 203.2741, D Loss: 0.7522
Epoch[31270/50000]
**Valid**: G Loss: 206.4580, D Loss: 0.7134
Epoch[31280/50000]
**Train**: G Loss: 235.3795, D Loss: 0.4547
Epoch[31280/50000]
**Valid**: G Loss: 230.4365, D Loss: 0.8128
Epoch[31290/50000]
**Train**: G Loss: 209.4094, D Loss: 0.1687
Epoch[31290/50000]
**Valid**: G Loss: 205.2593, D Loss: 0.9018
Epoch[31300/50000]
**Train**: G Loss: 237.6948, D Loss: 0.0098
Epoch[31300/50000]
**Valid**: G Loss: 250.4399, D Loss: 0.3630
Epoch[31310/50000]
**Train**: G Loss: 226.4249, D Loss: 0.5804
Epoch[31310/50000]
**Valid**: G Loss: 214.5939, D Loss: 0.1139
Epoch[31320/50000]
**Train**: G Loss: 204.4152, D Loss: 0.8030
Epoch[31320/50000]
**Valid**: G Loss: 216.0735, D Loss: 0.5834
Epoch[31330/50000]
**Train**: G Loss: 240.8799, D Loss: 0.6573
Epoch[31330/50000]
**Valid**: G Loss: 231.9907, D Loss: 0.8315
Epoch[31340/50000]
**Train**: G Loss: 214.8980, D Loss: 0.3492
Epoch[31340/50000]
**Valid**: G Loss: 209.0145, D Loss: 0.7522
Epoch[31350/50000]
**Train**: G Loss: 229.2230, D Loss: 0.2921
Epoch[31350/50000]
**Valid**: G Loss: 236.6624, D Loss: 0.4666
Epoch[31360/50000]
**Train**: G Loss: 216.4396, D Loss: 0.2208
Epoch[31360/50000]
**Valid**: G Loss: 209.2144, D Loss: 0.3986
Epoch[31370/50000]
**Train**: G Loss: 215.7533, D Loss: 0.4064
Epoch[31370/50000]
**Valid**: G Loss: 229.7446, D Loss: -0.0497
Epoch[31380/50000]
**Train**: G Loss: 221.2138, D Loss: 0.7502
Epoch[31380/50000]
**Valid**: G Loss: 215.4967, D Loss: 0.1863
Epoch[31390/50000]
**Train**: G Loss: 208.8071, D Loss: 0.7521
Epoch[31390/50000]
**Valid**: G Loss: 215.8513, D Loss: 0.4574
Epoch[31400/50000]
**Train**: G Loss: 233.0622, D Loss: 0.6537
Epoch[31400/50000]
**Valid**: G Loss: 226.5099, D Loss: 0.9522
Epoch[31410/50000]
**Train**: G Loss: 208.0978, D Loss: 0.3207
Epoch[31410/50000]
**Valid**: G Loss: 204.6899, D Loss: 0.8291
Epoch[31420/50000]
**Train**: G Loss: 225.2586, D Loss: 0.4961
Epoch[31420/50000]
**Valid**: G Loss: 237.3464, D Loss: 0.4003
Epoch[31430/50000]
**Train**: G Loss: 211.2635, D Loss: -0.1098
Epoch[31430/50000]
**Valid**: G Loss: 202.2069, D Loss: 0.5416
Epoch[31440/50000]
**Train**: G Loss: 230.7996, D Loss: 0.1505
Epoch[31440/50000]
**Valid**: G Loss: 242.5503, D Loss: 0.5236
Epoch[31450/50000]
**Train**: G Loss: 225.7849, D Loss: 0.4326
Epoch[31450/50000]
**Valid**: G Loss: 220.5592, D Loss: 0.3030
Epoch[31460/50000]
**Train**: G Loss: 211.7178, D Loss: 0.8105
Epoch[31460/50000]
**Valid**: G Loss: 220.9493, D Loss: 0.3470
Epoch[31470/50000]
**Train**: G Loss: 234.2205, D Loss: 0.7386
Epoch[31470/50000]
**Valid**: G Loss: 226.7313, D Loss: 0.7802
Epoch[31480/50000]
**Train**: G Loss: 205.6468, D Loss: 0.2410
Epoch[31480/50000]
**Valid**: G Loss: 202.4884, D Loss: 0.9760
Epoch[31490/50000]
**Train**: G Loss: 232.8027, D Loss: 0.2953
Epoch[31490/50000]
**Valid**: G Loss: 236.0953, D Loss: 0.7459
Epoch[31500/50000]
**Train**: G Loss: 224.3788, D Loss: 0.6518
Epoch[31500/50000]
**Valid**: G Loss: 217.4124, D Loss: 0.1221
Epoch[31510/50000]
**Train**: G Loss: 206.8073, D Loss: 0.6241
Epoch[31510/50000]
**Valid**: G Loss: 211.7336, D Loss: 0.7126
Epoch[31520/50000]
**Train**: G Loss: 232.4990, D Loss: 0.5430
Epoch[31520/50000]
**Valid**: G Loss: 227.1021, D Loss: 1.0514
Epoch[31530/50000]
**Train**: G Loss: 207.7196, D Loss: 0.2193
Epoch[31530/50000]
**Valid**: G Loss: 201.8505, D Loss: 0.6925
Epoch[31540/50000]
**Train**: G Loss: 221.3286, D Loss: 0.1699
Epoch[31540/50000]
**Valid**: G Loss: 232.0425, D Loss: 0.2068
Epoch[31550/50000]
**Train**: G Loss: 218.4896, D Loss: 0.1936
Epoch[31550/50000]
**Valid**: G Loss: 214.3213, D Loss: 0.2766
Epoch[31560/50000]
**Train**: G Loss: 210.5485, D Loss: 0.4427
Epoch[31560/50000]
**Valid**: G Loss: 223.1762, D Loss: -0.0197
Epoch[31570/50000]
**Train**: G Loss: 224.0782, D Loss: 0.5112
Epoch[31570/50000]
**Valid**: G Loss: 217.0430, D Loss: -0.0620
Epoch[31580/50000]
**Train**: G Loss: 195.9837, D Loss: 0.7776
Epoch[31580/50000]
**Valid**: G Loss: 212.0681, D Loss: 0.2791
Epoch[31590/50000]
**Train**: G Loss: 230.9579, D Loss: 0.8829
Epoch[31590/50000]
**Valid**: G Loss: 219.5898, D Loss: 0.5054
Epoch[31600/50000]
**Train**: G Loss: 203.5071, D Loss: 0.5973
Epoch[31600/50000]
**Valid**: G Loss: 204.6473, D Loss: 0.7371
Epoch[31610/50000]
**Train**: G Loss: 236.4834, D Loss: 0.5180
Epoch[31610/50000]
**Valid**: G Loss: 231.0873, D Loss: 0.9214
Epoch[31620/50000]
**Train**: G Loss: 205.9975, D Loss: 0.4712
Epoch[31620/50000]
**Valid**: G Loss: 206.6060, D Loss: 0.6956
Epoch[31630/50000]
**Train**: G Loss: 239.0265, D Loss: 0.3524
Epoch[31630/50000]
**Valid**: G Loss: 235.0593, D Loss: 1.0900
Epoch[31640/50000]
**Train**: G Loss: 206.8434, D Loss: 0.2714
Epoch[31640/50000]
**Valid**: G Loss: 203.5119, D Loss: 0.8835
Epoch[31650/50000]
**Train**: G Loss: 227.9106, D Loss: 0.2064
Epoch[31650/50000]
**Valid**: G Loss: 236.6653, D Loss: 0.6329
Epoch[31660/50000]
**Train**: G Loss: 221.6055, D Loss: 0.3443
Epoch[31660/50000]
**Valid**: G Loss: 217.7315, D Loss: 0.0899
Epoch[31670/50000]
**Train**: G Loss: 209.6647, D Loss: 0.5588
Epoch[31670/50000]
**Valid**: G Loss: 210.5371, D Loss: 0.4033
Epoch[31680/50000]
**Train**: G Loss: 230.8601, D Loss: 0.7494
Epoch[31680/50000]
**Valid**: G Loss: 223.9484, D Loss: 0.6822
Epoch[31690/50000]
**Train**: G Loss: 207.5233, D Loss: 0.4651
Epoch[31690/50000]
**Valid**: G Loss: 206.5777, D Loss: 0.6732
Epoch[31700/50000]
**Train**: G Loss: 230.6139, D Loss: 0.4180
Epoch[31700/50000]
**Valid**: G Loss: 229.3455, D Loss: 0.9114
Epoch[31710/50000]
**Train**: G Loss: 210.8292, D Loss: -0.1210
Epoch[31710/50000]
**Valid**: G Loss: 205.4872, D Loss: 0.2100
Epoch[31720/50000]
**Train**: G Loss: 229.3103, D Loss: 0.2972
Epoch[31720/50000]
**Valid**: G Loss: 240.3018, D Loss: 0.6644
Epoch[31730/50000]
**Train**: G Loss: 224.5016, D Loss: 0.4952
Epoch[31730/50000]
**Valid**: G Loss: 217.0615, D Loss: 0.0052
Epoch[31740/50000]
**Train**: G Loss: 206.8840, D Loss: 0.8142
Epoch[31740/50000]
**Valid**: G Loss: 210.2331, D Loss: 0.5370
Epoch[31750/50000]
**Train**: G Loss: 234.4895, D Loss: 0.2321
Epoch[31750/50000]
**Valid**: G Loss: 234.5505, D Loss: 0.5343
Epoch[31760/50000]
**Train**: G Loss: 209.6336, D Loss: 0.1547
Epoch[31760/50000]
**Valid**: G Loss: 201.4112, D Loss: 0.3044
Epoch[31770/50000]
**Train**: G Loss: 208.5066, D Loss: 0.5501
Epoch[31770/50000]
**Valid**: G Loss: 223.0472, D Loss: 0.0400
Epoch[31780/50000]
**Train**: G Loss: 222.1872, D Loss: 0.6637
Epoch[31780/50000]
**Valid**: G Loss: 213.7414, D Loss: -0.2612
Epoch[31790/50000]
**Train**: G Loss: 207.7656, D Loss: 0.8932
Epoch[31790/50000]
**Valid**: G Loss: 212.4076, D Loss: 0.5651
Epoch[31800/50000]
**Train**: G Loss: 234.9564, D Loss: 0.5441
Epoch[31800/50000]
**Valid**: G Loss: 230.0313, D Loss: 1.1527
Epoch[31810/50000]
**Train**: G Loss: 207.4767, D Loss: 0.3264
Epoch[31810/50000]
**Valid**: G Loss: 205.5369, D Loss: 0.8820
Epoch[31820/50000]
**Train**: G Loss: 219.8134, D Loss: 0.3047
Epoch[31820/50000]
**Valid**: G Loss: 229.0717, D Loss: 0.3290
Epoch[31830/50000]
**Train**: G Loss: 225.6582, D Loss: 0.7288
Epoch[31830/50000]
**Valid**: G Loss: 218.3314, D Loss: 0.7409
Epoch[31840/50000]
**Train**: G Loss: 208.6175, D Loss: 0.6142
Epoch[31840/50000]
**Valid**: G Loss: 209.9550, D Loss: 0.6356
Epoch[31850/50000]
**Train**: G Loss: 229.7905, D Loss: 0.2604
Epoch[31850/50000]
**Valid**: G Loss: 232.2467, D Loss: 0.9867
Epoch[31860/50000]
**Train**: G Loss: 205.4849, D Loss: 0.1679
Epoch[31860/50000]
**Valid**: G Loss: 199.3224, D Loss: 0.9481
Epoch[31870/50000]
**Train**: G Loss: 229.0790, D Loss: 0.1471
Epoch[31870/50000]
**Valid**: G Loss: 234.5471, D Loss: 0.8318
Epoch[31880/50000]
**Train**: G Loss: 212.9835, D Loss: 0.1658
Epoch[31880/50000]
**Valid**: G Loss: 207.7152, D Loss: 0.3522
Epoch[31890/50000]
**Train**: G Loss: 213.0279, D Loss: 0.3961
Epoch[31890/50000]
**Valid**: G Loss: 226.0129, D Loss: 0.2569
Epoch[31900/50000]
**Train**: G Loss: 221.6033, D Loss: 0.6111
Epoch[31900/50000]
**Valid**: G Loss: 215.0946, D Loss: 0.0558
Epoch[31910/50000]
**Train**: G Loss: 211.7680, D Loss: 0.6232
Epoch[31910/50000]
**Valid**: G Loss: 224.4985, D Loss: 0.0395
Epoch[31920/50000]
**Train**: G Loss: 224.8757, D Loss: 0.5728
Epoch[31920/50000]
**Valid**: G Loss: 217.2003, D Loss: 0.0162
Epoch[31930/50000]
**Train**: G Loss: 207.2334, D Loss: 0.7596
Epoch[31930/50000]
**Valid**: G Loss: 210.6097, D Loss: 0.7605
Epoch[31940/50000]
**Train**: G Loss: 237.0769, D Loss: 0.3268
Epoch[31940/50000]
**Valid**: G Loss: 231.8054, D Loss: 0.7367
Epoch[31950/50000]
**Train**: G Loss: 205.5098, D Loss: 0.2101
Epoch[31950/50000]
**Valid**: G Loss: 203.0099, D Loss: 0.6939
Epoch[31960/50000]
**Train**: G Loss: 235.3603, D Loss: 0.0756
Epoch[31960/50000]
**Valid**: G Loss: 243.7717, D Loss: 0.6065
Epoch[31970/50000]
**Train**: G Loss: 217.7805, D Loss: 0.0500
Epoch[31970/50000]
**Valid**: G Loss: 210.6389, D Loss: 0.2817
Epoch[31980/50000]
**Train**: G Loss: 229.0664, D Loss: 0.2019
Epoch[31980/50000]
**Valid**: G Loss: 237.6717, D Loss: 0.5486
Epoch[31990/50000]
**Train**: G Loss: 216.7367, D Loss: 0.1022
Epoch[31990/50000]
**Valid**: G Loss: 211.8432, D Loss: 0.5577
Epoch[32000/50000]
**Train**: G Loss: 228.8917, D Loss: 0.1296
Epoch[32000/50000]
**Valid**: G Loss: 236.3609, D Loss: 0.3612
Epoch[32010/50000]
**Train**: G Loss: 211.7843, D Loss: -0.0667
Epoch[32010/50000]
**Valid**: G Loss: 206.3691, D Loss: 0.5884
Epoch[32020/50000]
**Train**: G Loss: 227.8077, D Loss: 0.1839
Epoch[32020/50000]
**Valid**: G Loss: 241.1518, D Loss: 0.0620
Epoch[32030/50000]
**Train**: G Loss: 221.7348, D Loss: 0.5204
Epoch[32030/50000]
**Valid**: G Loss: 214.9480, D Loss: -0.0470
Epoch[32040/50000]
**Train**: G Loss: 216.1415, D Loss: 0.5439
Epoch[32040/50000]
**Valid**: G Loss: 227.3870, D Loss: 0.0059
Epoch[32050/50000]
**Train**: G Loss: 234.9044, D Loss: 0.7914
Epoch[32050/50000]
**Valid**: G Loss: 227.1168, D Loss: 0.2713
Epoch[32060/50000]
**Train**: G Loss: 214.0312, D Loss: 0.4417
Epoch[32060/50000]
**Valid**: G Loss: 213.0414, D Loss: 0.7735
Epoch[32070/50000]
**Train**: G Loss: 237.6335, D Loss: 0.2820
Epoch[32070/50000]
**Valid**: G Loss: 237.6536, D Loss: 0.7981
Epoch[32080/50000]
**Train**: G Loss: 212.2001, D Loss: 0.3088
Epoch[32080/50000]
**Valid**: G Loss: 206.6622, D Loss: 0.6700
Epoch[32090/50000]
**Train**: G Loss: 232.6503, D Loss: 0.1169
Epoch[32090/50000]
**Valid**: G Loss: 239.5811, D Loss: 0.4759
Epoch[32100/50000]
**Train**: G Loss: 223.3393, D Loss: 0.1626
Epoch[32100/50000]
**Valid**: G Loss: 220.0737, D Loss: 0.0798
Epoch[32110/50000]
**Train**: G Loss: 225.3503, D Loss: 0.2156
Epoch[32110/50000]
**Valid**: G Loss: 236.1267, D Loss: 0.0301
Epoch[32120/50000]
**Train**: G Loss: 229.3046, D Loss: 0.3947
Epoch[32120/50000]
**Valid**: G Loss: 224.7737, D Loss: -0.0162
Epoch[32130/50000]
**Train**: G Loss: 216.4496, D Loss: 0.4080
Epoch[32130/50000]
**Valid**: G Loss: 228.2606, D Loss: 0.0557
Epoch[32140/50000]
**Train**: G Loss: 220.2168, D Loss: 0.3790
Epoch[32140/50000]
**Valid**: G Loss: 211.2354, D Loss: -0.0918
Epoch[32150/50000]
**Train**: G Loss: 213.8259, D Loss: 0.4611
Epoch[32150/50000]
**Valid**: G Loss: 225.5133, D Loss: 0.3627
Epoch[32160/50000]
**Train**: G Loss: 222.8063, D Loss: 0.7018
Epoch[32160/50000]
**Valid**: G Loss: 219.7613, D Loss: 0.2691
Epoch[32170/50000]
**Train**: G Loss: 210.4362, D Loss: 0.5923
Epoch[32170/50000]
**Valid**: G Loss: 213.7002, D Loss: 0.5559
Epoch[32180/50000]
**Train**: G Loss: 237.6852, D Loss: 0.4743
Epoch[32180/50000]
**Valid**: G Loss: 232.2324, D Loss: 0.8974
Epoch[32190/50000]
**Train**: G Loss: 216.3041, D Loss: 0.1996
Epoch[32190/50000]
**Valid**: G Loss: 209.7138, D Loss: 0.7292
Epoch[32200/50000]
**Train**: G Loss: 231.7494, D Loss: 0.1362
Epoch[32200/50000]
**Valid**: G Loss: 244.3963, D Loss: 0.6356
Epoch[32210/50000]
**Train**: G Loss: 222.4859, D Loss: 0.0849
Epoch[32210/50000]
**Valid**: G Loss: 215.4231, D Loss: 0.4429
Epoch[32220/50000]
**Train**: G Loss: 229.8236, D Loss: 0.3579
Epoch[32220/50000]
**Valid**: G Loss: 242.8917, D Loss: 0.3321
Epoch[32230/50000]
**Train**: G Loss: 224.7432, D Loss: 0.3999
Epoch[32230/50000]
**Valid**: G Loss: 217.3827, D Loss: 0.0449
Epoch[32240/50000]
**Train**: G Loss: 217.7162, D Loss: 0.6300
Epoch[32240/50000]
**Valid**: G Loss: 229.3694, D Loss: 0.1871
Epoch[32250/50000]
**Train**: G Loss: 228.8305, D Loss: 0.5356
Epoch[32250/50000]
**Valid**: G Loss: 221.2338, D Loss: 0.4089
Epoch[32260/50000]
**Train**: G Loss: 219.9750, D Loss: 0.4630
Epoch[32260/50000]
**Valid**: G Loss: 231.7312, D Loss: 0.2993
Epoch[32270/50000]
**Train**: G Loss: 229.5112, D Loss: 0.5578
Epoch[32270/50000]
**Valid**: G Loss: 224.0024, D Loss: 0.0351
Epoch[32280/50000]
**Train**: G Loss: 219.2176, D Loss: 0.5375
Epoch[32280/50000]
**Valid**: G Loss: 232.0949, D Loss: 0.0295
Epoch[32290/50000]
**Train**: G Loss: 232.4754, D Loss: 0.7624
Epoch[32290/50000]
**Valid**: G Loss: 225.1304, D Loss: 0.0642
Epoch[32300/50000]
**Train**: G Loss: 209.2166, D Loss: 0.4033
Epoch[32300/50000]
**Valid**: G Loss: 212.0298, D Loss: 0.3229
Epoch[32310/50000]
**Train**: G Loss: 229.5747, D Loss: 0.6752
Epoch[32310/50000]
**Valid**: G Loss: 221.6717, D Loss: 0.5474
Epoch[32320/50000]
**Train**: G Loss: 216.4124, D Loss: 0.5784
Epoch[32320/50000]
**Valid**: G Loss: 225.0356, D Loss: 0.3243
Epoch[32330/50000]
**Train**: G Loss: 224.5123, D Loss: 0.2757
Epoch[32330/50000]
**Valid**: G Loss: 217.1467, D Loss: 0.0946
Epoch[32340/50000]
**Train**: G Loss: 224.2639, D Loss: 0.2608
Epoch[32340/50000]
**Valid**: G Loss: 235.1783, D Loss: 0.2253
Epoch[32350/50000]
**Train**: G Loss: 221.7447, D Loss: 0.1738
Epoch[32350/50000]
**Valid**: G Loss: 214.6624, D Loss: 0.7768
Epoch[32360/50000]
**Train**: G Loss: 240.0898, D Loss: 0.3059
Epoch[32360/50000]
**Valid**: G Loss: 241.9975, D Loss: 0.9443
Epoch[32370/50000]
**Train**: G Loss: 212.2585, D Loss: 0.0822
Epoch[32370/50000]
**Valid**: G Loss: 205.8036, D Loss: 1.1519
Epoch[32380/50000]
**Train**: G Loss: 245.7912, D Loss: 0.2576
Epoch[32380/50000]
**Valid**: G Loss: 246.2206, D Loss: 1.0977
Epoch[32390/50000]
**Train**: G Loss: 217.4658, D Loss: 0.2972
Epoch[32390/50000]
**Valid**: G Loss: 217.0102, D Loss: 0.8743
Epoch[32400/50000]
**Train**: G Loss: 238.8964, D Loss: 0.3336
Epoch[32400/50000]
**Valid**: G Loss: 238.1983, D Loss: 0.8521
Epoch[32410/50000]
**Train**: G Loss: 222.2840, D Loss: 0.3409
Epoch[32410/50000]
**Valid**: G Loss: 216.3012, D Loss: 0.4530
Epoch[32420/50000]
**Train**: G Loss: 231.3749, D Loss: 0.1862
Epoch[32420/50000]
**Valid**: G Loss: 236.4888, D Loss: 0.4200
Epoch[32430/50000]
**Train**: G Loss: 218.6275, D Loss: 0.1782
Epoch[32430/50000]
**Valid**: G Loss: 212.1386, D Loss: 0.5398
Epoch[32440/50000]
**Train**: G Loss: 232.4776, D Loss: 0.0919
Epoch[32440/50000]
**Valid**: G Loss: 241.3594, D Loss: 0.2268
Epoch[32450/50000]
**Train**: G Loss: 219.5168, D Loss: 0.3479
Epoch[32450/50000]
**Valid**: G Loss: 212.1628, D Loss: 0.3034
Epoch[32460/50000]
**Train**: G Loss: 227.0820, D Loss: 0.3550
Epoch[32460/50000]
**Valid**: G Loss: 239.7116, D Loss: 0.3170
Epoch[32470/50000]
**Train**: G Loss: 224.8806, D Loss: 0.1087
Epoch[32470/50000]
**Valid**: G Loss: 219.6463, D Loss: 0.0865
Epoch[32480/50000]
**Train**: G Loss: 226.4430, D Loss: 0.3439
Epoch[32480/50000]
**Valid**: G Loss: 237.9106, D Loss: 0.1759
Epoch[32490/50000]
**Train**: G Loss: 219.2328, D Loss: 0.0902
Epoch[32490/50000]
**Valid**: G Loss: 214.9820, D Loss: 0.5530
Epoch[32500/50000]
**Train**: G Loss: 233.9166, D Loss: -0.0269
Epoch[32500/50000]
**Valid**: G Loss: 244.5299, D Loss: 0.1827
Epoch[32510/50000]
**Train**: G Loss: 225.9226, D Loss: 0.3807
Epoch[32510/50000]
**Valid**: G Loss: 218.0623, D Loss: 0.0616
Epoch[32520/50000]
**Train**: G Loss: 214.5930, D Loss: 0.5132
Epoch[32520/50000]
**Valid**: G Loss: 225.7931, D Loss: 0.0410
Epoch[32530/50000]
**Train**: G Loss: 234.2556, D Loss: 0.7905
Epoch[32530/50000]
**Valid**: G Loss: 226.9451, D Loss: 0.6230
Epoch[32540/50000]
**Train**: G Loss: 211.0763, D Loss: 0.5720
Epoch[32540/50000]
**Valid**: G Loss: 212.0828, D Loss: 0.8112
Epoch[32550/50000]
**Train**: G Loss: 234.9632, D Loss: 0.5805
Epoch[32550/50000]
**Valid**: G Loss: 231.4353, D Loss: 0.8246
Epoch[32560/50000]
**Train**: G Loss: 212.9656, D Loss: 0.1036
Epoch[32560/50000]
**Valid**: G Loss: 208.4883, D Loss: 0.4633
Epoch[32570/50000]
**Train**: G Loss: 231.7719, D Loss: 0.2075
Epoch[32570/50000]
**Valid**: G Loss: 236.7123, D Loss: 0.4705
Epoch[32580/50000]
**Train**: G Loss: 221.9792, D Loss: 0.1978
Epoch[32580/50000]
**Valid**: G Loss: 215.2345, D Loss: 0.8001
Epoch[32590/50000]
**Train**: G Loss: 240.0756, D Loss: 0.2960
Epoch[32590/50000]
**Valid**: G Loss: 240.8420, D Loss: 0.7847
Epoch[32600/50000]
**Train**: G Loss: 207.4085, D Loss: 0.3240
Epoch[32600/50000]
**Valid**: G Loss: 202.9261, D Loss: 0.8060
Epoch[32610/50000]
**Train**: G Loss: 225.6952, D Loss: 0.3129
Epoch[32610/50000]
**Valid**: G Loss: 232.1102, D Loss: 0.4716
Epoch[32620/50000]
**Train**: G Loss: 219.2296, D Loss: 0.4367
Epoch[32620/50000]
**Valid**: G Loss: 210.7653, D Loss: 0.2286
Epoch[32630/50000]
**Train**: G Loss: 218.5661, D Loss: 0.3406
Epoch[32630/50000]
**Valid**: G Loss: 229.2439, D Loss: 0.1130
Epoch[32640/50000]
**Train**: G Loss: 208.2961, D Loss: 0.2787
Epoch[32640/50000]
**Valid**: G Loss: 187.8102, D Loss: 0.1446
Epoch[32650/50000]
**Train**: G Loss: 229.0242, D Loss: 0.8228
Epoch[32650/50000]
**Valid**: G Loss: 218.3717, D Loss: 0.3099
Epoch[32660/50000]
**Train**: G Loss: 210.9104, D Loss: 0.7968
Epoch[32660/50000]
**Valid**: G Loss: 224.2966, D Loss: 0.1194
Epoch[32670/50000]
**Train**: G Loss: 230.7772, D Loss: 0.6939
Epoch[32670/50000]
**Valid**: G Loss: 222.4380, D Loss: 0.2284
Epoch[32680/50000]
**Train**: G Loss: 213.2255, D Loss: 0.5416
Epoch[32680/50000]
**Valid**: G Loss: 213.0079, D Loss: 0.7250
Epoch[32690/50000]
**Train**: G Loss: 232.6395, D Loss: 0.3027
Epoch[32690/50000]
**Valid**: G Loss: 234.9095, D Loss: 0.6123
Epoch[32700/50000]
**Train**: G Loss: 223.5801, D Loss: 0.3789
Epoch[32700/50000]
**Valid**: G Loss: 216.6273, D Loss: -0.0319
Epoch[32710/50000]
**Train**: G Loss: 201.3725, D Loss: 0.6665
Epoch[32710/50000]
**Valid**: G Loss: 205.2404, D Loss: 0.5491
Epoch[32720/50000]
**Train**: G Loss: 233.8833, D Loss: 0.5021
Epoch[32720/50000]
**Valid**: G Loss: 231.0126, D Loss: 0.7268
Epoch[32730/50000]
**Train**: G Loss: 220.0749, D Loss: 0.3401
Epoch[32730/50000]
**Valid**: G Loss: 216.3527, D Loss: 0.4745
Epoch[32740/50000]
**Train**: G Loss: 211.0279, D Loss: 0.5213
Epoch[32740/50000]
**Valid**: G Loss: 222.1485, D Loss: -0.0822
Epoch[32750/50000]
**Train**: G Loss: 226.8604, D Loss: 0.7948
Epoch[32750/50000]
**Valid**: G Loss: 219.8829, D Loss: 0.1045
Epoch[32760/50000]
**Train**: G Loss: 215.6655, D Loss: 0.6198
Epoch[32760/50000]
**Valid**: G Loss: 224.2392, D Loss: 0.3362
Epoch[32770/50000]
**Train**: G Loss: 232.0900, D Loss: 0.8207
Epoch[32770/50000]
**Valid**: G Loss: 224.1958, D Loss: 0.3412
Epoch[32780/50000]
**Train**: G Loss: 211.2137, D Loss: 0.7259
Epoch[32780/50000]
**Valid**: G Loss: 218.5177, D Loss: 0.3004
Epoch[32790/50000]
**Train**: G Loss: 233.9966, D Loss: 0.6490
Epoch[32790/50000]
**Valid**: G Loss: 228.4713, D Loss: 0.6663
Epoch[32800/50000]
**Train**: G Loss: 206.5867, D Loss: 0.5866
Epoch[32800/50000]
**Valid**: G Loss: 207.3038, D Loss: 0.6204
Epoch[32810/50000]
**Train**: G Loss: 236.7960, D Loss: 0.2897
Epoch[32810/50000]
**Valid**: G Loss: 238.3364, D Loss: 0.8146
Epoch[32820/50000]
**Train**: G Loss: 213.5332, D Loss: 0.3950
Epoch[32820/50000]
**Valid**: G Loss: 208.1386, D Loss: 1.0057
Epoch[32830/50000]
**Train**: G Loss: 234.2177, D Loss: 0.5122
Epoch[32830/50000]
**Valid**: G Loss: 232.1572, D Loss: 0.8213
Epoch[32840/50000]
**Train**: G Loss: 215.1610, D Loss: 0.5452
Epoch[32840/50000]
**Valid**: G Loss: 215.3281, D Loss: 0.6568
Epoch[32850/50000]
**Train**: G Loss: 242.0648, D Loss: 0.5425
Epoch[32850/50000]
**Valid**: G Loss: 237.0415, D Loss: 0.9263
Epoch[32860/50000]
**Train**: G Loss: 211.0952, D Loss: 0.1313
Epoch[32860/50000]
**Valid**: G Loss: 207.0603, D Loss: 0.5131
Epoch[32870/50000]
**Train**: G Loss: 226.5462, D Loss: 0.2909
Epoch[32870/50000]
**Valid**: G Loss: 234.8123, D Loss: 0.5199
Epoch[32880/50000]
**Train**: G Loss: 215.7402, D Loss: 0.2787
Epoch[32880/50000]
**Valid**: G Loss: 210.1660, D Loss: 0.3097
Epoch[32890/50000]
**Train**: G Loss: 214.4136, D Loss: 0.5568
Epoch[32890/50000]
**Valid**: G Loss: 220.9530, D Loss: 0.3244
Epoch[32900/50000]
**Train**: G Loss: 231.5247, D Loss: 0.5351
Epoch[32900/50000]
**Valid**: G Loss: 229.6987, D Loss: 0.6798
Epoch[32910/50000]
**Train**: G Loss: 209.7934, D Loss: 0.6570
Epoch[32910/50000]
**Valid**: G Loss: 210.6424, D Loss: 0.9285
Epoch[32920/50000]
**Train**: G Loss: 235.7697, D Loss: 0.3981
Epoch[32920/50000]
**Valid**: G Loss: 233.3640, D Loss: 0.8949
Epoch[32930/50000]
**Train**: G Loss: 211.6441, D Loss: 0.4945
Epoch[32930/50000]
**Valid**: G Loss: 208.7715, D Loss: 0.6701
Epoch[32940/50000]
**Train**: G Loss: 236.2048, D Loss: 0.2344
Epoch[32940/50000]
**Valid**: G Loss: 242.0365, D Loss: 0.7541
Epoch[32950/50000]
**Train**: G Loss: 212.2746, D Loss: 0.3703
Epoch[32950/50000]
**Valid**: G Loss: 207.5914, D Loss: 0.7407
Epoch[32960/50000]
**Train**: G Loss: 234.2232, D Loss: 0.3463
Epoch[32960/50000]
**Valid**: G Loss: 240.9959, D Loss: 0.5063
Epoch[32970/50000]
**Train**: G Loss: 219.7180, D Loss: 0.1448
Epoch[32970/50000]
**Valid**: G Loss: 216.0388, D Loss: 0.5541
Epoch[32980/50000]
**Train**: G Loss: 226.6580, D Loss: 0.3904
Epoch[32980/50000]
**Valid**: G Loss: 229.5187, D Loss: 0.7354
Epoch[32990/50000]
**Train**: G Loss: 212.7531, D Loss: 0.3549
Epoch[32990/50000]
**Valid**: G Loss: 211.0477, D Loss: 0.8201
Epoch[33000/50000]
**Train**: G Loss: 233.2682, D Loss: 0.6873
Epoch[33000/50000]
**Valid**: G Loss: 228.0422, D Loss: 0.8160
Epoch[33010/50000]
**Train**: G Loss: 201.7715, D Loss: 0.5173
Epoch[33010/50000]
**Valid**: G Loss: 202.0869, D Loss: 0.7811
Epoch[33020/50000]
**Train**: G Loss: 232.7102, D Loss: 0.4719
Epoch[33020/50000]
**Valid**: G Loss: 229.0922, D Loss: 0.6672
Epoch[33030/50000]
**Train**: G Loss: 208.6210, D Loss: 0.4104
Epoch[33030/50000]
**Valid**: G Loss: 206.9482, D Loss: 0.6937
Epoch[33040/50000]
**Train**: G Loss: 231.4896, D Loss: 0.6947
Epoch[33040/50000]
**Valid**: G Loss: 230.4222, D Loss: 0.9929
Epoch[33050/50000]
**Train**: G Loss: 210.4507, D Loss: 0.5313
Epoch[33050/50000]
**Valid**: G Loss: 208.2071, D Loss: 0.8716
Epoch[33060/50000]
**Train**: G Loss: 230.6767, D Loss: 0.5456
Epoch[33060/50000]
**Valid**: G Loss: 225.9445, D Loss: 0.6005
Epoch[33070/50000]
**Train**: G Loss: 211.1927, D Loss: 0.6876
Epoch[33070/50000]
**Valid**: G Loss: 218.5466, D Loss: 0.2798
Epoch[33080/50000]
**Train**: G Loss: 228.5073, D Loss: 0.4270
Epoch[33080/50000]
**Valid**: G Loss: 222.6503, D Loss: 0.0988
Epoch[33090/50000]
**Train**: G Loss: 238.0713, D Loss: 0.1303
Epoch[33090/50000]
**Valid**: G Loss: 245.9825, D Loss: 0.6551
Epoch[33100/50000]
**Train**: G Loss: 215.1109, D Loss: 0.1063
Epoch[33100/50000]
**Valid**: G Loss: 210.3072, D Loss: 0.7490
Epoch[33110/50000]
**Train**: G Loss: 250.1258, D Loss: 0.7362
Epoch[33110/50000]
**Valid**: G Loss: 237.2042, D Loss: 0.6066
Epoch[33120/50000]
**Train**: G Loss: 220.0760, D Loss: 0.6549
Epoch[33120/50000]
**Valid**: G Loss: 232.6364, D Loss: 0.2769
Epoch[33130/50000]
**Train**: G Loss: 233.0508, D Loss: 0.6147
Epoch[33130/50000]
**Valid**: G Loss: 224.1393, D Loss: -0.0025
Epoch[33140/50000]
**Train**: G Loss: 223.2021, D Loss: 0.4666
Epoch[33140/50000]
**Valid**: G Loss: 235.1715, D Loss: -0.0051
Epoch[33150/50000]
**Train**: G Loss: 235.3388, D Loss: 0.4929
Epoch[33150/50000]
**Valid**: G Loss: 229.3472, D Loss: 0.0149
Epoch[33160/50000]
**Train**: G Loss: 230.9760, D Loss: 0.3744
Epoch[33160/50000]
**Valid**: G Loss: 240.7416, D Loss: 0.1859
Epoch[33170/50000]
**Train**: G Loss: 226.0103, D Loss: 0.2486
Epoch[33170/50000]
**Valid**: G Loss: 220.9893, D Loss: 0.4554
Epoch[33180/50000]
**Train**: G Loss: 243.7378, D Loss: 0.3154
Epoch[33180/50000]
**Valid**: G Loss: 247.5985, D Loss: 0.8588
Epoch[33190/50000]
**Train**: G Loss: 216.2898, D Loss: 0.7358
Epoch[33190/50000]
**Valid**: G Loss: 220.7249, D Loss: 0.2874
Epoch[33200/50000]
**Train**: G Loss: 232.1347, D Loss: 0.4167
Epoch[33200/50000]
**Valid**: G Loss: 224.6079, D Loss: -0.0659
Epoch[33210/50000]
**Train**: G Loss: 234.7816, D Loss: 0.2432
Epoch[33210/50000]
**Valid**: G Loss: 247.9160, D Loss: 0.2164
Epoch[33220/50000]
**Train**: G Loss: 217.1760, D Loss: 0.1756
Epoch[33220/50000]
**Valid**: G Loss: 212.0855, D Loss: 0.7201
Epoch[33230/50000]
**Train**: G Loss: 248.6091, D Loss: 0.1390
Epoch[33230/50000]
**Valid**: G Loss: 253.5951, D Loss: 0.9655
Epoch[33240/50000]
**Train**: G Loss: 210.3565, D Loss: 0.0811
Epoch[33240/50000]
**Valid**: G Loss: 202.0422, D Loss: 0.6633
Epoch[33250/50000]
**Train**: G Loss: 235.1133, D Loss: 0.1400
Epoch[33250/50000]
**Valid**: G Loss: 244.7443, D Loss: 0.2198
Epoch[33260/50000]
**Train**: G Loss: 217.6811, D Loss: 0.3876
Epoch[33260/50000]
**Valid**: G Loss: 209.6887, D Loss: 0.2961
Epoch[33270/50000]
**Train**: G Loss: 216.7528, D Loss: 0.3983
Epoch[33270/50000]
**Valid**: G Loss: 226.2772, D Loss: 0.2152
Epoch[33280/50000]
**Train**: G Loss: 226.5823, D Loss: 0.6989
Epoch[33280/50000]
**Valid**: G Loss: 218.3911, D Loss: 0.2241
Epoch[33290/50000]
**Train**: G Loss: 222.6736, D Loss: 0.4686
Epoch[33290/50000]
**Valid**: G Loss: 231.4596, D Loss: 0.2796
Epoch[33300/50000]
**Train**: G Loss: 208.3666, D Loss: -0.0562
Epoch[33300/50000]
**Valid**: G Loss: 198.4895, D Loss: 0.8018
Epoch[33310/50000]
**Train**: G Loss: 236.6704, D Loss: 0.3109
Epoch[33310/50000]
**Valid**: G Loss: 234.9317, D Loss: 0.9614
Epoch[33320/50000]
**Train**: G Loss: 215.4263, D Loss: 0.3608
Epoch[33320/50000]
**Valid**: G Loss: 212.7254, D Loss: 0.6488
Epoch[33330/50000]
**Train**: G Loss: 235.5836, D Loss: 0.1621
Epoch[33330/50000]
**Valid**: G Loss: 243.8085, D Loss: 0.5834
Epoch[33340/50000]
**Train**: G Loss: 229.7222, D Loss: 0.2157
Epoch[33340/50000]
**Valid**: G Loss: 221.5263, D Loss: 0.0508
Epoch[33350/50000]
**Train**: G Loss: 225.2709, D Loss: 0.3932
Epoch[33350/50000]
**Valid**: G Loss: 234.4905, D Loss: 0.0359
Epoch[33360/50000]
**Train**: G Loss: 230.8010, D Loss: 0.6122
Epoch[33360/50000]
**Valid**: G Loss: 225.0256, D Loss: 0.1337
Epoch[33370/50000]
**Train**: G Loss: 214.2057, D Loss: 0.7067
Epoch[33370/50000]
**Valid**: G Loss: 216.4014, D Loss: 0.8153
Epoch[33380/50000]
**Train**: G Loss: 238.4040, D Loss: 0.4068
Epoch[33380/50000]
**Valid**: G Loss: 235.2245, D Loss: 0.5944
Epoch[33390/50000]
**Train**: G Loss: 215.1125, D Loss: 0.3932
Epoch[33390/50000]
**Valid**: G Loss: 212.2514, D Loss: 0.4265
Epoch[33400/50000]
**Train**: G Loss: 239.1406, D Loss: 0.3707
Epoch[33400/50000]
**Valid**: G Loss: 239.2136, D Loss: 0.8947
Epoch[33410/50000]
**Train**: G Loss: 214.6472, D Loss: 0.3048
Epoch[33410/50000]
**Valid**: G Loss: 209.8397, D Loss: 0.7545
Epoch[33420/50000]
**Train**: G Loss: 246.9940, D Loss: 0.5423
Epoch[33420/50000]
**Valid**: G Loss: 240.3137, D Loss: 0.9584
Epoch[33430/50000]
**Train**: G Loss: 209.5813, D Loss: 0.3707
Epoch[33430/50000]
**Valid**: G Loss: 204.9463, D Loss: 1.0411
Epoch[33440/50000]
**Train**: G Loss: 244.6629, D Loss: 0.4045
Epoch[33440/50000]
**Valid**: G Loss: 241.4338, D Loss: 0.8771
Epoch[33450/50000]
**Train**: G Loss: 217.6860, D Loss: 0.5298
Epoch[33450/50000]
**Valid**: G Loss: 215.1694, D Loss: 0.7689
Epoch[33460/50000]
**Train**: G Loss: 236.8312, D Loss: 0.5730
Epoch[33460/50000]
**Valid**: G Loss: 233.6614, D Loss: 0.7175
Epoch[33470/50000]
**Train**: G Loss: 225.1542, D Loss: 0.0200
Epoch[33470/50000]
**Valid**: G Loss: 223.4153, D Loss: 0.6329
Epoch[33480/50000]
**Train**: G Loss: 238.7648, D Loss: 0.4466
Epoch[33480/50000]
**Valid**: G Loss: 236.6141, D Loss: 0.7851
Epoch[33490/50000]
**Train**: G Loss: 217.5487, D Loss: 0.5261
Epoch[33490/50000]
**Valid**: G Loss: 219.8667, D Loss: 0.4756
Epoch[33500/50000]
**Train**: G Loss: 232.1773, D Loss: 0.6491
Epoch[33500/50000]
**Valid**: G Loss: 228.2416, D Loss: 0.3922
Epoch[33510/50000]
**Train**: G Loss: 217.6496, D Loss: 0.6490
Epoch[33510/50000]
**Valid**: G Loss: 226.9465, D Loss: 0.3084
Epoch[33520/50000]
**Train**: G Loss: 222.2628, D Loss: 0.2468
Epoch[33520/50000]
**Valid**: G Loss: 215.6019, D Loss: 0.2163
Epoch[33530/50000]
**Train**: G Loss: 236.2993, D Loss: 0.2975
Epoch[33530/50000]
**Valid**: G Loss: 244.0462, D Loss: 0.5213
Epoch[33540/50000]
**Train**: G Loss: 214.8519, D Loss: 0.3020
Epoch[33540/50000]
**Valid**: G Loss: 211.3981, D Loss: 0.6518
Epoch[33550/50000]
**Train**: G Loss: 236.5860, D Loss: 0.1824
Epoch[33550/50000]
**Valid**: G Loss: 238.4917, D Loss: 0.6364
Epoch[33560/50000]
**Train**: G Loss: 211.4493, D Loss: 0.4599
Epoch[33560/50000]
**Valid**: G Loss: 209.3463, D Loss: 0.8648
Epoch[33570/50000]
**Train**: G Loss: 238.3712, D Loss: 0.7902
Epoch[33570/50000]
**Valid**: G Loss: 229.4296, D Loss: 0.3119
Epoch[33580/50000]
**Train**: G Loss: 214.5988, D Loss: 0.5212
Epoch[33580/50000]
**Valid**: G Loss: 224.0907, D Loss: 0.4504
Epoch[33590/50000]
**Train**: G Loss: 227.2962, D Loss: 0.4195
Epoch[33590/50000]
**Valid**: G Loss: 219.0449, D Loss: 0.2455
Epoch[33600/50000]
**Train**: G Loss: 233.7864, D Loss: 0.3941
Epoch[33600/50000]
**Valid**: G Loss: 239.9275, D Loss: 0.7499
Epoch[33610/50000]
**Train**: G Loss: 217.1437, D Loss: 0.1956
Epoch[33610/50000]
**Valid**: G Loss: 210.1850, D Loss: 0.6220
Epoch[33620/50000]
**Train**: G Loss: 235.9170, D Loss: 0.3911
Epoch[33620/50000]
**Valid**: G Loss: 240.5488, D Loss: 0.7075
Epoch[33630/50000]
**Train**: G Loss: 219.9577, D Loss: 0.1810
Epoch[33630/50000]
**Valid**: G Loss: 214.4493, D Loss: 0.8642
Epoch[33640/50000]
**Train**: G Loss: 242.4731, D Loss: 0.2818
Epoch[33640/50000]
**Valid**: G Loss: 241.9908, D Loss: 1.1406
Epoch[33650/50000]
**Train**: G Loss: 211.7714, D Loss: 0.3187
Epoch[33650/50000]
**Valid**: G Loss: 205.7784, D Loss: 0.8347
Epoch[33660/50000]
**Train**: G Loss: 242.4582, D Loss: 0.3823
Epoch[33660/50000]
**Valid**: G Loss: 241.5396, D Loss: 0.9838
Epoch[33670/50000]
**Train**: G Loss: 214.9815, D Loss: 0.2981
Epoch[33670/50000]
**Valid**: G Loss: 211.0919, D Loss: 0.8698
Epoch[33680/50000]
**Train**: G Loss: 248.5474, D Loss: 0.2945
Epoch[33680/50000]
**Valid**: G Loss: 245.1617, D Loss: 1.1230
Epoch[33690/50000]
**Train**: G Loss: 219.2311, D Loss: 0.5006
Epoch[33690/50000]
**Valid**: G Loss: 216.9857, D Loss: 0.9983
Epoch[33700/50000]
**Train**: G Loss: 246.1820, D Loss: 0.5840
Epoch[33700/50000]
**Valid**: G Loss: 238.6397, D Loss: 0.7341
Epoch[33710/50000]
**Train**: G Loss: 216.1967, D Loss: 0.5331
Epoch[33710/50000]
**Valid**: G Loss: 218.4524, D Loss: 0.6449
Epoch[33720/50000]
**Train**: G Loss: 239.6811, D Loss: 0.8421
Epoch[33720/50000]
**Valid**: G Loss: 233.8087, D Loss: 0.6905
Epoch[33730/50000]
**Train**: G Loss: 219.5217, D Loss: 0.5701
Epoch[33730/50000]
**Valid**: G Loss: 221.5671, D Loss: 0.5467
Epoch[33740/50000]
**Train**: G Loss: 237.4157, D Loss: 0.7454
Epoch[33740/50000]
**Valid**: G Loss: 231.4066, D Loss: 0.4913
Epoch[33750/50000]
**Train**: G Loss: 216.1377, D Loss: 0.6722
Epoch[33750/50000]
**Valid**: G Loss: 220.9944, D Loss: 0.3770
Epoch[33760/50000]
**Train**: G Loss: 238.3563, D Loss: 0.5382
Epoch[33760/50000]
**Valid**: G Loss: 232.7648, D Loss: 0.4629
Epoch[33770/50000]
**Train**: G Loss: 217.6882, D Loss: 0.6777
Epoch[33770/50000]
**Valid**: G Loss: 226.6272, D Loss: 0.3860
Epoch[33780/50000]
**Train**: G Loss: 236.5926, D Loss: 0.4591
Epoch[33780/50000]
**Valid**: G Loss: 230.9516, D Loss: 0.1491
Epoch[33790/50000]
**Train**: G Loss: 220.2046, D Loss: 0.6420
Epoch[33790/50000]
**Valid**: G Loss: 231.6600, D Loss: 0.2714
Epoch[33800/50000]
**Train**: G Loss: 233.7693, D Loss: 0.4835
Epoch[33800/50000]
**Valid**: G Loss: 229.5800, D Loss: 0.0620
Epoch[33810/50000]
**Train**: G Loss: 230.8663, D Loss: 0.4926
Epoch[33810/50000]
**Valid**: G Loss: 239.7402, D Loss: 0.2718
Epoch[33820/50000]
**Train**: G Loss: 232.4587, D Loss: 0.3783
Epoch[33820/50000]
**Valid**: G Loss: 227.1851, D Loss: 0.2046
Epoch[33830/50000]
**Train**: G Loss: 224.8658, D Loss: 0.5956
Epoch[33830/50000]
**Valid**: G Loss: 235.3137, D Loss: 0.1271
Epoch[33840/50000]
**Train**: G Loss: 233.8297, D Loss: 0.5581
Epoch[33840/50000]
**Valid**: G Loss: 229.7979, D Loss: 0.2462
Epoch[33850/50000]
**Train**: G Loss: 224.7665, D Loss: 0.4787
Epoch[33850/50000]
**Valid**: G Loss: 238.0927, D Loss: 0.0056
Epoch[33860/50000]
**Train**: G Loss: 229.0910, D Loss: 0.3124
Epoch[33860/50000]
**Valid**: G Loss: 222.8403, D Loss: -0.1327
Epoch[33870/50000]
**Train**: G Loss: 238.5375, D Loss: 0.2821
Epoch[33870/50000]
**Valid**: G Loss: 249.3823, D Loss: 0.2601
Epoch[33880/50000]
**Train**: G Loss: 228.3106, D Loss: 0.2727
Epoch[33880/50000]
**Valid**: G Loss: 221.9753, D Loss: 0.6298
Epoch[33890/50000]
**Train**: G Loss: 249.1069, D Loss: 0.3835
Epoch[33890/50000]
**Valid**: G Loss: 248.6312, D Loss: 1.0520
Epoch[33900/50000]
**Train**: G Loss: 221.0765, D Loss: 0.3186
Epoch[33900/50000]
**Valid**: G Loss: 217.8723, D Loss: 0.7471
Epoch[33910/50000]
**Train**: G Loss: 248.5761, D Loss: 0.4807
Epoch[33910/50000]
**Valid**: G Loss: 240.1101, D Loss: 0.5743
Epoch[33920/50000]
**Train**: G Loss: 214.8558, D Loss: 0.6021
Epoch[33920/50000]
**Valid**: G Loss: 220.5164, D Loss: 0.4302
Epoch[33930/50000]
**Train**: G Loss: 242.8850, D Loss: 0.5276
Epoch[33930/50000]
**Valid**: G Loss: 236.2830, D Loss: 0.2555
Epoch[33940/50000]
**Train**: G Loss: 218.6995, D Loss: 0.6379
Epoch[33940/50000]
**Valid**: G Loss: 223.9556, D Loss: 0.3741
Epoch[33950/50000]
**Train**: G Loss: 237.8813, D Loss: 0.6244
Epoch[33950/50000]
**Valid**: G Loss: 235.9033, D Loss: 0.2977
Epoch[33960/50000]
**Train**: G Loss: 218.7876, D Loss: 0.6873
Epoch[33960/50000]
**Valid**: G Loss: 224.2320, D Loss: 0.3645
Epoch[33970/50000]
**Train**: G Loss: 231.7909, D Loss: 0.7647
Epoch[33970/50000]
**Valid**: G Loss: 228.1773, D Loss: 0.3887
Epoch[33980/50000]
**Train**: G Loss: 229.3724, D Loss: 0.5913
Epoch[33980/50000]
**Valid**: G Loss: 235.7319, D Loss: 0.3303
Epoch[33990/50000]
**Train**: G Loss: 237.5070, D Loss: 0.6096
Epoch[33990/50000]
**Valid**: G Loss: 233.0775, D Loss: 0.2696
Epoch[34000/50000]
**Train**: G Loss: 231.8375, D Loss: 0.4183
Epoch[34000/50000]
**Valid**: G Loss: 241.5679, D Loss: 0.3609
Epoch[34010/50000]
**Train**: G Loss: 217.8734, D Loss: 0.2861
Epoch[34010/50000]
**Valid**: G Loss: 210.1252, D Loss: 0.7795
Epoch[34020/50000]
**Train**: G Loss: 242.6453, D Loss: 0.2234
Epoch[34020/50000]
**Valid**: G Loss: 246.7675, D Loss: 0.7604
Epoch[34030/50000]
**Train**: G Loss: 221.1252, D Loss: 0.3510
Epoch[34030/50000]
**Valid**: G Loss: 215.3731, D Loss: 0.8278
Epoch[34040/50000]
**Train**: G Loss: 241.6942, D Loss: 0.6172
Epoch[34040/50000]
**Valid**: G Loss: 236.4903, D Loss: 1.0025
Epoch[34050/50000]
**Train**: G Loss: 214.3916, D Loss: 0.6473
Epoch[34050/50000]
**Valid**: G Loss: 222.0417, D Loss: 0.4255
Epoch[34060/50000]
**Train**: G Loss: 237.2278, D Loss: 0.5323
Epoch[34060/50000]
**Valid**: G Loss: 230.3980, D Loss: 0.1167
Epoch[34070/50000]
**Train**: G Loss: 228.4832, D Loss: 0.5109
Epoch[34070/50000]
**Valid**: G Loss: 242.2068, D Loss: 0.3308
Epoch[34080/50000]
**Train**: G Loss: 229.3631, D Loss: 0.1741
Epoch[34080/50000]
**Valid**: G Loss: 222.8758, D Loss: 0.2248
Epoch[34090/50000]
**Train**: G Loss: 247.0032, D Loss: 0.4753
Epoch[34090/50000]
**Valid**: G Loss: 246.4936, D Loss: 0.9362
Epoch[34100/50000]
**Train**: G Loss: 219.5015, D Loss: 0.6708
Epoch[34100/50000]
**Valid**: G Loss: 217.0890, D Loss: 1.1067
Epoch[34110/50000]
**Train**: G Loss: 240.2393, D Loss: 0.7114
Epoch[34110/50000]
**Valid**: G Loss: 236.2148, D Loss: 0.5965
Epoch[34120/50000]
**Train**: G Loss: 228.3643, D Loss: 0.5237
Epoch[34120/50000]
**Valid**: G Loss: 234.2776, D Loss: 0.1365
Epoch[34130/50000]
**Train**: G Loss: 236.8076, D Loss: 0.5477
Epoch[34130/50000]
**Valid**: G Loss: 231.5928, D Loss: 0.1958
Epoch[34140/50000]
**Train**: G Loss: 232.8827, D Loss: 0.3665
Epoch[34140/50000]
**Valid**: G Loss: 244.0868, D Loss: 0.1343
Epoch[34150/50000]
**Train**: G Loss: 239.0037, D Loss: 0.3270
Epoch[34150/50000]
**Valid**: G Loss: 233.0884, D Loss: -0.0214
Epoch[34160/50000]
**Train**: G Loss: 232.4122, D Loss: 0.5180
Epoch[34160/50000]
**Valid**: G Loss: 241.3434, D Loss: 0.3798
Epoch[34170/50000]
**Train**: G Loss: 237.2014, D Loss: 0.6537
Epoch[34170/50000]
**Valid**: G Loss: 231.5108, D Loss: 0.2742
Epoch[34180/50000]
**Train**: G Loss: 222.8042, D Loss: 0.6353
Epoch[34180/50000]
**Valid**: G Loss: 233.5406, D Loss: 0.1802
Epoch[34190/50000]
**Train**: G Loss: 235.8514, D Loss: 0.4688
Epoch[34190/50000]
**Valid**: G Loss: 229.7656, D Loss: 0.1371
Epoch[34200/50000]
**Train**: G Loss: 220.5608, D Loss: 0.5366
Epoch[34200/50000]
**Valid**: G Loss: 228.4042, D Loss: 0.1710
Epoch[34210/50000]
**Train**: G Loss: 238.2361, D Loss: 0.6787
Epoch[34210/50000]
**Valid**: G Loss: 230.7155, D Loss: 0.3368
Epoch[34220/50000]
**Train**: G Loss: 226.6817, D Loss: 0.4972
Epoch[34220/50000]
**Valid**: G Loss: 238.9885, D Loss: 0.2376
Epoch[34230/50000]
**Train**: G Loss: 232.1509, D Loss: -0.0724
Epoch[34230/50000]
**Valid**: G Loss: 226.5728, D Loss: 0.3819
Epoch[34240/50000]
**Train**: G Loss: 246.5669, D Loss: 0.3695
Epoch[34240/50000]
**Valid**: G Loss: 245.7051, D Loss: 0.8990
Epoch[34250/50000]
**Train**: G Loss: 221.5693, D Loss: 0.6510
Epoch[34250/50000]
**Valid**: G Loss: 219.0262, D Loss: 0.9865
Epoch[34260/50000]
**Train**: G Loss: 242.4919, D Loss: 0.6677
Epoch[34260/50000]
**Valid**: G Loss: 238.9090, D Loss: 0.7274
Epoch[34270/50000]
**Train**: G Loss: 221.1434, D Loss: 0.6294
Epoch[34270/50000]
**Valid**: G Loss: 225.7168, D Loss: 0.5578
Epoch[34280/50000]
**Train**: G Loss: 243.3321, D Loss: 0.6598
Epoch[34280/50000]
**Valid**: G Loss: 238.4379, D Loss: 0.4443
Epoch[34290/50000]
**Train**: G Loss: 219.9101, D Loss: 0.4354
Epoch[34290/50000]
**Valid**: G Loss: 226.3896, D Loss: 0.1639
Epoch[34300/50000]
**Train**: G Loss: 239.6080, D Loss: 0.5749
Epoch[34300/50000]
**Valid**: G Loss: 234.6793, D Loss: 0.3801
Epoch[34310/50000]
**Train**: G Loss: 226.8353, D Loss: 0.5265
Epoch[34310/50000]
**Valid**: G Loss: 239.4380, D Loss: 0.1902
Epoch[34320/50000]
**Train**: G Loss: 230.9228, D Loss: 0.4968
Epoch[34320/50000]
**Valid**: G Loss: 225.3414, D Loss: 0.4088
Epoch[34330/50000]
**Train**: G Loss: 232.2979, D Loss: 0.4050
Epoch[34330/50000]
**Valid**: G Loss: 237.0636, D Loss: 0.5843
Epoch[34340/50000]
**Train**: G Loss: 222.5290, D Loss: 0.4390
Epoch[34340/50000]
**Valid**: G Loss: 218.4271, D Loss: 0.6723
Epoch[34350/50000]
**Train**: G Loss: 242.7968, D Loss: 0.5489
Epoch[34350/50000]
**Valid**: G Loss: 241.6889, D Loss: 0.8437
Epoch[34360/50000]
**Train**: G Loss: 221.1116, D Loss: 0.5726
Epoch[34360/50000]
**Valid**: G Loss: 225.2888, D Loss: 0.3922
Epoch[34370/50000]
**Train**: G Loss: 233.5476, D Loss: 0.6127
Epoch[34370/50000]
**Valid**: G Loss: 224.1571, D Loss: 0.2473
Epoch[34380/50000]
**Train**: G Loss: 243.9719, D Loss: 0.3238
Epoch[34380/50000]
**Valid**: G Loss: 248.4881, D Loss: 0.9409
Epoch[34390/50000]
**Train**: G Loss: 222.7589, D Loss: 0.2862
Epoch[34390/50000]
**Valid**: G Loss: 217.1449, D Loss: 1.0389
Epoch[34400/50000]
**Train**: G Loss: 242.4071, D Loss: 0.5623
Epoch[34400/50000]
**Valid**: G Loss: 237.0236, D Loss: 0.8319
Epoch[34410/50000]
**Train**: G Loss: 220.0068, D Loss: 0.5749
Epoch[34410/50000]
**Valid**: G Loss: 222.2154, D Loss: 0.4999
Epoch[34420/50000]
**Train**: G Loss: 236.2935, D Loss: 0.5244
Epoch[34420/50000]
**Valid**: G Loss: 231.8604, D Loss: 0.2165
Epoch[34430/50000]
**Train**: G Loss: 220.6533, D Loss: 0.3238
Epoch[34430/50000]
**Valid**: G Loss: 230.6327, D Loss: -0.0353
Epoch[34440/50000]
**Train**: G Loss: 232.4340, D Loss: 0.3550
Epoch[34440/50000]
**Valid**: G Loss: 227.7923, D Loss: 0.4102
Epoch[34450/50000]
**Train**: G Loss: 235.4818, D Loss: 0.5076
Epoch[34450/50000]
**Valid**: G Loss: 243.0709, D Loss: 0.8473
Epoch[34460/50000]
**Train**: G Loss: 214.4555, D Loss: 0.4809
Epoch[34460/50000]
**Valid**: G Loss: 210.2029, D Loss: 0.7838
Epoch[34470/50000]
**Train**: G Loss: 249.2027, D Loss: 0.6023
Epoch[34470/50000]
**Valid**: G Loss: 241.7001, D Loss: 0.4539
Epoch[34480/50000]
**Train**: G Loss: 217.9062, D Loss: 0.6962
Epoch[34480/50000]
**Valid**: G Loss: 223.3514, D Loss: 0.4845
Epoch[34490/50000]
**Train**: G Loss: 237.9603, D Loss: 0.5214
Epoch[34490/50000]
**Valid**: G Loss: 232.7885, D Loss: 0.4020
Epoch[34500/50000]
**Train**: G Loss: 235.4456, D Loss: 0.4633
Epoch[34500/50000]
**Valid**: G Loss: 242.8330, D Loss: 0.3646
Epoch[34510/50000]
**Train**: G Loss: 234.0428, D Loss: 0.2357
Epoch[34510/50000]
**Valid**: G Loss: 228.7957, D Loss: 0.4407
Epoch[34520/50000]
**Train**: G Loss: 244.0114, D Loss: 0.6392
Epoch[34520/50000]
**Valid**: G Loss: 239.3897, D Loss: 0.7761
Epoch[34530/50000]
**Train**: G Loss: 229.6348, D Loss: 0.6226
Epoch[34530/50000]
**Valid**: G Loss: 239.6339, D Loss: 0.2465
Epoch[34540/50000]
**Train**: G Loss: 232.6633, D Loss: 0.2689
Epoch[34540/50000]
**Valid**: G Loss: 227.0157, D Loss: 0.5334
Epoch[34550/50000]
**Train**: G Loss: 241.6074, D Loss: 0.4490
Epoch[34550/50000]
**Valid**: G Loss: 239.7443, D Loss: 0.7625
Epoch[34560/50000]
**Train**: G Loss: 222.6544, D Loss: 0.5597
Epoch[34560/50000]
**Valid**: G Loss: 229.8472, D Loss: 0.3088
Epoch[34570/50000]
**Train**: G Loss: 232.4482, D Loss: 0.2415
Epoch[34570/50000]
**Valid**: G Loss: 227.5297, D Loss: 0.5314
Epoch[34580/50000]
**Train**: G Loss: 240.8171, D Loss: 0.4569
Epoch[34580/50000]
**Valid**: G Loss: 239.7199, D Loss: 0.9946
Epoch[34590/50000]
**Train**: G Loss: 217.9255, D Loss: 0.2971
Epoch[34590/50000]
**Valid**: G Loss: 217.7266, D Loss: 0.6713
Epoch[34600/50000]
**Train**: G Loss: 235.0422, D Loss: 0.6499
Epoch[34600/50000]
**Valid**: G Loss: 229.8529, D Loss: 0.2720
Epoch[34610/50000]
**Train**: G Loss: 225.8643, D Loss: 0.4660
Epoch[34610/50000]
**Valid**: G Loss: 237.9845, D Loss: -0.0182
Epoch[34620/50000]
**Train**: G Loss: 231.4501, D Loss: 0.0902
Epoch[34620/50000]
**Valid**: G Loss: 226.3501, D Loss: 0.4800
Epoch[34630/50000]
**Train**: G Loss: 242.9886, D Loss: 0.6362
Epoch[34630/50000]
**Valid**: G Loss: 240.5151, D Loss: 0.7607
Epoch[34640/50000]
**Train**: G Loss: 223.1487, D Loss: 0.4940
Epoch[34640/50000]
**Valid**: G Loss: 226.5012, D Loss: 0.3825
Epoch[34650/50000]
**Train**: G Loss: 231.5419, D Loss: 0.5800
Epoch[34650/50000]
**Valid**: G Loss: 226.4879, D Loss: 0.0994
Epoch[34660/50000]
**Train**: G Loss: 225.5445, D Loss: 0.4712
Epoch[34660/50000]
**Valid**: G Loss: 234.6753, D Loss: 0.5025
Epoch[34670/50000]
**Train**: G Loss: 221.6293, D Loss: 0.4181
Epoch[34670/50000]
**Valid**: G Loss: 214.8069, D Loss: 0.7776
Epoch[34680/50000]
**Train**: G Loss: 238.0656, D Loss: 0.6648
Epoch[34680/50000]
**Valid**: G Loss: 232.8865, D Loss: 0.9697
Epoch[34690/50000]
**Train**: G Loss: 224.3432, D Loss: 0.6296
Epoch[34690/50000]
**Valid**: G Loss: 231.2193, D Loss: 0.4745
Epoch[34700/50000]
**Train**: G Loss: 232.1469, D Loss: 0.3346
Epoch[34700/50000]
**Valid**: G Loss: 228.6790, D Loss: 0.2896
Epoch[34710/50000]
**Train**: G Loss: 239.7374, D Loss: 0.3259
Epoch[34710/50000]
**Valid**: G Loss: 240.0038, D Loss: 0.7901
Epoch[34720/50000]
**Train**: G Loss: 219.3709, D Loss: 0.5769
Epoch[34720/50000]
**Valid**: G Loss: 226.5730, D Loss: 0.1742
Epoch[34730/50000]
**Train**: G Loss: 220.5072, D Loss: 0.3882
Epoch[34730/50000]
**Valid**: G Loss: 213.0102, D Loss: 0.5011
Epoch[34740/50000]
**Train**: G Loss: 243.9681, D Loss: 0.4712
Epoch[34740/50000]
**Valid**: G Loss: 238.6277, D Loss: 0.5665
Epoch[34750/50000]
**Train**: G Loss: 226.8132, D Loss: 0.7483
Epoch[34750/50000]
**Valid**: G Loss: 237.4444, D Loss: 0.3364
Epoch[34760/50000]
**Train**: G Loss: 224.8612, D Loss: 0.2155
Epoch[34760/50000]
**Valid**: G Loss: 219.4003, D Loss: 0.9296
Epoch[34770/50000]
**Train**: G Loss: 239.1136, D Loss: 0.6936
Epoch[34770/50000]
**Valid**: G Loss: 233.6463, D Loss: 0.5319
Epoch[34780/50000]
**Train**: G Loss: 228.0636, D Loss: 0.3715
Epoch[34780/50000]
**Valid**: G Loss: 239.9305, D Loss: 0.0633
Epoch[34790/50000]
**Train**: G Loss: 231.2357, D Loss: 0.1480
Epoch[34790/50000]
**Valid**: G Loss: 226.5185, D Loss: 0.1792
Epoch[34800/50000]
**Train**: G Loss: 236.3260, D Loss: 0.1794
Epoch[34800/50000]
**Valid**: G Loss: 241.9378, D Loss: 0.5091
Epoch[34810/50000]
**Train**: G Loss: 221.2733, D Loss: 0.3883
Epoch[34810/50000]
**Valid**: G Loss: 216.1626, D Loss: 0.6153
Epoch[34820/50000]
**Train**: G Loss: 237.2747, D Loss: 0.5089
Epoch[34820/50000]
**Valid**: G Loss: 241.9511, D Loss: 0.7539
Epoch[34830/50000]
**Train**: G Loss: 221.7408, D Loss: 0.3199
Epoch[34830/50000]
**Valid**: G Loss: 217.7874, D Loss: 0.7731
Epoch[34840/50000]
**Train**: G Loss: 234.1410, D Loss: 0.4454
Epoch[34840/50000]
**Valid**: G Loss: 227.7156, D Loss: 0.1860
Epoch[34850/50000]
**Train**: G Loss: 219.9499, D Loss: 0.5831
Epoch[34850/50000]
**Valid**: G Loss: 229.1278, D Loss: 0.0096
Epoch[34860/50000]
**Train**: G Loss: 230.0391, D Loss: 0.6610
Epoch[34860/50000]
**Valid**: G Loss: 224.6556, D Loss: 0.3321
Epoch[34870/50000]
**Train**: G Loss: 218.9423, D Loss: 0.5453
Epoch[34870/50000]
**Valid**: G Loss: 229.6620, D Loss: 0.2546
Epoch[34880/50000]
**Train**: G Loss: 219.4305, D Loss: 0.3600
Epoch[34880/50000]
**Valid**: G Loss: 213.2783, D Loss: 0.4176
Epoch[34890/50000]
**Train**: G Loss: 235.8549, D Loss: 0.3497
Epoch[34890/50000]
**Valid**: G Loss: 239.9499, D Loss: 1.0012
Epoch[34900/50000]
**Train**: G Loss: 214.6628, D Loss: 0.6120
Epoch[34900/50000]
**Valid**: G Loss: 212.8685, D Loss: 0.9832
Epoch[34910/50000]
**Train**: G Loss: 233.8386, D Loss: 0.6578
Epoch[34910/50000]
**Valid**: G Loss: 226.9413, D Loss: 0.2406
Epoch[34920/50000]
**Train**: G Loss: 228.3195, D Loss: 0.4490
Epoch[34920/50000]
**Valid**: G Loss: 239.5772, D Loss: 0.3532
Epoch[34930/50000]
**Train**: G Loss: 216.6824, D Loss: 0.0355
Epoch[34930/50000]
**Valid**: G Loss: 210.8911, D Loss: 0.5404
Epoch[34940/50000]
**Train**: G Loss: 245.4246, D Loss: 0.5342
Epoch[34940/50000]
**Valid**: G Loss: 239.1565, D Loss: 0.9652
Epoch[34950/50000]
**Train**: G Loss: 214.7896, D Loss: 0.6211
Epoch[34950/50000]
**Valid**: G Loss: 221.9966, D Loss: 0.3796
Epoch[34960/50000]
**Train**: G Loss: 227.2704, D Loss: 0.5182
Epoch[34960/50000]
**Valid**: G Loss: 218.5945, D Loss: 0.2269
Epoch[34970/50000]
**Train**: G Loss: 229.0584, D Loss: 0.4531
Epoch[34970/50000]
**Valid**: G Loss: 236.3049, D Loss: 0.4326
Epoch[34980/50000]
**Train**: G Loss: 216.1739, D Loss: 0.3425
Epoch[34980/50000]
**Valid**: G Loss: 210.8215, D Loss: 0.5336
Epoch[34990/50000]
**Train**: G Loss: 242.6218, D Loss: 0.4767
Epoch[34990/50000]
**Valid**: G Loss: 237.4389, D Loss: 0.9082
Epoch[35000/50000]
**Train**: G Loss: 213.1300, D Loss: 0.5510
Epoch[35000/50000]
**Valid**: G Loss: 214.6266, D Loss: 0.6334
Epoch[35010/50000]
**Train**: G Loss: 241.5008, D Loss: 0.5001
Epoch[35010/50000]
**Valid**: G Loss: 235.2898, D Loss: 0.6036
Epoch[35020/50000]
**Train**: G Loss: 217.5632, D Loss: 0.5906
Epoch[35020/50000]
**Valid**: G Loss: 216.2078, D Loss: 0.7436
Epoch[35030/50000]
**Train**: G Loss: 231.1213, D Loss: 0.6527
Epoch[35030/50000]
**Valid**: G Loss: 230.2962, D Loss: 0.6929
Epoch[35040/50000]
**Train**: G Loss: 218.2292, D Loss: 0.4771
Epoch[35040/50000]
**Valid**: G Loss: 215.5278, D Loss: 0.6533
Epoch[35050/50000]
**Train**: G Loss: 237.6707, D Loss: 0.5855
Epoch[35050/50000]
**Valid**: G Loss: 232.4820, D Loss: 0.6275
Epoch[35060/50000]
**Train**: G Loss: 218.8381, D Loss: 0.4299
Epoch[35060/50000]
**Valid**: G Loss: 227.5316, D Loss: 0.2316
Epoch[35070/50000]
**Train**: G Loss: 223.3949, D Loss: 0.1363
Epoch[35070/50000]
**Valid**: G Loss: 218.7605, D Loss: 0.4737
Epoch[35080/50000]
**Train**: G Loss: 237.6161, D Loss: 0.4612
Epoch[35080/50000]
**Valid**: G Loss: 238.8378, D Loss: 0.8881
Epoch[35090/50000]
**Train**: G Loss: 213.8211, D Loss: 0.5615
Epoch[35090/50000]
**Valid**: G Loss: 215.3185, D Loss: 0.6393
Epoch[35100/50000]
**Train**: G Loss: 228.3403, D Loss: 0.5635
Epoch[35100/50000]
**Valid**: G Loss: 221.9047, D Loss: 0.1148
Epoch[35110/50000]
**Train**: G Loss: 226.5973, D Loss: 0.3606
Epoch[35110/50000]
**Valid**: G Loss: 235.7169, D Loss: 0.2880
Epoch[35120/50000]
**Train**: G Loss: 218.5597, D Loss: 0.4742
Epoch[35120/50000]
**Valid**: G Loss: 212.2574, D Loss: 0.4411
Epoch[35130/50000]
**Train**: G Loss: 232.6526, D Loss: 0.1630
Epoch[35130/50000]
**Valid**: G Loss: 238.9068, D Loss: 0.4605
Epoch[35140/50000]
**Train**: G Loss: 217.4497, D Loss: 0.2126
Epoch[35140/50000]
**Valid**: G Loss: 213.2817, D Loss: 0.6337
Epoch[35150/50000]
**Train**: G Loss: 231.4353, D Loss: 0.3298
Epoch[35150/50000]
**Valid**: G Loss: 234.4667, D Loss: 0.8307
Epoch[35160/50000]
**Train**: G Loss: 210.5428, D Loss: 0.3029
Epoch[35160/50000]
**Valid**: G Loss: 210.8547, D Loss: 0.4821
Epoch[35170/50000]
**Train**: G Loss: 227.3151, D Loss: 0.7763
Epoch[35170/50000]
**Valid**: G Loss: 220.4102, D Loss: 0.5555
Epoch[35180/50000]
**Train**: G Loss: 220.5152, D Loss: 0.5633
Epoch[35180/50000]
**Valid**: G Loss: 230.7563, D Loss: 0.2510
Epoch[35190/50000]
**Train**: G Loss: 215.2985, D Loss: -0.1261
Epoch[35190/50000]
**Valid**: G Loss: 207.3490, D Loss: 0.5654
Epoch[35200/50000]
**Train**: G Loss: 239.6924, D Loss: 0.5422
Epoch[35200/50000]
**Valid**: G Loss: 231.3488, D Loss: 0.7693
Epoch[35210/50000]
**Train**: G Loss: 219.4471, D Loss: 0.6027
Epoch[35210/50000]
**Valid**: G Loss: 227.3211, D Loss: 0.1605
Epoch[35220/50000]
**Train**: G Loss: 233.3937, D Loss: 0.6384
Epoch[35220/50000]
**Valid**: G Loss: 227.0012, D Loss: 0.2407
Epoch[35230/50000]
**Train**: G Loss: 233.7870, D Loss: 0.2857
Epoch[35230/50000]
**Valid**: G Loss: 243.6762, D Loss: 0.1719
Epoch[35240/50000]
**Train**: G Loss: 227.4524, D Loss: 0.2925
Epoch[35240/50000]
**Valid**: G Loss: 221.1846, D Loss: 0.0880
Epoch[35250/50000]
**Train**: G Loss: 219.6702, D Loss: 0.5787
Epoch[35250/50000]
**Valid**: G Loss: 227.4943, D Loss: 0.3405
Epoch[35260/50000]
**Train**: G Loss: 232.8662, D Loss: 0.6856
Epoch[35260/50000]
**Valid**: G Loss: 226.5509, D Loss: 0.7380
Epoch[35270/50000]
**Train**: G Loss: 220.6088, D Loss: 0.4980
Epoch[35270/50000]
**Valid**: G Loss: 224.9547, D Loss: 0.3162
Epoch[35280/50000]
**Train**: G Loss: 226.0721, D Loss: 0.6656
Epoch[35280/50000]
**Valid**: G Loss: 220.0261, D Loss: 0.2216
Epoch[35290/50000]
**Train**: G Loss: 221.5023, D Loss: 0.3202
Epoch[35290/50000]
**Valid**: G Loss: 229.0937, D Loss: 0.3157
Epoch[35300/50000]
**Train**: G Loss: 220.2070, D Loss: 0.3596
Epoch[35300/50000]
**Valid**: G Loss: 214.7668, D Loss: 0.5005
Epoch[35310/50000]
**Train**: G Loss: 237.0052, D Loss: 0.1432
Epoch[35310/50000]
**Valid**: G Loss: 236.9314, D Loss: 0.7550
Epoch[35320/50000]
**Train**: G Loss: 220.2226, D Loss: 0.5803
Epoch[35320/50000]
**Valid**: G Loss: 222.4782, D Loss: 0.5224
Epoch[35330/50000]
**Train**: G Loss: 232.5582, D Loss: 0.4814
Epoch[35330/50000]
**Valid**: G Loss: 228.4032, D Loss: 0.0659
Epoch[35340/50000]
**Train**: G Loss: 233.0943, D Loss: 0.2598
Epoch[35340/50000]
**Valid**: G Loss: 238.5252, D Loss: 0.1666
Epoch[35350/50000]
**Train**: G Loss: 224.4359, D Loss: 0.1739
Epoch[35350/50000]
**Valid**: G Loss: 218.1557, D Loss: 0.3951
Epoch[35360/50000]
**Train**: G Loss: 241.8038, D Loss: 0.3001
Epoch[35360/50000]
**Valid**: G Loss: 242.9157, D Loss: 0.7906
Epoch[35370/50000]
**Train**: G Loss: 218.8355, D Loss: 0.3749
Epoch[35370/50000]
**Valid**: G Loss: 218.3099, D Loss: 0.7806
Epoch[35380/50000]
**Train**: G Loss: 238.4589, D Loss: 0.6811
Epoch[35380/50000]
**Valid**: G Loss: 233.5854, D Loss: 0.4016
Epoch[35390/50000]
**Train**: G Loss: 222.5008, D Loss: 0.6336
Epoch[35390/50000]
**Valid**: G Loss: 232.1329, D Loss: 0.2125
Epoch[35400/50000]
**Train**: G Loss: 231.1493, D Loss: 0.5377
Epoch[35400/50000]
**Valid**: G Loss: 226.1109, D Loss: 0.3428
Epoch[35410/50000]
**Train**: G Loss: 228.8400, D Loss: 0.4113
Epoch[35410/50000]
**Valid**: G Loss: 237.9580, D Loss: 0.3837
Epoch[35420/50000]
**Train**: G Loss: 226.2202, D Loss: 0.4484
Epoch[35420/50000]
**Valid**: G Loss: 222.1831, D Loss: -0.0511
Epoch[35430/50000]
**Train**: G Loss: 222.5536, D Loss: 0.6040
Epoch[35430/50000]
**Valid**: G Loss: 229.3855, D Loss: 0.3965
Epoch[35440/50000]
**Train**: G Loss: 229.0469, D Loss: 0.5123
Epoch[35440/50000]
**Valid**: G Loss: 222.8238, D Loss: 0.3158
Epoch[35450/50000]
**Train**: G Loss: 226.5051, D Loss: 0.3494
Epoch[35450/50000]
**Valid**: G Loss: 235.5344, D Loss: 0.1078
Epoch[35460/50000]
**Train**: G Loss: 233.0555, D Loss: 0.5014
Epoch[35460/50000]
**Valid**: G Loss: 227.6649, D Loss: -0.0772
Epoch[35470/50000]
**Train**: G Loss: 227.9977, D Loss: 0.4733
Epoch[35470/50000]
**Valid**: G Loss: 235.7853, D Loss: 0.3953
Epoch[35480/50000]
**Train**: G Loss: 233.2561, D Loss: 0.4377
Epoch[35480/50000]
**Valid**: G Loss: 228.5142, D Loss: 0.2098
Epoch[35490/50000]
**Train**: G Loss: 227.4382, D Loss: 0.5723
Epoch[35490/50000]
**Valid**: G Loss: 233.1043, D Loss: 0.4552
Epoch[35500/50000]
**Train**: G Loss: 231.1582, D Loss: 0.3589
Epoch[35500/50000]
**Valid**: G Loss: 226.0378, D Loss: 0.1658
Epoch[35510/50000]
**Train**: G Loss: 224.4841, D Loss: 0.4913
Epoch[35510/50000]
**Valid**: G Loss: 233.2274, D Loss: 0.2196
Epoch[35520/50000]
**Train**: G Loss: 230.1081, D Loss: 0.0828
Epoch[35520/50000]
**Valid**: G Loss: 224.4779, D Loss: 0.2961
Epoch[35530/50000]
**Train**: G Loss: 236.5358, D Loss: 0.2897
Epoch[35530/50000]
**Valid**: G Loss: 242.6331, D Loss: 0.7011
Epoch[35540/50000]
**Train**: G Loss: 221.0249, D Loss: 0.2752
Epoch[35540/50000]
**Valid**: G Loss: 215.9015, D Loss: 0.3961
Epoch[35550/50000]
**Train**: G Loss: 231.0763, D Loss: 0.2773
Epoch[35550/50000]
**Valid**: G Loss: 239.3112, D Loss: 0.2126
Epoch[35560/50000]
**Train**: G Loss: 219.3422, D Loss: 0.2178
Epoch[35560/50000]
**Valid**: G Loss: 214.2311, D Loss: 0.7304
Epoch[35570/50000]
**Train**: G Loss: 239.8472, D Loss: 0.5964
Epoch[35570/50000]
**Valid**: G Loss: 235.7411, D Loss: 0.9693
Epoch[35580/50000]
**Train**: G Loss: 219.5427, D Loss: 0.6197
Epoch[35580/50000]
**Valid**: G Loss: 221.6088, D Loss: 0.5393
Epoch[35590/50000]
**Train**: G Loss: 236.0553, D Loss: 0.6763
Epoch[35590/50000]
**Valid**: G Loss: 229.3989, D Loss: 0.2527
Epoch[35600/50000]
**Train**: G Loss: 223.7078, D Loss: 0.7323
Epoch[35600/50000]
**Valid**: G Loss: 227.5744, D Loss: 0.3058
Epoch[35610/50000]
**Train**: G Loss: 232.5267, D Loss: 0.6561
Epoch[35610/50000]
**Valid**: G Loss: 225.7328, D Loss: -0.0063
Epoch[35620/50000]
**Train**: G Loss: 220.0300, D Loss: 0.7067
Epoch[35620/50000]
**Valid**: G Loss: 227.3966, D Loss: 0.2102
Epoch[35630/50000]
**Train**: G Loss: 238.3920, D Loss: 0.7994
Epoch[35630/50000]
**Valid**: G Loss: 231.0235, D Loss: 0.4505
Epoch[35640/50000]
**Train**: G Loss: 210.3278, D Loss: 0.4724
Epoch[35640/50000]
**Valid**: G Loss: 206.2607, D Loss: 0.7651
Epoch[35650/50000]
**Train**: G Loss: 220.8845, D Loss: 0.3588
Epoch[35650/50000]
**Valid**: G Loss: 228.7345, D Loss: 0.3085
Epoch[35660/50000]
**Train**: G Loss: 219.3453, D Loss: 0.2154
Epoch[35660/50000]
**Valid**: G Loss: 211.7974, D Loss: -0.0872
Epoch[35670/50000]
**Train**: G Loss: 225.9094, D Loss: 0.4565
Epoch[35670/50000]
**Valid**: G Loss: 217.2102, D Loss: -0.6978
Epoch[35680/50000]
**Train**: G Loss: 235.7524, D Loss: 0.0179
Epoch[35680/50000]
**Valid**: G Loss: 250.2482, D Loss: 0.1699
Epoch[35690/50000]
**Train**: G Loss: 236.1770, D Loss: 0.2587
Epoch[35690/50000]
**Valid**: G Loss: 228.3330, D Loss: -0.2059
Epoch[35700/50000]
**Train**: G Loss: 221.9500, D Loss: 0.8918
Epoch[35700/50000]
**Valid**: G Loss: 232.8559, D Loss: 0.1957
Epoch[35710/50000]
**Train**: G Loss: 252.9050, D Loss: 0.6728
Epoch[35710/50000]
**Valid**: G Loss: 247.5136, D Loss: 0.9238
Epoch[35720/50000]
**Train**: G Loss: 228.4116, D Loss: -0.0051
Epoch[35720/50000]
**Valid**: G Loss: 222.1535, D Loss: 0.5385
Epoch[35730/50000]
**Train**: G Loss: 233.4891, D Loss: 0.2687
Epoch[35730/50000]
**Valid**: G Loss: 243.4093, D Loss: -0.0175
Epoch[35740/50000]
**Train**: G Loss: 244.1298, D Loss: 0.7496
Epoch[35740/50000]
**Valid**: G Loss: 236.9511, D Loss: 0.1010
Epoch[35750/50000]
**Train**: G Loss: 218.0058, D Loss: 0.6371
Epoch[35750/50000]
**Valid**: G Loss: 216.5711, D Loss: 1.0108
Epoch[35760/50000]
**Train**: G Loss: 243.5627, D Loss: 0.2986
Epoch[35760/50000]
**Valid**: G Loss: 248.0058, D Loss: 0.7886
Epoch[35770/50000]
**Train**: G Loss: 228.2706, D Loss: 0.2588
Epoch[35770/50000]
**Valid**: G Loss: 221.1236, D Loss: -0.0405
Epoch[35780/50000]
**Train**: G Loss: 215.9671, D Loss: 0.7762
Epoch[35780/50000]
**Valid**: G Loss: 223.1826, D Loss: 0.2879
Epoch[35790/50000]
**Train**: G Loss: 250.6810, D Loss: 0.4222
Epoch[35790/50000]
**Valid**: G Loss: 247.7870, D Loss: 1.0064
Epoch[35800/50000]
**Train**: G Loss: 228.6957, D Loss: 0.0343
Epoch[35800/50000]
**Valid**: G Loss: 220.8946, D Loss: 0.4555
Epoch[35810/50000]
**Train**: G Loss: 226.0117, D Loss: 0.6696
Epoch[35810/50000]
**Valid**: G Loss: 238.0916, D Loss: 0.2221
Epoch[35820/50000]
**Train**: G Loss: 244.2536, D Loss: 0.7346
Epoch[35820/50000]
**Valid**: G Loss: 236.6512, D Loss: 0.5460
Epoch[35830/50000]
**Train**: G Loss: 219.5725, D Loss: 0.3666
Epoch[35830/50000]
**Valid**: G Loss: 215.6250, D Loss: 0.9411
Epoch[35840/50000]
**Train**: G Loss: 243.1184, D Loss: 0.3344
Epoch[35840/50000]
**Valid**: G Loss: 250.0626, D Loss: 0.6843
Epoch[35850/50000]
**Train**: G Loss: 231.9515, D Loss: 0.1913
Epoch[35850/50000]
**Valid**: G Loss: 224.5654, D Loss: -0.0682
Epoch[35860/50000]
**Train**: G Loss: 222.0333, D Loss: 0.7355
Epoch[35860/50000]
**Valid**: G Loss: 228.8740, D Loss: 0.3540
Epoch[35870/50000]
**Train**: G Loss: 250.1665, D Loss: 0.6359
Epoch[35870/50000]
**Valid**: G Loss: 246.6324, D Loss: 1.4047
Epoch[35880/50000]
**Train**: G Loss: 227.8248, D Loss: 0.0860
Epoch[35880/50000]
**Valid**: G Loss: 222.3143, D Loss: 0.3375
Epoch[35890/50000]
**Train**: G Loss: 216.4629, D Loss: 0.7341
Epoch[35890/50000]
**Valid**: G Loss: 223.8050, D Loss: 0.9483
Epoch[35900/50000]
**Train**: G Loss: 241.0792, D Loss: 0.2161
Epoch[35900/50000]
**Valid**: G Loss: 243.8141, D Loss: 0.7980
Epoch[35910/50000]
**Train**: G Loss: 230.1215, D Loss: 0.4368
Epoch[35910/50000]
**Valid**: G Loss: 223.7789, D Loss: -0.0981
Epoch[35920/50000]
**Train**: G Loss: 212.4767, D Loss: 0.5811
Epoch[35920/50000]
**Valid**: G Loss: 213.4923, D Loss: 0.7597
Epoch[35930/50000]
**Train**: G Loss: 231.3588, D Loss: 0.1911
Epoch[35930/50000]
**Valid**: G Loss: 236.3735, D Loss: 0.7635
Epoch[35940/50000]
**Train**: G Loss: 231.3573, D Loss: 0.5298
Epoch[35940/50000]
**Valid**: G Loss: 226.8972, D Loss: 0.1333
Epoch[35950/50000]
**Train**: G Loss: 212.7288, D Loss: 0.6093
Epoch[35950/50000]
**Valid**: G Loss: 209.9757, D Loss: 0.9306
Epoch[35960/50000]
**Train**: G Loss: 233.1268, D Loss: 0.2373
Epoch[35960/50000]
**Valid**: G Loss: 240.9653, D Loss: 0.5758
Epoch[35970/50000]
**Train**: G Loss: 223.3715, D Loss: -0.3010
Epoch[35970/50000]
**Valid**: G Loss: 235.1641, D Loss: 0.2981
Epoch[35980/50000]
**Train**: G Loss: 219.4639, D Loss: 0.4184
Epoch[35980/50000]
**Valid**: G Loss: 208.0391, D Loss: -0.3717
Epoch[35990/50000]
**Train**: G Loss: 204.1464, D Loss: 0.5337
Epoch[35990/50000]
**Valid**: G Loss: 202.6178, D Loss: 0.8554
Epoch[36000/50000]
**Train**: G Loss: 213.3697, D Loss: 0.3811
Epoch[36000/50000]
**Valid**: G Loss: 221.6532, D Loss: 0.2249
Epoch[36010/50000]
**Train**: G Loss: 229.5534, D Loss: 0.6115
Epoch[36010/50000]
**Valid**: G Loss: 226.9810, D Loss: 1.1991
Epoch[36020/50000]
**Train**: G Loss: 216.4042, D Loss: 0.4961
Epoch[36020/50000]
**Valid**: G Loss: 210.5558, D Loss: 0.1919
Epoch[36030/50000]
**Train**: G Loss: 200.6666, D Loss: 0.7787
Epoch[36030/50000]
**Valid**: G Loss: 203.2383, D Loss: 0.7385
Epoch[36040/50000]
**Train**: G Loss: 220.2987, D Loss: 0.3038
Epoch[36040/50000]
**Valid**: G Loss: 224.6695, D Loss: 0.6114
Epoch[36050/50000]
**Train**: G Loss: 220.3284, D Loss: 0.6363
Epoch[36050/50000]
**Valid**: G Loss: 217.8229, D Loss: 0.0625
Epoch[36060/50000]
**Train**: G Loss: 206.4553, D Loss: 0.3649
Epoch[36060/50000]
**Valid**: G Loss: 203.8775, D Loss: 0.5999
Epoch[36070/50000]
**Train**: G Loss: 217.1091, D Loss: 0.3257
Epoch[36070/50000]
**Valid**: G Loss: 225.4353, D Loss: 0.1874
Epoch[36080/50000]
**Train**: G Loss: 219.1614, D Loss: 0.8252
Epoch[36080/50000]
**Valid**: G Loss: 213.6434, D Loss: 0.3244
Epoch[36090/50000]
**Train**: G Loss: 201.8468, D Loss: 0.2393
Epoch[36090/50000]
**Valid**: G Loss: 198.2390, D Loss: 0.7669
Epoch[36100/50000]
**Train**: G Loss: 198.1549, D Loss: 0.4162
Epoch[36100/50000]
**Valid**: G Loss: 205.4139, D Loss: 0.2459
Epoch[36110/50000]
**Train**: G Loss: 213.9997, D Loss: 0.5136
Epoch[36110/50000]
**Valid**: G Loss: 216.1779, D Loss: 0.9796
Epoch[36120/50000]
**Train**: G Loss: 208.1453, D Loss: 0.2068
Epoch[36120/50000]
**Valid**: G Loss: 203.6863, D Loss: 0.0962
Epoch[36130/50000]
**Train**: G Loss: 200.1439, D Loss: 0.4836
Epoch[36130/50000]
**Valid**: G Loss: 208.5609, D Loss: 0.1519
Epoch[36140/50000]
**Train**: G Loss: 211.0852, D Loss: 0.1350
Epoch[36140/50000]
**Valid**: G Loss: 202.3020, D Loss: 0.0171
Epoch[36150/50000]
**Train**: G Loss: 205.9591, D Loss: 0.6393
Epoch[36150/50000]
**Valid**: G Loss: 215.8483, D Loss: 0.2538
Epoch[36160/50000]
**Train**: G Loss: 226.3752, D Loss: 0.9235
Epoch[36160/50000]
**Valid**: G Loss: 217.1568, D Loss: 0.4595
Epoch[36170/50000]
**Train**: G Loss: 205.9294, D Loss: -0.0539
Epoch[36170/50000]
**Valid**: G Loss: 200.6154, D Loss: 0.7075
Epoch[36180/50000]
**Train**: G Loss: 210.6515, D Loss: 0.6466
Epoch[36180/50000]
**Valid**: G Loss: 220.4016, D Loss: 0.1687
Epoch[36190/50000]
**Train**: G Loss: 236.4633, D Loss: 0.2746
Epoch[36190/50000]
**Valid**: G Loss: 232.7330, D Loss: 1.0331
Epoch[36200/50000]
**Train**: G Loss: 217.0057, D Loss: 0.1681
Epoch[36200/50000]
**Valid**: G Loss: 212.1399, D Loss: 0.0349
Epoch[36210/50000]
**Train**: G Loss: 211.3319, D Loss: 0.6791
Epoch[36210/50000]
**Valid**: G Loss: 212.1198, D Loss: 0.6372
Epoch[36220/50000]
**Train**: G Loss: 230.6094, D Loss: 0.0923
Epoch[36220/50000]
**Valid**: G Loss: 238.6878, D Loss: 0.7392
Epoch[36230/50000]
**Train**: G Loss: 229.0001, D Loss: 0.4873
Epoch[36230/50000]
**Valid**: G Loss: 219.1005, D Loss: -0.0384
Epoch[36240/50000]
**Train**: G Loss: 208.6963, D Loss: 0.1880
Epoch[36240/50000]
**Valid**: G Loss: 207.5403, D Loss: 0.9219
Epoch[36250/50000]
**Train**: G Loss: 222.0947, D Loss: 0.2492
Epoch[36250/50000]
**Valid**: G Loss: 233.7780, D Loss: -0.0028
Epoch[36260/50000]
**Train**: G Loss: 234.7999, D Loss: 0.6807
Epoch[36260/50000]
**Valid**: G Loss: 230.0386, D Loss: 0.7592
Epoch[36270/50000]
**Train**: G Loss: 217.8234, D Loss: 0.2059
Epoch[36270/50000]
**Valid**: G Loss: 213.2363, D Loss: 0.6579
Epoch[36280/50000]
**Train**: G Loss: 215.0015, D Loss: 0.4265
Epoch[36280/50000]
**Valid**: G Loss: 224.3086, D Loss: 0.1132
Epoch[36290/50000]
**Train**: G Loss: 232.0464, D Loss: 0.4696
Epoch[36290/50000]
**Valid**: G Loss: 229.4962, D Loss: 1.3584
Epoch[36300/50000]
**Train**: G Loss: 214.7992, D Loss: 0.5315
Epoch[36300/50000]
**Valid**: G Loss: 206.7791, D Loss: -0.1882
Epoch[36310/50000]
**Train**: G Loss: 195.1667, D Loss: 0.8313
Epoch[36310/50000]
**Valid**: G Loss: 197.8980, D Loss: 0.8288
Epoch[36320/50000]
**Train**: G Loss: 227.0025, D Loss: 0.0302
Epoch[36320/50000]
**Valid**: G Loss: 234.2839, D Loss: 0.5923
Epoch[36330/50000]
**Train**: G Loss: 218.3423, D Loss: 0.3297
Epoch[36330/50000]
**Valid**: G Loss: 213.7035, D Loss: 0.0083
Epoch[36340/50000]
**Train**: G Loss: 205.7922, D Loss: 0.5291
Epoch[36340/50000]
**Valid**: G Loss: 205.7352, D Loss: 0.8603
Epoch[36350/50000]
**Train**: G Loss: 225.4760, D Loss: 0.0251
Epoch[36350/50000]
**Valid**: G Loss: 232.5038, D Loss: 0.3749
Epoch[36360/50000]
**Train**: G Loss: 223.8277, D Loss: 0.6979
Epoch[36360/50000]
**Valid**: G Loss: 219.1164, D Loss: 0.1753
Epoch[36370/50000]
**Train**: G Loss: 207.2731, D Loss: 0.4628
Epoch[36370/50000]
**Valid**: G Loss: 204.4138, D Loss: 0.9382
Epoch[36380/50000]
**Train**: G Loss: 221.4387, D Loss: 0.1552
Epoch[36380/50000]
**Valid**: G Loss: 234.5647, D Loss: -0.1017
Epoch[36390/50000]
**Train**: G Loss: 230.4246, D Loss: 0.8788
Epoch[36390/50000]
**Valid**: G Loss: 222.9626, D Loss: 0.5484
Epoch[36400/50000]
**Train**: G Loss: 211.0893, D Loss: 0.0201
Epoch[36400/50000]
**Valid**: G Loss: 204.4333, D Loss: 0.6260
Epoch[36410/50000]
**Train**: G Loss: 212.4756, D Loss: 0.5651
Epoch[36410/50000]
**Valid**: G Loss: 224.8822, D Loss: 0.1903
Epoch[36420/50000]
**Train**: G Loss: 236.3051, D Loss: 0.2764
Epoch[36420/50000]
**Valid**: G Loss: 236.1231, D Loss: 0.9635
Epoch[36430/50000]
**Train**: G Loss: 223.6070, D Loss: 0.8481
Epoch[36430/50000]
**Valid**: G Loss: 216.4326, D Loss: -0.0023
Epoch[36440/50000]
**Train**: G Loss: 207.7416, D Loss: 0.8961
Epoch[36440/50000]
**Valid**: G Loss: 208.9307, D Loss: 0.9467
Epoch[36450/50000]
**Train**: G Loss: 244.6768, D Loss: 0.5736
Epoch[36450/50000]
**Valid**: G Loss: 240.3758, D Loss: 1.2415
Epoch[36460/50000]
**Train**: G Loss: 221.1215, D Loss: 0.0983
Epoch[36460/50000]
**Valid**: G Loss: 215.3632, D Loss: -0.0634
Epoch[36470/50000]
**Train**: G Loss: 209.6299, D Loss: 0.2836
Epoch[36470/50000]
**Valid**: G Loss: 209.8609, D Loss: 0.7310
Epoch[36480/50000]
**Train**: G Loss: 232.1062, D Loss: 0.0651
Epoch[36480/50000]
**Valid**: G Loss: 242.4560, D Loss: 0.6136
Epoch[36490/50000]
**Train**: G Loss: 231.9926, D Loss: 0.7043
Epoch[36490/50000]
**Valid**: G Loss: 224.1215, D Loss: 0.4674
Epoch[36500/50000]
**Train**: G Loss: 211.7537, D Loss: -0.1032
Epoch[36500/50000]
**Valid**: G Loss: 204.9567, D Loss: 0.6959
Epoch[36510/50000]
**Train**: G Loss: 209.2906, D Loss: 0.7458
Epoch[36510/50000]
**Valid**: G Loss: 214.9451, D Loss: 0.5311
Epoch[36520/50000]
**Train**: G Loss: 237.9709, D Loss: 0.2154
Epoch[36520/50000]
**Valid**: G Loss: 241.3288, D Loss: 0.8931
Epoch[36530/50000]
**Train**: G Loss: 229.7897, D Loss: 0.8453
Epoch[36530/50000]
**Valid**: G Loss: 221.4269, D Loss: 0.3523
Epoch[36540/50000]
**Train**: G Loss: 204.6061, D Loss: 0.0336
Epoch[36540/50000]
**Valid**: G Loss: 198.6360, D Loss: 0.6295
Epoch[36550/50000]
**Train**: G Loss: 205.7379, D Loss: 0.7997
Epoch[36550/50000]
**Valid**: G Loss: 214.3872, D Loss: 0.3755
Epoch[36560/50000]
**Train**: G Loss: 225.4435, D Loss: 0.1155
Epoch[36560/50000]
**Valid**: G Loss: 230.2935, D Loss: 0.5022
Epoch[36570/50000]
**Train**: G Loss: 222.5956, D Loss: 0.8159
Epoch[36570/50000]
**Valid**: G Loss: 218.9480, D Loss: 1.1355
Epoch[36580/50000]
**Train**: G Loss: 205.3046, D Loss: 0.2656
Epoch[36580/50000]
**Valid**: G Loss: 198.3037, D Loss: 0.5071
Epoch[36590/50000]
**Train**: G Loss: 198.9217, D Loss: 0.7617
Epoch[36590/50000]
**Valid**: G Loss: 202.8147, D Loss: 0.3392
Epoch[36600/50000]
**Train**: G Loss: 222.7946, D Loss: 0.0943
Epoch[36600/50000]
**Valid**: G Loss: 226.6849, D Loss: 0.7462
Epoch[36610/50000]
**Train**: G Loss: 216.4145, D Loss: 0.7046
Epoch[36610/50000]
**Valid**: G Loss: 211.7027, D Loss: 0.1571
Epoch[36620/50000]
**Train**: G Loss: 200.0376, D Loss: 0.2011
Epoch[36620/50000]
**Valid**: G Loss: 195.6625, D Loss: 1.0077
Epoch[36630/50000]
**Train**: G Loss: 206.1870, D Loss: 0.2381
Epoch[36630/50000]
**Valid**: G Loss: 216.7356, D Loss: 0.2834
Epoch[36640/50000]
**Train**: G Loss: 212.9264, D Loss: 0.9437
Epoch[36640/50000]
**Valid**: G Loss: 207.0824, D Loss: 0.4815
Epoch[36650/50000]
**Train**: G Loss: 206.4036, D Loss: -0.0855
Epoch[36650/50000]
**Valid**: G Loss: 200.8521, D Loss: 0.2574
Epoch[36660/50000]
**Train**: G Loss: 197.4405, D Loss: 0.8346
Epoch[36660/50000]
**Valid**: G Loss: 204.2596, D Loss: 0.2069
Epoch[36670/50000]
**Train**: G Loss: 223.4551, D Loss: 0.1453
Epoch[36670/50000]
**Valid**: G Loss: 232.9978, D Loss: 0.4031
Epoch[36680/50000]
**Train**: G Loss: 231.0862, D Loss: 0.3412
Epoch[36680/50000]
**Valid**: G Loss: 227.7934, D Loss: 1.1002
Epoch[36690/50000]
**Train**: G Loss: 225.4811, D Loss: 0.8831
Epoch[36690/50000]
**Valid**: G Loss: 219.6145, D Loss: 0.4628
Epoch[36700/50000]
**Train**: G Loss: 215.7132, D Loss: 0.1042
Epoch[36700/50000]
**Valid**: G Loss: 210.8342, D Loss: 0.0280
Epoch[36710/50000]
**Train**: G Loss: 204.5148, D Loss: 0.5128
Epoch[36710/50000]
**Valid**: G Loss: 202.5905, D Loss: 1.0392
Epoch[36720/50000]
**Train**: G Loss: 208.8003, D Loss: 0.6917
Epoch[36720/50000]
**Valid**: G Loss: 219.7952, D Loss: 0.2896
Epoch[36730/50000]
**Train**: G Loss: 227.2867, D Loss: 0.1388
Epoch[36730/50000]
**Valid**: G Loss: 232.2074, D Loss: 0.7294
Epoch[36740/50000]
**Train**: G Loss: 225.2742, D Loss: 0.6591
Epoch[36740/50000]
**Valid**: G Loss: 219.0405, D Loss: 0.7101
Epoch[36750/50000]
**Train**: G Loss: 203.4299, D Loss: 0.1852
Epoch[36750/50000]
**Valid**: G Loss: 195.8567, D Loss: 0.5358
Epoch[36760/50000]
**Train**: G Loss: 193.9686, D Loss: 0.8110
Epoch[36760/50000]
**Valid**: G Loss: 193.8938, D Loss: 0.8383
Epoch[36770/50000]
**Train**: G Loss: 214.4834, D Loss: 0.0984
Epoch[36770/50000]
**Valid**: G Loss: 223.2198, D Loss: -0.0142
Epoch[36780/50000]
**Train**: G Loss: 224.0229, D Loss: 0.6414
Epoch[36780/50000]
**Valid**: G Loss: 221.8202, D Loss: 1.1668
Epoch[36790/50000]
**Train**: G Loss: 215.8778, D Loss: 0.5541
Epoch[36790/50000]
**Valid**: G Loss: 212.7741, D Loss: 0.2071
Epoch[36800/50000]
**Train**: G Loss: 204.5207, D Loss: 0.0502
Epoch[36800/50000]
**Valid**: G Loss: 198.0352, D Loss: 0.5464
Epoch[36810/50000]
**Train**: G Loss: 189.7867, D Loss: 0.8513
Epoch[36810/50000]
**Valid**: G Loss: 193.8416, D Loss: 0.7964
Epoch[36820/50000]
**Train**: G Loss: 210.7660, D Loss: 0.1864
Epoch[36820/50000]
**Valid**: G Loss: 221.4518, D Loss: 0.0383
Epoch[36830/50000]
**Train**: G Loss: 224.5182, D Loss: 0.7068
Epoch[36830/50000]
**Valid**: G Loss: 219.4394, D Loss: 1.1479
Epoch[36840/50000]
**Train**: G Loss: 206.4590, D Loss: 0.1504
Epoch[36840/50000]
**Valid**: G Loss: 200.1757, D Loss: 0.0457
Epoch[36850/50000]
**Train**: G Loss: 199.4817, D Loss: 0.6523
Epoch[36850/50000]
**Valid**: G Loss: 197.7855, D Loss: 0.8565
Epoch[36860/50000]
**Train**: G Loss: 200.0436, D Loss: 0.5024
Epoch[36860/50000]
**Valid**: G Loss: 208.4185, D Loss: 0.3138
Epoch[36870/50000]
**Train**: G Loss: 216.6823, D Loss: 0.4235
Epoch[36870/50000]
**Valid**: G Loss: 218.2474, D Loss: 0.9730
Epoch[36880/50000]
**Train**: G Loss: 209.3095, D Loss: 0.2546
Epoch[36880/50000]
**Valid**: G Loss: 201.7957, D Loss: -0.0799
Epoch[36890/50000]
**Train**: G Loss: 193.0290, D Loss: 0.5606
Epoch[36890/50000]
**Valid**: G Loss: 191.1828, D Loss: 0.9432
Epoch[36900/50000]
**Train**: G Loss: 209.7936, D Loss: 0.3770
Epoch[36900/50000]
**Valid**: G Loss: 221.8237, D Loss: -0.2499
Epoch[36910/50000]
**Train**: G Loss: 234.9118, D Loss: 0.3274
Epoch[36910/50000]
**Valid**: G Loss: 231.4731, D Loss: 0.9733
Epoch[36920/50000]
**Train**: G Loss: 211.0111, D Loss: 0.2960
Epoch[36920/50000]
**Valid**: G Loss: 204.5793, D Loss: 0.1690
Epoch[36930/50000]
**Train**: G Loss: 202.6960, D Loss: 0.5025
Epoch[36930/50000]
**Valid**: G Loss: 201.5532, D Loss: 0.5119
Epoch[36940/50000]
**Train**: G Loss: 212.6963, D Loss: 0.7107
Epoch[36940/50000]
**Valid**: G Loss: 221.7458, D Loss: 0.1514
Epoch[36950/50000]
**Train**: G Loss: 225.3723, D Loss: 0.3950
Epoch[36950/50000]
**Valid**: G Loss: 226.9395, D Loss: 0.8704
Epoch[36960/50000]
**Train**: G Loss: 216.8170, D Loss: 0.3769
Epoch[36960/50000]
**Valid**: G Loss: 210.9692, D Loss: -0.1949
Epoch[36970/50000]
**Train**: G Loss: 200.9626, D Loss: 0.3215
Epoch[36970/50000]
**Valid**: G Loss: 195.6907, D Loss: 1.1468
Epoch[36980/50000]
**Train**: G Loss: 204.4589, D Loss: 0.7923
Epoch[36980/50000]
**Valid**: G Loss: 215.1859, D Loss: 0.1339
Epoch[36990/50000]
**Train**: G Loss: 232.7239, D Loss: 0.0017
Epoch[36990/50000]
**Valid**: G Loss: 235.5171, D Loss: 0.7224
Epoch[37000/50000]
**Train**: G Loss: 229.1915, D Loss: 0.8044
Epoch[37000/50000]
**Valid**: G Loss: 221.1880, D Loss: 0.4402
Epoch[37010/50000]
**Train**: G Loss: 214.3604, D Loss: -0.0145
Epoch[37010/50000]
**Valid**: G Loss: 210.0959, D Loss: 0.2380
Epoch[37020/50000]
**Train**: G Loss: 210.0992, D Loss: 0.7603
Epoch[37020/50000]
**Valid**: G Loss: 212.5103, D Loss: 0.5541
Epoch[37030/50000]
**Train**: G Loss: 234.0604, D Loss: -0.0342
Epoch[37030/50000]
**Valid**: G Loss: 240.0386, D Loss: 0.3675
Epoch[37040/50000]
**Train**: G Loss: 211.8431, D Loss: 0.5256
Epoch[37040/50000]
**Valid**: G Loss: 206.4969, D Loss: 0.0333
Epoch[37050/50000]
**Train**: G Loss: 199.8510, D Loss: 0.6223
Epoch[37050/50000]
**Valid**: G Loss: 199.6488, D Loss: 0.9173
Epoch[37060/50000]
**Train**: G Loss: 219.3240, D Loss: 0.2730
Epoch[37060/50000]
**Valid**: G Loss: 232.8813, D Loss: 0.2913
Epoch[37070/50000]
**Train**: G Loss: 227.1681, D Loss: 0.8641
Epoch[37070/50000]
**Valid**: G Loss: 216.9847, D Loss: 0.4704
Epoch[37080/50000]
**Train**: G Loss: 207.8461, D Loss: 0.1504
Epoch[37080/50000]
**Valid**: G Loss: 201.0429, D Loss: 0.5403
Epoch[37090/50000]
**Train**: G Loss: 203.2178, D Loss: 0.7330
Epoch[37090/50000]
**Valid**: G Loss: 206.1027, D Loss: 0.6799
Epoch[37100/50000]
**Train**: G Loss: 235.3492, D Loss: 0.0621
Epoch[37100/50000]
**Valid**: G Loss: 243.3269, D Loss: 0.4134
Epoch[37110/50000]
**Train**: G Loss: 234.4489, D Loss: 0.9332
Epoch[37110/50000]
**Valid**: G Loss: 223.8927, D Loss: 0.8531
Epoch[37120/50000]
**Train**: G Loss: 209.1444, D Loss: 0.0098
Epoch[37120/50000]
**Valid**: G Loss: 202.1363, D Loss: 0.0772
Epoch[37130/50000]
**Train**: G Loss: 201.4293, D Loss: 0.3219
Epoch[37130/50000]
**Valid**: G Loss: 197.9466, D Loss: 1.0026
Epoch[37140/50000]
**Train**: G Loss: 207.5320, D Loss: 0.5910
Epoch[37140/50000]
**Valid**: G Loss: 216.5551, D Loss: 0.1222
Epoch[37150/50000]
**Train**: G Loss: 236.7671, D Loss: 0.1992
Epoch[37150/50000]
**Valid**: G Loss: 236.2197, D Loss: 0.8343
Epoch[37160/50000]
**Train**: G Loss: 223.6133, D Loss: 0.7800
Epoch[37160/50000]
**Valid**: G Loss: 217.7609, D Loss: 0.4709
Epoch[37170/50000]
**Train**: G Loss: 208.7440, D Loss: 0.3224
Epoch[37170/50000]
**Valid**: G Loss: 202.2841, D Loss: -0.2568
Epoch[37180/50000]
**Train**: G Loss: 202.4488, D Loss: 0.3665
Epoch[37180/50000]
**Valid**: G Loss: 198.3135, D Loss: 0.8731
Epoch[37190/50000]
**Train**: G Loss: 205.7997, D Loss: 0.5717
Epoch[37190/50000]
**Valid**: G Loss: 212.9337, D Loss: 0.0593
Epoch[37200/50000]
**Train**: G Loss: 222.2335, D Loss: 0.2429
Epoch[37200/50000]
**Valid**: G Loss: 221.5169, D Loss: 0.8692
Epoch[37210/50000]
**Train**: G Loss: 218.9758, D Loss: 0.7874
Epoch[37210/50000]
**Valid**: G Loss: 214.1801, D Loss: 0.3700
Epoch[37220/50000]
**Train**: G Loss: 208.5251, D Loss: 0.1625
Epoch[37220/50000]
**Valid**: G Loss: 202.6855, D Loss: 0.3967
Epoch[37230/50000]
**Train**: G Loss: 201.0277, D Loss: 0.3252
Epoch[37230/50000]
**Valid**: G Loss: 195.7150, D Loss: 1.0234
Epoch[37240/50000]
**Train**: G Loss: 202.1352, D Loss: 0.8355
Epoch[37240/50000]
**Valid**: G Loss: 211.2756, D Loss: 0.2913
Epoch[37250/50000]
**Train**: G Loss: 226.4592, D Loss: 0.1250
Epoch[37250/50000]
**Valid**: G Loss: 231.9037, D Loss: 0.4077
Epoch[37260/50000]
**Train**: G Loss: 231.3116, D Loss: 0.7724
Epoch[37260/50000]
**Valid**: G Loss: 221.4463, D Loss: 0.8669
Epoch[37270/50000]
**Train**: G Loss: 208.6884, D Loss: 0.1572
Epoch[37270/50000]
**Valid**: G Loss: 201.3126, D Loss: 0.1380
Epoch[37280/50000]
**Train**: G Loss: 203.6196, D Loss: 0.4558
Epoch[37280/50000]
**Valid**: G Loss: 200.9057, D Loss: 1.0449
Epoch[37290/50000]
**Train**: G Loss: 205.5133, D Loss: 0.8435
Epoch[37290/50000]
**Valid**: G Loss: 211.4123, D Loss: 0.3479
Epoch[37300/50000]
**Train**: G Loss: 228.9396, D Loss: -0.0869
Epoch[37300/50000]
**Valid**: G Loss: 235.7783, D Loss: 0.4183
Epoch[37310/50000]
**Train**: G Loss: 229.1913, D Loss: 0.8472
Epoch[37310/50000]
**Valid**: G Loss: 224.5134, D Loss: 0.7036
Epoch[37320/50000]
**Train**: G Loss: 213.9279, D Loss: 0.2242
Epoch[37320/50000]
**Valid**: G Loss: 209.9216, D Loss: -0.0490
Epoch[37330/50000]
**Train**: G Loss: 201.7423, D Loss: 0.2689
Epoch[37330/50000]
**Valid**: G Loss: 200.4800, D Loss: 0.9332
Epoch[37340/50000]
**Train**: G Loss: 208.5699, D Loss: 0.7997
Epoch[37340/50000]
**Valid**: G Loss: 218.5317, D Loss: 0.2890
Epoch[37350/50000]
**Train**: G Loss: 235.6361, D Loss: 0.2381
Epoch[37350/50000]
**Valid**: G Loss: 238.7256, D Loss: 0.8695
Epoch[37360/50000]
**Train**: G Loss: 222.1883, D Loss: 0.5394
Epoch[37360/50000]
**Valid**: G Loss: 214.5709, D Loss: 0.1533
Epoch[37370/50000]
**Train**: G Loss: 205.4999, D Loss: 0.1790
Epoch[37370/50000]
**Valid**: G Loss: 200.2269, D Loss: 0.9670
Epoch[37380/50000]
**Train**: G Loss: 196.1643, D Loss: 0.8473
Epoch[37380/50000]
**Valid**: G Loss: 208.6013, D Loss: 0.1651
Epoch[37390/50000]
**Train**: G Loss: 234.7271, D Loss: -0.0052
Epoch[37390/50000]
**Valid**: G Loss: 241.1048, D Loss: 0.6814
Epoch[37400/50000]
**Train**: G Loss: 231.0949, D Loss: 0.6436
Epoch[37400/50000]
**Valid**: G Loss: 223.2806, D Loss: 0.2449
Epoch[37410/50000]
**Train**: G Loss: 203.0682, D Loss: 0.1117
Epoch[37410/50000]
**Valid**: G Loss: 194.3380, D Loss: 0.5318
Epoch[37420/50000]
**Train**: G Loss: 201.8953, D Loss: 0.6164
Epoch[37420/50000]
**Valid**: G Loss: 215.6105, D Loss: -0.0082
Epoch[37430/50000]
**Train**: G Loss: 241.4366, D Loss: 0.1733
Epoch[37430/50000]
**Valid**: G Loss: 246.0126, D Loss: 0.6718
Epoch[37440/50000]
**Train**: G Loss: 230.8319, D Loss: 0.8306
Epoch[37440/50000]
**Valid**: G Loss: 222.2972, D Loss: 0.4720
Epoch[37450/50000]
**Train**: G Loss: 211.4552, D Loss: 0.4571
Epoch[37450/50000]
**Valid**: G Loss: 206.8579, D Loss: 0.7447
Epoch[37460/50000]
**Train**: G Loss: 201.3482, D Loss: 0.6922
Epoch[37460/50000]
**Valid**: G Loss: 206.8726, D Loss: 0.4168
Epoch[37470/50000]
**Train**: G Loss: 217.0379, D Loss: 0.3089
Epoch[37470/50000]
**Valid**: G Loss: 227.6011, D Loss: 0.2371
Epoch[37480/50000]
**Train**: G Loss: 227.6407, D Loss: 0.6537
Epoch[37480/50000]
**Valid**: G Loss: 222.9705, D Loss: 1.2145
Epoch[37490/50000]
**Train**: G Loss: 215.8502, D Loss: 0.5533
Epoch[37490/50000]
**Valid**: G Loss: 207.8278, D Loss: -0.0821
Epoch[37500/50000]
**Train**: G Loss: 194.2098, D Loss: 0.1203
Epoch[37500/50000]
**Valid**: G Loss: 189.9934, D Loss: 0.9689
Epoch[37510/50000]
**Train**: G Loss: 207.1279, D Loss: 0.6949
Epoch[37510/50000]
**Valid**: G Loss: 222.1323, D Loss: 0.2425
Epoch[37520/50000]
**Train**: G Loss: 240.0516, D Loss: 0.2814
Epoch[37520/50000]
**Valid**: G Loss: 239.3934, D Loss: 0.9540
Epoch[37530/50000]
**Train**: G Loss: 234.3404, D Loss: 0.7528
Epoch[37530/50000]
**Valid**: G Loss: 225.8500, D Loss: 0.6230
Epoch[37540/50000]
**Train**: G Loss: 220.0981, D Loss: 0.2740
Epoch[37540/50000]
**Valid**: G Loss: 214.7427, D Loss: -0.1387
Epoch[37550/50000]
**Train**: G Loss: 209.2232, D Loss: 0.3777
Epoch[37550/50000]
**Valid**: G Loss: 206.5413, D Loss: 0.7280
Epoch[37560/50000]
**Train**: G Loss: 215.5158, D Loss: 0.6628
Epoch[37560/50000]
**Valid**: G Loss: 224.3723, D Loss: 0.1752
Epoch[37570/50000]
**Train**: G Loss: 240.4465, D Loss: 0.0960
Epoch[37570/50000]
**Valid**: G Loss: 245.5117, D Loss: 0.7153
Epoch[37580/50000]
**Train**: G Loss: 225.2142, D Loss: 0.7375
Epoch[37580/50000]
**Valid**: G Loss: 218.8501, D Loss: 0.3203
Epoch[37590/50000]
**Train**: G Loss: 208.6704, D Loss: -0.0411
Epoch[37590/50000]
**Valid**: G Loss: 202.3447, D Loss: 0.5894
Epoch[37600/50000]
**Train**: G Loss: 198.1329, D Loss: 0.9063
Epoch[37600/50000]
**Valid**: G Loss: 201.2684, D Loss: 0.4749
Epoch[37610/50000]
**Train**: G Loss: 206.4619, D Loss: 0.4903
Epoch[37610/50000]
**Valid**: G Loss: 216.9078, D Loss: 0.2325
Epoch[37620/50000]
**Train**: G Loss: 234.8129, D Loss: 0.5288
Epoch[37620/50000]
**Valid**: G Loss: 229.5126, D Loss: 0.9993
Epoch[37630/50000]
**Train**: G Loss: 219.4235, D Loss: 0.5260
Epoch[37630/50000]
**Valid**: G Loss: 213.5710, D Loss: -0.0526
Epoch[37640/50000]
**Train**: G Loss: 198.4003, D Loss: 0.0278
Epoch[37640/50000]
**Valid**: G Loss: 195.0704, D Loss: 0.6330
Epoch[37650/50000]
**Train**: G Loss: 194.6773, D Loss: 0.7576
Epoch[37650/50000]
**Valid**: G Loss: 199.1671, D Loss: 0.4344
Epoch[37660/50000]
**Train**: G Loss: 204.0227, D Loss: 0.3766
Epoch[37660/50000]
**Valid**: G Loss: 212.7395, D Loss: 0.2998
Epoch[37670/50000]
**Train**: G Loss: 208.7882, D Loss: 0.2710
Epoch[37670/50000]
**Valid**: G Loss: 204.8549, D Loss: -0.2822
Epoch[37680/50000]
**Train**: G Loss: 196.6965, D Loss: 0.5508
Epoch[37680/50000]
**Valid**: G Loss: 194.8576, D Loss: 0.9920
Epoch[37690/50000]
**Train**: G Loss: 205.0653, D Loss: 0.5776
Epoch[37690/50000]
**Valid**: G Loss: 212.9146, D Loss: 0.1175
Epoch[37700/50000]
**Train**: G Loss: 224.4087, D Loss: 0.1111
Epoch[37700/50000]
**Valid**: G Loss: 228.7136, D Loss: 0.5746
Epoch[37710/50000]
**Train**: G Loss: 225.4543, D Loss: 0.6867
Epoch[37710/50000]
**Valid**: G Loss: 219.7932, D Loss: 0.7039
Epoch[37720/50000]
**Train**: G Loss: 218.8872, D Loss: 0.6527
Epoch[37720/50000]
**Valid**: G Loss: 214.1313, D Loss: 0.0076
Epoch[37730/50000]
**Train**: G Loss: 207.1079, D Loss: 0.2995
Epoch[37730/50000]
**Valid**: G Loss: 201.3854, D Loss: 0.7462
Epoch[37740/50000]
**Train**: G Loss: 205.3419, D Loss: 0.5385
Epoch[37740/50000]
**Valid**: G Loss: 205.2333, D Loss: 0.7056
Epoch[37750/50000]
**Train**: G Loss: 213.4520, D Loss: 0.3799
Epoch[37750/50000]
**Valid**: G Loss: 221.5424, D Loss: 0.1057
Epoch[37760/50000]
**Train**: G Loss: 230.5184, D Loss: 0.4427
Epoch[37760/50000]
**Valid**: G Loss: 230.5365, D Loss: 1.0473
Epoch[37770/50000]
**Train**: G Loss: 217.2320, D Loss: 0.4418
Epoch[37770/50000]
**Valid**: G Loss: 212.7413, D Loss: 0.3442
Epoch[37780/50000]
**Train**: G Loss: 204.2608, D Loss: 0.6666
Epoch[37780/50000]
**Valid**: G Loss: 206.6098, D Loss: 0.7923
Epoch[37790/50000]
**Train**: G Loss: 238.9666, D Loss: 0.2455
Epoch[37790/50000]
**Valid**: G Loss: 234.3205, D Loss: 0.8973
Epoch[37800/50000]
**Train**: G Loss: 190.0030, D Loss: 0.6706
Epoch[37800/50000]
**Valid**: G Loss: 194.8884, D Loss: 0.8378
Epoch[37810/50000]
**Train**: G Loss: 234.8394, D Loss: -0.0312
Epoch[37810/50000]
**Valid**: G Loss: 239.0218, D Loss: 0.8788
Epoch[37820/50000]
**Train**: G Loss: 222.1255, D Loss: 0.7070
Epoch[37820/50000]
**Valid**: G Loss: 214.6083, D Loss: -0.0669
Epoch[37830/50000]
**Train**: G Loss: 207.5894, D Loss: 0.1203
Epoch[37830/50000]
**Valid**: G Loss: 203.1087, D Loss: 0.6536
Epoch[37840/50000]
**Train**: G Loss: 209.6924, D Loss: 0.4669
Epoch[37840/50000]
**Valid**: G Loss: 217.1843, D Loss: 0.0588
Epoch[37850/50000]
**Train**: G Loss: 225.2121, D Loss: 0.3083
Epoch[37850/50000]
**Valid**: G Loss: 226.2047, D Loss: 0.7600
Epoch[37860/50000]
**Train**: G Loss: 229.2474, D Loss: 0.6579
Epoch[37860/50000]
**Valid**: G Loss: 223.9809, D Loss: 0.4220
Epoch[37870/50000]
**Train**: G Loss: 210.0594, D Loss: 0.1710
Epoch[37870/50000]
**Valid**: G Loss: 204.1063, D Loss: 0.1929
Epoch[37880/50000]
**Train**: G Loss: 204.1300, D Loss: 0.5918
Epoch[37880/50000]
**Valid**: G Loss: 211.5295, D Loss: 0.2113
Epoch[37890/50000]
**Train**: G Loss: 217.8755, D Loss: 0.3394
Epoch[37890/50000]
**Valid**: G Loss: 224.7973, D Loss: 0.3827
Epoch[37900/50000]
**Train**: G Loss: 230.0615, D Loss: 0.3432
Epoch[37900/50000]
**Valid**: G Loss: 227.2280, D Loss: 0.9895
Epoch[37910/50000]
**Train**: G Loss: 226.7744, D Loss: 0.8502
Epoch[37910/50000]
**Valid**: G Loss: 221.7304, D Loss: 0.4675
Epoch[37920/50000]
**Train**: G Loss: 218.1147, D Loss: 0.0391
Epoch[37920/50000]
**Valid**: G Loss: 210.7423, D Loss: 0.3898
Epoch[37930/50000]
**Train**: G Loss: 208.0682, D Loss: 0.6951
Epoch[37930/50000]
**Valid**: G Loss: 214.8739, D Loss: 0.5839
Epoch[37940/50000]
**Train**: G Loss: 228.7852, D Loss: 0.1921
Epoch[37940/50000]
**Valid**: G Loss: 238.2278, D Loss: 0.1750
Epoch[37950/50000]
**Train**: G Loss: 232.3399, D Loss: 0.6336
Epoch[37950/50000]
**Valid**: G Loss: 227.6099, D Loss: 1.2900
Epoch[37960/50000]
**Train**: G Loss: 217.6518, D Loss: 0.2534
Epoch[37960/50000]
**Valid**: G Loss: 214.7755, D Loss: -0.2009
Epoch[37970/50000]
**Train**: G Loss: 208.7371, D Loss: 0.1800
Epoch[37970/50000]
**Valid**: G Loss: 203.3396, D Loss: 0.8775
Epoch[37980/50000]
**Train**: G Loss: 207.2124, D Loss: 0.5536
Epoch[37980/50000]
**Valid**: G Loss: 214.5006, D Loss: 0.2332
Epoch[37990/50000]
**Train**: G Loss: 237.7509, D Loss: 0.0869
Epoch[37990/50000]
**Valid**: G Loss: 238.5197, D Loss: 1.0139
Epoch[38000/50000]
**Train**: G Loss: 226.9517, D Loss: 0.8875
Epoch[38000/50000]
**Valid**: G Loss: 219.6262, D Loss: 0.4330
Epoch[38010/50000]
**Train**: G Loss: 208.9216, D Loss: 0.2209
Epoch[38010/50000]
**Valid**: G Loss: 202.5272, D Loss: 0.8852
Epoch[38020/50000]
**Train**: G Loss: 209.3035, D Loss: 0.7114
Epoch[38020/50000]
**Valid**: G Loss: 217.0432, D Loss: 0.1809
Epoch[38030/50000]
**Train**: G Loss: 229.8995, D Loss: 0.2614
Epoch[38030/50000]
**Valid**: G Loss: 236.0072, D Loss: 0.6739
Epoch[38040/50000]
**Train**: G Loss: 231.7402, D Loss: 0.6371
Epoch[38040/50000]
**Valid**: G Loss: 226.9827, D Loss: 0.7460
Epoch[38050/50000]
**Train**: G Loss: 221.0957, D Loss: 0.0684
Epoch[38050/50000]
**Valid**: G Loss: 217.2314, D Loss: -0.1603
Epoch[38060/50000]
**Train**: G Loss: 209.4925, D Loss: 0.3804
Epoch[38060/50000]
**Valid**: G Loss: 209.3955, D Loss: 0.9133
Epoch[38070/50000]
**Train**: G Loss: 219.9122, D Loss: 0.5621
Epoch[38070/50000]
**Valid**: G Loss: 228.5753, D Loss: 0.1987
Epoch[38080/50000]
**Train**: G Loss: 232.6671, D Loss: 0.3381
Epoch[38080/50000]
**Valid**: G Loss: 231.7962, D Loss: 0.9578
Epoch[38090/50000]
**Train**: G Loss: 221.6147, D Loss: 0.3876
Epoch[38090/50000]
**Valid**: G Loss: 214.8567, D Loss: 0.0945
Epoch[38100/50000]
**Train**: G Loss: 204.6027, D Loss: 0.4397
Epoch[38100/50000]
**Valid**: G Loss: 201.6159, D Loss: 0.9419
Epoch[38110/50000]
**Train**: G Loss: 214.9451, D Loss: 0.6534
Epoch[38110/50000]
**Valid**: G Loss: 229.4821, D Loss: 0.0598
Epoch[38120/50000]
**Train**: G Loss: 237.2780, D Loss: 0.5730
Epoch[38120/50000]
**Valid**: G Loss: 230.0006, D Loss: 0.9790
Epoch[38130/50000]
**Train**: G Loss: 221.6233, D Loss: 0.5450
Epoch[38130/50000]
**Valid**: G Loss: 215.3427, D Loss: -0.1809
Epoch[38140/50000]
**Train**: G Loss: 209.0334, D Loss: 0.1463
Epoch[38140/50000]
**Valid**: G Loss: 203.9701, D Loss: 1.0005
Epoch[38150/50000]
**Train**: G Loss: 218.5778, D Loss: 0.3519
Epoch[38150/50000]
**Valid**: G Loss: 231.3535, D Loss: -0.1335
Epoch[38160/50000]
**Train**: G Loss: 237.8802, D Loss: -0.0301
Epoch[38160/50000]
**Valid**: G Loss: 238.6867, D Loss: 0.4381
Epoch[38170/50000]
**Train**: G Loss: 219.1169, D Loss: 0.8048
Epoch[38170/50000]
**Valid**: G Loss: 210.7735, D Loss: 0.3265
Epoch[38180/50000]
**Train**: G Loss: 199.8390, D Loss: 0.0100
Epoch[38180/50000]
**Valid**: G Loss: 193.1405, D Loss: 0.6685
Epoch[38190/50000]
**Train**: G Loss: 198.2708, D Loss: 0.8244
Epoch[38190/50000]
**Valid**: G Loss: 205.4392, D Loss: 0.5160
Epoch[38200/50000]
**Train**: G Loss: 224.5257, D Loss: 0.4815
Epoch[38200/50000]
**Valid**: G Loss: 228.1484, D Loss: 0.7258
Epoch[38210/50000]
**Train**: G Loss: 216.8643, D Loss: 0.6662
Epoch[38210/50000]
**Valid**: G Loss: 212.7940, D Loss: 0.7697
Epoch[38220/50000]
**Train**: G Loss: 205.3600, D Loss: 0.1536
Epoch[38220/50000]
**Valid**: G Loss: 200.5338, D Loss: 0.3026
Epoch[38230/50000]
**Train**: G Loss: 201.7840, D Loss: 0.6242
Epoch[38230/50000]
**Valid**: G Loss: 201.1075, D Loss: 0.5811
Epoch[38240/50000]
**Train**: G Loss: 219.1223, D Loss: 0.2850
Epoch[38240/50000]
**Valid**: G Loss: 224.5015, D Loss: 0.1423
Epoch[38250/50000]
**Train**: G Loss: 221.3076, D Loss: 0.8550
Epoch[38250/50000]
**Valid**: G Loss: 213.1528, D Loss: 0.2925
Epoch[38260/50000]
**Train**: G Loss: 209.0162, D Loss: 0.1309
Epoch[38260/50000]
**Valid**: G Loss: 204.1621, D Loss: 0.9316
Epoch[38270/50000]
**Train**: G Loss: 218.3320, D Loss: 0.4447
Epoch[38270/50000]
**Valid**: G Loss: 223.5099, D Loss: 0.2376
Epoch[38280/50000]
**Train**: G Loss: 229.5332, D Loss: 0.3836
Epoch[38280/50000]
**Valid**: G Loss: 229.4288, D Loss: 0.8151
Epoch[38290/50000]
**Train**: G Loss: 221.2809, D Loss: 0.6316
Epoch[38290/50000]
**Valid**: G Loss: 218.6908, D Loss: 0.1307
Epoch[38300/50000]
**Train**: G Loss: 209.1745, D Loss: 0.4828
Epoch[38300/50000]
**Valid**: G Loss: 210.4794, D Loss: 0.7612
Epoch[38310/50000]
**Train**: G Loss: 219.5124, D Loss: 0.2247
Epoch[38310/50000]
**Valid**: G Loss: 230.7288, D Loss: 0.1480
Epoch[38320/50000]
**Train**: G Loss: 228.7570, D Loss: 0.6930
Epoch[38320/50000]
**Valid**: G Loss: 219.5546, D Loss: 0.6685
Epoch[38330/50000]
**Train**: G Loss: 206.7050, D Loss: 0.1872
Epoch[38330/50000]
**Valid**: G Loss: 198.8907, D Loss: 0.2697
Epoch[38340/50000]
**Train**: G Loss: 200.4783, D Loss: 0.5736
Epoch[38340/50000]
**Valid**: G Loss: 200.7695, D Loss: 0.7875
Epoch[38350/50000]
**Train**: G Loss: 211.4187, D Loss: 0.2910
Epoch[38350/50000]
**Valid**: G Loss: 220.5461, D Loss: 0.2941
Epoch[38360/50000]
**Train**: G Loss: 221.0392, D Loss: 0.4892
Epoch[38360/50000]
**Valid**: G Loss: 219.4943, D Loss: 0.1972
Epoch[38370/50000]
**Train**: G Loss: 204.1657, D Loss: 0.5537
Epoch[38370/50000]
**Valid**: G Loss: 201.1271, D Loss: 0.8833
Epoch[38380/50000]
**Train**: G Loss: 214.3371, D Loss: 0.1802
Epoch[38380/50000]
**Valid**: G Loss: 222.7854, D Loss: 0.2571
Epoch[38390/50000]
**Train**: G Loss: 212.1906, D Loss: -0.0616
Epoch[38390/50000]
**Valid**: G Loss: 207.2050, D Loss: 0.0379
Epoch[38400/50000]
**Train**: G Loss: 218.4724, D Loss: 0.0074
Epoch[38400/50000]
**Valid**: G Loss: 231.5264, D Loss: 0.0004
Epoch[38410/50000]
**Train**: G Loss: 219.7432, D Loss: 0.4946
Epoch[38410/50000]
**Valid**: G Loss: 212.1827, D Loss: -0.1672
Epoch[38420/50000]
**Train**: G Loss: 201.3137, D Loss: 0.3918
Epoch[38420/50000]
**Valid**: G Loss: 200.5512, D Loss: 0.8107
Epoch[38430/50000]
**Train**: G Loss: 223.2938, D Loss: 0.1288
Epoch[38430/50000]
**Valid**: G Loss: 231.9318, D Loss: 0.3582
Epoch[38440/50000]
**Train**: G Loss: 221.9062, D Loss: 0.8536
Epoch[38440/50000]
**Valid**: G Loss: 214.6059, D Loss: 0.3060
Epoch[38450/50000]
**Train**: G Loss: 204.8817, D Loss: 0.1437
Epoch[38450/50000]
**Valid**: G Loss: 201.9526, D Loss: 0.9492
Epoch[38460/50000]
**Train**: G Loss: 207.2745, D Loss: 0.7999
Epoch[38460/50000]
**Valid**: G Loss: 214.8333, D Loss: 0.2227
Epoch[38470/50000]
**Train**: G Loss: 231.9866, D Loss: 0.2620
Epoch[38470/50000]
**Valid**: G Loss: 235.8353, D Loss: 1.0379
Epoch[38480/50000]
**Train**: G Loss: 224.1884, D Loss: 0.5415
Epoch[38480/50000]
**Valid**: G Loss: 218.5063, D Loss: 0.1670
Epoch[38490/50000]
**Train**: G Loss: 214.1277, D Loss: 0.2837
Epoch[38490/50000]
**Valid**: G Loss: 208.9812, D Loss: 0.9583
Epoch[38500/50000]
**Train**: G Loss: 219.7633, D Loss: 0.1171
Epoch[38500/50000]
**Valid**: G Loss: 226.0606, D Loss: 0.3263
Epoch[38510/50000]
**Train**: G Loss: 218.0815, D Loss: 0.6467
Epoch[38510/50000]
**Valid**: G Loss: 217.5146, D Loss: 0.1617
Epoch[38520/50000]
**Train**: G Loss: 214.4590, D Loss: 0.2935
Epoch[38520/50000]
**Valid**: G Loss: 211.2241, D Loss: 0.9283
Epoch[38530/50000]
**Train**: G Loss: 223.7203, D Loss: 0.1336
Epoch[38530/50000]
**Valid**: G Loss: 232.9523, D Loss: 0.3815
Epoch[38540/50000]
**Train**: G Loss: 218.7842, D Loss: 0.6903
Epoch[38540/50000]
**Valid**: G Loss: 213.4699, D Loss: 0.3053
Epoch[38550/50000]
**Train**: G Loss: 205.3789, D Loss: 0.4557
Epoch[38550/50000]
**Valid**: G Loss: 204.9367, D Loss: 1.0589
Epoch[38560/50000]
**Train**: G Loss: 221.7393, D Loss: 0.3264
Epoch[38560/50000]
**Valid**: G Loss: 231.6487, D Loss: 0.1213
Epoch[38570/50000]
**Train**: G Loss: 222.3118, D Loss: 0.6758
Epoch[38570/50000]
**Valid**: G Loss: 215.7923, D Loss: 0.2753
Epoch[38580/50000]
**Train**: G Loss: 208.2553, D Loss: 0.4293
Epoch[38580/50000]
**Valid**: G Loss: 206.8836, D Loss: 0.9319
Epoch[38590/50000]
**Train**: G Loss: 228.8133, D Loss: 0.1883
Epoch[38590/50000]
**Valid**: G Loss: 237.9606, D Loss: 0.4241
Epoch[38600/50000]
**Train**: G Loss: 222.0959, D Loss: 0.7416
Epoch[38600/50000]
**Valid**: G Loss: 216.8168, D Loss: 0.4995
Epoch[38610/50000]
**Train**: G Loss: 203.7457, D Loss: 0.1450
Epoch[38610/50000]
**Valid**: G Loss: 196.3392, D Loss: 0.9691
Epoch[38620/50000]
**Train**: G Loss: 212.6410, D Loss: 0.6735
Epoch[38620/50000]
**Valid**: G Loss: 230.4365, D Loss: 0.0016
Epoch[38630/50000]
**Train**: G Loss: 235.6695, D Loss: 0.8040
Epoch[38630/50000]
**Valid**: G Loss: 222.9867, D Loss: 0.8025
Epoch[38640/50000]
**Train**: G Loss: 199.2034, D Loss: 0.1460
Epoch[38640/50000]
**Valid**: G Loss: 191.1052, D Loss: 0.6242
Epoch[38650/50000]
**Train**: G Loss: 203.2092, D Loss: 0.7539
Epoch[38650/50000]
**Valid**: G Loss: 220.9104, D Loss: 0.1909
Epoch[38660/50000]
**Train**: G Loss: 245.8204, D Loss: 0.2577
Epoch[38660/50000]
**Valid**: G Loss: 240.5043, D Loss: 1.3276
Epoch[38670/50000]
**Train**: G Loss: 202.2086, D Loss: 0.1182
Epoch[38670/50000]
**Valid**: G Loss: 193.6213, D Loss: 0.1665
Epoch[38680/50000]
**Train**: G Loss: 196.9991, D Loss: 0.8762
Epoch[38680/50000]
**Valid**: G Loss: 206.0870, D Loss: 0.5851
Epoch[38690/50000]
**Train**: G Loss: 235.2197, D Loss: 0.0148
Epoch[38690/50000]
**Valid**: G Loss: 247.4589, D Loss: 0.3795
Epoch[38700/50000]
**Train**: G Loss: 223.3637, D Loss: 0.9577
Epoch[38700/50000]
**Valid**: G Loss: 212.5579, D Loss: 0.6102
Epoch[38710/50000]
**Train**: G Loss: 207.1673, D Loss: -0.0678
Epoch[38710/50000]
**Valid**: G Loss: 201.1989, D Loss: 0.7296
Epoch[38720/50000]
**Train**: G Loss: 214.5847, D Loss: 0.5000
Epoch[38720/50000]
**Valid**: G Loss: 229.2836, D Loss: 0.0188
Epoch[38730/50000]
**Train**: G Loss: 239.0917, D Loss: 0.7003
Epoch[38730/50000]
**Valid**: G Loss: 231.2697, D Loss: 1.0602
Epoch[38740/50000]
**Train**: G Loss: 210.9151, D Loss: 0.1853
Epoch[38740/50000]
**Valid**: G Loss: 202.3641, D Loss: 0.2521
Epoch[38750/50000]
**Train**: G Loss: 202.1242, D Loss: 0.7978
Epoch[38750/50000]
**Valid**: G Loss: 205.0439, D Loss: 0.9184
Epoch[38760/50000]
**Train**: G Loss: 224.5476, D Loss: 0.3655
Epoch[38760/50000]
**Valid**: G Loss: 235.5572, D Loss: 0.1996
Epoch[38770/50000]
**Train**: G Loss: 234.6773, D Loss: 0.6294
Epoch[38770/50000]
**Valid**: G Loss: 228.5425, D Loss: 1.0772
Epoch[38780/50000]
**Train**: G Loss: 216.9604, D Loss: 0.1596
Epoch[38780/50000]
**Valid**: G Loss: 211.4069, D Loss: 0.1698
Epoch[38790/50000]
**Train**: G Loss: 210.2657, D Loss: 0.7656
Epoch[38790/50000]
**Valid**: G Loss: 215.4949, D Loss: 0.5570
Epoch[38800/50000]
**Train**: G Loss: 244.0005, D Loss: 0.2617
Epoch[38800/50000]
**Valid**: G Loss: 245.1692, D Loss: 0.9354
Epoch[38810/50000]
**Train**: G Loss: 224.9824, D Loss: 0.8235
Epoch[38810/50000]
**Valid**: G Loss: 217.8024, D Loss: 0.2608
Epoch[38820/50000]
**Train**: G Loss: 207.6170, D Loss: -0.1186
Epoch[38820/50000]
**Valid**: G Loss: 201.4845, D Loss: 0.5267
Epoch[38830/50000]
**Train**: G Loss: 210.7855, D Loss: 0.7461
Epoch[38830/50000]
**Valid**: G Loss: 233.5726, D Loss: 0.2343
Epoch[38840/50000]
**Train**: G Loss: 254.2640, D Loss: 0.4098
Epoch[38840/50000]
**Valid**: G Loss: 249.1877, D Loss: 1.4372
Epoch[38850/50000]
**Train**: G Loss: 228.3063, D Loss: 0.5444
Epoch[38850/50000]
**Valid**: G Loss: 217.1644, D Loss: 0.0562
Epoch[38860/50000]
**Train**: G Loss: 209.6721, D Loss: 0.0700
Epoch[38860/50000]
**Valid**: G Loss: 202.8951, D Loss: 0.7272
Epoch[38870/50000]
**Train**: G Loss: 209.3754, D Loss: 0.6350
Epoch[38870/50000]
**Valid**: G Loss: 217.3708, D Loss: 0.3335
Epoch[38880/50000]
**Train**: G Loss: 245.2638, D Loss: -0.0486
Epoch[38880/50000]
**Valid**: G Loss: 251.1241, D Loss: 0.8899
Epoch[38890/50000]
**Train**: G Loss: 238.1845, D Loss: 0.9604
Epoch[38890/50000]
**Valid**: G Loss: 229.4853, D Loss: 0.5461
Epoch[38900/50000]
**Train**: G Loss: 225.6237, D Loss: -0.0093
Epoch[38900/50000]
**Valid**: G Loss: 221.8037, D Loss: 0.1799
Epoch[38910/50000]
**Train**: G Loss: 215.5624, D Loss: 0.7021
Epoch[38910/50000]
**Valid**: G Loss: 215.2368, D Loss: 0.9165
Epoch[38920/50000]
**Train**: G Loss: 231.7669, D Loss: 0.2472
Epoch[38920/50000]
**Valid**: G Loss: 236.1856, D Loss: 0.8482
Epoch[38930/50000]
**Train**: G Loss: 226.8279, D Loss: 0.8610
Epoch[38930/50000]
**Valid**: G Loss: 222.0618, D Loss: 0.6746
Epoch[38940/50000]
**Train**: G Loss: 213.0033, D Loss: 0.4003
Epoch[38940/50000]
**Valid**: G Loss: 211.8111, D Loss: 0.5617
Epoch[38950/50000]
**Train**: G Loss: 202.1823, D Loss: 0.6787
Epoch[38950/50000]
**Valid**: G Loss: 200.7919, D Loss: 0.8039
Epoch[38960/50000]
**Train**: G Loss: 204.4553, D Loss: 0.4931
Epoch[38960/50000]
**Valid**: G Loss: 213.3418, D Loss: 0.2762
Epoch[38970/50000]
**Train**: G Loss: 214.5913, D Loss: 0.2368
Epoch[38970/50000]
**Valid**: G Loss: 215.6207, D Loss: 0.6327
Epoch[38980/50000]
**Train**: G Loss: 212.2955, D Loss: 0.6067
Epoch[38980/50000]
**Valid**: G Loss: 210.3235, D Loss: -0.0047
Epoch[38990/50000]
**Train**: G Loss: 196.4378, D Loss: 0.2011
Epoch[38990/50000]
**Valid**: G Loss: 190.0067, D Loss: 0.7386
Epoch[39000/50000]
**Train**: G Loss: 201.3906, D Loss: 0.5465
Epoch[39000/50000]
**Valid**: G Loss: 211.0004, D Loss: 0.2270
Epoch[39010/50000]
**Train**: G Loss: 222.7412, D Loss: 0.2708
Epoch[39010/50000]
**Valid**: G Loss: 223.7865, D Loss: 0.9161
Epoch[39020/50000]
**Train**: G Loss: 212.3141, D Loss: 0.1698
Epoch[39020/50000]
**Valid**: G Loss: 209.1107, D Loss: 0.0961
Epoch[39030/50000]
**Train**: G Loss: 207.4790, D Loss: 0.3143
Epoch[39030/50000]
**Valid**: G Loss: 213.4556, D Loss: 0.0946
Epoch[39040/50000]
**Train**: G Loss: 215.8116, D Loss: 0.2751
Epoch[39040/50000]
**Valid**: G Loss: 218.0797, D Loss: 0.5273
Epoch[39050/50000]
**Train**: G Loss: 218.0722, D Loss: 0.9401
Epoch[39050/50000]
**Valid**: G Loss: 213.1094, D Loss: 0.8993
Epoch[39060/50000]
**Train**: G Loss: 194.9512, D Loss: 0.1109
Epoch[39060/50000]
**Valid**: G Loss: 190.8590, D Loss: 0.7577
Epoch[39070/50000]
**Train**: G Loss: 191.7843, D Loss: 0.7082
Epoch[39070/50000]
**Valid**: G Loss: 195.4219, D Loss: 0.5257
Epoch[39080/50000]
**Train**: G Loss: 210.5932, D Loss: 0.1746
Epoch[39080/50000]
**Valid**: G Loss: 219.3921, D Loss: 0.4164
Epoch[39090/50000]
**Train**: G Loss: 216.6046, D Loss: 0.7548
Epoch[39090/50000]
**Valid**: G Loss: 213.1492, D Loss: 0.3041
Epoch[39100/50000]
**Train**: G Loss: 198.4531, D Loss: 0.4003
Epoch[39100/50000]
**Valid**: G Loss: 194.9838, D Loss: 0.9352
Epoch[39110/50000]
**Train**: G Loss: 201.5978, D Loss: 0.6345
Epoch[39110/50000]
**Valid**: G Loss: 204.7664, D Loss: 0.4407
Epoch[39120/50000]
**Train**: G Loss: 212.1424, D Loss: 0.2188
Epoch[39120/50000]
**Valid**: G Loss: 216.6267, D Loss: 0.3755
Epoch[39130/50000]
**Train**: G Loss: 216.1893, D Loss: 0.7347
Epoch[39130/50000]
**Valid**: G Loss: 209.7606, D Loss: 0.5459
Epoch[39140/50000]
**Train**: G Loss: 207.4753, D Loss: 0.3243
Epoch[39140/50000]
**Valid**: G Loss: 201.7994, D Loss: 0.1718
Epoch[39150/50000]
**Train**: G Loss: 203.5949, D Loss: 0.0461
Epoch[39150/50000]
**Valid**: G Loss: 200.0226, D Loss: 0.3728
Epoch[39160/50000]
**Train**: G Loss: 201.8899, D Loss: 0.5239
Epoch[39160/50000]
**Valid**: G Loss: 218.3776, D Loss: 0.0747
Epoch[39170/50000]
**Train**: G Loss: 233.2231, D Loss: 0.8362
Epoch[39170/50000]
**Valid**: G Loss: 219.8113, D Loss: 0.8884
Epoch[39180/50000]
**Train**: G Loss: 202.4996, D Loss: 0.1193
Epoch[39180/50000]
**Valid**: G Loss: 196.7305, D Loss: 0.4824
Epoch[39190/50000]
**Train**: G Loss: 207.0475, D Loss: 0.7216
Epoch[39190/50000]
**Valid**: G Loss: 215.7990, D Loss: 0.4702
Epoch[39200/50000]
**Train**: G Loss: 231.9486, D Loss: 0.2668
Epoch[39200/50000]
**Valid**: G Loss: 227.2766, D Loss: 0.8287
Epoch[39210/50000]
**Train**: G Loss: 208.5831, D Loss: 0.4677
Epoch[39210/50000]
**Valid**: G Loss: 200.8228, D Loss: 0.4195
Epoch[39220/50000]
**Train**: G Loss: 200.3102, D Loss: 0.6924
Epoch[39220/50000]
**Valid**: G Loss: 202.3792, D Loss: 0.6276
Epoch[39230/50000]
**Train**: G Loss: 232.0751, D Loss: 0.3523
Epoch[39230/50000]
**Valid**: G Loss: 230.4444, D Loss: 0.7868
Epoch[39240/50000]
**Train**: G Loss: 221.1451, D Loss: 0.4845
Epoch[39240/50000]
**Valid**: G Loss: 214.1391, D Loss: 0.2189
Epoch[39250/50000]
**Train**: G Loss: 208.6458, D Loss: 0.7235
Epoch[39250/50000]
**Valid**: G Loss: 215.2974, D Loss: 0.5342
Epoch[39260/50000]
**Train**: G Loss: 230.8281, D Loss: 0.2196
Epoch[39260/50000]
**Valid**: G Loss: 232.8736, D Loss: 0.6691
Epoch[39270/50000]
**Train**: G Loss: 220.3303, D Loss: 0.5908
Epoch[39270/50000]
**Valid**: G Loss: 215.0025, D Loss: -0.1685
Epoch[39280/50000]
**Train**: G Loss: 205.2043, D Loss: 0.6623
Epoch[39280/50000]
**Valid**: G Loss: 203.4067, D Loss: 0.9098
Epoch[39290/50000]
**Train**: G Loss: 228.7441, D Loss: -0.0919
Epoch[39290/50000]
**Valid**: G Loss: 239.1660, D Loss: 0.4945
Epoch[39300/50000]
**Train**: G Loss: 220.2579, D Loss: 0.5751
Epoch[39300/50000]
**Valid**: G Loss: 211.2375, D Loss: 0.1363
Epoch[39310/50000]
**Train**: G Loss: 194.9904, D Loss: 0.5913
Epoch[39310/50000]
**Valid**: G Loss: 195.4426, D Loss: 0.8432
Epoch[39320/50000]
**Train**: G Loss: 223.7051, D Loss: 0.3741
Epoch[39320/50000]
**Valid**: G Loss: 229.5361, D Loss: 0.5943
Epoch[39330/50000]
**Train**: G Loss: 213.8316, D Loss: 0.4674
Epoch[39330/50000]
**Valid**: G Loss: 208.9560, D Loss: 0.0190
Epoch[39340/50000]
**Train**: G Loss: 207.4768, D Loss: 0.3875
Epoch[39340/50000]
**Valid**: G Loss: 204.0378, D Loss: 0.7859
Epoch[39350/50000]
**Train**: G Loss: 214.3802, D Loss: 0.3385
Epoch[39350/50000]
**Valid**: G Loss: 220.1378, D Loss: 0.3629
Epoch[39360/50000]
**Train**: G Loss: 211.8191, D Loss: 0.5426
Epoch[39360/50000]
**Valid**: G Loss: 208.7986, D Loss: 0.4226
Epoch[39370/50000]
**Train**: G Loss: 191.9615, D Loss: 0.5063
Epoch[39370/50000]
**Valid**: G Loss: 193.1459, D Loss: 0.5275
Epoch[39380/50000]
**Train**: G Loss: 229.9809, D Loss: 0.2132
Epoch[39380/50000]
**Valid**: G Loss: 225.4208, D Loss: 1.0607
Epoch[39390/50000]
**Train**: G Loss: 189.6916, D Loss: 0.2763
Epoch[39390/50000]
**Valid**: G Loss: 181.7409, D Loss: 1.0582
Epoch[39400/50000]
**Train**: G Loss: 214.4988, D Loss: 0.1523
Epoch[39400/50000]
**Valid**: G Loss: 230.6616, D Loss: -0.2460
Epoch[39410/50000]
**Train**: G Loss: 222.2796, D Loss: 0.6600
Epoch[39410/50000]
**Valid**: G Loss: 217.9592, D Loss: 1.0313
Epoch[39420/50000]
**Train**: G Loss: 209.7528, D Loss: 0.4232
Epoch[39420/50000]
**Valid**: G Loss: 207.8771, D Loss: 0.2472
Epoch[39430/50000]
**Train**: G Loss: 199.3257, D Loss: 0.5727
Epoch[39430/50000]
**Valid**: G Loss: 196.9231, D Loss: 0.7923
Epoch[39440/50000]
**Train**: G Loss: 216.8364, D Loss: 0.3010
Epoch[39440/50000]
**Valid**: G Loss: 219.9969, D Loss: 0.4973
Epoch[39450/50000]
**Train**: G Loss: 219.2931, D Loss: 0.7843
Epoch[39450/50000]
**Valid**: G Loss: 216.9527, D Loss: 0.5555
Epoch[39460/50000]
**Train**: G Loss: 214.0055, D Loss: 0.2006
Epoch[39460/50000]
**Valid**: G Loss: 207.9390, D Loss: 0.6365
Epoch[39470/50000]
**Train**: G Loss: 213.1511, D Loss: 0.2353
Epoch[39470/50000]
**Valid**: G Loss: 221.4815, D Loss: 0.2176
Epoch[39480/50000]
**Train**: G Loss: 225.1909, D Loss: 0.4975
Epoch[39480/50000]
**Valid**: G Loss: 218.8081, D Loss: 0.6060
Epoch[39490/50000]
**Train**: G Loss: 202.4223, D Loss: 0.2457
Epoch[39490/50000]
**Valid**: G Loss: 194.6038, D Loss: 0.4571
Epoch[39500/50000]
**Train**: G Loss: 200.4063, D Loss: 0.6196
Epoch[39500/50000]
**Valid**: G Loss: 209.6438, D Loss: 0.2264
Epoch[39510/50000]
**Train**: G Loss: 233.6990, D Loss: 0.3194
Epoch[39510/50000]
**Valid**: G Loss: 227.8409, D Loss: 0.7575
Epoch[39520/50000]
**Train**: G Loss: 210.2872, D Loss: 0.1190
Epoch[39520/50000]
**Valid**: G Loss: 202.9041, D Loss: 0.3155
Epoch[39530/50000]
**Train**: G Loss: 208.5310, D Loss: 0.6200
Epoch[39530/50000]
**Valid**: G Loss: 218.7530, D Loss: 0.0467
Epoch[39540/50000]
**Train**: G Loss: 231.9942, D Loss: 0.4105
Epoch[39540/50000]
**Valid**: G Loss: 227.3659, D Loss: 0.8860
Epoch[39550/50000]
**Train**: G Loss: 214.8094, D Loss: 0.6028
Epoch[39550/50000]
**Valid**: G Loss: 209.8085, D Loss: 0.5089
Epoch[39560/50000]
**Train**: G Loss: 207.5412, D Loss: 0.5953
Epoch[39560/50000]
**Valid**: G Loss: 205.6609, D Loss: 0.7470
Epoch[39570/50000]
**Train**: G Loss: 215.5726, D Loss: 0.4128
Epoch[39570/50000]
**Valid**: G Loss: 220.7090, D Loss: 0.6245
Epoch[39580/50000]
**Train**: G Loss: 214.1168, D Loss: 0.6068
Epoch[39580/50000]
**Valid**: G Loss: 211.8278, D Loss: 0.0802
Epoch[39590/50000]
**Train**: G Loss: 210.1630, D Loss: 0.3669
Epoch[39590/50000]
**Valid**: G Loss: 205.4003, D Loss: 0.8120
Epoch[39600/50000]
**Train**: G Loss: 206.4243, D Loss: 0.1122
Epoch[39600/50000]
**Valid**: G Loss: 211.4332, D Loss: 0.4842
Epoch[39610/50000]
**Train**: G Loss: 208.3271, D Loss: 0.0823
Epoch[39610/50000]
**Valid**: G Loss: 207.3690, D Loss: -0.0119
Epoch[39620/50000]
**Train**: G Loss: 197.7827, D Loss: 0.6505
Epoch[39620/50000]
**Valid**: G Loss: 207.9876, D Loss: 0.1930
Epoch[39630/50000]
**Train**: G Loss: 226.6109, D Loss: 0.5367
Epoch[39630/50000]
**Valid**: G Loss: 215.3568, D Loss: 0.9752
Epoch[39640/50000]
**Train**: G Loss: 208.4701, D Loss: 0.2170
Epoch[39640/50000]
**Valid**: G Loss: 201.8470, D Loss: 0.6187
Epoch[39650/50000]
**Train**: G Loss: 208.6618, D Loss: 0.4071
Epoch[39650/50000]
**Valid**: G Loss: 219.5285, D Loss: 0.0406
Epoch[39660/50000]
**Train**: G Loss: 223.3408, D Loss: 0.6910
Epoch[39660/50000]
**Valid**: G Loss: 215.6635, D Loss: 0.9721
Epoch[39670/50000]
**Train**: G Loss: 216.4252, D Loss: -0.0440
Epoch[39670/50000]
**Valid**: G Loss: 211.2870, D Loss: 0.2241
Epoch[39680/50000]
**Train**: G Loss: 200.6339, D Loss: 0.7307
Epoch[39680/50000]
**Valid**: G Loss: 207.3016, D Loss: 0.2956
Epoch[39690/50000]
**Train**: G Loss: 219.1983, D Loss: 0.4306
Epoch[39690/50000]
**Valid**: G Loss: 217.9730, D Loss: 0.9210
Epoch[39700/50000]
**Train**: G Loss: 217.5486, D Loss: 0.2116
Epoch[39700/50000]
**Valid**: G Loss: 214.1517, D Loss: 0.0679
Epoch[39710/50000]
**Train**: G Loss: 205.4580, D Loss: 0.6519
Epoch[39710/50000]
**Valid**: G Loss: 206.6139, D Loss: 0.4763
Epoch[39720/50000]
**Train**: G Loss: 211.9255, D Loss: 0.4172
Epoch[39720/50000]
**Valid**: G Loss: 214.1965, D Loss: 1.0508
Epoch[39730/50000]
**Train**: G Loss: 210.0040, D Loss: 0.4501
Epoch[39730/50000]
**Valid**: G Loss: 210.3298, D Loss: -0.0836
Epoch[39740/50000]
**Train**: G Loss: 202.4874, D Loss: 0.2701
Epoch[39740/50000]
**Valid**: G Loss: 200.3343, D Loss: 0.5132
Epoch[39750/50000]
**Train**: G Loss: 206.6173, D Loss: 0.3738
Epoch[39750/50000]
**Valid**: G Loss: 216.8673, D Loss: 0.1393
Epoch[39760/50000]
**Train**: G Loss: 215.0353, D Loss: 0.6033
Epoch[39760/50000]
**Valid**: G Loss: 213.3367, D Loss: 0.5232
Epoch[39770/50000]
**Train**: G Loss: 194.1045, D Loss: 0.3437
Epoch[39770/50000]
**Valid**: G Loss: 190.7966, D Loss: 0.7955
Epoch[39780/50000]
**Train**: G Loss: 211.8524, D Loss: 0.2763
Epoch[39780/50000]
**Valid**: G Loss: 223.7568, D Loss: 0.1124
Epoch[39790/50000]
**Train**: G Loss: 221.5693, D Loss: 0.6785
Epoch[39790/50000]
**Valid**: G Loss: 205.5823, D Loss: 0.2186
Epoch[39800/50000]
**Train**: G Loss: 186.8065, D Loss: 0.4837
Epoch[39800/50000]
**Valid**: G Loss: 186.7146, D Loss: 0.9925
Epoch[39810/50000]
**Train**: G Loss: 220.8067, D Loss: 0.3035
Epoch[39810/50000]
**Valid**: G Loss: 228.9303, D Loss: 0.4705
Epoch[39820/50000]
**Train**: G Loss: 213.6395, D Loss: 0.4864
Epoch[39820/50000]
**Valid**: G Loss: 208.4113, D Loss: 0.0388
Epoch[39830/50000]
**Train**: G Loss: 198.9468, D Loss: 0.2803
Epoch[39830/50000]
**Valid**: G Loss: 193.4196, D Loss: 0.6801
Epoch[39840/50000]
**Train**: G Loss: 206.6126, D Loss: 0.4389
Epoch[39840/50000]
**Valid**: G Loss: 210.1045, D Loss: 0.1586
Epoch[39850/50000]
**Train**: G Loss: 209.8069, D Loss: 0.5367
Epoch[39850/50000]
**Valid**: G Loss: 209.0763, D Loss: 1.0269
Epoch[39860/50000]
**Train**: G Loss: 206.5473, D Loss: -0.0157
Epoch[39860/50000]
**Valid**: G Loss: 201.5354, D Loss: 0.3610
Epoch[39870/50000]
**Train**: G Loss: 203.6762, D Loss: 0.5009
Epoch[39870/50000]
**Valid**: G Loss: 206.4795, D Loss: 0.1493
Epoch[39880/50000]
**Train**: G Loss: 221.2117, D Loss: 0.6811
Epoch[39880/50000]
**Valid**: G Loss: 220.7215, D Loss: 0.9979
Epoch[39890/50000]
**Train**: G Loss: 206.3144, D Loss: 0.1607
Epoch[39890/50000]
**Valid**: G Loss: 199.9181, D Loss: 0.0396
Epoch[39900/50000]
**Train**: G Loss: 194.5355, D Loss: 0.4934
Epoch[39900/50000]
**Valid**: G Loss: 197.7094, D Loss: 0.7713
Epoch[39910/50000]
**Train**: G Loss: 229.6318, D Loss: 0.1723
Epoch[39910/50000]
**Valid**: G Loss: 238.2328, D Loss: 0.4439
Epoch[39920/50000]
**Train**: G Loss: 220.2563, D Loss: 0.7055
Epoch[39920/50000]
**Valid**: G Loss: 207.8601, D Loss: 0.1486
Epoch[39930/50000]
**Train**: G Loss: 198.3982, D Loss: 0.2656
Epoch[39930/50000]
**Valid**: G Loss: 192.2284, D Loss: 0.6332
Epoch[39940/50000]
**Train**: G Loss: 196.4897, D Loss: 0.7531
Epoch[39940/50000]
**Valid**: G Loss: 201.0025, D Loss: 0.5868
Epoch[39950/50000]
**Train**: G Loss: 217.3509, D Loss: 0.1795
Epoch[39950/50000]
**Valid**: G Loss: 220.5439, D Loss: 0.5648
Epoch[39960/50000]
**Train**: G Loss: 220.3482, D Loss: 0.6166
Epoch[39960/50000]
**Valid**: G Loss: 216.4372, D Loss: 0.5819
Epoch[39970/50000]
**Train**: G Loss: 206.2788, D Loss: 0.1180
Epoch[39970/50000]
**Valid**: G Loss: 202.9569, D Loss: 0.3092
Epoch[39980/50000]
**Train**: G Loss: 194.0676, D Loss: 0.7415
Epoch[39980/50000]
**Valid**: G Loss: 195.3805, D Loss: 0.6498
Epoch[39990/50000]
**Train**: G Loss: 216.2403, D Loss: 0.2802
Epoch[39990/50000]
**Valid**: G Loss: 230.8190, D Loss: 0.0914
Epoch[40000/50000]
**Train**: G Loss: 216.3506, D Loss: 0.6731
Epoch[40000/50000]
**Valid**: G Loss: 208.9060, D Loss: 0.0417
Epoch[40010/50000]
**Train**: G Loss: 194.9474, D Loss: 0.2123
Epoch[40010/50000]
**Valid**: G Loss: 191.6957, D Loss: 0.9175
Epoch[40020/50000]
**Train**: G Loss: 208.9060, D Loss: 0.3945
Epoch[40020/50000]
**Valid**: G Loss: 218.3695, D Loss: 0.1272
Epoch[40030/50000]
**Train**: G Loss: 228.7331, D Loss: 0.7113
Epoch[40030/50000]
**Valid**: G Loss: 219.9643, D Loss: 0.4931
Epoch[40040/50000]
**Train**: G Loss: 210.1396, D Loss: 0.3814
Epoch[40040/50000]
**Valid**: G Loss: 204.4958, D Loss: 0.2911
Epoch[40050/50000]
**Train**: G Loss: 203.3508, D Loss: 0.3545
Epoch[40050/50000]
**Valid**: G Loss: 201.5753, D Loss: 0.7277
Epoch[40060/50000]
**Train**: G Loss: 222.2356, D Loss: 0.2192
Epoch[40060/50000]
**Valid**: G Loss: 229.8517, D Loss: 0.1482
Epoch[40070/50000]
**Train**: G Loss: 220.1541, D Loss: 0.9321
Epoch[40070/50000]
**Valid**: G Loss: 211.5101, D Loss: 0.6438
Epoch[40080/50000]
**Train**: G Loss: 192.3343, D Loss: 0.2429
Epoch[40080/50000]
**Valid**: G Loss: 189.9052, D Loss: 0.8391
Epoch[40090/50000]
**Train**: G Loss: 218.2862, D Loss: 0.1902
Epoch[40090/50000]
**Valid**: G Loss: 230.9735, D Loss: 0.0638
Epoch[40100/50000]
**Train**: G Loss: 232.2786, D Loss: 0.6507
Epoch[40100/50000]
**Valid**: G Loss: 226.0755, D Loss: 0.9410
Epoch[40110/50000]
**Train**: G Loss: 212.0056, D Loss: 0.3897
Epoch[40110/50000]
**Valid**: G Loss: 205.3704, D Loss: -0.1428
Epoch[40120/50000]
**Train**: G Loss: 201.3715, D Loss: 0.5239
Epoch[40120/50000]
**Valid**: G Loss: 200.4756, D Loss: 0.8793
Epoch[40130/50000]
**Train**: G Loss: 216.6986, D Loss: 0.1927
Epoch[40130/50000]
**Valid**: G Loss: 223.2961, D Loss: 0.1469
Epoch[40140/50000]
**Train**: G Loss: 218.4094, D Loss: 0.7952
Epoch[40140/50000]
**Valid**: G Loss: 213.5391, D Loss: 0.3644
Epoch[40150/50000]
**Train**: G Loss: 215.9367, D Loss: 0.2968
Epoch[40150/50000]
**Valid**: G Loss: 212.9626, D Loss: 0.6491
Epoch[40160/50000]
**Train**: G Loss: 224.7744, D Loss: 0.3555
Epoch[40160/50000]
**Valid**: G Loss: 231.2508, D Loss: 0.1388
Epoch[40170/50000]
**Train**: G Loss: 217.0044, D Loss: 0.6274
Epoch[40170/50000]
**Valid**: G Loss: 215.0877, D Loss: -0.0578
Epoch[40180/50000]
**Train**: G Loss: 196.2398, D Loss: 0.5403
Epoch[40180/50000]
**Valid**: G Loss: 194.9778, D Loss: 0.8383
Epoch[40190/50000]
**Train**: G Loss: 224.1000, D Loss: 0.2289
Epoch[40190/50000]
**Valid**: G Loss: 229.4998, D Loss: 0.7073
Epoch[40200/50000]
**Train**: G Loss: 213.7810, D Loss: 0.2885
Epoch[40200/50000]
**Valid**: G Loss: 208.5711, D Loss: 0.0831
Epoch[40210/50000]
**Train**: G Loss: 204.1608, D Loss: 0.8243
Epoch[40210/50000]
**Valid**: G Loss: 212.4475, D Loss: 0.2086
Epoch[40220/50000]
**Train**: G Loss: 231.6868, D Loss: 0.5523
Epoch[40220/50000]
**Valid**: G Loss: 226.8740, D Loss: 0.9504
Epoch[40230/50000]
**Train**: G Loss: 202.1436, D Loss: 0.2921
Epoch[40230/50000]
**Valid**: G Loss: 197.1376, D Loss: 0.5506
Epoch[40240/50000]
**Train**: G Loss: 220.3724, D Loss: 0.1929
Epoch[40240/50000]
**Valid**: G Loss: 226.1768, D Loss: 0.2899
Epoch[40250/50000]
**Train**: G Loss: 230.5710, D Loss: 0.5527
Epoch[40250/50000]
**Valid**: G Loss: 225.8437, D Loss: 0.4433
Epoch[40260/50000]
**Train**: G Loss: 213.7029, D Loss: 0.7491
Epoch[40260/50000]
**Valid**: G Loss: 210.5530, D Loss: 0.9126
Epoch[40270/50000]
**Train**: G Loss: 220.2316, D Loss: 0.2414
Epoch[40270/50000]
**Valid**: G Loss: 225.6285, D Loss: 0.3931
Epoch[40280/50000]
**Train**: G Loss: 217.3284, D Loss: 0.4962
Epoch[40280/50000]
**Valid**: G Loss: 215.4870, D Loss: -0.0391
Epoch[40290/50000]
**Train**: G Loss: 200.4129, D Loss: 0.9251
Epoch[40290/50000]
**Valid**: G Loss: 205.1353, D Loss: 0.5062
Epoch[40300/50000]
**Train**: G Loss: 223.6280, D Loss: 0.6141
Epoch[40300/50000]
**Valid**: G Loss: 217.0865, D Loss: 0.9726
Epoch[40310/50000]
**Train**: G Loss: 207.3476, D Loss: -0.0267
Epoch[40310/50000]
**Valid**: G Loss: 200.8387, D Loss: 0.3504
Epoch[40320/50000]
**Train**: G Loss: 211.5540, D Loss: 0.5319
Epoch[40320/50000]
**Valid**: G Loss: 220.5922, D Loss: 0.2299
Epoch[40330/50000]
**Train**: G Loss: 228.6548, D Loss: 0.4464
Epoch[40330/50000]
**Valid**: G Loss: 230.0623, D Loss: 0.9633
Epoch[40340/50000]
**Train**: G Loss: 215.4594, D Loss: 0.3444
Epoch[40340/50000]
**Valid**: G Loss: 209.4641, D Loss: 0.1189
Epoch[40350/50000]
**Train**: G Loss: 212.1583, D Loss: 0.5523
Epoch[40350/50000]
**Valid**: G Loss: 222.0166, D Loss: 0.1853
Epoch[40360/50000]
**Train**: G Loss: 222.8911, D Loss: 0.7797
Epoch[40360/50000]
**Valid**: G Loss: 216.8454, D Loss: 0.5779
Epoch[40370/50000]
**Train**: G Loss: 208.3159, D Loss: 0.2478
Epoch[40370/50000]
**Valid**: G Loss: 205.1001, D Loss: 0.6095
Epoch[40380/50000]
**Train**: G Loss: 220.3646, D Loss: 0.3092
Epoch[40380/50000]
**Valid**: G Loss: 223.6545, D Loss: 0.5467
Epoch[40390/50000]
**Train**: G Loss: 212.6853, D Loss: 0.2042
Epoch[40390/50000]
**Valid**: G Loss: 208.9548, D Loss: 0.0113
Epoch[40400/50000]
**Train**: G Loss: 192.5675, D Loss: 0.7917
Epoch[40400/50000]
**Valid**: G Loss: 196.1817, D Loss: 0.6383
Epoch[40410/50000]
**Train**: G Loss: 227.5202, D Loss: 0.2574
Epoch[40410/50000]
**Valid**: G Loss: 235.0103, D Loss: 0.4137
Epoch[40420/50000]
**Train**: G Loss: 212.1902, D Loss: 0.5948
Epoch[40420/50000]
**Valid**: G Loss: 203.2443, D Loss: 0.2836
Epoch[40430/50000]
**Train**: G Loss: 194.9430, D Loss: 0.7300
Epoch[40430/50000]
**Valid**: G Loss: 204.5827, D Loss: 0.4686
Epoch[40440/50000]
**Train**: G Loss: 236.6733, D Loss: 0.7166
Epoch[40440/50000]
**Valid**: G Loss: 227.9673, D Loss: 0.8450
Epoch[40450/50000]
**Train**: G Loss: 204.4234, D Loss: 0.3377
Epoch[40450/50000]
**Valid**: G Loss: 201.5606, D Loss: 1.0963
Epoch[40460/50000]
**Train**: G Loss: 229.3181, D Loss: 0.1114
Epoch[40460/50000]
**Valid**: G Loss: 235.5152, D Loss: 0.5161
Epoch[40470/50000]
**Train**: G Loss: 220.8220, D Loss: 0.5073
Epoch[40470/50000]
**Valid**: G Loss: 216.2440, D Loss: -0.0093
Epoch[40480/50000]
**Train**: G Loss: 200.8372, D Loss: 0.6496
Epoch[40480/50000]
**Valid**: G Loss: 202.7464, D Loss: 0.8378
Epoch[40490/50000]
**Train**: G Loss: 240.3808, D Loss: 0.3023
Epoch[40490/50000]
**Valid**: G Loss: 239.5054, D Loss: 0.9651
Epoch[40500/50000]
**Train**: G Loss: 203.8006, D Loss: 0.3302
Epoch[40500/50000]
**Valid**: G Loss: 194.0452, D Loss: 0.1514
Epoch[40510/50000]
**Train**: G Loss: 194.9889, D Loss: 0.6995
Epoch[40510/50000]
**Valid**: G Loss: 200.8076, D Loss: 0.5031
Epoch[40520/50000]
**Train**: G Loss: 223.0511, D Loss: 0.4413
Epoch[40520/50000]
**Valid**: G Loss: 222.3996, D Loss: 0.9957
Epoch[40530/50000]
**Train**: G Loss: 214.9298, D Loss: 0.1262
Epoch[40530/50000]
**Valid**: G Loss: 210.0706, D Loss: 0.5177
Epoch[40540/50000]
**Train**: G Loss: 205.0483, D Loss: 0.6329
Epoch[40540/50000]
**Valid**: G Loss: 211.8118, D Loss: 0.1581
Epoch[40550/50000]
**Train**: G Loss: 229.8561, D Loss: 0.3507
Epoch[40550/50000]
**Valid**: G Loss: 231.4275, D Loss: 1.1454
Epoch[40560/50000]
**Train**: G Loss: 210.2573, D Loss: 0.4100
Epoch[40560/50000]
**Valid**: G Loss: 204.1235, D Loss: 0.1322
Epoch[40570/50000]
**Train**: G Loss: 199.5625, D Loss: 0.5029
Epoch[40570/50000]
**Valid**: G Loss: 201.5210, D Loss: 0.5493
Epoch[40580/50000]
**Train**: G Loss: 214.1264, D Loss: 0.4467
Epoch[40580/50000]
**Valid**: G Loss: 223.2707, D Loss: 0.4241
Epoch[40590/50000]
**Train**: G Loss: 222.9701, D Loss: 0.9220
Epoch[40590/50000]
**Valid**: G Loss: 216.0013, D Loss: 1.0742
Epoch[40600/50000]
**Train**: G Loss: 203.8341, D Loss: 0.1434
Epoch[40600/50000]
**Valid**: G Loss: 198.3887, D Loss: 0.8410
Epoch[40610/50000]
**Train**: G Loss: 205.1385, D Loss: 0.4524
Epoch[40610/50000]
**Valid**: G Loss: 214.0817, D Loss: 0.1400
Epoch[40620/50000]
**Train**: G Loss: 226.1737, D Loss: 0.8704
Epoch[40620/50000]
**Valid**: G Loss: 221.7754, D Loss: 1.1460
Epoch[40630/50000]
**Train**: G Loss: 218.5768, D Loss: 0.2534
Epoch[40630/50000]
**Valid**: G Loss: 216.3063, D Loss: 0.3887
Epoch[40640/50000]
**Train**: G Loss: 208.9092, D Loss: 0.6535
Epoch[40640/50000]
**Valid**: G Loss: 212.4512, D Loss: 0.5482
Epoch[40650/50000]
**Train**: G Loss: 241.0058, D Loss: 0.1009
Epoch[40650/50000]
**Valid**: G Loss: 246.9100, D Loss: 0.5313
Epoch[40660/50000]
**Train**: G Loss: 229.4317, D Loss: 0.6856
Epoch[40660/50000]
**Valid**: G Loss: 223.3433, D Loss: 0.1777
Epoch[40670/50000]
**Train**: G Loss: 213.2108, D Loss: 0.6317
Epoch[40670/50000]
**Valid**: G Loss: 214.9852, D Loss: 0.7631
Epoch[40680/50000]
**Train**: G Loss: 238.4212, D Loss: 0.2846
Epoch[40680/50000]
**Valid**: G Loss: 243.4558, D Loss: 0.7279
Epoch[40690/50000]
**Train**: G Loss: 222.4204, D Loss: 0.2442
Epoch[40690/50000]
**Valid**: G Loss: 216.4468, D Loss: 0.1813
Epoch[40700/50000]
**Train**: G Loss: 211.4183, D Loss: 0.8306
Epoch[40700/50000]
**Valid**: G Loss: 215.0663, D Loss: 0.4429
Epoch[40710/50000]
**Train**: G Loss: 228.0742, D Loss: 0.4114
Epoch[40710/50000]
**Valid**: G Loss: 226.8049, D Loss: 0.9258
Epoch[40720/50000]
**Train**: G Loss: 212.3167, D Loss: 0.2141
Epoch[40720/50000]
**Valid**: G Loss: 205.7340, D Loss: 0.1467
Epoch[40730/50000]
**Train**: G Loss: 196.7664, D Loss: 0.3907
Epoch[40730/50000]
**Valid**: G Loss: 191.9780, D Loss: 1.0163
Epoch[40740/50000]
**Train**: G Loss: 211.8865, D Loss: 0.3222
Epoch[40740/50000]
**Valid**: G Loss: 217.8089, D Loss: 0.3788
Epoch[40750/50000]
**Train**: G Loss: 216.1574, D Loss: 0.5599
Epoch[40750/50000]
**Valid**: G Loss: 215.2865, D Loss: -0.0234
Epoch[40760/50000]
**Train**: G Loss: 209.1482, D Loss: 0.5235
Epoch[40760/50000]
**Valid**: G Loss: 209.8423, D Loss: 0.6845
Epoch[40770/50000]
**Train**: G Loss: 226.4149, D Loss: 0.2010
Epoch[40770/50000]
**Valid**: G Loss: 232.7501, D Loss: 0.6085
Epoch[40780/50000]
**Train**: G Loss: 226.8932, D Loss: 0.5418
Epoch[40780/50000]
**Valid**: G Loss: 217.2591, D Loss: 0.0422
Epoch[40790/50000]
**Train**: G Loss: 204.1874, D Loss: 0.3778
Epoch[40790/50000]
**Valid**: G Loss: 202.7961, D Loss: 0.8243
Epoch[40800/50000]
**Train**: G Loss: 221.8352, D Loss: 0.2684
Epoch[40800/50000]
**Valid**: G Loss: 235.3498, D Loss: 0.2205
Epoch[40810/50000]
**Train**: G Loss: 232.3414, D Loss: 1.0099
Epoch[40810/50000]
**Valid**: G Loss: 222.0692, D Loss: 0.7917
Epoch[40820/50000]
**Train**: G Loss: 213.3276, D Loss: 0.1314
Epoch[40820/50000]
**Valid**: G Loss: 209.5722, D Loss: 0.5114
Epoch[40830/50000]
**Train**: G Loss: 216.3585, D Loss: 0.2001
Epoch[40830/50000]
**Valid**: G Loss: 227.7441, D Loss: 0.1177
Epoch[40840/50000]
**Train**: G Loss: 222.2225, D Loss: 0.6751
Epoch[40840/50000]
**Valid**: G Loss: 215.4759, D Loss: 0.3617
Epoch[40850/50000]
**Train**: G Loss: 207.8266, D Loss: 0.4422
Epoch[40850/50000]
**Valid**: G Loss: 207.1911, D Loss: 0.6259
Epoch[40860/50000]
**Train**: G Loss: 227.2509, D Loss: 0.1146
Epoch[40860/50000]
**Valid**: G Loss: 233.1126, D Loss: 0.2756
Epoch[40870/50000]
**Train**: G Loss: 218.6095, D Loss: 0.7133
Epoch[40870/50000]
**Valid**: G Loss: 215.7701, D Loss: 0.4048
Epoch[40880/50000]
**Train**: G Loss: 198.5889, D Loss: 0.4953
Epoch[40880/50000]
**Valid**: G Loss: 196.4569, D Loss: 0.8272
Epoch[40890/50000]
**Train**: G Loss: 204.6693, D Loss: 0.5924
Epoch[40890/50000]
**Valid**: G Loss: 213.3853, D Loss: 0.1599
Epoch[40900/50000]
**Train**: G Loss: 225.6349, D Loss: 0.6824
Epoch[40900/50000]
**Valid**: G Loss: 220.9940, D Loss: 0.6969
Epoch[40910/50000]
**Train**: G Loss: 218.0637, D Loss: 0.1807
Epoch[40910/50000]
**Valid**: G Loss: 214.3146, D Loss: 0.5343
Epoch[40920/50000]
**Train**: G Loss: 224.0083, D Loss: 0.3775
Epoch[40920/50000]
**Valid**: G Loss: 230.6474, D Loss: 0.3354
Epoch[40930/50000]
**Train**: G Loss: 221.7650, D Loss: 0.5297
Epoch[40930/50000]
**Valid**: G Loss: 217.9405, D Loss: 0.2009
Epoch[40940/50000]
**Train**: G Loss: 212.4593, D Loss: 0.3084
Epoch[40940/50000]
**Valid**: G Loss: 209.5871, D Loss: 0.4751
Epoch[40950/50000]
**Train**: G Loss: 230.4495, D Loss: 0.2756
Epoch[40950/50000]
**Valid**: G Loss: 234.8356, D Loss: 0.7625
Epoch[40960/50000]
**Train**: G Loss: 217.4005, D Loss: 0.5930
Epoch[40960/50000]
**Valid**: G Loss: 212.0507, D Loss: 0.1596
Epoch[40970/50000]
**Train**: G Loss: 203.0127, D Loss: 0.5876
Epoch[40970/50000]
**Valid**: G Loss: 206.3623, D Loss: 0.4696
Epoch[40980/50000]
**Train**: G Loss: 241.3841, D Loss: 0.1350
Epoch[40980/50000]
**Valid**: G Loss: 240.1986, D Loss: 0.9955
Epoch[40990/50000]
**Train**: G Loss: 209.0629, D Loss: 0.1858
Epoch[40990/50000]
**Valid**: G Loss: 202.9874, D Loss: 0.4265
Epoch[41000/50000]
**Train**: G Loss: 211.2190, D Loss: 0.6116
Epoch[41000/50000]
**Valid**: G Loss: 217.6818, D Loss: 0.2795
Epoch[41010/50000]
**Train**: G Loss: 220.1595, D Loss: 0.6476
Epoch[41010/50000]
**Valid**: G Loss: 216.8497, D Loss: 0.8883
Epoch[41020/50000]
**Train**: G Loss: 213.3085, D Loss: 0.2998
Epoch[41020/50000]
**Valid**: G Loss: 209.4741, D Loss: 1.0671
Epoch[41030/50000]
**Train**: G Loss: 216.5895, D Loss: 0.2561
Epoch[41030/50000]
**Valid**: G Loss: 223.5350, D Loss: 0.3635
Epoch[41040/50000]
**Train**: G Loss: 224.6093, D Loss: 0.6427
Epoch[41040/50000]
**Valid**: G Loss: 215.6665, D Loss: 0.1946
Epoch[41050/50000]
**Train**: G Loss: 211.4083, D Loss: 0.4090
Epoch[41050/50000]
**Valid**: G Loss: 209.9685, D Loss: 0.8981
Epoch[41060/50000]
**Train**: G Loss: 222.1706, D Loss: 0.3144
Epoch[41060/50000]
**Valid**: G Loss: 227.1840, D Loss: 0.3558
Epoch[41070/50000]
**Train**: G Loss: 223.3583, D Loss: 0.5627
Epoch[41070/50000]
**Valid**: G Loss: 219.9384, D Loss: 0.7299
Epoch[41080/50000]
**Train**: G Loss: 211.6956, D Loss: 0.1379
Epoch[41080/50000]
**Valid**: G Loss: 207.7728, D Loss: 0.4352
Epoch[41090/50000]
**Train**: G Loss: 198.3781, D Loss: 0.9021
Epoch[41090/50000]
**Valid**: G Loss: 203.8324, D Loss: 0.6352
Epoch[41100/50000]
**Train**: G Loss: 228.9110, D Loss: 0.4014
Epoch[41100/50000]
**Valid**: G Loss: 230.6762, D Loss: 0.8741
Epoch[41110/50000]
**Train**: G Loss: 212.8639, D Loss: 0.2180
Epoch[41110/50000]
**Valid**: G Loss: 207.4525, D Loss: 0.1673
Epoch[41120/50000]
**Train**: G Loss: 205.3135, D Loss: 0.5839
Epoch[41120/50000]
**Valid**: G Loss: 211.3502, D Loss: 0.2186
Epoch[41130/50000]
**Train**: G Loss: 225.1810, D Loss: 0.3082
Epoch[41130/50000]
**Valid**: G Loss: 225.2732, D Loss: 0.8278
Epoch[41140/50000]
**Train**: G Loss: 217.7149, D Loss: 0.1843
Epoch[41140/50000]
**Valid**: G Loss: 215.0648, D Loss: 0.1413
Epoch[41150/50000]
**Train**: G Loss: 205.8998, D Loss: 0.5825
Epoch[41150/50000]
**Valid**: G Loss: 213.8090, D Loss: 0.4081
Epoch[41160/50000]
**Train**: G Loss: 229.2784, D Loss: 0.5441
Epoch[41160/50000]
**Valid**: G Loss: 222.4002, D Loss: 0.9811
Epoch[41170/50000]
**Train**: G Loss: 193.6163, D Loss: 0.0166
Epoch[41170/50000]
**Valid**: G Loss: 188.9228, D Loss: 0.9212
Epoch[41180/50000]
**Train**: G Loss: 206.7724, D Loss: 0.5666
Epoch[41180/50000]
**Valid**: G Loss: 218.3832, D Loss: -0.0270
Epoch[41190/50000]
**Train**: G Loss: 230.3694, D Loss: 0.5820
Epoch[41190/50000]
**Valid**: G Loss: 225.4750, D Loss: 1.1034
Epoch[41200/50000]
**Train**: G Loss: 211.1165, D Loss: 0.1129
Epoch[41200/50000]
**Valid**: G Loss: 203.8877, D Loss: 0.3909
Epoch[41210/50000]
**Train**: G Loss: 208.0626, D Loss: 0.4621
Epoch[41210/50000]
**Valid**: G Loss: 210.5379, D Loss: 0.4722
Epoch[41220/50000]
**Train**: G Loss: 227.8132, D Loss: 0.2141
Epoch[41220/50000]
**Valid**: G Loss: 235.1142, D Loss: 0.5936
Epoch[41230/50000]
**Train**: G Loss: 218.0758, D Loss: 0.6684
Epoch[41230/50000]
**Valid**: G Loss: 213.2379, D Loss: 0.2584
Epoch[41240/50000]
**Train**: G Loss: 213.1119, D Loss: 0.4726
Epoch[41240/50000]
**Valid**: G Loss: 212.0625, D Loss: 0.5191
Epoch[41250/50000]
**Train**: G Loss: 228.1894, D Loss: 0.2941
Epoch[41250/50000]
**Valid**: G Loss: 233.8810, D Loss: 0.6362
Epoch[41260/50000]
**Train**: G Loss: 211.5891, D Loss: 0.2715
Epoch[41260/50000]
**Valid**: G Loss: 207.9242, D Loss: 0.1555
Epoch[41270/50000]
**Train**: G Loss: 208.3816, D Loss: 0.7281
Epoch[41270/50000]
**Valid**: G Loss: 213.3118, D Loss: 0.3593
Epoch[41280/50000]
**Train**: G Loss: 229.9074, D Loss: 0.5172
Epoch[41280/50000]
**Valid**: G Loss: 224.3135, D Loss: 0.5640
Epoch[41290/50000]
**Train**: G Loss: 211.7302, D Loss: 0.2293
Epoch[41290/50000]
**Valid**: G Loss: 207.4629, D Loss: 0.6595
Epoch[41300/50000]
**Train**: G Loss: 215.5404, D Loss: 0.4816
Epoch[41300/50000]
**Valid**: G Loss: 223.8273, D Loss: 0.3230
Epoch[41310/50000]
**Train**: G Loss: 225.7625, D Loss: 0.7825
Epoch[41310/50000]
**Valid**: G Loss: 219.8600, D Loss: 0.6075
Epoch[41320/50000]
**Train**: G Loss: 203.2108, D Loss: 0.2610
Epoch[41320/50000]
**Valid**: G Loss: 198.3966, D Loss: 0.9451
Epoch[41330/50000]
**Train**: G Loss: 217.8747, D Loss: 0.4728
Epoch[41330/50000]
**Valid**: G Loss: 229.6866, D Loss: 0.0186
Epoch[41340/50000]
**Train**: G Loss: 230.8687, D Loss: 0.4740
Epoch[41340/50000]
**Valid**: G Loss: 226.5848, D Loss: 0.8910
Epoch[41350/50000]
**Train**: G Loss: 214.3579, D Loss: 0.1352
Epoch[41350/50000]
**Valid**: G Loss: 208.4334, D Loss: 0.2620
Epoch[41360/50000]
**Train**: G Loss: 216.0295, D Loss: 0.6317
Epoch[41360/50000]
**Valid**: G Loss: 221.0210, D Loss: 0.5763
Epoch[41370/50000]
**Train**: G Loss: 223.7205, D Loss: 0.3152
Epoch[41370/50000]
**Valid**: G Loss: 230.5115, D Loss: 0.5697
Epoch[41380/50000]
**Train**: G Loss: 223.3295, D Loss: 0.6449
Epoch[41380/50000]
**Valid**: G Loss: 219.5329, D Loss: 0.3929
Epoch[41390/50000]
**Train**: G Loss: 209.4197, D Loss: 0.5555
Epoch[41390/50000]
**Valid**: G Loss: 204.3489, D Loss: 0.9679
Epoch[41400/50000]
**Train**: G Loss: 227.0905, D Loss: 0.1792
Epoch[41400/50000]
**Valid**: G Loss: 234.1607, D Loss: 0.3993
Epoch[41410/50000]
**Train**: G Loss: 226.4473, D Loss: 0.7416
Epoch[41410/50000]
**Valid**: G Loss: 219.1040, D Loss: 0.3696
Epoch[41420/50000]
**Train**: G Loss: 206.0984, D Loss: 0.2264
Epoch[41420/50000]
**Valid**: G Loss: 201.8163, D Loss: 0.8356
Epoch[41430/50000]
**Train**: G Loss: 224.1713, D Loss: 0.2926
Epoch[41430/50000]
**Valid**: G Loss: 234.6561, D Loss: 0.3141
Epoch[41440/50000]
**Train**: G Loss: 232.0412, D Loss: 0.6022
Epoch[41440/50000]
**Valid**: G Loss: 221.4173, D Loss: 0.2032
Epoch[41450/50000]
**Train**: G Loss: 202.5759, D Loss: 0.3738
Epoch[41450/50000]
**Valid**: G Loss: 200.1461, D Loss: 0.8994
Epoch[41460/50000]
**Train**: G Loss: 222.3147, D Loss: 0.2365
Epoch[41460/50000]
**Valid**: G Loss: 237.2240, D Loss: 0.2030
Epoch[41470/50000]
**Train**: G Loss: 239.5698, D Loss: 0.4701
Epoch[41470/50000]
**Valid**: G Loss: 234.1152, D Loss: 0.6482
Epoch[41480/50000]
**Train**: G Loss: 216.7170, D Loss: 0.2609
Epoch[41480/50000]
**Valid**: G Loss: 211.5181, D Loss: 0.5534
Epoch[41490/50000]
**Train**: G Loss: 212.7809, D Loss: 0.7482
Epoch[41490/50000]
**Valid**: G Loss: 221.9170, D Loss: 0.2942
Epoch[41500/50000]
**Train**: G Loss: 238.5200, D Loss: 0.4961
Epoch[41500/50000]
**Valid**: G Loss: 232.5696, D Loss: 0.8256
Epoch[41510/50000]
**Train**: G Loss: 214.2881, D Loss: 0.3581
Epoch[41510/50000]
**Valid**: G Loss: 206.7941, D Loss: 0.4638
Epoch[41520/50000]
**Train**: G Loss: 207.0520, D Loss: 0.5433
Epoch[41520/50000]
**Valid**: G Loss: 209.7945, D Loss: 0.4548
Epoch[41530/50000]
**Train**: G Loss: 226.9201, D Loss: 0.2671
Epoch[41530/50000]
**Valid**: G Loss: 227.6463, D Loss: 0.8679
Epoch[41540/50000]
**Train**: G Loss: 212.9313, D Loss: 0.2706
Epoch[41540/50000]
**Valid**: G Loss: 203.8778, D Loss: 0.2072
Epoch[41550/50000]
**Train**: G Loss: 197.7576, D Loss: 0.8114
Epoch[41550/50000]
**Valid**: G Loss: 203.5325, D Loss: 0.6229
Epoch[41560/50000]
**Train**: G Loss: 226.0817, D Loss: 0.2799
Epoch[41560/50000]
**Valid**: G Loss: 228.6589, D Loss: 0.7026
Epoch[41570/50000]
**Train**: G Loss: 214.9889, D Loss: 0.3873
Epoch[41570/50000]
**Valid**: G Loss: 208.3873, D Loss: 0.1230
Epoch[41580/50000]
**Train**: G Loss: 198.9708, D Loss: 0.5806
Epoch[41580/50000]
**Valid**: G Loss: 202.0584, D Loss: 0.6216
Epoch[41590/50000]
**Train**: G Loss: 229.1649, D Loss: 0.4241
Epoch[41590/50000]
**Valid**: G Loss: 228.2740, D Loss: 1.0032
Epoch[41600/50000]
**Train**: G Loss: 215.6765, D Loss: -0.0493
Epoch[41600/50000]
**Valid**: G Loss: 209.9620, D Loss: 0.3907
Epoch[41610/50000]
**Train**: G Loss: 217.3168, D Loss: 0.5069
Epoch[41610/50000]
**Valid**: G Loss: 226.6531, D Loss: 0.3391
Epoch[41620/50000]
**Train**: G Loss: 226.2546, D Loss: 0.8106
Epoch[41620/50000]
**Valid**: G Loss: 223.9967, D Loss: 0.5113
Epoch[41630/50000]
**Train**: G Loss: 209.4996, D Loss: 0.3208
Epoch[41630/50000]
**Valid**: G Loss: 207.6695, D Loss: 0.8113
Epoch[41640/50000]
**Train**: G Loss: 213.6562, D Loss: 0.4010
Epoch[41640/50000]
**Valid**: G Loss: 219.9012, D Loss: 0.2348
Epoch[41650/50000]
**Train**: G Loss: 222.3839, D Loss: 0.4098
Epoch[41650/50000]
**Valid**: G Loss: 224.6350, D Loss: 0.7121
Epoch[41660/50000]
**Train**: G Loss: 214.1239, D Loss: 0.4491
Epoch[41660/50000]
**Valid**: G Loss: 207.0566, D Loss: 0.2972
Epoch[41670/50000]
**Train**: G Loss: 207.5709, D Loss: 0.5088
Epoch[41670/50000]
**Valid**: G Loss: 212.1448, D Loss: 0.1791
Epoch[41680/50000]
**Train**: G Loss: 230.9672, D Loss: 0.5254
Epoch[41680/50000]
**Valid**: G Loss: 225.9790, D Loss: 1.0401
Epoch[41690/50000]
**Train**: G Loss: 218.1337, D Loss: -0.1061
Epoch[41690/50000]
**Valid**: G Loss: 213.8852, D Loss: 0.2339
Epoch[41700/50000]
**Train**: G Loss: 213.7430, D Loss: 0.6136
Epoch[41700/50000]
**Valid**: G Loss: 215.2594, D Loss: 0.4635
Epoch[41710/50000]
**Train**: G Loss: 220.4209, D Loss: 0.1366
Epoch[41710/50000]
**Valid**: G Loss: 225.1645, D Loss: 0.4110
Epoch[41720/50000]
**Train**: G Loss: 222.5289, D Loss: 0.4620
Epoch[41720/50000]
**Valid**: G Loss: 216.5291, D Loss: 0.1008
Epoch[41730/50000]
**Train**: G Loss: 211.7993, D Loss: 0.7905
Epoch[41730/50000]
**Valid**: G Loss: 212.3914, D Loss: 0.7484
Epoch[41740/50000]
**Train**: G Loss: 236.7414, D Loss: 0.4179
Epoch[41740/50000]
**Valid**: G Loss: 241.8738, D Loss: 0.7159
Epoch[41750/50000]
**Train**: G Loss: 220.4745, D Loss: 0.3058
Epoch[41750/50000]
**Valid**: G Loss: 212.1760, D Loss: 0.2661
Epoch[41760/50000]
**Train**: G Loss: 214.7157, D Loss: 0.5383
Epoch[41760/50000]
**Valid**: G Loss: 219.4195, D Loss: 0.3271
Epoch[41770/50000]
**Train**: G Loss: 230.2187, D Loss: 0.4503
Epoch[41770/50000]
**Valid**: G Loss: 228.3442, D Loss: 0.9090
Epoch[41780/50000]
**Train**: G Loss: 212.1928, D Loss: 0.2377
Epoch[41780/50000]
**Valid**: G Loss: 206.1289, D Loss: 0.4937
Epoch[41790/50000]
**Train**: G Loss: 204.3998, D Loss: 0.3377
Epoch[41790/50000]
**Valid**: G Loss: 209.0638, D Loss: 0.0998
Epoch[41800/50000]
**Train**: G Loss: 205.4617, D Loss: 0.6179
Epoch[41800/50000]
**Valid**: G Loss: 205.3182, D Loss: 0.6982
Epoch[41810/50000]
**Train**: G Loss: 202.2454, D Loss: 0.3206
Epoch[41810/50000]
**Valid**: G Loss: 198.3563, D Loss: 0.5744
Epoch[41820/50000]
**Train**: G Loss: 203.5734, D Loss: 0.6645
Epoch[41820/50000]
**Valid**: G Loss: 212.5460, D Loss: 0.3726
Epoch[41830/50000]
**Train**: G Loss: 219.6093, D Loss: 0.6711
Epoch[41830/50000]
**Valid**: G Loss: 213.7716, D Loss: 0.7154
Epoch[41840/50000]
**Train**: G Loss: 207.2129, D Loss: 0.3832
Epoch[41840/50000]
**Valid**: G Loss: 203.8272, D Loss: 0.6650
Epoch[41850/50000]
**Train**: G Loss: 212.0365, D Loss: 0.2882
Epoch[41850/50000]
**Valid**: G Loss: 222.2904, D Loss: -0.0701
Epoch[41860/50000]
**Train**: G Loss: 218.0056, D Loss: 0.5832
Epoch[41860/50000]
**Valid**: G Loss: 212.5744, D Loss: 0.2772
Epoch[41870/50000]
**Train**: G Loss: 200.8083, D Loss: 0.6555
Epoch[41870/50000]
**Valid**: G Loss: 200.9558, D Loss: 0.7109
Epoch[41880/50000]
**Train**: G Loss: 230.2176, D Loss: 0.1516
Epoch[41880/50000]
**Valid**: G Loss: 230.0559, D Loss: 0.6814
Epoch[41890/50000]
**Train**: G Loss: 195.3842, D Loss: 0.1047
Epoch[41890/50000]
**Valid**: G Loss: 189.8761, D Loss: 0.6598
Epoch[41900/50000]
**Train**: G Loss: 213.8865, D Loss: 0.4458
Epoch[41900/50000]
**Valid**: G Loss: 221.3006, D Loss: 0.2105
Epoch[41910/50000]
**Train**: G Loss: 228.3537, D Loss: 0.5220
Epoch[41910/50000]
**Valid**: G Loss: 222.3833, D Loss: 0.2327
Epoch[41920/50000]
**Train**: G Loss: 194.2357, D Loss: 0.4097
Epoch[41920/50000]
**Valid**: G Loss: 193.5226, D Loss: 0.8723
Epoch[41930/50000]
**Train**: G Loss: 216.3126, D Loss: 0.2554
Epoch[41930/50000]
**Valid**: G Loss: 217.9558, D Loss: 0.7856
Epoch[41940/50000]
**Train**: G Loss: 213.8991, D Loss: 0.5221
Epoch[41940/50000]
**Valid**: G Loss: 210.2857, D Loss: 0.2015
Epoch[41950/50000]
**Train**: G Loss: 200.5329, D Loss: 0.4306
Epoch[41950/50000]
**Valid**: G Loss: 200.4720, D Loss: 0.6415
Epoch[41960/50000]
**Train**: G Loss: 220.6581, D Loss: 0.3588
Epoch[41960/50000]
**Valid**: G Loss: 227.6737, D Loss: 0.8026
Epoch[41970/50000]
**Train**: G Loss: 200.9009, D Loss: 0.1906
Epoch[41970/50000]
**Valid**: G Loss: 184.9666, D Loss: 0.1005
Epoch[41980/50000]
**Train**: G Loss: 218.2093, D Loss: 0.4333
Epoch[41980/50000]
**Valid**: G Loss: 227.8310, D Loss: -0.0662
Epoch[41990/50000]
**Train**: G Loss: 226.0780, D Loss: 0.7004
Epoch[41990/50000]
**Valid**: G Loss: 222.0478, D Loss: 0.6118
Epoch[42000/50000]
**Train**: G Loss: 212.8400, D Loss: 0.4104
Epoch[42000/50000]
**Valid**: G Loss: 208.5618, D Loss: 0.8427
Epoch[42010/50000]
**Train**: G Loss: 228.2745, D Loss: 0.2795
Epoch[42010/50000]
**Valid**: G Loss: 235.1228, D Loss: 0.2077
Epoch[42020/50000]
**Train**: G Loss: 221.4678, D Loss: 0.7164
Epoch[42020/50000]
**Valid**: G Loss: 214.7646, D Loss: 0.3896
Epoch[42030/50000]
**Train**: G Loss: 207.4195, D Loss: 0.2110
Epoch[42030/50000]
**Valid**: G Loss: 206.0201, D Loss: 0.7708
Epoch[42040/50000]
**Train**: G Loss: 225.4505, D Loss: 0.3203
Epoch[42040/50000]
**Valid**: G Loss: 235.4209, D Loss: 0.5639
Epoch[42050/50000]
**Train**: G Loss: 220.7894, D Loss: 0.6016
Epoch[42050/50000]
**Valid**: G Loss: 213.1620, D Loss: -0.2027
Epoch[42060/50000]
**Train**: G Loss: 209.4048, D Loss: 0.2796
Epoch[42060/50000]
**Valid**: G Loss: 209.1838, D Loss: 0.6366
Epoch[42070/50000]
**Train**: G Loss: 224.6970, D Loss: 0.5241
Epoch[42070/50000]
**Valid**: G Loss: 234.2767, D Loss: 0.2911
Epoch[42080/50000]
**Train**: G Loss: 228.0755, D Loss: 0.7871
Epoch[42080/50000]
**Valid**: G Loss: 222.4505, D Loss: 0.5400
Epoch[42090/50000]
**Train**: G Loss: 204.8297, D Loss: 0.3640
Epoch[42090/50000]
**Valid**: G Loss: 199.6991, D Loss: 0.6538
Epoch[42100/50000]
**Train**: G Loss: 223.7454, D Loss: 0.1415
Epoch[42100/50000]
**Valid**: G Loss: 230.7334, D Loss: 0.2448
Epoch[42110/50000]
**Train**: G Loss: 218.1475, D Loss: 0.6743
Epoch[42110/50000]
**Valid**: G Loss: 213.7705, D Loss: 0.2653
Epoch[42120/50000]
**Train**: G Loss: 208.7209, D Loss: 0.4980
Epoch[42120/50000]
**Valid**: G Loss: 205.7187, D Loss: 0.9431
Epoch[42130/50000]
**Train**: G Loss: 225.1642, D Loss: 0.4263
Epoch[42130/50000]
**Valid**: G Loss: 222.9587, D Loss: 1.0385
Epoch[42140/50000]
**Train**: G Loss: 216.8939, D Loss: 0.3107
Epoch[42140/50000]
**Valid**: G Loss: 214.6030, D Loss: 0.0630
Epoch[42150/50000]
**Train**: G Loss: 205.8650, D Loss: 0.7173
Epoch[42150/50000]
**Valid**: G Loss: 216.9001, D Loss: 0.2822
Epoch[42160/50000]
**Train**: G Loss: 235.0640, D Loss: 0.2549
Epoch[42160/50000]
**Valid**: G Loss: 237.0455, D Loss: 0.7653
Epoch[42170/50000]
**Train**: G Loss: 219.2705, D Loss: 0.4335
Epoch[42170/50000]
**Valid**: G Loss: 216.3871, D Loss: 0.1902
Epoch[42180/50000]
**Train**: G Loss: 210.4695, D Loss: 0.6874
Epoch[42180/50000]
**Valid**: G Loss: 211.6473, D Loss: 0.4552
Epoch[42190/50000]
**Train**: G Loss: 226.7364, D Loss: 0.4553
Epoch[42190/50000]
**Valid**: G Loss: 226.3563, D Loss: 0.7347
Epoch[42200/50000]
**Train**: G Loss: 216.8938, D Loss: 0.4764
Epoch[42200/50000]
**Valid**: G Loss: 214.9949, D Loss: 0.2685
Epoch[42210/50000]
**Train**: G Loss: 208.8389, D Loss: 0.4251
Epoch[42210/50000]
**Valid**: G Loss: 208.0654, D Loss: 0.9706
Epoch[42220/50000]
**Train**: G Loss: 204.2390, D Loss: 0.6742
Epoch[42220/50000]
**Valid**: G Loss: 210.8273, D Loss: 0.2524
Epoch[42230/50000]
**Train**: G Loss: 221.8346, D Loss: 0.2688
Epoch[42230/50000]
**Valid**: G Loss: 218.4912, D Loss: 0.6864
Epoch[42240/50000]
**Train**: G Loss: 206.2374, D Loss: 0.3757
Epoch[42240/50000]
**Valid**: G Loss: 199.2091, D Loss: 0.1131
Epoch[42250/50000]
**Train**: G Loss: 197.0930, D Loss: 0.6518
Epoch[42250/50000]
**Valid**: G Loss: 202.7279, D Loss: 0.4369
Epoch[42260/50000]
**Train**: G Loss: 227.0038, D Loss: 0.1861
Epoch[42260/50000]
**Valid**: G Loss: 228.1584, D Loss: 0.9107
Epoch[42270/50000]
**Train**: G Loss: 218.6158, D Loss: 0.4682
Epoch[42270/50000]
**Valid**: G Loss: 212.0104, D Loss: 0.1123
Epoch[42280/50000]
**Train**: G Loss: 204.5749, D Loss: 0.5581
Epoch[42280/50000]
**Valid**: G Loss: 205.2158, D Loss: 0.7273
Epoch[42290/50000]
**Train**: G Loss: 220.2864, D Loss: 0.2576
Epoch[42290/50000]
**Valid**: G Loss: 222.9455, D Loss: 0.6300
Epoch[42300/50000]
**Train**: G Loss: 217.2887, D Loss: 0.5648
Epoch[42300/50000]
**Valid**: G Loss: 212.4376, D Loss: 0.3032
Epoch[42310/50000]
**Train**: G Loss: 204.5902, D Loss: 0.4050
Epoch[42310/50000]
**Valid**: G Loss: 203.0424, D Loss: 0.7656
Epoch[42320/50000]
**Train**: G Loss: 213.1934, D Loss: 0.3972
Epoch[42320/50000]
**Valid**: G Loss: 220.7510, D Loss: 0.3561
Epoch[42330/50000]
**Train**: G Loss: 214.8786, D Loss: 0.7435
Epoch[42330/50000]
**Valid**: G Loss: 209.4983, D Loss: 0.4351
Epoch[42340/50000]
**Train**: G Loss: 198.8300, D Loss: 0.6687
Epoch[42340/50000]
**Valid**: G Loss: 198.3392, D Loss: 0.7780
Epoch[42350/50000]
**Train**: G Loss: 227.5094, D Loss: -0.0303
Epoch[42350/50000]
**Valid**: G Loss: 229.4627, D Loss: 0.5579
Epoch[42360/50000]
**Train**: G Loss: 210.2199, D Loss: 0.5069
Epoch[42360/50000]
**Valid**: G Loss: 207.5626, D Loss: 0.2713
Epoch[42370/50000]
**Train**: G Loss: 201.7268, D Loss: 0.5692
Epoch[42370/50000]
**Valid**: G Loss: 200.7681, D Loss: 0.9021
Epoch[42380/50000]
**Train**: G Loss: 229.7400, D Loss: 0.1316
Epoch[42380/50000]
**Valid**: G Loss: 235.9559, D Loss: 0.8267
Epoch[42390/50000]
**Train**: G Loss: 207.6168, D Loss: 0.0848
Epoch[42390/50000]
**Valid**: G Loss: 201.6857, D Loss: 0.4138
Epoch[42400/50000]
**Train**: G Loss: 208.9865, D Loss: 0.4723
Epoch[42400/50000]
**Valid**: G Loss: 219.4886, D Loss: 0.1181
Epoch[42410/50000]
**Train**: G Loss: 226.5546, D Loss: 0.5654
Epoch[42410/50000]
**Valid**: G Loss: 222.5628, D Loss: 0.8576
Epoch[42420/50000]
**Train**: G Loss: 207.8991, D Loss: 0.6424
Epoch[42420/50000]
**Valid**: G Loss: 202.4300, D Loss: 0.4609
Epoch[42430/50000]
**Train**: G Loss: 205.6828, D Loss: 0.4289
Epoch[42430/50000]
**Valid**: G Loss: 210.4986, D Loss: 0.0759
Epoch[42440/50000]
**Train**: G Loss: 221.1248, D Loss: 0.4666
Epoch[42440/50000]
**Valid**: G Loss: 220.8954, D Loss: 0.8427
Epoch[42450/50000]
**Train**: G Loss: 212.5041, D Loss: 0.5513
Epoch[42450/50000]
**Valid**: G Loss: 211.3322, D Loss: 0.2403
Epoch[42460/50000]
**Train**: G Loss: 187.8582, D Loss: 0.2514
Epoch[42460/50000]
**Valid**: G Loss: 183.6202, D Loss: 0.8502
Epoch[42470/50000]
**Train**: G Loss: 205.1576, D Loss: 0.1926
Epoch[42470/50000]
**Valid**: G Loss: 214.8960, D Loss: -0.0479
Epoch[42480/50000]
**Train**: G Loss: 219.9679, D Loss: 0.6914
Epoch[42480/50000]
**Valid**: G Loss: 215.5885, D Loss: 0.9625
Epoch[42490/50000]
**Train**: G Loss: 205.9887, D Loss: 0.0659
Epoch[42490/50000]
**Valid**: G Loss: 200.2736, D Loss: 0.3752
Epoch[42500/50000]
**Train**: G Loss: 213.1464, D Loss: 0.4449
Epoch[42500/50000]
**Valid**: G Loss: 219.5125, D Loss: -0.0159
Epoch[42510/50000]
**Train**: G Loss: 221.8707, D Loss: 0.6856
Epoch[42510/50000]
**Valid**: G Loss: 214.6301, D Loss: 0.6984
Epoch[42520/50000]
**Train**: G Loss: 194.3600, D Loss: -0.0968
Epoch[42520/50000]
**Valid**: G Loss: 189.2624, D Loss: 0.6980
Epoch[42530/50000]
**Train**: G Loss: 204.5140, D Loss: 0.5618
Epoch[42530/50000]
**Valid**: G Loss: 215.6159, D Loss: 0.0731
Epoch[42540/50000]
**Train**: G Loss: 228.1334, D Loss: 0.6417
Epoch[42540/50000]
**Valid**: G Loss: 224.4028, D Loss: 0.8190
Epoch[42550/50000]
**Train**: G Loss: 209.3916, D Loss: 0.4020
Epoch[42550/50000]
**Valid**: G Loss: 205.8656, D Loss: 0.6092
Epoch[42560/50000]
**Train**: G Loss: 208.0424, D Loss: 0.5659
Epoch[42560/50000]
**Valid**: G Loss: 208.4963, D Loss: 0.4962
Epoch[42570/50000]
**Train**: G Loss: 226.7463, D Loss: 0.3681
Epoch[42570/50000]
**Valid**: G Loss: 228.7368, D Loss: 0.8771
Epoch[42580/50000]
**Train**: G Loss: 214.6328, D Loss: 0.3515
Epoch[42580/50000]
**Valid**: G Loss: 206.4059, D Loss: 0.1881
Epoch[42590/50000]
**Train**: G Loss: 209.6015, D Loss: 0.5119
Epoch[42590/50000]
**Valid**: G Loss: 213.6823, D Loss: 0.5456
Epoch[42600/50000]
**Train**: G Loss: 224.2722, D Loss: 0.3193
Epoch[42600/50000]
**Valid**: G Loss: 229.7940, D Loss: 0.8517
Epoch[42610/50000]
**Train**: G Loss: 221.4693, D Loss: 0.7114
Epoch[42610/50000]
**Valid**: G Loss: 213.3944, D Loss: 0.0077
Epoch[42620/50000]
**Train**: G Loss: 201.7878, D Loss: 0.3687
Epoch[42620/50000]
**Valid**: G Loss: 201.6010, D Loss: 0.6621
Epoch[42630/50000]
**Train**: G Loss: 210.1797, D Loss: 0.4508
Epoch[42630/50000]
**Valid**: G Loss: 219.4765, D Loss: 0.4216
Epoch[42640/50000]
**Train**: G Loss: 223.0158, D Loss: 0.6358
Epoch[42640/50000]
**Valid**: G Loss: 216.7933, D Loss: 0.6571
Epoch[42650/50000]
**Train**: G Loss: 214.6694, D Loss: 0.2847
Epoch[42650/50000]
**Valid**: G Loss: 211.6009, D Loss: -0.0255
Epoch[42660/50000]
**Train**: G Loss: 201.8124, D Loss: 0.8276
Epoch[42660/50000]
**Valid**: G Loss: 205.9837, D Loss: 0.4145
Epoch[42670/50000]
**Train**: G Loss: 214.5773, D Loss: 0.4442
Epoch[42670/50000]
**Valid**: G Loss: 213.3714, D Loss: 1.0535
Epoch[42680/50000]
**Train**: G Loss: 207.3800, D Loss: 0.3000
Epoch[42680/50000]
**Valid**: G Loss: 203.3138, D Loss: 0.3284
Epoch[42690/50000]
**Train**: G Loss: 202.6896, D Loss: 0.7562
Epoch[42690/50000]
**Valid**: G Loss: 208.3353, D Loss: 0.6090
Epoch[42700/50000]
**Train**: G Loss: 216.1036, D Loss: 0.2309
Epoch[42700/50000]
**Valid**: G Loss: 220.2006, D Loss: 0.3766
Epoch[42710/50000]
**Train**: G Loss: 218.2010, D Loss: 0.4634
Epoch[42710/50000]
**Valid**: G Loss: 212.5726, D Loss: 0.4249
Epoch[42720/50000]
**Train**: G Loss: 201.1578, D Loss: -0.0619
Epoch[42720/50000]
**Valid**: G Loss: 194.8597, D Loss: 0.3251
Epoch[42730/50000]
**Train**: G Loss: 211.5502, D Loss: 0.1835
Epoch[42730/50000]
**Valid**: G Loss: 225.5864, D Loss: 0.2508
Epoch[42740/50000]
**Train**: G Loss: 223.6051, D Loss: 0.9288
Epoch[42740/50000]
**Valid**: G Loss: 216.3564, D Loss: 0.5127
Epoch[42750/50000]
**Train**: G Loss: 205.3586, D Loss: -0.0175
Epoch[42750/50000]
**Valid**: G Loss: 199.8807, D Loss: 0.5554
Epoch[42760/50000]
**Train**: G Loss: 206.8271, D Loss: 0.6422
Epoch[42760/50000]
**Valid**: G Loss: 212.1114, D Loss: 0.1903
Epoch[42770/50000]
**Train**: G Loss: 228.0380, D Loss: 0.3696
Epoch[42770/50000]
**Valid**: G Loss: 228.2780, D Loss: 0.8090
Epoch[42780/50000]
**Train**: G Loss: 214.5853, D Loss: 0.5548
Epoch[42780/50000]
**Valid**: G Loss: 208.1848, D Loss: 0.2209
Epoch[42790/50000]
**Train**: G Loss: 197.2338, D Loss: 0.3036
Epoch[42790/50000]
**Valid**: G Loss: 195.2453, D Loss: 0.7386
Epoch[42800/50000]
**Train**: G Loss: 204.6641, D Loss: 0.4767
Epoch[42800/50000]
**Valid**: G Loss: 212.4802, D Loss: 0.1939
Epoch[42810/50000]
**Train**: G Loss: 218.5187, D Loss: 0.4101
Epoch[42810/50000]
**Valid**: G Loss: 218.6725, D Loss: 0.7363
Epoch[42820/50000]
**Train**: G Loss: 207.4118, D Loss: 0.2263
Epoch[42820/50000]
**Valid**: G Loss: 201.9859, D Loss: 0.5012
Epoch[42830/50000]
**Train**: G Loss: 204.5775, D Loss: 0.3934
Epoch[42830/50000]
**Valid**: G Loss: 213.8098, D Loss: -0.0460
Epoch[42840/50000]
**Train**: G Loss: 218.8843, D Loss: 0.7180
Epoch[42840/50000]
**Valid**: G Loss: 215.6976, D Loss: 0.9502
Epoch[42850/50000]
**Train**: G Loss: 199.5894, D Loss: 0.3559
Epoch[42850/50000]
**Valid**: G Loss: 197.4655, D Loss: 0.9988
Epoch[42860/50000]
**Train**: G Loss: 216.5431, D Loss: 0.4326
Epoch[42860/50000]
**Valid**: G Loss: 216.8922, D Loss: 0.9846
Epoch[42870/50000]
**Train**: G Loss: 204.6534, D Loss: 0.1700
Epoch[42870/50000]
**Valid**: G Loss: 199.0786, D Loss: 0.1705
Epoch[42880/50000]
**Train**: G Loss: 203.4799, D Loss: 0.7616
Epoch[42880/50000]
**Valid**: G Loss: 210.6533, D Loss: 0.3568
Epoch[42890/50000]
**Train**: G Loss: 219.8130, D Loss: 0.4992
Epoch[42890/50000]
**Valid**: G Loss: 215.7371, D Loss: 0.9341
Epoch[42900/50000]
**Train**: G Loss: 201.5527, D Loss: 0.2864
Epoch[42900/50000]
**Valid**: G Loss: 196.7818, D Loss: 0.4495
Epoch[42910/50000]
**Train**: G Loss: 199.7869, D Loss: 0.5121
Epoch[42910/50000]
**Valid**: G Loss: 210.4279, D Loss: 0.1699
Epoch[42920/50000]
**Train**: G Loss: 222.7330, D Loss: 0.3759
Epoch[42920/50000]
**Valid**: G Loss: 217.9340, D Loss: 0.6648
Epoch[42930/50000]
**Train**: G Loss: 205.2210, D Loss: 0.1159
Epoch[42930/50000]
**Valid**: G Loss: 201.5362, D Loss: 0.6696
Epoch[42940/50000]
**Train**: G Loss: 210.3086, D Loss: 0.4434
Epoch[42940/50000]
**Valid**: G Loss: 220.6704, D Loss: 0.1898
Epoch[42950/50000]
**Train**: G Loss: 217.6703, D Loss: 0.4745
Epoch[42950/50000]
**Valid**: G Loss: 212.8592, D Loss: 0.5251
Epoch[42960/50000]
**Train**: G Loss: 207.4534, D Loss: 0.3231
Epoch[42960/50000]
**Valid**: G Loss: 203.5895, D Loss: 0.5484
Epoch[42970/50000]
**Train**: G Loss: 207.4177, D Loss: 0.7079
Epoch[42970/50000]
**Valid**: G Loss: 213.5702, D Loss: 0.0612
Epoch[42980/50000]
**Train**: G Loss: 222.9547, D Loss: 0.2975
Epoch[42980/50000]
**Valid**: G Loss: 220.6535, D Loss: 0.9442
Epoch[42990/50000]
**Train**: G Loss: 212.6619, D Loss: 0.4312
Epoch[42990/50000]
**Valid**: G Loss: 205.2551, D Loss: 0.0231
Epoch[43000/50000]
**Train**: G Loss: 195.6681, D Loss: 0.4852
Epoch[43000/50000]
**Valid**: G Loss: 196.0428, D Loss: 0.7488
Epoch[43010/50000]
**Train**: G Loss: 222.2357, D Loss: 0.3809
Epoch[43010/50000]
**Valid**: G Loss: 231.1395, D Loss: 0.5538
Epoch[43020/50000]
**Train**: G Loss: 210.2232, D Loss: 0.5805
Epoch[43020/50000]
**Valid**: G Loss: 202.8660, D Loss: 0.2685
Epoch[43030/50000]
**Train**: G Loss: 186.8630, D Loss: 0.6700
Epoch[43030/50000]
**Valid**: G Loss: 193.1093, D Loss: 0.5261
Epoch[43040/50000]
**Train**: G Loss: 220.9679, D Loss: 0.2904
Epoch[43040/50000]
**Valid**: G Loss: 219.8958, D Loss: 1.2906
Epoch[43050/50000]
**Train**: G Loss: 207.9440, D Loss: 0.2812
Epoch[43050/50000]
**Valid**: G Loss: 199.9345, D Loss: -0.1391
Epoch[43060/50000]
**Train**: G Loss: 195.2842, D Loss: 0.6217
Epoch[43060/50000]
**Valid**: G Loss: 195.2704, D Loss: 0.9690
Epoch[43070/50000]
**Train**: G Loss: 213.7500, D Loss: 0.1370
Epoch[43070/50000]
**Valid**: G Loss: 221.8508, D Loss: 0.5948
Epoch[43080/50000]
**Train**: G Loss: 217.7144, D Loss: 0.7864
Epoch[43080/50000]
**Valid**: G Loss: 210.3817, D Loss: 0.5685
Epoch[43090/50000]
**Train**: G Loss: 204.0770, D Loss: 0.1994
Epoch[43090/50000]
**Valid**: G Loss: 198.3664, D Loss: 0.3303
Epoch[43100/50000]
**Train**: G Loss: 202.8356, D Loss: 0.4461
Epoch[43100/50000]
**Valid**: G Loss: 207.8566, D Loss: 0.2062
Epoch[43110/50000]
**Train**: G Loss: 216.9675, D Loss: 0.2726
Epoch[43110/50000]
**Valid**: G Loss: 221.1669, D Loss: 0.4569
Epoch[43120/50000]
**Train**: G Loss: 220.9081, D Loss: 0.7516
Epoch[43120/50000]
**Valid**: G Loss: 216.1853, D Loss: 0.7624
Epoch[43130/50000]
**Train**: G Loss: 211.6967, D Loss: 0.1390
Epoch[43130/50000]
**Valid**: G Loss: 207.0017, D Loss: -0.0380
Epoch[43140/50000]
**Train**: G Loss: 202.9175, D Loss: 0.7042
Epoch[43140/50000]
**Valid**: G Loss: 206.7703, D Loss: 0.6099
Epoch[43150/50000]
**Train**: G Loss: 220.1183, D Loss: 0.2177
Epoch[43150/50000]
**Valid**: G Loss: 226.7037, D Loss: 0.7309
Epoch[43160/50000]
**Train**: G Loss: 214.6702, D Loss: 0.4095
Epoch[43160/50000]
**Valid**: G Loss: 209.4406, D Loss: 0.0736
Epoch[43170/50000]
**Train**: G Loss: 192.6535, D Loss: 0.6130
Epoch[43170/50000]
**Valid**: G Loss: 194.3925, D Loss: 1.0295
Epoch[43180/50000]
**Train**: G Loss: 215.9573, D Loss: 0.1824
Epoch[43180/50000]
**Valid**: G Loss: 224.4738, D Loss: 0.2347
Epoch[43190/50000]
**Train**: G Loss: 209.7899, D Loss: 0.6183
Epoch[43190/50000]
**Valid**: G Loss: 204.3642, D Loss: 0.0222
Epoch[43200/50000]
**Train**: G Loss: 202.2059, D Loss: 0.5504
Epoch[43200/50000]
**Valid**: G Loss: 200.5519, D Loss: 0.9746
Epoch[43210/50000]
**Train**: G Loss: 214.7674, D Loss: 0.2155
Epoch[43210/50000]
**Valid**: G Loss: 223.1184, D Loss: 0.3645
Epoch[43220/50000]
**Train**: G Loss: 220.0135, D Loss: 0.7874
Epoch[43220/50000]
**Valid**: G Loss: 210.9283, D Loss: 0.5981
Epoch[43230/50000]
**Train**: G Loss: 199.9029, D Loss: 0.4300
Epoch[43230/50000]
**Valid**: G Loss: 199.4073, D Loss: 0.8431
Epoch[43240/50000]
**Train**: G Loss: 234.2016, D Loss: 0.3674
Epoch[43240/50000]
**Valid**: G Loss: 238.1293, D Loss: 1.2221
Epoch[43250/50000]
**Train**: G Loss: 216.2010, D Loss: 0.3304
Epoch[43250/50000]
**Valid**: G Loss: 211.3139, D Loss: -0.0084
Epoch[43260/50000]
**Train**: G Loss: 203.6086, D Loss: 0.7644
Epoch[43260/50000]
**Valid**: G Loss: 206.0201, D Loss: 0.3772
Epoch[43270/50000]
**Train**: G Loss: 225.9689, D Loss: 0.2366
Epoch[43270/50000]
**Valid**: G Loss: 234.4388, D Loss: 0.4479
Epoch[43280/50000]
**Train**: G Loss: 225.4619, D Loss: 0.7195
Epoch[43280/50000]
**Valid**: G Loss: 218.0868, D Loss: 0.4519
Epoch[43290/50000]
**Train**: G Loss: 213.3854, D Loss: 0.1659
Epoch[43290/50000]
**Valid**: G Loss: 208.0719, D Loss: 0.6578
Epoch[43300/50000]
**Train**: G Loss: 212.3175, D Loss: 0.5105
Epoch[43300/50000]
**Valid**: G Loss: 220.8654, D Loss: -0.0191
Epoch[43310/50000]
**Train**: G Loss: 234.8346, D Loss: 0.3986
Epoch[43310/50000]
**Valid**: G Loss: 233.0624, D Loss: 1.1596
Epoch[43320/50000]
**Train**: G Loss: 211.5713, D Loss: 0.1374
Epoch[43320/50000]
**Valid**: G Loss: 207.6470, D Loss: 0.5547
Epoch[43330/50000]
**Train**: G Loss: 210.0104, D Loss: 0.8485
Epoch[43330/50000]
**Valid**: G Loss: 218.5799, D Loss: 0.4646
Epoch[43340/50000]
**Train**: G Loss: 231.4683, D Loss: 0.2559
Epoch[43340/50000]
**Valid**: G Loss: 231.0214, D Loss: 0.8750
Epoch[43350/50000]
**Train**: G Loss: 214.4302, D Loss: 0.4413
Epoch[43350/50000]
**Valid**: G Loss: 208.3764, D Loss: 0.0520
Epoch[43360/50000]
**Train**: G Loss: 207.4524, D Loss: 0.3878
Epoch[43360/50000]
**Valid**: G Loss: 205.4869, D Loss: 0.6294
Epoch[43370/50000]
**Train**: G Loss: 204.9082, D Loss: 0.5855
Epoch[43370/50000]
**Valid**: G Loss: 212.4641, D Loss: 0.2165
Epoch[43380/50000]
**Train**: G Loss: 220.7180, D Loss: 0.2242
Epoch[43380/50000]
**Valid**: G Loss: 226.0793, D Loss: 0.5573
Epoch[43390/50000]
**Train**: G Loss: 219.7162, D Loss: 0.8490
Epoch[43390/50000]
**Valid**: G Loss: 214.2372, D Loss: 0.6947
Epoch[43400/50000]
**Train**: G Loss: 213.7010, D Loss: -0.0340
Epoch[43400/50000]
**Valid**: G Loss: 209.5365, D Loss: 0.1070
Epoch[43410/50000]
**Train**: G Loss: 207.1651, D Loss: 0.6737
Epoch[43410/50000]
**Valid**: G Loss: 208.1142, D Loss: 0.6430
Epoch[43420/50000]
**Train**: G Loss: 221.5633, D Loss: 0.2768
Epoch[43420/50000]
**Valid**: G Loss: 227.6721, D Loss: 0.4863
Epoch[43430/50000]
**Train**: G Loss: 223.1019, D Loss: 0.9308
Epoch[43430/50000]
**Valid**: G Loss: 217.3722, D Loss: 0.4305
Epoch[43440/50000]
**Train**: G Loss: 210.7751, D Loss: 0.1106
Epoch[43440/50000]
**Valid**: G Loss: 207.8766, D Loss: 0.3559
Epoch[43450/50000]
**Train**: G Loss: 200.9652, D Loss: 0.8951
Epoch[43450/50000]
**Valid**: G Loss: 205.9684, D Loss: 0.5770
Epoch[43460/50000]
**Train**: G Loss: 222.3439, D Loss: 0.3175
Epoch[43460/50000]
**Valid**: G Loss: 228.1051, D Loss: 0.4564
Epoch[43470/50000]
**Train**: G Loss: 216.6966, D Loss: 0.7044
Epoch[43470/50000]
**Valid**: G Loss: 207.1108, D Loss: 0.2803
Epoch[43480/50000]
**Train**: G Loss: 190.9988, D Loss: 0.2353
Epoch[43480/50000]
**Valid**: G Loss: 180.5234, D Loss: 0.2520
Epoch[43490/50000]
**Train**: G Loss: 185.4246, D Loss: 0.6652
Epoch[43490/50000]
**Valid**: G Loss: 186.1095, D Loss: 1.0407
Epoch[43500/50000]
**Train**: G Loss: 193.6681, D Loss: 0.6618
Epoch[43500/50000]
**Valid**: G Loss: 203.3724, D Loss: 0.2441
Epoch[43510/50000]
**Train**: G Loss: 216.0193, D Loss: 0.1833
Epoch[43510/50000]
**Valid**: G Loss: 222.3663, D Loss: 0.3415
Epoch[43520/50000]
**Train**: G Loss: 215.8706, D Loss: 0.4699
Epoch[43520/50000]
**Valid**: G Loss: 214.6087, D Loss: 0.7681
Epoch[43530/50000]
**Train**: G Loss: 207.1677, D Loss: 0.8680
Epoch[43530/50000]
**Valid**: G Loss: 203.1415, D Loss: 0.7655
Epoch[43540/50000]
**Train**: G Loss: 193.4683, D Loss: 0.1585
Epoch[43540/50000]
**Valid**: G Loss: 189.2197, D Loss: 0.7191
Epoch[43550/50000]
**Train**: G Loss: 195.7301, D Loss: 0.6099
Epoch[43550/50000]
**Valid**: G Loss: 204.0543, D Loss: -0.1812
Epoch[43560/50000]
**Train**: G Loss: 216.6669, D Loss: 0.5689
Epoch[43560/50000]
**Valid**: G Loss: 213.9376, D Loss: 0.9268
Epoch[43570/50000]
**Train**: G Loss: 208.3662, D Loss: 0.5683
Epoch[43570/50000]
**Valid**: G Loss: 204.5453, D Loss: 0.2442
Epoch[43580/50000]
**Train**: G Loss: 197.0588, D Loss: 0.6710
Epoch[43580/50000]
**Valid**: G Loss: 194.4093, D Loss: 0.9297
Epoch[43590/50000]
**Train**: G Loss: 206.4977, D Loss: 0.5334
Epoch[43590/50000]
**Valid**: G Loss: 216.1796, D Loss: 0.3181
Epoch[43600/50000]
**Train**: G Loss: 220.1076, D Loss: 0.5397
Epoch[43600/50000]
**Valid**: G Loss: 212.1975, D Loss: 0.9082
Epoch[43610/50000]
**Train**: G Loss: 195.0268, D Loss: -0.1071
Epoch[43610/50000]
**Valid**: G Loss: 189.1539, D Loss: 0.8163
Epoch[43620/50000]
**Train**: G Loss: 202.6638, D Loss: 0.5955
Epoch[43620/50000]
**Valid**: G Loss: 213.3486, D Loss: -0.0602
Epoch[43630/50000]
**Train**: G Loss: 225.1936, D Loss: 0.5209
Epoch[43630/50000]
**Valid**: G Loss: 221.3976, D Loss: 0.8456
Epoch[43640/50000]
**Train**: G Loss: 204.9260, D Loss: 0.2099
Epoch[43640/50000]
**Valid**: G Loss: 201.4085, D Loss: 0.2651
Epoch[43650/50000]
**Train**: G Loss: 204.0320, D Loss: 0.7002
Epoch[43650/50000]
**Valid**: G Loss: 205.7300, D Loss: 0.5764
Epoch[43660/50000]
**Train**: G Loss: 215.2132, D Loss: 0.3189
Epoch[43660/50000]
**Valid**: G Loss: 221.0799, D Loss: 0.4296
Epoch[43670/50000]
**Train**: G Loss: 221.4422, D Loss: 0.5834
Epoch[43670/50000]
**Valid**: G Loss: 215.9390, D Loss: 0.6946
Epoch[43680/50000]
**Train**: G Loss: 205.3022, D Loss: 0.0297
Epoch[43680/50000]
**Valid**: G Loss: 202.6433, D Loss: 0.3757
Epoch[43690/50000]
**Train**: G Loss: 196.8508, D Loss: 0.6883
Epoch[43690/50000]
**Valid**: G Loss: 205.8690, D Loss: 0.3978
Epoch[43700/50000]
**Train**: G Loss: 223.1757, D Loss: 0.4608
Epoch[43700/50000]
**Valid**: G Loss: 221.7414, D Loss: 0.8861
Epoch[43710/50000]
**Train**: G Loss: 212.5902, D Loss: 0.3088
Epoch[43710/50000]
**Valid**: G Loss: 206.3729, D Loss: -0.0258
Epoch[43720/50000]
**Train**: G Loss: 205.7986, D Loss: 0.6607
Epoch[43720/50000]
**Valid**: G Loss: 216.7216, D Loss: 0.3713
Epoch[43730/50000]
**Train**: G Loss: 230.8193, D Loss: 0.5953
Epoch[43730/50000]
**Valid**: G Loss: 223.0310, D Loss: 0.7401
Epoch[43740/50000]
**Train**: G Loss: 204.0994, D Loss: 0.1755
Epoch[43740/50000]
**Valid**: G Loss: 201.2784, D Loss: 0.7846
Epoch[43750/50000]
**Train**: G Loss: 203.9828, D Loss: 0.5747
Epoch[43750/50000]
**Valid**: G Loss: 213.8426, D Loss: 0.3966
Epoch[43760/50000]
**Train**: G Loss: 222.2980, D Loss: 0.5339
Epoch[43760/50000]
**Valid**: G Loss: 221.3103, D Loss: 1.1211
Epoch[43770/50000]
**Train**: G Loss: 213.1453, D Loss: 0.3311
Epoch[43770/50000]
**Valid**: G Loss: 207.0511, D Loss: 0.1747
Epoch[43780/50000]
**Train**: G Loss: 189.6806, D Loss: 0.1428
Epoch[43780/50000]
**Valid**: G Loss: 187.7996, D Loss: 0.7297
Epoch[43790/50000]
**Train**: G Loss: 217.1268, D Loss: 0.3867
Epoch[43790/50000]
**Valid**: G Loss: 223.7321, D Loss: 0.5740
Epoch[43800/50000]
**Train**: G Loss: 221.2465, D Loss: 0.5791
Epoch[43800/50000]
**Valid**: G Loss: 213.7650, D Loss: 0.3110
Epoch[43810/50000]
**Train**: G Loss: 199.1845, D Loss: 0.4928
Epoch[43810/50000]
**Valid**: G Loss: 193.1635, D Loss: 0.2892
Epoch[43820/50000]
**Train**: G Loss: 195.9593, D Loss: 0.2808
Epoch[43820/50000]
**Valid**: G Loss: 193.9436, D Loss: 0.6807
Epoch[43830/50000]
**Train**: G Loss: 203.3455, D Loss: 0.3873
Epoch[43830/50000]
**Valid**: G Loss: 209.4772, D Loss: 0.0539
Epoch[43840/50000]
**Train**: G Loss: 220.2982, D Loss: 0.4402
Epoch[43840/50000]
**Valid**: G Loss: 220.6045, D Loss: 0.8756
Epoch[43850/50000]
**Train**: G Loss: 198.9079, D Loss: 0.1163
Epoch[43850/50000]
**Valid**: G Loss: 190.6085, D Loss: 0.4528
Epoch[43860/50000]
**Train**: G Loss: 197.5902, D Loss: 0.7019
Epoch[43860/50000]
**Valid**: G Loss: 207.6100, D Loss: 0.2030
Epoch[43870/50000]
**Train**: G Loss: 225.4869, D Loss: 0.0972
Epoch[43870/50000]
**Valid**: G Loss: 226.4374, D Loss: 0.7707
Epoch[43880/50000]
**Train**: G Loss: 213.1302, D Loss: 0.6742
Epoch[43880/50000]
**Valid**: G Loss: 207.1205, D Loss: 0.2715
Epoch[43890/50000]
**Train**: G Loss: 199.2711, D Loss: 0.1878
Epoch[43890/50000]
**Valid**: G Loss: 193.8263, D Loss: 0.6574
Epoch[43900/50000]
**Train**: G Loss: 199.7141, D Loss: 0.6104
Epoch[43900/50000]
**Valid**: G Loss: 203.3333, D Loss: 0.4867
Epoch[43910/50000]
**Train**: G Loss: 214.8170, D Loss: 0.1661
Epoch[43910/50000]
**Valid**: G Loss: 220.3901, D Loss: 0.3563
Epoch[43920/50000]
**Train**: G Loss: 212.1927, D Loss: 0.7643
Epoch[43920/50000]
**Valid**: G Loss: 207.1622, D Loss: 0.7494
Epoch[43930/50000]
**Train**: G Loss: 199.0235, D Loss: 0.1900
Epoch[43930/50000]
**Valid**: G Loss: 194.2441, D Loss: 0.4033
Epoch[43940/50000]
**Train**: G Loss: 188.0767, D Loss: 0.6633
Epoch[43940/50000]
**Valid**: G Loss: 187.3376, D Loss: 1.1164
Epoch[43950/50000]
**Train**: G Loss: 207.5526, D Loss: 0.2645
Epoch[43950/50000]
**Valid**: G Loss: 219.7031, D Loss: -0.1862
Epoch[43960/50000]
**Train**: G Loss: 222.5721, D Loss: 0.4102
Epoch[43960/50000]
**Valid**: G Loss: 222.8275, D Loss: 1.0331
Epoch[43970/50000]
**Train**: G Loss: 207.1105, D Loss: 0.6580
Epoch[43970/50000]
**Valid**: G Loss: 198.7482, D Loss: 0.1033
Epoch[43980/50000]
**Train**: G Loss: 196.6499, D Loss: 0.3934
Epoch[43980/50000]
**Valid**: G Loss: 196.1878, D Loss: 0.9048
Epoch[43990/50000]
**Train**: G Loss: 204.9287, D Loss: 0.3905
Epoch[43990/50000]
**Valid**: G Loss: 217.4409, D Loss: -0.1984
Epoch[44000/50000]
**Train**: G Loss: 225.4317, D Loss: 0.3401
Epoch[44000/50000]
**Valid**: G Loss: 223.6918, D Loss: 0.9745
Epoch[44010/50000]
**Train**: G Loss: 210.1667, D Loss: 0.6558
Epoch[44010/50000]
**Valid**: G Loss: 205.1932, D Loss: 0.0393
Epoch[44020/50000]
**Train**: G Loss: 200.6126, D Loss: 0.3110
Epoch[44020/50000]
**Valid**: G Loss: 197.6760, D Loss: 0.6541
Epoch[44030/50000]
**Train**: G Loss: 201.6367, D Loss: 0.5386
Epoch[44030/50000]
**Valid**: G Loss: 207.9605, D Loss: 0.1265
Epoch[44040/50000]
**Train**: G Loss: 212.5831, D Loss: 0.2174
Epoch[44040/50000]
**Valid**: G Loss: 210.8133, D Loss: 0.8268
Epoch[44050/50000]
**Train**: G Loss: 212.0834, D Loss: 0.6822
Epoch[44050/50000]
**Valid**: G Loss: 207.3737, D Loss: 0.2774
Epoch[44060/50000]
**Train**: G Loss: 199.9364, D Loss: 0.1708
Epoch[44060/50000]
**Valid**: G Loss: 194.7577, D Loss: 0.4966
Epoch[44070/50000]
**Train**: G Loss: 189.9550, D Loss: 0.6638
Epoch[44070/50000]
**Valid**: G Loss: 191.2441, D Loss: 0.8639
Epoch[44080/50000]
**Train**: G Loss: 211.8921, D Loss: 0.3000
Epoch[44080/50000]
**Valid**: G Loss: 220.4390, D Loss: 0.0372
Epoch[44090/50000]
**Train**: G Loss: 219.1104, D Loss: 0.7388
Epoch[44090/50000]
**Valid**: G Loss: 213.0152, D Loss: 0.4785
Epoch[44100/50000]
**Train**: G Loss: 203.5827, D Loss: 0.0127
Epoch[44100/50000]
**Valid**: G Loss: 200.8961, D Loss: 0.5826
Epoch[44110/50000]
**Train**: G Loss: 198.8375, D Loss: 0.5968
Epoch[44110/50000]
**Valid**: G Loss: 207.5024, D Loss: 0.0630
Epoch[44120/50000]
**Train**: G Loss: 223.3782, D Loss: 0.2163
Epoch[44120/50000]
**Valid**: G Loss: 229.9576, D Loss: 0.5661
Epoch[44130/50000]
**Train**: G Loss: 226.3607, D Loss: 0.6082
Epoch[44130/50000]
**Valid**: G Loss: 219.5371, D Loss: 0.5311
Epoch[44140/50000]
**Train**: G Loss: 203.3002, D Loss: 0.3739
Epoch[44140/50000]
**Valid**: G Loss: 197.9709, D Loss: 0.3762
Epoch[44150/50000]
**Train**: G Loss: 201.7891, D Loss: 0.8002
Epoch[44150/50000]
**Valid**: G Loss: 209.4763, D Loss: 0.3981
Epoch[44160/50000]
**Train**: G Loss: 230.2481, D Loss: 0.4452
Epoch[44160/50000]
**Valid**: G Loss: 224.5569, D Loss: 0.8971
Epoch[44170/50000]
**Train**: G Loss: 205.8695, D Loss: 0.2811
Epoch[44170/50000]
**Valid**: G Loss: 199.4264, D Loss: 0.1689
Epoch[44180/50000]
**Train**: G Loss: 189.8446, D Loss: 0.6267
Epoch[44180/50000]
**Valid**: G Loss: 191.5990, D Loss: 0.9438
Epoch[44190/50000]
**Train**: G Loss: 216.7202, D Loss: 0.2481
Epoch[44190/50000]
**Valid**: G Loss: 227.9685, D Loss: 0.1672
Epoch[44200/50000]
**Train**: G Loss: 224.4526, D Loss: 0.5046
Epoch[44200/50000]
**Valid**: G Loss: 216.1487, D Loss: 0.5793
Epoch[44210/50000]
**Train**: G Loss: 204.9258, D Loss: 0.3271
Epoch[44210/50000]
**Valid**: G Loss: 195.6804, D Loss: -0.1625
Epoch[44220/50000]
**Train**: G Loss: 189.7461, D Loss: 0.2782
Epoch[44220/50000]
**Valid**: G Loss: 186.2061, D Loss: 0.9896
Epoch[44230/50000]
**Train**: G Loss: 193.0370, D Loss: 0.7373
Epoch[44230/50000]
**Valid**: G Loss: 203.2067, D Loss: 0.2669
Epoch[44240/50000]
**Train**: G Loss: 222.5714, D Loss: 0.3370
Epoch[44240/50000]
**Valid**: G Loss: 234.5715, D Loss: 0.2188
Epoch[44250/50000]
**Train**: G Loss: 224.4894, D Loss: 0.5683
Epoch[44250/50000]
**Valid**: G Loss: 215.8380, D Loss: 0.6688
Epoch[44260/50000]
**Train**: G Loss: 198.7361, D Loss: 0.2152
Epoch[44260/50000]
**Valid**: G Loss: 190.8101, D Loss: 0.3167
Epoch[44270/50000]
**Train**: G Loss: 195.6687, D Loss: 0.6183
Epoch[44270/50000]
**Valid**: G Loss: 196.7805, D Loss: 0.8994
Epoch[44280/50000]
**Train**: G Loss: 217.2234, D Loss: 0.1015
Epoch[44280/50000]
**Valid**: G Loss: 223.6161, D Loss: 0.3122
Epoch[44290/50000]
**Train**: G Loss: 214.9527, D Loss: 0.8542
Epoch[44290/50000]
**Valid**: G Loss: 208.1026, D Loss: 0.3757
Epoch[44300/50000]
**Train**: G Loss: 198.3610, D Loss: 0.1675
Epoch[44300/50000]
**Valid**: G Loss: 194.1853, D Loss: 0.4332
Epoch[44310/50000]
**Train**: G Loss: 189.8928, D Loss: 0.8015
Epoch[44310/50000]
**Valid**: G Loss: 197.0985, D Loss: 0.6229
Epoch[44320/50000]
**Train**: G Loss: 216.4089, D Loss: 0.2192
Epoch[44320/50000]
**Valid**: G Loss: 219.1545, D Loss: 0.7898
Epoch[44330/50000]
**Train**: G Loss: 209.8790, D Loss: 0.7229
Epoch[44330/50000]
**Valid**: G Loss: 201.6715, D Loss: 0.3080
Epoch[44340/50000]
**Train**: G Loss: 188.3112, D Loss: 0.3301
Epoch[44340/50000]
**Valid**: G Loss: 183.9215, D Loss: 0.9905
Epoch[44350/50000]
**Train**: G Loss: 200.1648, D Loss: 0.3585
Epoch[44350/50000]
**Valid**: G Loss: 215.5097, D Loss: 0.0148
Epoch[44360/50000]
**Train**: G Loss: 221.2453, D Loss: 0.7693
Epoch[44360/50000]
**Valid**: G Loss: 212.6176, D Loss: 0.8123
Epoch[44370/50000]
**Train**: G Loss: 201.9828, D Loss: 0.1101
Epoch[44370/50000]
**Valid**: G Loss: 196.1233, D Loss: 0.1706
Epoch[44380/50000]
**Train**: G Loss: 179.7943, D Loss: 0.2687
Epoch[44380/50000]
**Valid**: G Loss: 177.0149, D Loss: 0.9944
Epoch[44390/50000]
**Train**: G Loss: 180.9891, D Loss: 0.7115
Epoch[44390/50000]
**Valid**: G Loss: 192.6498, D Loss: 0.3120
Epoch[44400/50000]
**Train**: G Loss: 204.8160, D Loss: 0.4289
Epoch[44400/50000]
**Valid**: G Loss: 208.1819, D Loss: 0.6709
Epoch[44410/50000]
**Train**: G Loss: 201.9736, D Loss: 0.8191
Epoch[44410/50000]
**Valid**: G Loss: 196.1228, D Loss: 0.5208
Epoch[44420/50000]
**Train**: G Loss: 181.1777, D Loss: 0.2307
Epoch[44420/50000]
**Valid**: G Loss: 177.3511, D Loss: 0.8172
Epoch[44430/50000]
**Train**: G Loss: 195.7910, D Loss: 0.3319
Epoch[44430/50000]
**Valid**: G Loss: 205.1788, D Loss: 0.2160
Epoch[44440/50000]
**Train**: G Loss: 209.0752, D Loss: 0.6285
Epoch[44440/50000]
**Valid**: G Loss: 203.9658, D Loss: 1.0367
Epoch[44450/50000]
**Train**: G Loss: 203.9713, D Loss: 0.5104
Epoch[44450/50000]
**Valid**: G Loss: 198.0425, D Loss: -0.0878
Epoch[44460/50000]
**Train**: G Loss: 188.4423, D Loss: 0.0313
Epoch[44460/50000]
**Valid**: G Loss: 183.0918, D Loss: 0.6725
Epoch[44470/50000]
**Train**: G Loss: 190.2266, D Loss: 0.6107
Epoch[44470/50000]
**Valid**: G Loss: 197.4201, D Loss: -0.0250
Epoch[44480/50000]
**Train**: G Loss: 210.0249, D Loss: 0.3482
Epoch[44480/50000]
**Valid**: G Loss: 207.8247, D Loss: 0.9229
Epoch[44490/50000]
**Train**: G Loss: 203.3708, D Loss: 0.5303
Epoch[44490/50000]
**Valid**: G Loss: 196.7233, D Loss: 0.0222
Epoch[44500/50000]
**Train**: G Loss: 175.5418, D Loss: 0.6297
Epoch[44500/50000]
**Valid**: G Loss: 174.6916, D Loss: 0.8993
Epoch[44510/50000]
**Train**: G Loss: 189.1358, D Loss: 0.5258
Epoch[44510/50000]
**Valid**: G Loss: 200.6916, D Loss: 0.1864
Epoch[44520/50000]
**Train**: G Loss: 220.4463, D Loss: 0.5056
Epoch[44520/50000]
**Valid**: G Loss: 218.8797, D Loss: 0.8022
Epoch[44530/50000]
**Train**: G Loss: 208.6688, D Loss: 0.8107
Epoch[44530/50000]
**Valid**: G Loss: 199.9348, D Loss: 0.0505
Epoch[44540/50000]
**Train**: G Loss: 193.8463, D Loss: -0.0021
Epoch[44540/50000]
**Valid**: G Loss: 187.3829, D Loss: 0.1317
Epoch[44550/50000]
**Train**: G Loss: 186.1143, D Loss: 0.4866
Epoch[44550/50000]
**Valid**: G Loss: 183.8780, D Loss: 0.7344
Epoch[44560/50000]
**Train**: G Loss: 196.9446, D Loss: 0.4900
Epoch[44560/50000]
**Valid**: G Loss: 211.1612, D Loss: -0.0910
Epoch[44570/50000]
**Train**: G Loss: 222.5184, D Loss: 0.2418
Epoch[44570/50000]
**Valid**: G Loss: 224.3135, D Loss: 0.7118
Epoch[44580/50000]
**Train**: G Loss: 208.9103, D Loss: 0.6150
Epoch[44580/50000]
**Valid**: G Loss: 199.7561, D Loss: -0.0505
Epoch[44590/50000]
**Train**: G Loss: 192.4997, D Loss: 0.1572
Epoch[44590/50000]
**Valid**: G Loss: 185.3342, D Loss: 0.8215
Epoch[44600/50000]
**Train**: G Loss: 181.5337, D Loss: 0.7047
Epoch[44600/50000]
**Valid**: G Loss: 190.4729, D Loss: 0.3984
Epoch[44610/50000]
**Train**: G Loss: 219.9874, D Loss: 0.3321
Epoch[44610/50000]
**Valid**: G Loss: 217.4133, D Loss: 0.9718
Epoch[44620/50000]
**Train**: G Loss: 203.3972, D Loss: 0.5588
Epoch[44620/50000]
**Valid**: G Loss: 193.7777, D Loss: 0.1019
Epoch[44630/50000]
**Train**: G Loss: 186.9237, D Loss: 0.4998
Epoch[44630/50000]
**Valid**: G Loss: 187.2303, D Loss: 0.8635
Epoch[44640/50000]
**Train**: G Loss: 209.2435, D Loss: 0.1816
Epoch[44640/50000]
**Valid**: G Loss: 218.4111, D Loss: 0.4618
Epoch[44650/50000]
**Train**: G Loss: 221.0769, D Loss: 0.4772
Epoch[44650/50000]
**Valid**: G Loss: 209.9330, D Loss: 0.6068
Epoch[44660/50000]
**Train**: G Loss: 194.1443, D Loss: 0.1650
Epoch[44660/50000]
**Valid**: G Loss: 186.6620, D Loss: 0.3555
Epoch[44670/50000]
**Train**: G Loss: 188.8427, D Loss: 0.4443
Epoch[44670/50000]
**Valid**: G Loss: 188.6900, D Loss: 0.9433
Epoch[44680/50000]
**Train**: G Loss: 201.2902, D Loss: 0.4770
Epoch[44680/50000]
**Valid**: G Loss: 216.4042, D Loss: 0.0924
Epoch[44690/50000]
**Train**: G Loss: 223.4190, D Loss: 0.0050
Epoch[44690/50000]
**Valid**: G Loss: 229.7216, D Loss: 0.7785
Epoch[44700/50000]
**Train**: G Loss: 226.9890, D Loss: 0.7710
Epoch[44700/50000]
**Valid**: G Loss: 215.7854, D Loss: 1.0169
Epoch[44710/50000]
**Train**: G Loss: 203.6984, D Loss: 0.1342
Epoch[44710/50000]
**Valid**: G Loss: 194.3051, D Loss: -0.3469
Epoch[44720/50000]
**Train**: G Loss: 193.0935, D Loss: -0.0637
Epoch[44720/50000]
**Valid**: G Loss: 186.7874, D Loss: 0.4944
Epoch[44730/50000]
**Train**: G Loss: 182.0246, D Loss: 0.4090
Epoch[44730/50000]
**Valid**: G Loss: 184.0087, D Loss: 0.7339
Epoch[44740/50000]
**Train**: G Loss: 205.0641, D Loss: 0.2539
Epoch[44740/50000]
**Valid**: G Loss: 218.5324, D Loss: 0.0110
Epoch[44750/50000]
**Train**: G Loss: 228.1921, D Loss: -0.0952
Epoch[44750/50000]
**Valid**: G Loss: 233.4084, D Loss: 0.6579
Epoch[44760/50000]
**Train**: G Loss: 231.0635, D Loss: 0.4865
Epoch[44760/50000]
**Valid**: G Loss: 225.7053, D Loss: 1.2918
Epoch[44770/50000]
**Train**: G Loss: 207.0542, D Loss: 0.6270
Epoch[44770/50000]
**Valid**: G Loss: 199.3311, D Loss: 0.0587
Epoch[44780/50000]
**Train**: G Loss: 200.4302, D Loss: -0.1975
Epoch[44780/50000]
**Valid**: G Loss: 195.8751, D Loss: 0.2416
Epoch[44790/50000]
**Train**: G Loss: 197.9899, D Loss: 0.6650
Epoch[44790/50000]
**Valid**: G Loss: 199.3097, D Loss: 0.7565
Epoch[44800/50000]
**Train**: G Loss: 205.0369, D Loss: 0.2525
Epoch[44800/50000]
**Valid**: G Loss: 212.3340, D Loss: 0.1841
Epoch[44810/50000]
**Train**: G Loss: 217.8139, D Loss: 0.4467
Epoch[44810/50000]
**Valid**: G Loss: 214.6542, D Loss: 1.0346
Epoch[44820/50000]
**Train**: G Loss: 204.1083, D Loss: 0.6355
Epoch[44820/50000]
**Valid**: G Loss: 200.5830, D Loss: -0.1298
Epoch[44830/50000]
**Train**: G Loss: 191.5978, D Loss: 0.0303
Epoch[44830/50000]
**Valid**: G Loss: 184.7438, D Loss: 0.3835
Epoch[44840/50000]
**Train**: G Loss: 189.8236, D Loss: 0.4434
Epoch[44840/50000]
**Valid**: G Loss: 193.2868, D Loss: 0.9570
Epoch[44850/50000]
**Train**: G Loss: 207.4588, D Loss: 0.3006
Epoch[44850/50000]
**Valid**: G Loss: 216.2138, D Loss: 0.2057
Epoch[44860/50000]
**Train**: G Loss: 213.7559, D Loss: 0.7712
Epoch[44860/50000]
**Valid**: G Loss: 206.8030, D Loss: 0.8288
Epoch[44870/50000]
**Train**: G Loss: 205.7938, D Loss: 0.4209
Epoch[44870/50000]
**Valid**: G Loss: 199.7760, D Loss: -0.1923
Epoch[44880/50000]
**Train**: G Loss: 195.5514, D Loss: 0.1627
Epoch[44880/50000]
**Valid**: G Loss: 191.8335, D Loss: 0.8154
Epoch[44890/50000]
**Train**: G Loss: 198.2857, D Loss: 0.7018
Epoch[44890/50000]
**Valid**: G Loss: 208.0642, D Loss: 0.2220
Epoch[44900/50000]
**Train**: G Loss: 220.5166, D Loss: 0.0532
Epoch[44900/50000]
**Valid**: G Loss: 227.0799, D Loss: 0.4887
Epoch[44910/50000]
**Train**: G Loss: 220.0929, D Loss: 0.6473
Epoch[44910/50000]
**Valid**: G Loss: 214.2410, D Loss: 0.8780
Epoch[44920/50000]
**Train**: G Loss: 205.7836, D Loss: 0.2467
Epoch[44920/50000]
**Valid**: G Loss: 201.0288, D Loss: 0.0493
Epoch[44930/50000]
**Train**: G Loss: 192.6304, D Loss: 0.4572
Epoch[44930/50000]
**Valid**: G Loss: 189.3874, D Loss: 0.9869
Epoch[44940/50000]
**Train**: G Loss: 204.4602, D Loss: 0.5322
Epoch[44940/50000]
**Valid**: G Loss: 211.0379, D Loss: 0.0768
Epoch[44950/50000]
**Train**: G Loss: 209.0355, D Loss: 0.2872
Epoch[44950/50000]
**Valid**: G Loss: 218.1607, D Loss: 0.4761
Epoch[44960/50000]
**Train**: G Loss: 223.3868, D Loss: 0.3822
Epoch[44960/50000]
**Valid**: G Loss: 218.7484, D Loss: 1.1754
Epoch[44970/50000]
**Train**: G Loss: 207.3393, D Loss: 0.7579
Epoch[44970/50000]
**Valid**: G Loss: 197.5592, D Loss: 0.0615
Epoch[44980/50000]
**Train**: G Loss: 203.6000, D Loss: 0.2988
Epoch[44980/50000]
**Valid**: G Loss: 201.5089, D Loss: 0.6569
Epoch[44990/50000]
**Train**: G Loss: 192.7210, D Loss: 0.4227
Epoch[44990/50000]
**Valid**: G Loss: 191.8837, D Loss: 0.6556
Epoch[45000/50000]
**Train**: G Loss: 184.4160, D Loss: 0.7760
Epoch[45000/50000]
**Valid**: G Loss: 188.9999, D Loss: 0.5696
Epoch[45010/50000]
**Train**: G Loss: 206.8412, D Loss: 0.0720
Epoch[45010/50000]
**Valid**: G Loss: 212.2561, D Loss: 0.5160
Epoch[45020/50000]
**Train**: G Loss: 214.3489, D Loss: 1.0970
Epoch[45020/50000]
**Valid**: G Loss: 200.6043, D Loss: 0.6657
Epoch[45030/50000]
**Train**: G Loss: 191.5883, D Loss: 0.2532
Epoch[45030/50000]
**Valid**: G Loss: 186.6544, D Loss: 0.8711
Epoch[45040/50000]
**Train**: G Loss: 206.8200, D Loss: 0.2392
Epoch[45040/50000]
**Valid**: G Loss: 221.2796, D Loss: 0.2514
Epoch[45050/50000]
**Train**: G Loss: 219.8091, D Loss: 0.7606
Epoch[45050/50000]
**Valid**: G Loss: 210.0094, D Loss: 0.5067
Epoch[45060/50000]
**Train**: G Loss: 203.9726, D Loss: -0.0417
Epoch[45060/50000]
**Valid**: G Loss: 197.0005, D Loss: 0.2229
Epoch[45070/50000]
**Train**: G Loss: 197.0346, D Loss: 0.7196
Epoch[45070/50000]
**Valid**: G Loss: 200.1150, D Loss: 0.5500
Epoch[45080/50000]
**Train**: G Loss: 214.2454, D Loss: 0.2622
Epoch[45080/50000]
**Valid**: G Loss: 221.6401, D Loss: 0.5675
Epoch[45090/50000]
**Train**: G Loss: 210.4507, D Loss: 0.6434
Epoch[45090/50000]
**Valid**: G Loss: 205.9349, D Loss: 0.5459
Epoch[45100/50000]
**Train**: G Loss: 196.7368, D Loss: 0.0414
Epoch[45100/50000]
**Valid**: G Loss: 192.6419, D Loss: 0.3345
Epoch[45110/50000]
**Train**: G Loss: 196.0588, D Loss: 0.6991
Epoch[45110/50000]
**Valid**: G Loss: 204.1893, D Loss: -0.0591
Epoch[45120/50000]
**Train**: G Loss: 212.8135, D Loss: 0.1535
Epoch[45120/50000]
**Valid**: G Loss: 216.9485, D Loss: 0.7102
Epoch[45130/50000]
**Train**: G Loss: 213.3518, D Loss: 0.7604
Epoch[45130/50000]
**Valid**: G Loss: 207.0649, D Loss: 0.3102
Epoch[45140/50000]
**Train**: G Loss: 194.2806, D Loss: 0.3188
Epoch[45140/50000]
**Valid**: G Loss: 191.3888, D Loss: 1.0660
Epoch[45150/50000]
**Train**: G Loss: 212.1591, D Loss: 0.3079
Epoch[45150/50000]
**Valid**: G Loss: 223.6080, D Loss: 0.1626
Epoch[45160/50000]
**Train**: G Loss: 224.0284, D Loss: 0.3852
Epoch[45160/50000]
**Valid**: G Loss: 222.9507, D Loss: 1.0363
Epoch[45170/50000]
**Train**: G Loss: 208.5546, D Loss: 0.4207
Epoch[45170/50000]
**Valid**: G Loss: 203.2060, D Loss: 0.0188
Epoch[45180/50000]
**Train**: G Loss: 194.2742, D Loss: 0.1110
Epoch[45180/50000]
**Valid**: G Loss: 190.5566, D Loss: 0.5910
Epoch[45190/50000]
**Train**: G Loss: 189.0525, D Loss: 0.5989
Epoch[45190/50000]
**Valid**: G Loss: 193.7503, D Loss: 0.5003
Epoch[45200/50000]
**Train**: G Loss: 214.8827, D Loss: 0.2256
Epoch[45200/50000]
**Valid**: G Loss: 221.9056, D Loss: 0.4858
Epoch[45210/50000]
**Train**: G Loss: 210.0190, D Loss: 0.8770
Epoch[45210/50000]
**Valid**: G Loss: 201.1211, D Loss: 0.5435
Epoch[45220/50000]
**Train**: G Loss: 202.0467, D Loss: 0.1942
Epoch[45220/50000]
**Valid**: G Loss: 198.0387, D Loss: 0.0270
Epoch[45230/50000]
**Train**: G Loss: 192.6381, D Loss: 0.7393
Epoch[45230/50000]
**Valid**: G Loss: 196.9938, D Loss: 0.5946
Epoch[45240/50000]
**Train**: G Loss: 203.0466, D Loss: 0.3673
Epoch[45240/50000]
**Valid**: G Loss: 216.8127, D Loss: 0.2601
Epoch[45250/50000]
**Train**: G Loss: 218.8383, D Loss: 0.5586
Epoch[45250/50000]
**Valid**: G Loss: 212.0785, D Loss: 1.0859
Epoch[45260/50000]
**Train**: G Loss: 200.9343, D Loss: 0.5435
Epoch[45260/50000]
**Valid**: G Loss: 196.0868, D Loss: 0.0781
Epoch[45270/50000]
**Train**: G Loss: 187.9700, D Loss: -0.1114
Epoch[45270/50000]
**Valid**: G Loss: 182.7694, D Loss: 0.4077
Epoch[45280/50000]
**Train**: G Loss: 182.2813, D Loss: 0.7109
Epoch[45280/50000]
**Valid**: G Loss: 190.5739, D Loss: 0.1204
Epoch[45290/50000]
**Train**: G Loss: 203.3725, D Loss: 0.0971
Epoch[45290/50000]
**Valid**: G Loss: 213.9505, D Loss: 0.1090
Epoch[45300/50000]
**Train**: G Loss: 217.2539, D Loss: 0.5639
Epoch[45300/50000]
**Valid**: G Loss: 214.4454, D Loss: 1.3248
Epoch[45310/50000]
**Train**: G Loss: 203.2107, D Loss: 0.2546
Epoch[45310/50000]
**Valid**: G Loss: 195.8283, D Loss: -0.2662
Epoch[45320/50000]
**Train**: G Loss: 197.6140, D Loss: 0.3666
Epoch[45320/50000]
**Valid**: G Loss: 192.7022, D Loss: 0.8818
Epoch[45330/50000]
**Train**: G Loss: 195.6036, D Loss: 0.5609
Epoch[45330/50000]
**Valid**: G Loss: 199.8070, D Loss: 0.3244
Epoch[45340/50000]
**Train**: G Loss: 205.3445, D Loss: 0.3519
Epoch[45340/50000]
**Valid**: G Loss: 212.6501, D Loss: 0.2962
Epoch[45350/50000]
**Train**: G Loss: 212.4505, D Loss: 0.6643
Epoch[45350/50000]
**Valid**: G Loss: 206.8840, D Loss: 0.6865
Epoch[45360/50000]
**Train**: G Loss: 196.7065, D Loss: 0.1162
Epoch[45360/50000]
**Valid**: G Loss: 194.4491, D Loss: 0.3194
Epoch[45370/50000]
**Train**: G Loss: 193.6144, D Loss: 0.5816
Epoch[45370/50000]
**Valid**: G Loss: 194.0503, D Loss: 0.5759
Epoch[45380/50000]
**Train**: G Loss: 219.7771, D Loss: 0.0299
Epoch[45380/50000]
**Valid**: G Loss: 228.4808, D Loss: 0.3350
Epoch[45390/50000]
**Train**: G Loss: 213.4614, D Loss: 0.9826
Epoch[45390/50000]
**Valid**: G Loss: 205.5155, D Loss: 0.5962
Epoch[45400/50000]
**Train**: G Loss: 199.6229, D Loss: 0.0502
Epoch[45400/50000]
**Valid**: G Loss: 195.6760, D Loss: 0.2896
Epoch[45410/50000]
**Train**: G Loss: 197.5939, D Loss: 0.6807
Epoch[45410/50000]
**Valid**: G Loss: 200.0875, D Loss: 0.5454
Epoch[45420/50000]
**Train**: G Loss: 209.2055, D Loss: 0.3301
Epoch[45420/50000]
**Valid**: G Loss: 211.5621, D Loss: 0.7476
Epoch[45430/50000]
**Train**: G Loss: 202.2972, D Loss: 0.7429
Epoch[45430/50000]
**Valid**: G Loss: 198.4497, D Loss: 0.1750
Epoch[45440/50000]
**Train**: G Loss: 195.3290, D Loss: 0.0013
Epoch[45440/50000]
**Valid**: G Loss: 191.5031, D Loss: 0.5268
Epoch[45450/50000]
**Train**: G Loss: 187.4103, D Loss: 0.5578
Epoch[45450/50000]
**Valid**: G Loss: 185.6379, D Loss: 1.0922
Epoch[45460/50000]
**Train**: G Loss: 202.8880, D Loss: 0.4617
Epoch[45460/50000]
**Valid**: G Loss: 211.4431, D Loss: 0.1318
Epoch[45470/50000]
**Train**: G Loss: 224.3744, D Loss: 0.3308
Epoch[45470/50000]
**Valid**: G Loss: 222.1833, D Loss: 1.1733
Epoch[45480/50000]
**Train**: G Loss: 209.7299, D Loss: 0.7160
Epoch[45480/50000]
**Valid**: G Loss: 202.7581, D Loss: 0.1315
Epoch[45490/50000]
**Train**: G Loss: 189.3974, D Loss: 0.4852
Epoch[45490/50000]
**Valid**: G Loss: 187.1835, D Loss: 1.0204
Epoch[45500/50000]
**Train**: G Loss: 204.2160, D Loss: 0.5041
Epoch[45500/50000]
**Valid**: G Loss: 214.8973, D Loss: 0.2381
Epoch[45510/50000]
**Train**: G Loss: 222.6352, D Loss: 0.4306
Epoch[45510/50000]
**Valid**: G Loss: 219.6016, D Loss: 0.9585
Epoch[45520/50000]
**Train**: G Loss: 203.7593, D Loss: 0.3422
Epoch[45520/50000]
**Valid**: G Loss: 196.1041, D Loss: 0.2269
Epoch[45530/50000]
**Train**: G Loss: 191.2823, D Loss: 0.6052
Epoch[45530/50000]
**Valid**: G Loss: 192.8882, D Loss: 0.8775
Epoch[45540/50000]
**Train**: G Loss: 209.5469, D Loss: 0.4942
Epoch[45540/50000]
**Valid**: G Loss: 218.3732, D Loss: 0.2840
Epoch[45550/50000]
**Train**: G Loss: 213.8544, D Loss: 0.8384
Epoch[45550/50000]
**Valid**: G Loss: 204.2116, D Loss: 0.4847
Epoch[45560/50000]
**Train**: G Loss: 190.7837, D Loss: 0.1327
Epoch[45560/50000]
**Valid**: G Loss: 183.5829, D Loss: 0.5205
Epoch[45570/50000]
**Train**: G Loss: 182.2808, D Loss: 0.6277
Epoch[45570/50000]
**Valid**: G Loss: 185.9480, D Loss: 0.7473
Epoch[45580/50000]
**Train**: G Loss: 217.1100, D Loss: 0.2829
Epoch[45580/50000]
**Valid**: G Loss: 228.8091, D Loss: 0.1802
Epoch[45590/50000]
**Train**: G Loss: 218.8035, D Loss: 0.6796
Epoch[45590/50000]
**Valid**: G Loss: 207.0853, D Loss: 0.3951
Epoch[45600/50000]
**Train**: G Loss: 192.4403, D Loss: 0.0607
Epoch[45600/50000]
**Valid**: G Loss: 187.0536, D Loss: 0.5905
Epoch[45610/50000]
**Train**: G Loss: 202.5663, D Loss: 0.5667
Epoch[45610/50000]
**Valid**: G Loss: 211.3020, D Loss: 0.0588
Epoch[45620/50000]
**Train**: G Loss: 215.3512, D Loss: 0.1600
Epoch[45620/50000]
**Valid**: G Loss: 219.8149, D Loss: 0.5521
Epoch[45630/50000]
**Train**: G Loss: 215.1764, D Loss: 0.7803
Epoch[45630/50000]
**Valid**: G Loss: 209.3748, D Loss: 0.3293
Epoch[45640/50000]
**Train**: G Loss: 195.4890, D Loss: 0.1509
Epoch[45640/50000]
**Valid**: G Loss: 189.9414, D Loss: 0.4504
Epoch[45650/50000]
**Train**: G Loss: 188.9054, D Loss: 0.8065
Epoch[45650/50000]
**Valid**: G Loss: 196.2537, D Loss: 0.5911
Epoch[45660/50000]
**Train**: G Loss: 225.6974, D Loss: 0.3674
Epoch[45660/50000]
**Valid**: G Loss: 219.9902, D Loss: 0.8153
Epoch[45670/50000]
**Train**: G Loss: 210.8629, D Loss: 0.5211
Epoch[45670/50000]
**Valid**: G Loss: 200.7175, D Loss: 0.2310
Epoch[45680/50000]
**Train**: G Loss: 190.7874, D Loss: 0.7684
Epoch[45680/50000]
**Valid**: G Loss: 200.3092, D Loss: 0.1879
Epoch[45690/50000]
**Train**: G Loss: 224.6748, D Loss: 0.4514
Epoch[45690/50000]
**Valid**: G Loss: 218.1979, D Loss: 0.7114
Epoch[45700/50000]
**Train**: G Loss: 203.1473, D Loss: 0.0718
Epoch[45700/50000]
**Valid**: G Loss: 196.7066, D Loss: 0.2965
Epoch[45710/50000]
**Train**: G Loss: 180.9484, D Loss: 0.7518
Epoch[45710/50000]
**Valid**: G Loss: 186.6043, D Loss: 0.5522
Epoch[45720/50000]
**Train**: G Loss: 209.6129, D Loss: 0.0674
Epoch[45720/50000]
**Valid**: G Loss: 219.4207, D Loss: 0.4858
Epoch[45730/50000]
**Train**: G Loss: 210.4762, D Loss: 0.7701
Epoch[45730/50000]
**Valid**: G Loss: 202.7261, D Loss: 0.1512
Epoch[45740/50000]
**Train**: G Loss: 186.6150, D Loss: 0.0122
Epoch[45740/50000]
**Valid**: G Loss: 182.4413, D Loss: 0.6903
Epoch[45750/50000]
**Train**: G Loss: 193.4847, D Loss: 0.2973
Epoch[45750/50000]
**Valid**: G Loss: 205.3821, D Loss: -0.1924
Epoch[45760/50000]
**Train**: G Loss: 219.0732, D Loss: 0.6429
Epoch[45760/50000]
**Valid**: G Loss: 212.6536, D Loss: 0.8680
Epoch[45770/50000]
**Train**: G Loss: 194.0900, D Loss: 0.1677
Epoch[45770/50000]
**Valid**: G Loss: 188.7631, D Loss: 0.4805
Epoch[45780/50000]
**Train**: G Loss: 202.0774, D Loss: 0.3848
Epoch[45780/50000]
**Valid**: G Loss: 211.7280, D Loss: 0.0705
Epoch[45790/50000]
**Train**: G Loss: 216.3885, D Loss: 0.4273
Epoch[45790/50000]
**Valid**: G Loss: 217.3504, D Loss: 0.8230
Epoch[45800/50000]
**Train**: G Loss: 210.7646, D Loss: 0.6641
Epoch[45800/50000]
**Valid**: G Loss: 203.7031, D Loss: 0.3197
Epoch[45810/50000]
**Train**: G Loss: 205.0345, D Loss: 0.2003
Epoch[45810/50000]
**Valid**: G Loss: 200.0608, D Loss: 0.4352
Epoch[45820/50000]
**Train**: G Loss: 196.9736, D Loss: 0.5916
Epoch[45820/50000]
**Valid**: G Loss: 197.5031, D Loss: 0.6085
Epoch[45830/50000]
**Train**: G Loss: 205.1064, D Loss: 0.1927
Epoch[45830/50000]
**Valid**: G Loss: 213.6371, D Loss: 0.2651
Epoch[45840/50000]
**Train**: G Loss: 208.4358, D Loss: 0.6126
Epoch[45840/50000]
**Valid**: G Loss: 202.9757, D Loss: 0.4860
Epoch[45850/50000]
**Train**: G Loss: 204.0750, D Loss: 0.1971
Epoch[45850/50000]
**Valid**: G Loss: 199.9325, D Loss: 0.0616
Epoch[45860/50000]
**Train**: G Loss: 196.0340, D Loss: 0.5548
Epoch[45860/50000]
**Valid**: G Loss: 194.2969, D Loss: 0.9434
Epoch[45870/50000]
**Train**: G Loss: 194.0351, D Loss: 0.5698
Epoch[45870/50000]
**Valid**: G Loss: 207.0467, D Loss: 0.3217
Epoch[45880/50000]
**Train**: G Loss: 214.9505, D Loss: 0.1636
Epoch[45880/50000]
**Valid**: G Loss: 219.4909, D Loss: 1.0948
Epoch[45890/50000]
**Train**: G Loss: 199.8002, D Loss: 0.7703
Epoch[45890/50000]
**Valid**: G Loss: 194.0101, D Loss: 0.0805
Epoch[45900/50000]
**Train**: G Loss: 179.5385, D Loss: 0.5639
Epoch[45900/50000]
**Valid**: G Loss: 179.5567, D Loss: 0.9136
Epoch[45910/50000]
**Train**: G Loss: 190.5200, D Loss: 0.3571
Epoch[45910/50000]
**Valid**: G Loss: 200.8990, D Loss: 0.2232
Epoch[45920/50000]
**Train**: G Loss: 218.5936, D Loss: 0.2801
Epoch[45920/50000]
**Valid**: G Loss: 212.0957, D Loss: 1.0465
Epoch[45930/50000]
**Train**: G Loss: 209.3677, D Loss: 0.7798
Epoch[45930/50000]
**Valid**: G Loss: 201.0785, D Loss: 0.1889
Epoch[45940/50000]
**Train**: G Loss: 200.3905, D Loss: 0.0017
Epoch[45940/50000]
**Valid**: G Loss: 194.7320, D Loss: 0.2709
Epoch[45950/50000]
**Train**: G Loss: 187.1338, D Loss: 0.7502
Epoch[45950/50000]
**Valid**: G Loss: 189.5598, D Loss: 0.7927
Epoch[45960/50000]
**Train**: G Loss: 206.3616, D Loss: 0.2363
Epoch[45960/50000]
**Valid**: G Loss: 217.1246, D Loss: -0.0752
Epoch[45970/50000]
**Train**: G Loss: 223.3766, D Loss: 0.2204
Epoch[45970/50000]
**Valid**: G Loss: 223.1163, D Loss: 0.7902
Epoch[45980/50000]
**Train**: G Loss: 215.0592, D Loss: 0.8019
Epoch[45980/50000]
**Valid**: G Loss: 209.8682, D Loss: 0.5166
Epoch[45990/50000]
**Train**: G Loss: 206.7082, D Loss: 0.0460
Epoch[45990/50000]
**Valid**: G Loss: 202.8980, D Loss: 0.1052
Epoch[46000/50000]
**Train**: G Loss: 192.3459, D Loss: 0.7063
Epoch[46000/50000]
**Valid**: G Loss: 192.6690, D Loss: 0.8433
Epoch[46010/50000]
**Train**: G Loss: 205.9005, D Loss: 0.3607
Epoch[46010/50000]
**Valid**: G Loss: 212.4777, D Loss: 0.0940
Epoch[46020/50000]
**Train**: G Loss: 213.1559, D Loss: 0.3860
Epoch[46020/50000]
**Valid**: G Loss: 215.5567, D Loss: 0.6885
Epoch[46030/50000]
**Train**: G Loss: 195.5657, D Loss: 0.3132
Epoch[46030/50000]
**Valid**: G Loss: 187.4832, D Loss: 0.0136
Epoch[46040/50000]
**Train**: G Loss: 194.7952, D Loss: 0.9984
Epoch[46040/50000]
**Valid**: G Loss: 206.4182, D Loss: 0.3893
Epoch[46050/50000]
**Train**: G Loss: 222.3691, D Loss: 0.2550
Epoch[46050/50000]
**Valid**: G Loss: 230.5648, D Loss: 0.4994
Epoch[46060/50000]
**Train**: G Loss: 233.2698, D Loss: 0.5514
Epoch[46060/50000]
**Valid**: G Loss: 225.5243, D Loss: 0.7656
Epoch[46070/50000]
**Train**: G Loss: 206.0924, D Loss: 0.2973
Epoch[46070/50000]
**Valid**: G Loss: 200.6089, D Loss: 0.3783
Epoch[46080/50000]
**Train**: G Loss: 198.6993, D Loss: 0.5093
Epoch[46080/50000]
**Valid**: G Loss: 204.9024, D Loss: 0.1812
Epoch[46090/50000]
**Train**: G Loss: 222.6919, D Loss: -0.0523
Epoch[46090/50000]
**Valid**: G Loss: 231.2123, D Loss: 0.5098
Epoch[46100/50000]
**Train**: G Loss: 220.4863, D Loss: 1.0075
Epoch[46100/50000]
**Valid**: G Loss: 211.7193, D Loss: 0.3616
Epoch[46110/50000]
**Train**: G Loss: 206.9892, D Loss: 0.0581
Epoch[46110/50000]
**Valid**: G Loss: 203.0217, D Loss: 0.5847
Epoch[46120/50000]
**Train**: G Loss: 207.7777, D Loss: 0.7848
Epoch[46120/50000]
**Valid**: G Loss: 212.5459, D Loss: 0.4200
Epoch[46130/50000]
**Train**: G Loss: 226.0180, D Loss: -0.0248
Epoch[46130/50000]
**Valid**: G Loss: 230.7900, D Loss: 0.6354
Epoch[46140/50000]
**Train**: G Loss: 215.6475, D Loss: 0.8112
Epoch[46140/50000]
**Valid**: G Loss: 210.1955, D Loss: 0.4909
Epoch[46150/50000]
**Train**: G Loss: 202.4104, D Loss: 0.1245
Epoch[46150/50000]
**Valid**: G Loss: 195.5745, D Loss: 0.1859
Epoch[46160/50000]
**Train**: G Loss: 176.2646, D Loss: 0.2675
Epoch[46160/50000]
**Valid**: G Loss: 176.5762, D Loss: 0.8314
Epoch[46170/50000]
**Train**: G Loss: 200.2326, D Loss: 0.2675
Epoch[46170/50000]
**Valid**: G Loss: 210.0141, D Loss: 0.1626
Epoch[46180/50000]
**Train**: G Loss: 211.4761, D Loss: 0.9907
Epoch[46180/50000]
**Valid**: G Loss: 206.1040, D Loss: 0.8516
Epoch[46190/50000]
**Train**: G Loss: 201.0266, D Loss: 0.3099
Epoch[46190/50000]
**Valid**: G Loss: 196.3465, D Loss: 0.3079
Epoch[46200/50000]
**Train**: G Loss: 199.1927, D Loss: 0.5912
Epoch[46200/50000]
**Valid**: G Loss: 202.8037, D Loss: 0.5381
Epoch[46210/50000]
**Train**: G Loss: 225.5454, D Loss: 0.3327
Epoch[46210/50000]
**Valid**: G Loss: 227.9886, D Loss: 0.9914
Epoch[46220/50000]
**Train**: G Loss: 206.1011, D Loss: 0.4300
Epoch[46220/50000]
**Valid**: G Loss: 196.6059, D Loss: -0.1832
Epoch[46230/50000]
**Train**: G Loss: 190.4102, D Loss: 0.7199
Epoch[46230/50000]
**Valid**: G Loss: 194.3380, D Loss: 0.9501
Epoch[46240/50000]
**Train**: G Loss: 214.8404, D Loss: 0.1263
Epoch[46240/50000]
**Valid**: G Loss: 228.7571, D Loss: 0.2696
Epoch[46250/50000]
**Train**: G Loss: 228.4575, D Loss: 0.7601
Epoch[46250/50000]
**Valid**: G Loss: 218.4303, D Loss: 0.5526
Epoch[46260/50000]
**Train**: G Loss: 200.8447, D Loss: 0.1017
Epoch[46260/50000]
**Valid**: G Loss: 194.1427, D Loss: 0.3356
Epoch[46270/50000]
**Train**: G Loss: 193.2012, D Loss: 0.7075
Epoch[46270/50000]
**Valid**: G Loss: 200.7956, D Loss: 0.4556
Epoch[46280/50000]
**Train**: G Loss: 228.6434, D Loss: -0.0199
Epoch[46280/50000]
**Valid**: G Loss: 235.3459, D Loss: 0.6093
Epoch[46290/50000]
**Train**: G Loss: 220.7405, D Loss: 0.5436
Epoch[46290/50000]
**Valid**: G Loss: 212.1594, D Loss: 0.0228
Epoch[46300/50000]
**Train**: G Loss: 182.8183, D Loss: 0.4377
Epoch[46300/50000]
**Valid**: G Loss: 183.4875, D Loss: 1.2809
Epoch[46310/50000]
**Train**: G Loss: 215.0552, D Loss: 0.1820
Epoch[46310/50000]
**Valid**: G Loss: 229.2695, D Loss: 0.1868
Epoch[46320/50000]
**Train**: G Loss: 228.1237, D Loss: 0.7775
Epoch[46320/50000]
**Valid**: G Loss: 218.2733, D Loss: 0.4341
Epoch[46330/50000]
**Train**: G Loss: 193.7148, D Loss: -0.0503
Epoch[46330/50000]
**Valid**: G Loss: 186.4641, D Loss: 0.4865
Epoch[46340/50000]
**Train**: G Loss: 194.7967, D Loss: 0.6998
Epoch[46340/50000]
**Valid**: G Loss: 199.4056, D Loss: 0.4999
Epoch[46350/50000]
**Train**: G Loss: 223.4680, D Loss: 0.0882
Epoch[46350/50000]
**Valid**: G Loss: 228.9073, D Loss: 0.6188
Epoch[46360/50000]
**Train**: G Loss: 233.5825, D Loss: 0.6208
Epoch[46360/50000]
**Valid**: G Loss: 226.3943, D Loss: 0.7211
Epoch[46370/50000]
**Train**: G Loss: 211.6693, D Loss: 0.1736
Epoch[46370/50000]
**Valid**: G Loss: 204.0370, D Loss: 0.0862
Epoch[46380/50000]
**Train**: G Loss: 205.8645, D Loss: 0.4347
Epoch[46380/50000]
**Valid**: G Loss: 205.2904, D Loss: 0.8543
Epoch[46390/50000]
**Train**: G Loss: 210.5617, D Loss: 0.5921
Epoch[46390/50000]
**Valid**: G Loss: 221.4156, D Loss: -0.0795
Epoch[46400/50000]
**Train**: G Loss: 225.5820, D Loss: 0.7850
Epoch[46400/50000]
**Valid**: G Loss: 219.3473, D Loss: 1.1094
Epoch[46410/50000]
**Train**: G Loss: 207.5371, D Loss: 0.1530
Epoch[46410/50000]
**Valid**: G Loss: 200.4381, D Loss: -0.2703
Epoch[46420/50000]
**Train**: G Loss: 199.7862, D Loss: 0.3447
Epoch[46420/50000]
**Valid**: G Loss: 197.6849, D Loss: 1.1060
Epoch[46430/50000]
**Train**: G Loss: 207.6052, D Loss: 0.7132
Epoch[46430/50000]
**Valid**: G Loss: 214.9857, D Loss: 0.2656
Epoch[46440/50000]
**Train**: G Loss: 227.0698, D Loss: 0.2130
Epoch[46440/50000]
**Valid**: G Loss: 226.5791, D Loss: 0.9472
Epoch[46450/50000]
**Train**: G Loss: 208.8302, D Loss: 0.3533
Epoch[46450/50000]
**Valid**: G Loss: 199.6784, D Loss: -0.1610
Epoch[46460/50000]
**Train**: G Loss: 196.8660, D Loss: 0.5652
Epoch[46460/50000]
**Valid**: G Loss: 197.1566, D Loss: 0.9890
Epoch[46470/50000]
**Train**: G Loss: 209.9134, D Loss: 0.4897
Epoch[46470/50000]
**Valid**: G Loss: 222.6742, D Loss: 0.1592
Epoch[46480/50000]
**Train**: G Loss: 234.0238, D Loss: -0.0268
Epoch[46480/50000]
**Valid**: G Loss: 236.8974, D Loss: 0.8544
Epoch[46490/50000]
**Train**: G Loss: 228.3299, D Loss: 0.7415
Epoch[46490/50000]
**Valid**: G Loss: 221.1752, D Loss: 0.6020
Epoch[46500/50000]
**Train**: G Loss: 216.1285, D Loss: 0.2356
Epoch[46500/50000]
**Valid**: G Loss: 210.3354, D Loss: -0.0437
Epoch[46510/50000]
**Train**: G Loss: 187.7182, D Loss: 0.4460
Epoch[46510/50000]
**Valid**: G Loss: 186.1950, D Loss: 1.0148
Epoch[46520/50000]
**Train**: G Loss: 201.4433, D Loss: 0.6359
Epoch[46520/50000]
**Valid**: G Loss: 214.1179, D Loss: -0.0567
Epoch[46530/50000]
**Train**: G Loss: 222.5204, D Loss: 0.0480
Epoch[46530/50000]
**Valid**: G Loss: 224.9284, D Loss: 0.7196
Epoch[46540/50000]
**Train**: G Loss: 227.6352, D Loss: 0.3088
Epoch[46540/50000]
**Valid**: G Loss: 222.8252, D Loss: 1.0817
Epoch[46550/50000]
**Train**: G Loss: 222.4618, D Loss: 1.0128
Epoch[46550/50000]
**Valid**: G Loss: 215.0072, D Loss: 0.5463
Epoch[46560/50000]
**Train**: G Loss: 214.4772, D Loss: 0.3355
Epoch[46560/50000]
**Valid**: G Loss: 209.1730, D Loss: 0.0879
Epoch[46570/50000]
**Train**: G Loss: 209.5170, D Loss: 0.6801
Epoch[46570/50000]
**Valid**: G Loss: 212.6342, D Loss: 0.6548
Epoch[46580/50000]
**Train**: G Loss: 207.9146, D Loss: 0.5449
Epoch[46580/50000]
**Valid**: G Loss: 218.4705, D Loss: 0.2262
Epoch[46590/50000]
**Train**: G Loss: 228.8355, D Loss: 0.1618
Epoch[46590/50000]
**Valid**: G Loss: 234.0740, D Loss: 0.5335
Epoch[46600/50000]
**Train**: G Loss: 233.8194, D Loss: 0.6067
Epoch[46600/50000]
**Valid**: G Loss: 227.9701, D Loss: 0.7937
Epoch[46610/50000]
**Train**: G Loss: 220.4928, D Loss: 0.6459
Epoch[46610/50000]
**Valid**: G Loss: 214.3370, D Loss: -0.1052
Epoch[46620/50000]
**Train**: G Loss: 215.0662, D Loss: -0.0066
Epoch[46620/50000]
**Valid**: G Loss: 209.9052, D Loss: 0.2727
Epoch[46630/50000]
**Train**: G Loss: 212.9263, D Loss: 0.5565
Epoch[46630/50000]
**Valid**: G Loss: 218.9186, D Loss: 0.4496
Epoch[46640/50000]
**Train**: G Loss: 244.5845, D Loss: -0.2167
Epoch[46640/50000]
**Valid**: G Loss: 248.6598, D Loss: 0.4632
Epoch[46650/50000]
**Train**: G Loss: 227.4517, D Loss: 0.8140
Epoch[46650/50000]
**Valid**: G Loss: 219.9903, D Loss: 0.1927
Epoch[46660/50000]
**Train**: G Loss: 206.4625, D Loss: 0.5557
Epoch[46660/50000]
**Valid**: G Loss: 203.8111, D Loss: 1.1159
Epoch[46670/50000]
**Train**: G Loss: 215.4099, D Loss: 0.5578
Epoch[46670/50000]
**Valid**: G Loss: 226.5925, D Loss: 0.1240
Epoch[46680/50000]
**Train**: G Loss: 226.5506, D Loss: 0.4941
Epoch[46680/50000]
**Valid**: G Loss: 222.1709, D Loss: 0.8083
Epoch[46690/50000]
**Train**: G Loss: 210.9734, D Loss: 0.0360
Epoch[46690/50000]
**Valid**: G Loss: 203.9168, D Loss: 0.0471
Epoch[46700/50000]
**Train**: G Loss: 190.8263, D Loss: 0.4144
Epoch[46700/50000]
**Valid**: G Loss: 190.8133, D Loss: 0.8618
Epoch[46710/50000]
**Train**: G Loss: 217.1173, D Loss: 0.4040
Epoch[46710/50000]
**Valid**: G Loss: 226.3722, D Loss: 0.2663
Epoch[46720/50000]
**Train**: G Loss: 227.1823, D Loss: 0.4731
Epoch[46720/50000]
**Valid**: G Loss: 223.1225, D Loss: 1.2338
Epoch[46730/50000]
**Train**: G Loss: 216.3225, D Loss: 0.5652
Epoch[46730/50000]
**Valid**: G Loss: 207.6352, D Loss: -0.2536
Epoch[46740/50000]
**Train**: G Loss: 191.0003, D Loss: -0.1941
Epoch[46740/50000]
**Valid**: G Loss: 186.5711, D Loss: 0.8360
Epoch[46750/50000]
**Train**: G Loss: 198.4111, D Loss: 0.5148
Epoch[46750/50000]
**Valid**: G Loss: 201.1376, D Loss: 0.7216
Epoch[46760/50000]
**Train**: G Loss: 224.3038, D Loss: 0.3978
Epoch[46760/50000]
**Valid**: G Loss: 234.6741, D Loss: 0.2306
Epoch[46770/50000]
**Train**: G Loss: 228.5898, D Loss: 0.5958
Epoch[46770/50000]
**Valid**: G Loss: 224.0715, D Loss: 0.8244
Epoch[46780/50000]
**Train**: G Loss: 217.4355, D Loss: 0.7844
Epoch[46780/50000]
**Valid**: G Loss: 206.6197, D Loss: -0.0788
Epoch[46790/50000]
**Train**: G Loss: 214.6005, D Loss: -0.0229
Epoch[46790/50000]
**Valid**: G Loss: 208.8847, D Loss: 0.3362
Epoch[46800/50000]
**Train**: G Loss: 200.7193, D Loss: 0.2143
Epoch[46800/50000]
**Valid**: G Loss: 198.6483, D Loss: 0.9305
Epoch[46810/50000]
**Train**: G Loss: 202.1095, D Loss: 0.8009
Epoch[46810/50000]
**Valid**: G Loss: 208.0178, D Loss: 0.3622
Epoch[46820/50000]
**Train**: G Loss: 216.5612, D Loss: 0.1524
Epoch[46820/50000]
**Valid**: G Loss: 226.4921, D Loss: 0.2765
Epoch[46830/50000]
**Train**: G Loss: 234.1647, D Loss: 0.7863
Epoch[46830/50000]
**Valid**: G Loss: 227.9893, D Loss: 1.1799
Epoch[46840/50000]
**Train**: G Loss: 212.4170, D Loss: 0.3162
Epoch[46840/50000]
**Valid**: G Loss: 204.4406, D Loss: -0.0522
Epoch[46850/50000]
**Train**: G Loss: 208.9526, D Loss: 0.2669
Epoch[46850/50000]
**Valid**: G Loss: 204.6405, D Loss: 0.7776
Epoch[46860/50000]
**Train**: G Loss: 196.6742, D Loss: 0.6734
Epoch[46860/50000]
**Valid**: G Loss: 199.3769, D Loss: 0.9146
Epoch[46870/50000]
**Train**: G Loss: 216.6339, D Loss: 0.0164
Epoch[46870/50000]
**Valid**: G Loss: 228.3190, D Loss: -0.1509
Epoch[46880/50000]
**Train**: G Loss: 225.0584, D Loss: 0.4448
Epoch[46880/50000]
**Valid**: G Loss: 221.7903, D Loss: 1.1647
Epoch[46890/50000]
**Train**: G Loss: 216.8554, D Loss: 0.4489
Epoch[46890/50000]
**Valid**: G Loss: 211.8923, D Loss: -0.0917
Epoch[46900/50000]
**Train**: G Loss: 205.4317, D Loss: 0.3773
Epoch[46900/50000]
**Valid**: G Loss: 202.6638, D Loss: 1.0073
Epoch[46910/50000]
**Train**: G Loss: 210.0132, D Loss: 0.8005
Epoch[46910/50000]
**Valid**: G Loss: 217.7352, D Loss: 0.2370
Epoch[46920/50000]
**Train**: G Loss: 219.3070, D Loss: 0.2681
Epoch[46920/50000]
**Valid**: G Loss: 228.9643, D Loss: 0.1107
Epoch[46930/50000]
**Train**: G Loss: 233.1332, D Loss: -0.1142
Epoch[46930/50000]
**Valid**: G Loss: 238.4606, D Loss: 0.4506
Epoch[46940/50000]
**Train**: G Loss: 220.6396, D Loss: 0.7671
Epoch[46940/50000]
**Valid**: G Loss: 211.4868, D Loss: 0.0485
Epoch[46950/50000]
**Train**: G Loss: 203.9800, D Loss: 0.1998
Epoch[46950/50000]
**Valid**: G Loss: 198.5862, D Loss: 0.6795
Epoch[46960/50000]
**Train**: G Loss: 202.1004, D Loss: 0.7046
Epoch[46960/50000]
**Valid**: G Loss: 210.4537, D Loss: -0.0252
Epoch[46970/50000]
**Train**: G Loss: 231.2829, D Loss: 0.1849
Epoch[46970/50000]
**Valid**: G Loss: 232.9047, D Loss: 1.0080
Epoch[46980/50000]
**Train**: G Loss: 226.1006, D Loss: 0.6311
Epoch[46980/50000]
**Valid**: G Loss: 217.9902, D Loss: 0.1805
Epoch[46990/50000]
**Train**: G Loss: 202.0035, D Loss: 0.2092
Epoch[46990/50000]
**Valid**: G Loss: 199.9006, D Loss: 0.8111
Epoch[47000/50000]
**Train**: G Loss: 212.3773, D Loss: 0.8928
Epoch[47000/50000]
**Valid**: G Loss: 218.1193, D Loss: 0.5581
Epoch[47010/50000]
**Train**: G Loss: 226.9097, D Loss: 0.1606
Epoch[47010/50000]
**Valid**: G Loss: 231.9126, D Loss: 0.5977
Epoch[47020/50000]
**Train**: G Loss: 213.9444, D Loss: 0.7204
Epoch[47020/50000]
**Valid**: G Loss: 204.5505, D Loss: 0.0994
Epoch[47030/50000]
**Train**: G Loss: 200.0589, D Loss: 0.2182
Epoch[47030/50000]
**Valid**: G Loss: 193.6967, D Loss: 0.4815
Epoch[47040/50000]
**Train**: G Loss: 204.5824, D Loss: 0.5503
Epoch[47040/50000]
**Valid**: G Loss: 216.8159, D Loss: -0.0072
Epoch[47050/50000]
**Train**: G Loss: 234.3882, D Loss: 0.4845
Epoch[47050/50000]
**Valid**: G Loss: 226.5188, D Loss: 0.6951
Epoch[47060/50000]
**Train**: G Loss: 193.6692, D Loss: -0.0614
Epoch[47060/50000]
**Valid**: G Loss: 186.7756, D Loss: 0.4969
Epoch[47070/50000]
**Train**: G Loss: 192.0758, D Loss: 0.8395
Epoch[47070/50000]
**Valid**: G Loss: 201.3531, D Loss: 0.3572
Epoch[47080/50000]
**Train**: G Loss: 233.8123, D Loss: 0.2661
Epoch[47080/50000]
**Valid**: G Loss: 231.8958, D Loss: 1.0754
Epoch[47090/50000]
**Train**: G Loss: 197.5004, D Loss: -0.0634
Epoch[47090/50000]
**Valid**: G Loss: 186.6431, D Loss: 0.1659
Epoch[47100/50000]
**Train**: G Loss: 195.4758, D Loss: 0.4880
Epoch[47100/50000]
**Valid**: G Loss: 212.3268, D Loss: -0.0173
Epoch[47110/50000]
**Train**: G Loss: 228.7877, D Loss: 0.3717
Epoch[47110/50000]
**Valid**: G Loss: 229.7634, D Loss: 0.8241
Epoch[47120/50000]
**Train**: G Loss: 205.6892, D Loss: 0.1629
Epoch[47120/50000]
**Valid**: G Loss: 195.4902, D Loss: 0.2168
Epoch[47130/50000]
**Train**: G Loss: 196.6041, D Loss: 0.7636
Epoch[47130/50000]
**Valid**: G Loss: 200.0058, D Loss: 0.8218
Epoch[47140/50000]
**Train**: G Loss: 228.6720, D Loss: 0.0336
Epoch[47140/50000]
**Valid**: G Loss: 233.6548, D Loss: 0.5995
Epoch[47150/50000]
**Train**: G Loss: 215.9492, D Loss: 0.4222
Epoch[47150/50000]
**Valid**: G Loss: 207.9392, D Loss: -0.2128
Epoch[47160/50000]
**Train**: G Loss: 206.6718, D Loss: 0.5218
Epoch[47160/50000]
**Valid**: G Loss: 208.6458, D Loss: 0.6600
Epoch[47170/50000]
**Train**: G Loss: 233.2655, D Loss: 0.1685
Epoch[47170/50000]
**Valid**: G Loss: 239.5240, D Loss: 0.5423
Epoch[47180/50000]
**Train**: G Loss: 222.9360, D Loss: 0.6864
Epoch[47180/50000]
**Valid**: G Loss: 217.3288, D Loss: 0.1532
Epoch[47190/50000]
**Train**: G Loss: 207.3154, D Loss: 0.1030
Epoch[47190/50000]
**Valid**: G Loss: 203.7053, D Loss: 0.8516
Epoch[47200/50000]
**Train**: G Loss: 207.7158, D Loss: 0.6378
Epoch[47200/50000]
**Valid**: G Loss: 216.7020, D Loss: 0.2001
Epoch[47210/50000]
**Train**: G Loss: 227.7244, D Loss: 0.6828
Epoch[47210/50000]
**Valid**: G Loss: 221.7825, D Loss: 1.0433
Epoch[47220/50000]
**Train**: G Loss: 199.9447, D Loss: -0.0579
Epoch[47220/50000]
**Valid**: G Loss: 193.7948, D Loss: 0.4946
Epoch[47230/50000]
**Train**: G Loss: 208.6181, D Loss: 0.5155
Epoch[47230/50000]
**Valid**: G Loss: 220.2973, D Loss: 0.2233
Epoch[47240/50000]
**Train**: G Loss: 233.7026, D Loss: 0.9637
Epoch[47240/50000]
**Valid**: G Loss: 224.8308, D Loss: 0.8935
Epoch[47250/50000]
**Train**: G Loss: 206.4348, D Loss: 0.1217
Epoch[47250/50000]
**Valid**: G Loss: 205.4529, D Loss: 0.8644
Epoch[47260/50000]
**Train**: G Loss: 232.0502, D Loss: -0.0476
Epoch[47260/50000]
**Valid**: G Loss: 234.4271, D Loss: 0.4696
Epoch[47270/50000]
**Train**: G Loss: 222.0107, D Loss: 0.5410
Epoch[47270/50000]
**Valid**: G Loss: 214.4994, D Loss: -0.0381
Epoch[47280/50000]
**Train**: G Loss: 200.9583, D Loss: 0.6802
Epoch[47280/50000]
**Valid**: G Loss: 212.4866, D Loss: 0.2407
Epoch[47290/50000]
**Train**: G Loss: 231.1397, D Loss: 0.5256
Epoch[47290/50000]
**Valid**: G Loss: 222.4323, D Loss: 0.9654
Epoch[47300/50000]
**Train**: G Loss: 194.9037, D Loss: 0.0951
Epoch[47300/50000]
**Valid**: G Loss: 192.9484, D Loss: 0.9233
Epoch[47310/50000]
**Train**: G Loss: 229.0272, D Loss: -0.1841
Epoch[47310/50000]
**Valid**: G Loss: 236.3330, D Loss: 0.5879
Epoch[47320/50000]
**Train**: G Loss: 200.1620, D Loss: 0.3967
Epoch[47320/50000]
**Valid**: G Loss: 190.8623, D Loss: 0.1723
Epoch[47330/50000]
**Train**: G Loss: 198.5872, D Loss: 0.6869
Epoch[47330/50000]
**Valid**: G Loss: 209.2986, D Loss: 0.2526
Epoch[47340/50000]
**Train**: G Loss: 235.1836, D Loss: 0.1594
Epoch[47340/50000]
**Valid**: G Loss: 237.6514, D Loss: 1.1943
Epoch[47350/50000]
**Train**: G Loss: 208.8830, D Loss: 0.3701
Epoch[47350/50000]
**Valid**: G Loss: 199.6538, D Loss: -0.2667
Epoch[47360/50000]
**Train**: G Loss: 198.8811, D Loss: 0.1916
Epoch[47360/50000]
**Valid**: G Loss: 196.5853, D Loss: 0.9152
Epoch[47370/50000]
**Train**: G Loss: 201.2739, D Loss: 0.7202
Epoch[47370/50000]
**Valid**: G Loss: 208.6539, D Loss: 0.3476
Epoch[47380/50000]
**Train**: G Loss: 237.6092, D Loss: 0.1310
Epoch[47380/50000]
**Valid**: G Loss: 235.9474, D Loss: 0.9753
Epoch[47390/50000]
**Train**: G Loss: 223.2996, D Loss: 0.8706
Epoch[47390/50000]
**Valid**: G Loss: 214.9154, D Loss: -0.2461
Epoch[47400/50000]
**Train**: G Loss: 192.8552, D Loss: -0.2057
Epoch[47400/50000]
**Valid**: G Loss: 189.3177, D Loss: 0.7481
Epoch[47410/50000]
**Train**: G Loss: 203.3977, D Loss: 0.8198
Epoch[47410/50000]
**Valid**: G Loss: 208.8279, D Loss: 0.4765
Epoch[47420/50000]
**Train**: G Loss: 228.7388, D Loss: -0.0542
Epoch[47420/50000]
**Valid**: G Loss: 233.6671, D Loss: 0.6667
Epoch[47430/50000]
**Train**: G Loss: 221.9255, D Loss: 0.6125
Epoch[47430/50000]
**Valid**: G Loss: 209.2469, D Loss: -0.1981
Epoch[47440/50000]
**Train**: G Loss: 196.4126, D Loss: 0.2444
Epoch[47440/50000]
**Valid**: G Loss: 193.8279, D Loss: 0.9246
Epoch[47450/50000]
**Train**: G Loss: 214.2048, D Loss: 0.5392
Epoch[47450/50000]
**Valid**: G Loss: 226.0910, D Loss: 0.1442
Epoch[47460/50000]
**Train**: G Loss: 223.3104, D Loss: 0.7991
Epoch[47460/50000]
**Valid**: G Loss: 213.7733, D Loss: 0.7957
Epoch[47470/50000]
**Train**: G Loss: 191.1088, D Loss: -0.0580
Epoch[47470/50000]
**Valid**: G Loss: 181.5295, D Loss: 0.1860
Epoch[47480/50000]
**Train**: G Loss: 193.7634, D Loss: 0.8015
Epoch[47480/50000]
**Valid**: G Loss: 201.1174, D Loss: 0.6772
Epoch[47490/50000]
**Train**: G Loss: 229.5904, D Loss: 0.2543
Epoch[47490/50000]
**Valid**: G Loss: 231.7713, D Loss: 0.9393
Epoch[47500/50000]
**Train**: G Loss: 209.9047, D Loss: 1.0431
Epoch[47500/50000]
**Valid**: G Loss: 198.3092, D Loss: 0.5842
Epoch[47510/50000]
**Train**: G Loss: 173.4089, D Loss: 0.1715
Epoch[47510/50000]
**Valid**: G Loss: 173.2514, D Loss: 0.7832
Epoch[47520/50000]
**Train**: G Loss: 206.0307, D Loss: 0.4183
Epoch[47520/50000]
**Valid**: G Loss: 221.4877, D Loss: -0.0712
Epoch[47530/50000]
**Train**: G Loss: 234.0059, D Loss: 0.2126
Epoch[47530/50000]
**Valid**: G Loss: 231.6348, D Loss: 1.0582
Epoch[47540/50000]
**Train**: G Loss: 213.8036, D Loss: 0.9398
Epoch[47540/50000]
**Valid**: G Loss: 205.6628, D Loss: 0.0005
Epoch[47550/50000]
**Train**: G Loss: 200.3751, D Loss: 0.2840
Epoch[47550/50000]
**Valid**: G Loss: 198.7463, D Loss: 1.0594
Epoch[47560/50000]
**Train**: G Loss: 209.1630, D Loss: 0.7506
Epoch[47560/50000]
**Valid**: G Loss: 213.6257, D Loss: 0.4417
Epoch[47570/50000]
**Train**: G Loss: 226.5137, D Loss: 0.0770
Epoch[47570/50000]
**Valid**: G Loss: 233.2914, D Loss: 0.4412
Epoch[47580/50000]
**Train**: G Loss: 221.4720, D Loss: 0.8313
Epoch[47580/50000]
**Valid**: G Loss: 215.2370, D Loss: 0.8372
Epoch[47590/50000]
**Train**: G Loss: 209.1308, D Loss: 0.1710
Epoch[47590/50000]
**Valid**: G Loss: 203.5924, D Loss: -0.1003
Epoch[47600/50000]
**Train**: G Loss: 204.8584, D Loss: 0.4710
Epoch[47600/50000]
**Valid**: G Loss: 205.4830, D Loss: 0.7740
Epoch[47610/50000]
**Train**: G Loss: 219.2884, D Loss: 0.0620
Epoch[47610/50000]
**Valid**: G Loss: 225.1749, D Loss: 0.4730
Epoch[47620/50000]
**Train**: G Loss: 210.8208, D Loss: 0.5624
Epoch[47620/50000]
**Valid**: G Loss: 206.6358, D Loss: -0.0593
Epoch[47630/50000]
**Train**: G Loss: 202.6356, D Loss: -0.1014
Epoch[47630/50000]
**Valid**: G Loss: 197.8843, D Loss: 0.1151
Epoch[47640/50000]
**Train**: G Loss: 211.4527, D Loss: 0.8595
Epoch[47640/50000]
**Valid**: G Loss: 214.6100, D Loss: 0.4110
Epoch[47650/50000]
**Train**: G Loss: 228.6803, D Loss: 0.0132
Epoch[47650/50000]
**Valid**: G Loss: 233.2790, D Loss: 0.6391
Epoch[47660/50000]
**Train**: G Loss: 226.0394, D Loss: 0.7674
Epoch[47660/50000]
**Valid**: G Loss: 218.1942, D Loss: 1.3412
Epoch[47670/50000]
**Train**: G Loss: 217.3625, D Loss: 0.5526
Epoch[47670/50000]
**Valid**: G Loss: 210.1615, D Loss: -0.1499
Epoch[47680/50000]
**Train**: G Loss: 198.4617, D Loss: 0.0270
Epoch[47680/50000]
**Valid**: G Loss: 195.0251, D Loss: 0.8920
Epoch[47690/50000]
**Train**: G Loss: 205.4071, D Loss: 0.6804
Epoch[47690/50000]
**Valid**: G Loss: 214.7355, D Loss: 0.0452
Epoch[47700/50000]
**Train**: G Loss: 226.5705, D Loss: 0.6271
Epoch[47700/50000]
**Valid**: G Loss: 215.2933, D Loss: 0.8378
Epoch[47710/50000]
**Train**: G Loss: 201.4814, D Loss: -0.0783
Epoch[47710/50000]
**Valid**: G Loss: 195.3575, D Loss: 0.3970
Epoch[47720/50000]
**Train**: G Loss: 202.2965, D Loss: 0.6106
Epoch[47720/50000]
**Valid**: G Loss: 202.6055, D Loss: 0.7528
Epoch[47730/50000]
**Train**: G Loss: 203.6652, D Loss: 0.8462
Epoch[47730/50000]
**Valid**: G Loss: 213.2455, D Loss: 0.5300
Epoch[47740/50000]
**Train**: G Loss: 226.6358, D Loss: 0.2600
Epoch[47740/50000]
**Valid**: G Loss: 225.3621, D Loss: 0.9816
Epoch[47750/50000]
**Train**: G Loss: 202.4846, D Loss: 0.4632
Epoch[47750/50000]
**Valid**: G Loss: 192.0554, D Loss: -0.0756
Epoch[47760/50000]
**Train**: G Loss: 196.6756, D Loss: 0.7092
Epoch[47760/50000]
**Valid**: G Loss: 202.8755, D Loss: 0.7795
Epoch[47770/50000]
**Train**: G Loss: 217.1067, D Loss: 0.2224
Epoch[47770/50000]
**Valid**: G Loss: 223.6066, D Loss: 0.4986
Epoch[47780/50000]
**Train**: G Loss: 230.5265, D Loss: 0.8121
Epoch[47780/50000]
**Valid**: G Loss: 217.4187, D Loss: 0.9154
Epoch[47790/50000]
**Train**: G Loss: 204.4397, D Loss: 0.4061
Epoch[47790/50000]
**Valid**: G Loss: 197.5483, D Loss: 0.0467
Epoch[47800/50000]
**Train**: G Loss: 189.7116, D Loss: 0.4282
Epoch[47800/50000]
**Valid**: G Loss: 191.6108, D Loss: 0.8282
Epoch[47810/50000]
**Train**: G Loss: 202.1681, D Loss: 0.6468
Epoch[47810/50000]
**Valid**: G Loss: 212.7951, D Loss: -0.0140
Epoch[47820/50000]
**Train**: G Loss: 227.5768, D Loss: 0.4690
Epoch[47820/50000]
**Valid**: G Loss: 222.3940, D Loss: 1.0574
Epoch[47830/50000]
**Train**: G Loss: 199.6413, D Loss: 0.1618
Epoch[47830/50000]
**Valid**: G Loss: 195.0371, D Loss: 0.5922
Epoch[47840/50000]
**Train**: G Loss: 215.5715, D Loss: 0.4796
Epoch[47840/50000]
**Valid**: G Loss: 233.6586, D Loss: 0.0741
Epoch[47850/50000]
**Train**: G Loss: 235.1079, D Loss: 0.9184
Epoch[47850/50000]
**Valid**: G Loss: 222.8849, D Loss: 0.8937
Epoch[47860/50000]
**Train**: G Loss: 191.7650, D Loss: 0.2641
Epoch[47860/50000]
**Valid**: G Loss: 188.1538, D Loss: 0.8869
Epoch[47870/50000]
**Train**: G Loss: 210.7453, D Loss: 0.6732
Epoch[47870/50000]
**Valid**: G Loss: 226.8639, D Loss: -0.0235
Epoch[47880/50000]
**Train**: G Loss: 222.1009, D Loss: 0.5085
Epoch[47880/50000]
**Valid**: G Loss: 215.9073, D Loss: 0.3927
Epoch[47890/50000]
**Train**: G Loss: 189.1775, D Loss: 0.4677
Epoch[47890/50000]
**Valid**: G Loss: 188.8555, D Loss: 0.9824
Epoch[47900/50000]
**Train**: G Loss: 181.6409, D Loss: 0.6916
Epoch[47900/50000]
**Valid**: G Loss: 186.5023, D Loss: 0.8736
Epoch[47910/50000]
**Train**: G Loss: 215.2531, D Loss: -0.0995
Epoch[47910/50000]
**Valid**: G Loss: 223.1395, D Loss: 0.1696
Epoch[47920/50000]
**Train**: G Loss: 213.6914, D Loss: 0.6543
Epoch[47920/50000]
**Valid**: G Loss: 201.3639, D Loss: -0.4116
Epoch[47930/50000]
**Train**: G Loss: 180.8199, D Loss: 0.0674
Epoch[47930/50000]
**Valid**: G Loss: 178.0823, D Loss: 1.1422
Epoch[47940/50000]
**Train**: G Loss: 203.7990, D Loss: 0.2269
Epoch[47940/50000]
**Valid**: G Loss: 217.8941, D Loss: -0.0158
Epoch[47950/50000]
**Train**: G Loss: 229.0018, D Loss: 0.3539
Epoch[47950/50000]
**Valid**: G Loss: 227.4783, D Loss: 1.0569
Epoch[47960/50000]
**Train**: G Loss: 210.7337, D Loss: 0.1170
Epoch[47960/50000]
**Valid**: G Loss: 207.7821, D Loss: 0.0562
Epoch[47970/50000]
**Train**: G Loss: 203.2871, D Loss: 0.2484
Epoch[47970/50000]
**Valid**: G Loss: 200.7599, D Loss: 0.7322
Epoch[47980/50000]
**Train**: G Loss: 211.0999, D Loss: 0.1252
Epoch[47980/50000]
**Valid**: G Loss: 218.6776, D Loss: 0.0009
Epoch[47990/50000]
**Train**: G Loss: 218.4104, D Loss: 0.8043
Epoch[47990/50000]
**Valid**: G Loss: 214.1394, D Loss: 0.5681
Epoch[48000/50000]
**Train**: G Loss: 209.8039, D Loss: 0.2547
Epoch[48000/50000]
**Valid**: G Loss: 206.5874, D Loss: 0.1892
Epoch[48010/50000]
**Train**: G Loss: 208.0809, D Loss: 0.1170
Epoch[48010/50000]
**Valid**: G Loss: 206.2618, D Loss: 0.5445
Epoch[48020/50000]
**Train**: G Loss: 201.9518, D Loss: 0.6237
Epoch[48020/50000]
**Valid**: G Loss: 202.0552, D Loss: 0.5084
Epoch[48030/50000]
**Train**: G Loss: 205.3124, D Loss: 0.7209
Epoch[48030/50000]
**Valid**: G Loss: 215.6240, D Loss: 0.1843
Epoch[48040/50000]
**Train**: G Loss: 227.0133, D Loss: -0.1805
Epoch[48040/50000]
**Valid**: G Loss: 235.9693, D Loss: 0.5857
Epoch[48050/50000]
**Train**: G Loss: 230.1083, D Loss: 0.7200
Epoch[48050/50000]
**Valid**: G Loss: 219.5376, D Loss: 1.1023
Epoch[48060/50000]
**Train**: G Loss: 216.5146, D Loss: 0.5966
Epoch[48060/50000]
**Valid**: G Loss: 206.6543, D Loss: -0.3331
Epoch[48070/50000]
**Train**: G Loss: 179.7523, D Loss: 0.3093
Epoch[48070/50000]
**Valid**: G Loss: 180.5565, D Loss: 0.8446
Epoch[48080/50000]
**Train**: G Loss: 209.3412, D Loss: 0.0590
Epoch[48080/50000]
**Valid**: G Loss: 217.5637, D Loss: 0.3283
Epoch[48090/50000]
**Train**: G Loss: 221.9146, D Loss: 0.4593
Epoch[48090/50000]
**Valid**: G Loss: 220.9818, D Loss: 1.0233
Epoch[48100/50000]
**Train**: G Loss: 205.1920, D Loss: 0.8173
Epoch[48100/50000]
**Valid**: G Loss: 198.4853, D Loss: 0.4926
Epoch[48110/50000]
**Train**: G Loss: 189.5821, D Loss: 0.0815
Epoch[48110/50000]
**Valid**: G Loss: 183.6231, D Loss: 0.2269
Epoch[48120/50000]
**Train**: G Loss: 181.6826, D Loss: 0.3806
Epoch[48120/50000]
**Valid**: G Loss: 182.0663, D Loss: 0.9143
Epoch[48130/50000]
**Train**: G Loss: 197.4523, D Loss: 0.1598
Epoch[48130/50000]
**Valid**: G Loss: 208.5879, D Loss: -0.0118
Epoch[48140/50000]
**Train**: G Loss: 201.2060, D Loss: 0.9504
Epoch[48140/50000]
**Valid**: G Loss: 191.2009, D Loss: 0.6092
Epoch[48150/50000]
**Train**: G Loss: 178.4781, D Loss: -0.0083
Epoch[48150/50000]
**Valid**: G Loss: 173.5889, D Loss: 0.7093
Epoch[48160/50000]
**Train**: G Loss: 180.8714, D Loss: 0.5718
Epoch[48160/50000]
**Valid**: G Loss: 188.5827, D Loss: 0.4342
Epoch[48170/50000]
**Train**: G Loss: 200.7206, D Loss: 0.1456
Epoch[48170/50000]
**Valid**: G Loss: 208.9036, D Loss: 0.4221
Epoch[48180/50000]
**Train**: G Loss: 218.3197, D Loss: 0.7381
Epoch[48180/50000]
**Valid**: G Loss: 209.4260, D Loss: 0.8663
Epoch[48190/50000]
**Train**: G Loss: 204.2847, D Loss: 0.2914
Epoch[48190/50000]
**Valid**: G Loss: 194.6962, D Loss: -0.3312
Epoch[48200/50000]
**Train**: G Loss: 189.8628, D Loss: -0.0506
Epoch[48200/50000]
**Valid**: G Loss: 188.3061, D Loss: 0.8756
Epoch[48210/50000]
**Train**: G Loss: 202.2472, D Loss: 0.5169
Epoch[48210/50000]
**Valid**: G Loss: 211.3444, D Loss: 0.0276
Epoch[48220/50000]
**Train**: G Loss: 218.7940, D Loss: 0.1191
Epoch[48220/50000]
**Valid**: G Loss: 220.2026, D Loss: 1.1886
Epoch[48230/50000]
**Train**: G Loss: 202.2313, D Loss: 0.7200
Epoch[48230/50000]
**Valid**: G Loss: 192.7997, D Loss: 0.0049
Epoch[48240/50000]
**Train**: G Loss: 188.0924, D Loss: 0.6012
Epoch[48240/50000]
**Valid**: G Loss: 189.5971, D Loss: 0.7161
Epoch[48250/50000]
**Train**: G Loss: 217.0814, D Loss: 0.2019
Epoch[48250/50000]
**Valid**: G Loss: 220.3333, D Loss: 0.9826
Epoch[48260/50000]
**Train**: G Loss: 207.7109, D Loss: 0.6105
Epoch[48260/50000]
**Valid**: G Loss: 198.1173, D Loss: 0.3735
Epoch[48270/50000]
**Train**: G Loss: 188.0389, D Loss: 0.1509
Epoch[48270/50000]
**Valid**: G Loss: 186.5368, D Loss: 0.8775
Epoch[48280/50000]
**Train**: G Loss: 196.3394, D Loss: 0.2357
Epoch[48280/50000]
**Valid**: G Loss: 206.8789, D Loss: -0.0839
Epoch[48290/50000]
**Train**: G Loss: 225.8542, D Loss: 0.1711
Epoch[48290/50000]
**Valid**: G Loss: 239.4789, D Loss: 0.6131
Epoch[48300/50000]
**Train**: G Loss: 227.3983, D Loss: 0.9020
Epoch[48300/50000]
**Valid**: G Loss: 212.5378, D Loss: 1.0691
Epoch[48310/50000]
**Train**: G Loss: 204.9859, D Loss: 0.1804
Epoch[48310/50000]
**Valid**: G Loss: 194.7377, D Loss: -0.1405
Epoch[48320/50000]
**Train**: G Loss: 189.0549, D Loss: 0.6592
Epoch[48320/50000]
**Valid**: G Loss: 201.1219, D Loss: -0.0225
Epoch[48330/50000]
**Train**: G Loss: 213.5721, D Loss: 0.1586
Epoch[48330/50000]
**Valid**: G Loss: 214.6928, D Loss: 1.1457
Epoch[48340/50000]
**Train**: G Loss: 197.0649, D Loss: 0.5580
Epoch[48340/50000]
**Valid**: G Loss: 189.4893, D Loss: 0.1222
Epoch[48350/50000]
**Train**: G Loss: 178.2940, D Loss: 0.2622
Epoch[48350/50000]
**Valid**: G Loss: 180.5737, D Loss: 0.5540
Epoch[48360/50000]
**Train**: G Loss: 205.8236, D Loss: 0.3090
Epoch[48360/50000]
**Valid**: G Loss: 218.5754, D Loss: 0.4116
Epoch[48370/50000]
**Train**: G Loss: 215.5769, D Loss: 0.8259
Epoch[48370/50000]
**Valid**: G Loss: 206.5377, D Loss: 1.0637
Epoch[48380/50000]
**Train**: G Loss: 191.6635, D Loss: 0.1552
Epoch[48380/50000]
**Valid**: G Loss: 183.9076, D Loss: 0.1019
Epoch[48390/50000]
**Train**: G Loss: 173.2651, D Loss: 0.6961
Epoch[48390/50000]
**Valid**: G Loss: 181.0910, D Loss: 0.4989
Epoch[48400/50000]
**Train**: G Loss: 215.4662, D Loss: -0.0224
Epoch[48400/50000]
**Valid**: G Loss: 228.4667, D Loss: 0.2700
Epoch[48410/50000]
**Train**: G Loss: 209.2618, D Loss: 0.5347
Epoch[48410/50000]
**Valid**: G Loss: 201.4155, D Loss: 1.3062
Epoch[48420/50000]
**Train**: G Loss: 174.0912, D Loss: 0.3240
Epoch[48420/50000]
**Valid**: G Loss: 161.6040, D Loss: -0.2581
Epoch[48430/50000]
**Train**: G Loss: 159.5203, D Loss: 0.5843
Epoch[48430/50000]
**Valid**: G Loss: 161.3509, D Loss: 1.0734
Epoch[48440/50000]
**Train**: G Loss: 192.5591, D Loss: 0.3268
Epoch[48440/50000]
**Valid**: G Loss: 207.7050, D Loss: 0.1457
Epoch[48450/50000]
**Train**: G Loss: 203.2326, D Loss: 0.6599
Epoch[48450/50000]
**Valid**: G Loss: 195.9169, D Loss: 0.8024
Epoch[48460/50000]
**Train**: G Loss: 182.1280, D Loss: -0.1856
Epoch[48460/50000]
**Valid**: G Loss: 174.5321, D Loss: 0.0933
Epoch[48470/50000]
**Train**: G Loss: 175.1721, D Loss: 0.8250
Epoch[48470/50000]
**Valid**: G Loss: 180.8174, D Loss: 0.6697
Epoch[48480/50000]
**Train**: G Loss: 198.0884, D Loss: -0.0075
Epoch[48480/50000]
**Valid**: G Loss: 203.1684, D Loss: 0.7668
Epoch[48490/50000]
**Train**: G Loss: 202.3323, D Loss: 0.9107
Epoch[48490/50000]
**Valid**: G Loss: 193.5855, D Loss: 0.2911
Epoch[48500/50000]
**Train**: G Loss: 179.7488, D Loss: 0.2471
Epoch[48500/50000]
**Valid**: G Loss: 174.3403, D Loss: 0.2044
Epoch[48510/50000]
**Train**: G Loss: 185.5029, D Loss: 0.4917
Epoch[48510/50000]
**Valid**: G Loss: 185.0551, D Loss: 0.6788
Epoch[48520/50000]
**Train**: G Loss: 186.7137, D Loss: 0.6401
Epoch[48520/50000]
**Valid**: G Loss: 199.2173, D Loss: -0.0706
Epoch[48530/50000]
**Train**: G Loss: 208.5572, D Loss: 0.2051
Epoch[48530/50000]
**Valid**: G Loss: 214.4459, D Loss: 0.4770
Epoch[48540/50000]
**Train**: G Loss: 202.3354, D Loss: 0.9964
Epoch[48540/50000]
**Valid**: G Loss: 192.5045, D Loss: 0.6570
Epoch[48550/50000]
**Train**: G Loss: 177.7737, D Loss: 0.0274
Epoch[48550/50000]
**Valid**: G Loss: 173.9540, D Loss: 0.8780
Epoch[48560/50000]
**Train**: G Loss: 183.5361, D Loss: 0.9157
Epoch[48560/50000]
**Valid**: G Loss: 191.8724, D Loss: 0.3113
Epoch[48570/50000]
**Train**: G Loss: 204.6632, D Loss: 0.2371
Epoch[48570/50000]
**Valid**: G Loss: 213.3923, D Loss: 0.2289
Epoch[48580/50000]
**Train**: G Loss: 214.0563, D Loss: 0.6882
Epoch[48580/50000]
**Valid**: G Loss: 204.8422, D Loss: 0.8716
Epoch[48590/50000]
**Train**: G Loss: 190.7996, D Loss: -0.3173
Epoch[48590/50000]
**Valid**: G Loss: 186.7721, D Loss: 0.1538
Epoch[48600/50000]
**Train**: G Loss: 189.5481, D Loss: 0.6693
Epoch[48600/50000]
**Valid**: G Loss: 190.9712, D Loss: 0.8912
Epoch[48610/50000]
**Train**: G Loss: 198.0468, D Loss: 0.5691
Epoch[48610/50000]
**Valid**: G Loss: 208.8452, D Loss: -0.1985
Epoch[48620/50000]
**Train**: G Loss: 220.7346, D Loss: 0.6446
Epoch[48620/50000]
**Valid**: G Loss: 210.8487, D Loss: 1.0504
Epoch[48630/50000]
**Train**: G Loss: 186.2990, D Loss: 0.1610
Epoch[48630/50000]
**Valid**: G Loss: 180.6448, D Loss: 0.5585
Epoch[48640/50000]
**Train**: G Loss: 184.0856, D Loss: 0.7901
Epoch[48640/50000]
**Valid**: G Loss: 193.7550, D Loss: 0.3201
Epoch[48650/50000]
**Train**: G Loss: 227.0038, D Loss: 0.1092
Epoch[48650/50000]
**Valid**: G Loss: 225.4031, D Loss: 0.9609
Epoch[48660/50000]
**Train**: G Loss: 196.0028, D Loss: 0.8678
Epoch[48660/50000]
**Valid**: G Loss: 178.0671, D Loss: 0.1174
Epoch[48670/50000]
**Train**: G Loss: 163.9691, D Loss: -0.0401
Epoch[48670/50000]
**Valid**: G Loss: 157.1104, D Loss: 0.6717
Epoch[48680/50000]
**Train**: G Loss: 178.6405, D Loss: 0.6527
Epoch[48680/50000]
**Valid**: G Loss: 186.1915, D Loss: 0.2974
Epoch[48690/50000]
**Train**: G Loss: 212.9656, D Loss: 0.0949
Epoch[48690/50000]
**Valid**: G Loss: 220.1589, D Loss: 0.5901
Epoch[48700/50000]
**Train**: G Loss: 197.9574, D Loss: 0.4869
Epoch[48700/50000]
**Valid**: G Loss: 186.9758, D Loss: -0.3209
Epoch[48710/50000]
**Train**: G Loss: 179.1401, D Loss: 0.5688
Epoch[48710/50000]
**Valid**: G Loss: 178.9935, D Loss: 1.1498
Epoch[48720/50000]
**Train**: G Loss: 192.7704, D Loss: 0.2090
Epoch[48720/50000]
**Valid**: G Loss: 203.1927, D Loss: 0.0318
Epoch[48730/50000]
**Train**: G Loss: 204.8830, D Loss: 0.2225
Epoch[48730/50000]
**Valid**: G Loss: 208.1008, D Loss: 0.8342
Epoch[48740/50000]
**Train**: G Loss: 197.3037, D Loss: 0.7779
Epoch[48740/50000]
**Valid**: G Loss: 189.8390, D Loss: 0.5449
Epoch[48750/50000]
**Train**: G Loss: 188.5025, D Loss: 0.2484
Epoch[48750/50000]
**Valid**: G Loss: 182.3328, D Loss: -0.4119
Epoch[48760/50000]
**Train**: G Loss: 175.6299, D Loss: 0.2056
Epoch[48760/50000]
**Valid**: G Loss: 173.7186, D Loss: 0.9032
Epoch[48770/50000]
**Train**: G Loss: 180.2812, D Loss: 0.7460
Epoch[48770/50000]
**Valid**: G Loss: 187.5172, D Loss: 0.3504
Epoch[48780/50000]
**Train**: G Loss: 207.7767, D Loss: 0.3303
Epoch[48780/50000]
**Valid**: G Loss: 207.6089, D Loss: 1.0258
Epoch[48790/50000]
**Train**: G Loss: 194.9169, D Loss: 0.1837
Epoch[48790/50000]
**Valid**: G Loss: 188.1792, D Loss: -0.1797
Epoch[48800/50000]
**Train**: G Loss: 178.9686, D Loss: 0.7106
Epoch[48800/50000]
**Valid**: G Loss: 180.1234, D Loss: 0.8422
Epoch[48810/50000]
**Train**: G Loss: 199.6531, D Loss: 0.3747
Epoch[48810/50000]
**Valid**: G Loss: 204.5301, D Loss: 0.7483
Epoch[48820/50000]
**Train**: G Loss: 200.0446, D Loss: 0.7236
Epoch[48820/50000]
**Valid**: G Loss: 191.0473, D Loss: 0.3982
Epoch[48830/50000]
**Train**: G Loss: 176.5520, D Loss: 0.0342
Epoch[48830/50000]
**Valid**: G Loss: 169.3072, D Loss: 0.2585
Epoch[48840/50000]
**Train**: G Loss: 161.6835, D Loss: 0.8404
Epoch[48840/50000]
**Valid**: G Loss: 166.9782, D Loss: 0.9254
Epoch[48850/50000]
**Train**: G Loss: 199.5467, D Loss: -0.0931
Epoch[48850/50000]
**Valid**: G Loss: 202.6215, D Loss: 0.6696
Epoch[48860/50000]
**Train**: G Loss: 194.4602, D Loss: 0.6370
Epoch[48860/50000]
**Valid**: G Loss: 188.2196, D Loss: 0.0766
Epoch[48870/50000]
**Train**: G Loss: 179.7840, D Loss: 0.2944
Epoch[48870/50000]
**Valid**: G Loss: 178.3087, D Loss: 0.8780
Epoch[48880/50000]
**Train**: G Loss: 189.4319, D Loss: 0.5137
Epoch[48880/50000]
**Valid**: G Loss: 199.7279, D Loss: 0.3189
Epoch[48890/50000]
**Train**: G Loss: 206.5975, D Loss: 0.3078
Epoch[48890/50000]
**Valid**: G Loss: 199.7756, D Loss: 0.9681
Epoch[48900/50000]
**Train**: G Loss: 186.2128, D Loss: 0.4652
Epoch[48900/50000]
**Valid**: G Loss: 177.2224, D Loss: -0.1110
Epoch[48910/50000]
**Train**: G Loss: 173.7490, D Loss: 0.3990
Epoch[48910/50000]
**Valid**: G Loss: 176.8651, D Loss: 1.0621
Epoch[48920/50000]
**Train**: G Loss: 221.5073, D Loss: 0.1443
Epoch[48920/50000]
**Valid**: G Loss: 230.2465, D Loss: 0.6169
Epoch[48930/50000]
**Train**: G Loss: 215.2034, D Loss: 0.9320
Epoch[48930/50000]
**Valid**: G Loss: 206.5441, D Loss: 0.7405
Epoch[48940/50000]
**Train**: G Loss: 170.9569, D Loss: -0.0126
Epoch[48940/50000]
**Valid**: G Loss: 160.1039, D Loss: -0.0318
Epoch[48950/50000]
**Train**: G Loss: 157.8216, D Loss: 0.8641
Epoch[48950/50000]
**Valid**: G Loss: 166.1027, D Loss: 0.8068
Epoch[48960/50000]
**Train**: G Loss: 182.3693, D Loss: 0.4026
Epoch[48960/50000]
**Valid**: G Loss: 193.7367, D Loss: 0.0540
Epoch[48970/50000]
**Train**: G Loss: 188.5845, D Loss: 0.5706
Epoch[48970/50000]
**Valid**: G Loss: 189.0355, D Loss: 0.8002
Epoch[48980/50000]
**Train**: G Loss: 189.9136, D Loss: 0.0999
Epoch[48980/50000]
**Valid**: G Loss: 181.6458, D Loss: -0.0031
Epoch[48990/50000]
**Train**: G Loss: 192.2194, D Loss: 0.5290
Epoch[48990/50000]
**Valid**: G Loss: 195.5090, D Loss: 0.4776
Epoch[49000/50000]
**Train**: G Loss: 215.5488, D Loss: 0.6304
Epoch[49000/50000]
**Valid**: G Loss: 209.9626, D Loss: 0.7918
Epoch[49010/50000]
**Train**: G Loss: 174.9100, D Loss: -0.2180
Epoch[49010/50000]
**Valid**: G Loss: 164.7666, D Loss: 0.0673
Epoch[49020/50000]
**Train**: G Loss: 166.0305, D Loss: 0.7647
Epoch[49020/50000]
**Valid**: G Loss: 174.6355, D Loss: 0.6499
Epoch[49030/50000]
**Train**: G Loss: 186.2671, D Loss: 0.0574
Epoch[49030/50000]
**Valid**: G Loss: 191.9140, D Loss: 0.5067
Epoch[49040/50000]
**Train**: G Loss: 184.6608, D Loss: 0.7034
Epoch[49040/50000]
**Valid**: G Loss: 176.4976, D Loss: -0.1272
Epoch[49050/50000]
**Train**: G Loss: 180.1431, D Loss: 0.2793
Epoch[49050/50000]
**Valid**: G Loss: 177.1636, D Loss: 1.1133
Epoch[49060/50000]
**Train**: G Loss: 183.9126, D Loss: 0.4496
Epoch[49060/50000]
**Valid**: G Loss: 193.9115, D Loss: 0.1662
Epoch[49070/50000]
**Train**: G Loss: 200.4307, D Loss: 0.2931
Epoch[49070/50000]
**Valid**: G Loss: 205.8266, D Loss: 0.6764
Epoch[49080/50000]
**Train**: G Loss: 196.9511, D Loss: 0.7088
Epoch[49080/50000]
**Valid**: G Loss: 190.0298, D Loss: 0.5333
Epoch[49090/50000]
**Train**: G Loss: 173.6492, D Loss: -0.0815
Epoch[49090/50000]
**Valid**: G Loss: 169.2101, D Loss: 0.3670
Epoch[49100/50000]
**Train**: G Loss: 174.9538, D Loss: 0.6721
Epoch[49100/50000]
**Valid**: G Loss: 176.8048, D Loss: 0.7666
Epoch[49110/50000]
**Train**: G Loss: 183.7845, D Loss: 0.3932
Epoch[49110/50000]
**Valid**: G Loss: 192.9105, D Loss: -0.2023
Epoch[49120/50000]
**Train**: G Loss: 195.2048, D Loss: 0.5799
Epoch[49120/50000]
**Valid**: G Loss: 192.1160, D Loss: 0.8022
Epoch[49130/50000]
**Train**: G Loss: 184.5370, D Loss: 0.6330
Epoch[49130/50000]
**Valid**: G Loss: 179.0854, D Loss: -0.0979
Epoch[49140/50000]
**Train**: G Loss: 184.4852, D Loss: 0.3458
Epoch[49140/50000]
**Valid**: G Loss: 183.5368, D Loss: 0.7322
Epoch[49150/50000]
**Train**: G Loss: 186.8796, D Loss: 0.4543
Epoch[49150/50000]
**Valid**: G Loss: 196.1680, D Loss: -0.1150
Epoch[49160/50000]
**Train**: G Loss: 209.9086, D Loss: 0.5341
Epoch[49160/50000]
**Valid**: G Loss: 205.3784, D Loss: 1.1454
Epoch[49170/50000]
**Train**: G Loss: 184.1091, D Loss: 0.0398
Epoch[49170/50000]
**Valid**: G Loss: 179.2739, D Loss: 0.3219
Epoch[49180/50000]
**Train**: G Loss: 186.5231, D Loss: 0.6083
Epoch[49180/50000]
**Valid**: G Loss: 194.5678, D Loss: 0.1947
Epoch[49190/50000]
**Train**: G Loss: 204.0530, D Loss: 0.1805
Epoch[49190/50000]
**Valid**: G Loss: 203.2947, D Loss: 0.8751
Epoch[49200/50000]
**Train**: G Loss: 186.1500, D Loss: 0.3006
Epoch[49200/50000]
**Valid**: G Loss: 177.7235, D Loss: 0.0821
Epoch[49210/50000]
**Train**: G Loss: 180.1046, D Loss: 0.6178
Epoch[49210/50000]
**Valid**: G Loss: 190.7188, D Loss: 0.0487
Epoch[49220/50000]
**Train**: G Loss: 209.4174, D Loss: 0.4864
Epoch[49220/50000]
**Valid**: G Loss: 203.2799, D Loss: 1.1666
Epoch[49230/50000]
**Train**: G Loss: 185.9325, D Loss: 0.4609
Epoch[49230/50000]
**Valid**: G Loss: 175.0911, D Loss: 0.1449
Epoch[49240/50000]
**Train**: G Loss: 165.3926, D Loss: 0.7041
Epoch[49240/50000]
**Valid**: G Loss: 168.3060, D Loss: 1.0245
Epoch[49250/50000]
**Train**: G Loss: 193.7150, D Loss: -0.1317
Epoch[49250/50000]
**Valid**: G Loss: 200.4934, D Loss: 0.2093
Epoch[49260/50000]
**Train**: G Loss: 183.0578, D Loss: 0.7951
Epoch[49260/50000]
**Valid**: G Loss: 177.5525, D Loss: 0.5769
Epoch[49270/50000]
**Train**: G Loss: 170.1400, D Loss: 0.0336
Epoch[49270/50000]
**Valid**: G Loss: 164.1411, D Loss: 0.6283
Epoch[49280/50000]
**Train**: G Loss: 173.3814, D Loss: 0.8106
Epoch[49280/50000]
**Valid**: G Loss: 182.8219, D Loss: 0.1448
Epoch[49290/50000]
**Train**: G Loss: 195.8305, D Loss: 0.3056
Epoch[49290/50000]
**Valid**: G Loss: 193.6572, D Loss: 0.9624
Epoch[49300/50000]
**Train**: G Loss: 188.2973, D Loss: 0.1532
Epoch[49300/50000]
**Valid**: G Loss: 182.6620, D Loss: -0.0132
Epoch[49310/50000]
**Train**: G Loss: 176.6646, D Loss: 0.7031
Epoch[49310/50000]
**Valid**: G Loss: 177.5750, D Loss: 0.9087
Epoch[49320/50000]
**Train**: G Loss: 188.2041, D Loss: 0.7517
Epoch[49320/50000]
**Valid**: G Loss: 194.4050, D Loss: 0.0367
Epoch[49330/50000]
**Train**: G Loss: 211.1032, D Loss: 0.1489
Epoch[49330/50000]
**Valid**: G Loss: 205.0860, D Loss: 0.9404
Epoch[49340/50000]
**Train**: G Loss: 187.1153, D Loss: 0.0854
Epoch[49340/50000]
**Valid**: G Loss: 182.1187, D Loss: 0.2019
Epoch[49350/50000]
**Train**: G Loss: 185.0418, D Loss: 0.8149
Epoch[49350/50000]
**Valid**: G Loss: 191.3464, D Loss: 0.5880
Epoch[49360/50000]
**Train**: G Loss: 211.9192, D Loss: 0.2285
Epoch[49360/50000]
**Valid**: G Loss: 210.3445, D Loss: 0.7996
Epoch[49370/50000]
**Train**: G Loss: 202.7783, D Loss: 0.7425
Epoch[49370/50000]
**Valid**: G Loss: 194.8571, D Loss: -0.2593
Epoch[49380/50000]
**Train**: G Loss: 179.2474, D Loss: 0.1705
Epoch[49380/50000]
**Valid**: G Loss: 173.9103, D Loss: 0.6352
Epoch[49390/50000]
**Train**: G Loss: 166.6435, D Loss: 0.6939
Epoch[49390/50000]
**Valid**: G Loss: 171.2621, D Loss: 0.5884
Epoch[49400/50000]
**Train**: G Loss: 200.6008, D Loss: 0.6896
Epoch[49400/50000]
**Valid**: G Loss: 192.7574, D Loss: 1.3714
Epoch[49410/50000]
**Train**: G Loss: 179.9081, D Loss: 0.0676
Epoch[49410/50000]
**Valid**: G Loss: 172.2937, D Loss: 0.1021
Epoch[49420/50000]
**Train**: G Loss: 158.1003, D Loss: 0.3672
Epoch[49420/50000]
**Valid**: G Loss: 156.2246, D Loss: 0.9095
Epoch[49430/50000]
**Train**: G Loss: 169.8398, D Loss: 0.5221
Epoch[49430/50000]
**Valid**: G Loss: 181.6256, D Loss: 0.0880
Epoch[49440/50000]
**Train**: G Loss: 190.4952, D Loss: 0.2769
Epoch[49440/50000]
**Valid**: G Loss: 190.9340, D Loss: 0.8448
Epoch[49450/50000]
**Train**: G Loss: 172.1969, D Loss: 0.1272
Epoch[49450/50000]
**Valid**: G Loss: 165.9608, D Loss: -0.2201
Epoch[49460/50000]
**Train**: G Loss: 172.7857, D Loss: 0.5074
Epoch[49460/50000]
**Valid**: G Loss: 170.1363, D Loss: 0.9909
Epoch[49470/50000]
**Train**: G Loss: 179.9416, D Loss: 0.5044
Epoch[49470/50000]
**Valid**: G Loss: 184.1805, D Loss: 0.2095
Epoch[49480/50000]
**Train**: G Loss: 190.9778, D Loss: 0.2761
Epoch[49480/50000]
**Valid**: G Loss: 195.0879, D Loss: 0.7007
Epoch[49490/50000]
**Train**: G Loss: 197.9730, D Loss: 0.6838
Epoch[49490/50000]
**Valid**: G Loss: 196.6736, D Loss: 0.0938
Epoch[49500/50000]
**Train**: G Loss: 175.3743, D Loss: -0.0457
Epoch[49500/50000]
**Valid**: G Loss: 170.7744, D Loss: 0.5983
Epoch[49510/50000]
**Train**: G Loss: 185.8722, D Loss: 0.6769
Epoch[49510/50000]
**Valid**: G Loss: 197.0823, D Loss: 0.1785
Epoch[49520/50000]
**Train**: G Loss: 209.4821, D Loss: 0.8009
Epoch[49520/50000]
**Valid**: G Loss: 205.7789, D Loss: 0.8426
Epoch[49530/50000]
**Train**: G Loss: 193.7380, D Loss: 0.0108
Epoch[49530/50000]
**Valid**: G Loss: 188.2339, D Loss: -0.0211
Epoch[49540/50000]
**Train**: G Loss: 195.7317, D Loss: 0.7206
Epoch[49540/50000]
**Valid**: G Loss: 198.0622, D Loss: 0.6751
Epoch[49550/50000]
**Train**: G Loss: 206.5996, D Loss: 0.2091
Epoch[49550/50000]
**Valid**: G Loss: 212.1017, D Loss: 0.3537
Epoch[49560/50000]
**Train**: G Loss: 216.0217, D Loss: 0.9421
Epoch[49560/50000]
**Valid**: G Loss: 209.2363, D Loss: 0.1750
Epoch[49570/50000]
**Train**: G Loss: 198.7595, D Loss: -0.0858
Epoch[49570/50000]
**Valid**: G Loss: 194.7272, D Loss: 0.4078
Epoch[49580/50000]
**Train**: G Loss: 191.3508, D Loss: 0.7316
Epoch[49580/50000]
**Valid**: G Loss: 194.9037, D Loss: 0.5693
Epoch[49590/50000]
**Train**: G Loss: 214.3610, D Loss: 0.1255
Epoch[49590/50000]
**Valid**: G Loss: 221.0788, D Loss: 0.4450
Epoch[49600/50000]
**Train**: G Loss: 223.0001, D Loss: 0.6833
Epoch[49600/50000]
**Valid**: G Loss: 213.0642, D Loss: 0.1784
Epoch[49610/50000]
**Train**: G Loss: 186.0468, D Loss: 0.3345
Epoch[49610/50000]
**Valid**: G Loss: 186.2496, D Loss: 0.9642
Epoch[49620/50000]
**Train**: G Loss: 207.8173, D Loss: 0.5898
Epoch[49620/50000]
**Valid**: G Loss: 218.2682, D Loss: 0.1932
Epoch[49630/50000]
**Train**: G Loss: 234.6815, D Loss: 0.5776
Epoch[49630/50000]
**Valid**: G Loss: 223.8233, D Loss: 0.7702
Epoch[49640/50000]
**Train**: G Loss: 204.8340, D Loss: 0.2198
Epoch[49640/50000]
**Valid**: G Loss: 197.3229, D Loss: -0.0785
Epoch[49650/50000]
**Train**: G Loss: 195.5220, D Loss: 0.4984
Epoch[49650/50000]
**Valid**: G Loss: 194.1574, D Loss: 0.9018
Epoch[49660/50000]
**Train**: G Loss: 218.4359, D Loss: 0.1772
Epoch[49660/50000]
**Valid**: G Loss: 221.1682, D Loss: 0.6420
Epoch[49670/50000]
**Train**: G Loss: 203.7256, D Loss: 0.1454
Epoch[49670/50000]
**Valid**: G Loss: 197.9005, D Loss: -0.1006
Epoch[49680/50000]
**Train**: G Loss: 206.0290, D Loss: 0.3927
Epoch[49680/50000]
**Valid**: G Loss: 213.8302, D Loss: 0.0215
Epoch[49690/50000]
**Train**: G Loss: 221.8246, D Loss: 0.6784
Epoch[49690/50000]
**Valid**: G Loss: 216.7626, D Loss: 0.7564
Epoch[49700/50000]
**Train**: G Loss: 200.0635, D Loss: 0.0898
Epoch[49700/50000]
**Valid**: G Loss: 199.0982, D Loss: 1.0726
Epoch[49710/50000]
**Train**: G Loss: 203.2153, D Loss: 0.1269
Epoch[49710/50000]
**Valid**: G Loss: 213.1458, D Loss: 0.0996
Epoch[49720/50000]
**Train**: G Loss: 213.8415, D Loss: 0.8582
Epoch[49720/50000]
**Valid**: G Loss: 208.3206, D Loss: 0.6685
Epoch[49730/50000]
**Train**: G Loss: 193.8356, D Loss: 0.2213
Epoch[49730/50000]
**Valid**: G Loss: 187.7359, D Loss: -0.1751
Epoch[49740/50000]
**Train**: G Loss: 188.0247, D Loss: 0.6577
Epoch[49740/50000]
**Valid**: G Loss: 191.1841, D Loss: 0.5237
Epoch[49750/50000]
**Train**: G Loss: 215.2065, D Loss: 0.0902
Epoch[49750/50000]
**Valid**: G Loss: 221.0279, D Loss: 0.5063
Epoch[49760/50000]
**Train**: G Loss: 203.6104, D Loss: 0.5825
Epoch[49760/50000]
**Valid**: G Loss: 194.8998, D Loss: -0.1123
Epoch[49770/50000]
**Train**: G Loss: 193.7605, D Loss: 0.1226
Epoch[49770/50000]
**Valid**: G Loss: 189.0870, D Loss: 0.4284
Epoch[49780/50000]
**Train**: G Loss: 187.9678, D Loss: 0.4302
Epoch[49780/50000]
**Valid**: G Loss: 187.6826, D Loss: 0.6339
Epoch[49790/50000]
**Train**: G Loss: 193.8139, D Loss: 0.3897
Epoch[49790/50000]
**Valid**: G Loss: 198.6280, D Loss: 0.3863
Epoch[49800/50000]
**Train**: G Loss: 202.8544, D Loss: 0.4402
Epoch[49800/50000]
**Valid**: G Loss: 203.7917, D Loss: 0.9212
Epoch[49810/50000]
**Train**: G Loss: 209.1602, D Loss: 0.8925
Epoch[49810/50000]
**Valid**: G Loss: 203.2721, D Loss: 0.4691
Epoch[49820/50000]
**Train**: G Loss: 189.0459, D Loss: -0.0274
Epoch[49820/50000]
**Valid**: G Loss: 178.7965, D Loss: -0.0410
Epoch[49830/50000]
**Train**: G Loss: 191.4000, D Loss: 0.3339
Epoch[49830/50000]
**Valid**: G Loss: 192.2021, D Loss: 0.9454
Epoch[49840/50000]
**Train**: G Loss: 202.4546, D Loss: -0.0390
Epoch[49840/50000]
**Valid**: G Loss: 213.3429, D Loss: 0.3168
Epoch[49850/50000]
**Train**: G Loss: 212.0141, D Loss: 0.6194
Epoch[49850/50000]
**Valid**: G Loss: 208.2538, D Loss: 0.8871
Epoch[49860/50000]
**Train**: G Loss: 197.4223, D Loss: 0.6679
Epoch[49860/50000]
**Valid**: G Loss: 191.4544, D Loss: 0.0331
Epoch[49870/50000]
**Train**: G Loss: 192.2001, D Loss: 0.1879
Epoch[49870/50000]
**Valid**: G Loss: 185.9120, D Loss: 0.0483
Epoch[49880/50000]
**Train**: G Loss: 179.1250, D Loss: 0.1843
Epoch[49880/50000]
**Valid**: G Loss: 177.4777, D Loss: 0.8924
Epoch[49890/50000]
**Train**: G Loss: 185.0502, D Loss: 0.6175
Epoch[49890/50000]
**Valid**: G Loss: 192.8901, D Loss: 0.1173
Epoch[49900/50000]
**Train**: G Loss: 187.6476, D Loss: 0.4839
Epoch[49900/50000]
**Valid**: G Loss: 194.5073, D Loss: 0.2305
Epoch[49910/50000]
**Train**: G Loss: 199.9328, D Loss: 0.2115
Epoch[49910/50000]
**Valid**: G Loss: 206.1772, D Loss: 0.5943
Epoch[49920/50000]
**Train**: G Loss: 193.8517, D Loss: 0.6741
Epoch[49920/50000]
**Valid**: G Loss: 189.2116, D Loss: 0.7592
Epoch[49930/50000]
**Train**: G Loss: 190.1370, D Loss: 0.2464
Epoch[49930/50000]
**Valid**: G Loss: 182.7268, D Loss: -0.1620
Epoch[49940/50000]
**Train**: G Loss: 175.8909, D Loss: 0.1521
Epoch[49940/50000]
**Valid**: G Loss: 171.1056, D Loss: 0.4795
Epoch[49950/50000]
**Train**: G Loss: 177.5036, D Loss: 0.7537
Epoch[49950/50000]
**Valid**: G Loss: 181.8185, D Loss: 0.9807
Epoch[49960/50000]
**Train**: G Loss: 194.8501, D Loss: 0.1568
Epoch[49960/50000]
**Valid**: G Loss: 206.9385, D Loss: -0.0891
Epoch[49970/50000]
**Train**: G Loss: 204.7066, D Loss: 0.7739
Epoch[49970/50000]
**Valid**: G Loss: 199.4476, D Loss: 1.1089
Epoch[49980/50000]
**Train**: G Loss: 196.2908, D Loss: 0.2987
Epoch[49980/50000]
**Valid**: G Loss: 190.0879, D Loss: 0.2569
Epoch[49990/50000]
**Train**: G Loss: 177.0773, D Loss: 0.2518
Epoch[49990/50000]
**Valid**: G Loss: 175.0043, D Loss: 1.0718
Epoch[50000/50000]
**Train**: G Loss: 185.1597, D Loss: 0.4434
Epoch[50000/50000]
**Valid**: G Loss: 188.7756, D Loss: 0.2512

=============best model=============
**Train**: G Loss: 188.7671, D Loss: 0.2904
**Valid**: G Loss: 188.7515, D Loss: 0.2742
**Test**: G Loss: 188.7547, D Loss: 0.3295
